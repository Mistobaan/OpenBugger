{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import inspect\n",
    "\n",
    "import types\n",
    "import ast\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocstringExtractor:\n",
    "    def __init__(self, module_name):\n",
    "        self.module_name = module_name\n",
    "        self.module = importlib.import_module(module_name)\n",
    "\n",
    "    \n",
    "    def remove_docstrings(self, source):\n",
    "        \"\"\"\n",
    "        Removes the docstrings from the source code\n",
    "        \"\"\"\n",
    "        pattern = r'^(\\s*([\\'\\\"]{3}|#{1,3}))[\\s\\S]*?\\2'\n",
    "        stripped = re.sub(pattern,'', source, flags=re.M)\n",
    "        stripped_lines = [l.rstrip() for l in stripped.split(\"\\n\") if l.strip()!=\"\"]\n",
    "        return \"\\n\".join(stripped_lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def extract_docstrings(self):\n",
    "        docstrings = {}\n",
    "        for name, obj in self.module.__dict__.items():\n",
    "            if inspect.isclass(obj):\n",
    "                for m_name, method in inspect.getmembers(obj, inspect.isfunction):\n",
    "                    if method.__doc__:\n",
    "                        if hasattr(method, '__module__'):\n",
    "                            try:\n",
    "                                raw_source = inspect.getsource(method)\n",
    "                                code = self.remove_docstrings(raw_source)\n",
    "                            except TypeError:\n",
    "                                raw_source = \"\"\n",
    "                                code = \"\"\n",
    "                            docstrings[f'{name}.{m_name}'] = (raw_source, code, method.__doc__)\n",
    "            elif callable(obj) and obj.__doc__:\n",
    "                if hasattr(obj, '__module__'):\n",
    "                    try:\n",
    "                        raw_source = inspect.getsource(obj)\n",
    "                        code = self.remove_docstrings(raw_source)\n",
    "                    except TypeError:\n",
    "                        raw_source = \"\"\n",
    "                        code = \"\"\n",
    "                    docstrings[name] = (raw_source, code, obj.__doc__)\n",
    "        return docstrings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code: show_config\n",
      "def show():\n",
      "    from numpy.core._multiarray_umath import (\n",
      "        __cpu_features__, __cpu_baseline__, __cpu_dispatch__\n",
      "    )\n",
      "    for name,info_dict in globals().items():\n",
      "        if name[0] == \"_\" or type(info_dict) is not type({}): continue\n",
      "        print(name + \":\")\n",
      "        if not info_dict:\n",
      "            print(\"  NOT AVAILABLE\")\n",
      "        for k,v in info_dict.items():\n",
      "            v = str(v)\n",
      "            if k == \"sources\" and len(v) > 200:\n",
      "                v = v[:60] + \" ...\\n... \" + v[-60:]\n",
      "            print(\"    %s = %s\" % (k,v))\n",
      "    features_found, features_not_found = [], []\n",
      "    for feature in __cpu_dispatch__:\n",
      "        if __cpu_features__[feature]:\n",
      "            features_found.append(feature)\n",
      "        else:\n",
      "            features_not_found.append(feature)\n",
      "    print(\"Supported SIMD extensions in this NumPy install:\")\n",
      "    print(\"    baseline = %s\" % (','.join(__cpu_baseline__)))\n",
      "    print(\"    found = %s\" % (','.join(features_found)))\n",
      "    print(\"    not found = %s\" % (','.join(features_not_found)))\n",
      "docstring: show_config\n",
      "\n",
      "    Show libraries in the system on which NumPy was built.\n",
      "\n",
      "    Print information about various resources (libraries, library\n",
      "    directories, include directories, etc.) in the system on which\n",
      "    NumPy was built.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    get_include : Returns the directory containing NumPy C\n",
      "                  header files.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    1. Classes specifying the information to be printed are defined\n",
      "       in the `numpy.distutils.system_info` module.\n",
      "\n",
      "       Information may include:\n",
      "\n",
      "       * ``language``: language used to write the libraries (mostly\n",
      "         C or f77)\n",
      "       * ``libraries``: names of libraries found in the system\n",
      "       * ``library_dirs``: directories containing the libraries\n",
      "       * ``include_dirs``: directories containing library header files\n",
      "       * ``src_dirs``: directories containing library source files\n",
      "       * ``define_macros``: preprocessor macros used by\n",
      "         ``distutils.setup``\n",
      "       * ``baseline``: minimum CPU features required\n",
      "       * ``found``: dispatched features supported in the system\n",
      "       * ``not found``: dispatched features that are not supported\n",
      "         in the system\n",
      "\n",
      "    2. NumPy BLAS/LAPACK Installation Notes\n",
      "\n",
      "       Installing a numpy wheel (``pip install numpy`` or force it\n",
      "       via ``pip install numpy --only-binary :numpy: numpy``) includes\n",
      "       an OpenBLAS implementation of the BLAS and LAPACK linear algebra\n",
      "       APIs. In this case, ``library_dirs`` reports the original build\n",
      "       time configuration as compiled with gcc/gfortran; at run time\n",
      "       the OpenBLAS library is in\n",
      "       ``site-packages/numpy.libs/`` (linux), or\n",
      "       ``site-packages/numpy/.dylibs/`` (macOS), or\n",
      "       ``site-packages/numpy/.libs/`` (windows).\n",
      "\n",
      "       Installing numpy from source\n",
      "       (``pip install numpy --no-binary numpy``) searches for BLAS and\n",
      "       LAPACK dynamic link libraries at build time as influenced by\n",
      "       environment variables NPY_BLAS_LIBS, NPY_CBLAS_LIBS, and\n",
      "       NPY_LAPACK_LIBS; or NPY_BLAS_ORDER and NPY_LAPACK_ORDER;\n",
      "       or the optional file ``~/.numpy-site.cfg``.\n",
      "       NumPy remembers those locations and expects to load the same\n",
      "       libraries at run-time.\n",
      "       In NumPy 1.21+ on macOS, 'accelerate' (Apple's Accelerate BLAS\n",
      "       library) is in the default build-time search order after\n",
      "       'openblas'.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> np.show_config()\n",
      "    blas_opt_info:\n",
      "        language = c\n",
      "        define_macros = [('HAVE_CBLAS', None)]\n",
      "        libraries = ['openblas', 'openblas']\n",
      "        library_dirs = ['/usr/local/lib']\n",
      "    \n",
      "code: memmap.flush\n",
      "    def flush(self):\n",
      "        if self.base is not None and hasattr(self.base, 'flush'):\n",
      "            self.base.flush()\n",
      "docstring: memmap.flush\n",
      "\n",
      "        Write any changes in the array to the file on disk.\n",
      "\n",
      "        For further information, see `memmap`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        None\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        memmap\n",
      "\n",
      "        \n",
      "code: nested_iters\n",
      "\n",
      "docstring: nested_iters\n",
      "nested_iters(op, axes, flags=None, op_flags=None, op_dtypes=None,     order=\"K\", casting=\"safe\", buffersize=0)\n",
      "\n",
      "    Create nditers for use in nested loops\n",
      "\n",
      "    Create a tuple of `nditer` objects which iterate in nested loops over\n",
      "    different axes of the op argument. The first iterator is used in the\n",
      "    outermost loop, the last in the innermost loop. Advancing one will change\n",
      "    the subsequent iterators to point at its new element.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    op : ndarray or sequence of array_like\n",
      "        The array(s) to iterate over.\n",
      "\n",
      "    axes : list of list of int\n",
      "        Each item is used as an \"op_axes\" argument to an nditer\n",
      "\n",
      "    flags, op_flags, op_dtypes, order, casting, buffersize (optional)\n",
      "        See `nditer` parameters of the same name\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    iters : tuple of nditer\n",
      "        An nditer for each item in `axes`, outermost first\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    nditer\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    Basic usage. Note how y is the \"flattened\" version of\n",
      "    [a[:, 0, :], a[:, 1, 0], a[:, 2, :]] since we specified\n",
      "    the first iter's axes as [1]\n",
      "\n",
      "    >>> a = np.arange(12).reshape(2, 3, 2)\n",
      "    >>> i, j = np.nested_iters(a, [[1], [0, 2]], flags=[\"multi_index\"])\n",
      "    >>> for x in i:\n",
      "    ...      print(i.multi_index)\n",
      "    ...      for y in j:\n",
      "    ...          print('', j.multi_index, y)\n",
      "    (0,)\n",
      "     (0, 0) 0\n",
      "     (0, 1) 1\n",
      "     (1, 0) 6\n",
      "     (1, 1) 7\n",
      "    (1,)\n",
      "     (0, 0) 2\n",
      "     (0, 1) 3\n",
      "     (1, 0) 8\n",
      "     (1, 1) 9\n",
      "    (2,)\n",
      "     (0, 0) 4\n",
      "     (0, 1) 5\n",
      "     (1, 0) 10\n",
      "     (1, 1) 11\n",
      "code: arange\n",
      "\n",
      "docstring: arange\n",
      "arange([start,] stop[, step,], dtype=None, *, like=None)\n",
      "\n",
      "    Return evenly spaced values within a given interval.\n",
      "\n",
      "    ``arange`` can be called with a varying number of positional arguments:\n",
      "\n",
      "    * ``arange(stop)``: Values are generated within the half-open interval\n",
      "      ``[0, stop)`` (in other words, the interval including `start` but\n",
      "      excluding `stop`).\n",
      "    * ``arange(start, stop)``: Values are generated within the half-open\n",
      "      interval ``[start, stop)``.\n",
      "    * ``arange(start, stop, step)`` Values are generated within the half-open\n",
      "      interval ``[start, stop)``, with spacing between values given by\n",
      "      ``step``.\n",
      "\n",
      "    For integer arguments the function is roughly equivalent to the Python\n",
      "    built-in :py:class:`range`, but returns an ndarray rather than a ``range``\n",
      "    instance.\n",
      "\n",
      "    When using a non-integer step, such as 0.1, it is often better to use\n",
      "    `numpy.linspace`.\n",
      "\n",
      "    See the Warning sections below for more information.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    start : integer or real, optional\n",
      "        Start of interval.  The interval includes this value.  The default\n",
      "        start value is 0.\n",
      "    stop : integer or real\n",
      "        End of interval.  The interval does not include this value, except\n",
      "        in some cases where `step` is not an integer and floating point\n",
      "        round-off affects the length of `out`.\n",
      "    step : integer or real, optional\n",
      "        Spacing between values.  For any output `out`, this is the distance\n",
      "        between two adjacent values, ``out[i+1] - out[i]``.  The default\n",
      "        step size is 1.  If `step` is specified as a position argument,\n",
      "        `start` must also be given.\n",
      "    dtype : dtype, optional\n",
      "        The type of the output array.  If `dtype` is not given, infer the data\n",
      "        type from the other input arguments.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    arange : ndarray\n",
      "        Array of evenly spaced values.\n",
      "\n",
      "        For floating point arguments, the length of the result is\n",
      "        ``ceil((stop - start)/step)``.  Because of floating point overflow,\n",
      "        this rule may result in the last element of `out` being greater\n",
      "        than `stop`.\n",
      "\n",
      "    Warnings\n",
      "    --------\n",
      "    The length of the output might not be numerically stable.\n",
      "\n",
      "    Another stability issue is due to the internal implementation of\n",
      "    `numpy.arange`.\n",
      "    The actual step value used to populate the array is\n",
      "    ``dtype(start + step) - dtype(start)`` and not `step`. Precision loss\n",
      "    can occur here, due to casting or due to using floating points when\n",
      "    `start` is much larger than `step`. This can lead to unexpected\n",
      "    behaviour. For example::\n",
      "\n",
      "      >>> np.arange(0, 5, 0.5, dtype=int)\n",
      "      array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "      >>> np.arange(-3, 3, 0.5, dtype=int)\n",
      "      array([-3, -2, -1,  0,  1,  2,  3,  4,  5,  6,  7,  8])\n",
      "\n",
      "    In such cases, the use of `numpy.linspace` should be preferred.\n",
      "\n",
      "    The built-in :py:class:`range` generates :std:doc:`Python built-in integers\n",
      "    that have arbitrary size <python:c-api/long>`, while `numpy.arange`\n",
      "    produces `numpy.int32` or `numpy.int64` numbers. This may result in\n",
      "    incorrect results for large integer values::\n",
      "\n",
      "      >>> power = 40\n",
      "      >>> modulo = 10000\n",
      "      >>> x1 = [(n ** power) % modulo for n in range(8)]\n",
      "      >>> x2 = [(n ** power) % modulo for n in np.arange(8)]\n",
      "      >>> print(x1)\n",
      "      [0, 1, 7776, 8801, 6176, 625, 6576, 4001]  # correct\n",
      "      >>> print(x2)\n",
      "      [0, 1, 7776, 7185, 0, 5969, 4816, 3361]  # incorrect\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.linspace : Evenly spaced numbers with careful handling of endpoints.\n",
      "    numpy.ogrid: Arrays of evenly spaced numbers in N-dimensions.\n",
      "    numpy.mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions.\n",
      "    :ref:`how-to-partition`\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.arange(3)\n",
      "    array([0, 1, 2])\n",
      "    >>> np.arange(3.0)\n",
      "    array([ 0.,  1.,  2.])\n",
      "    >>> np.arange(3,7)\n",
      "    array([3, 4, 5, 6])\n",
      "    >>> np.arange(3,7,2)\n",
      "    array([3, 5])\n",
      "code: array\n",
      "\n",
      "docstring: array\n",
      "array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\n",
      "          like=None)\n",
      "\n",
      "    Create an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    object : array_like\n",
      "        An array, any object exposing the array interface, an object whose\n",
      "        __array__ method returns an array, or any (nested) sequence.\n",
      "        If object is a scalar, a 0-dimensional array containing object is\n",
      "        returned.\n",
      "    dtype : data-type, optional\n",
      "        The desired data-type for the array.  If not given, then the type will\n",
      "        be determined as the minimum type required to hold the objects in the\n",
      "        sequence.\n",
      "    copy : bool, optional\n",
      "        If true (default), then the object is copied.  Otherwise, a copy will\n",
      "        only be made if __array__ returns a copy, if obj is a nested sequence,\n",
      "        or if a copy is needed to satisfy any of the other requirements\n",
      "        (`dtype`, `order`, etc.).\n",
      "    order : {'K', 'A', 'C', 'F'}, optional\n",
      "        Specify the memory layout of the array. If object is not an array, the\n",
      "        newly created array will be in C order (row major) unless 'F' is\n",
      "        specified, in which case it will be in Fortran order (column major).\n",
      "        If object is an array the following holds.\n",
      "\n",
      "        ===== ========= ===================================================\n",
      "        order  no copy                     copy=True\n",
      "        ===== ========= ===================================================\n",
      "        'K'   unchanged F & C order preserved, otherwise most similar order\n",
      "        'A'   unchanged F order if input is F and not C, otherwise C order\n",
      "        'C'   C order   C order\n",
      "        'F'   F order   F order\n",
      "        ===== ========= ===================================================\n",
      "\n",
      "        When ``copy=False`` and a copy is made for other reasons, the result is\n",
      "        the same as if ``copy=True``, with some exceptions for 'A', see the\n",
      "        Notes section. The default order is 'K'.\n",
      "    subok : bool, optional\n",
      "        If True, then sub-classes will be passed-through, otherwise\n",
      "        the returned array will be forced to be a base-class array (default).\n",
      "    ndmin : int, optional\n",
      "        Specifies the minimum number of dimensions that the resulting\n",
      "        array should have.  Ones will be prepended to the shape as\n",
      "        needed to meet this requirement.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        An array object satisfying the specified requirements.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    empty_like : Return an empty array with shape and type of input.\n",
      "    ones_like : Return an array of ones with shape and type of input.\n",
      "    zeros_like : Return an array of zeros with shape and type of input.\n",
      "    full_like : Return a new array with shape of input filled with value.\n",
      "    empty : Return a new uninitialized array.\n",
      "    ones : Return a new array setting values to one.\n",
      "    zeros : Return a new array setting values to zero.\n",
      "    full : Return a new array of given shape filled with value.\n",
      "\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When order is 'A' and `object` is an array in neither 'C' nor 'F' order,\n",
      "    and a copy is forced by a change in dtype, then the order of the result is\n",
      "    not necessarily 'C' as expected. This is likely a bug.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.array([1, 2, 3])\n",
      "    array([1, 2, 3])\n",
      "\n",
      "    Upcasting:\n",
      "\n",
      "    >>> np.array([1, 2, 3.0])\n",
      "    array([ 1.,  2.,  3.])\n",
      "\n",
      "    More than one dimension:\n",
      "\n",
      "    >>> np.array([[1, 2], [3, 4]])\n",
      "    array([[1, 2],\n",
      "           [3, 4]])\n",
      "\n",
      "    Minimum dimensions 2:\n",
      "\n",
      "    >>> np.array([1, 2, 3], ndmin=2)\n",
      "    array([[1, 2, 3]])\n",
      "\n",
      "    Type provided:\n",
      "\n",
      "    >>> np.array([1, 2, 3], dtype=complex)\n",
      "    array([ 1.+0.j,  2.+0.j,  3.+0.j])\n",
      "\n",
      "    Data-type consisting of more than one element:\n",
      "\n",
      "    >>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\n",
      "    >>> x['a']\n",
      "    array([1, 3])\n",
      "\n",
      "    Creating an array from sub-classes:\n",
      "\n",
      "    >>> np.array(np.mat('1 2; 3 4'))\n",
      "    array([[1, 2],\n",
      "           [3, 4]])\n",
      "\n",
      "    >>> np.array(np.mat('1 2; 3 4'), subok=True)\n",
      "    matrix([[1, 2],\n",
      "            [3, 4]])\n",
      "code: asarray\n",
      "\n",
      "docstring: asarray\n",
      "asarray(a, dtype=None, order=None, *, like=None)\n",
      "\n",
      "    Convert the input to an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data, in any form that can be converted to an array.  This\n",
      "        includes lists, lists of tuples, tuples, tuples of tuples, tuples\n",
      "        of lists and ndarrays.\n",
      "    dtype : data-type, optional\n",
      "        By default, the data-type is inferred from the input data.\n",
      "    order : {'C', 'F', 'A', 'K'}, optional\n",
      "        Memory layout.  'A' and 'K' depend on the order of input array a.\n",
      "        'C' row-major (C-style),\n",
      "        'F' column-major (Fortran-style) memory representation.\n",
      "        'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n",
      "        'K' (keep) preserve input order\n",
      "        Defaults to 'K'.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array interpretation of `a`.  No copy is performed if the input\n",
      "        is already an ndarray with matching dtype and order.  If `a` is a\n",
      "        subclass of ndarray, a base class ndarray is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    asanyarray : Similar function which passes through subclasses.\n",
      "    ascontiguousarray : Convert input to a contiguous array.\n",
      "    asfarray : Convert input to a floating point ndarray.\n",
      "    asfortranarray : Convert input to an ndarray with column-major\n",
      "                     memory order.\n",
      "    asarray_chkfinite : Similar function which checks input for NaNs and Infs.\n",
      "    fromiter : Create an array from an iterator.\n",
      "    fromfunction : Construct an array by executing a function on grid\n",
      "                   positions.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Convert a list into an array:\n",
      "\n",
      "    >>> a = [1, 2]\n",
      "    >>> np.asarray(a)\n",
      "    array([1, 2])\n",
      "\n",
      "    Existing arrays are not copied:\n",
      "\n",
      "    >>> a = np.array([1, 2])\n",
      "    >>> np.asarray(a) is a\n",
      "    True\n",
      "\n",
      "    If `dtype` is set, array is copied only if dtype does not match:\n",
      "\n",
      "    >>> a = np.array([1, 2], dtype=np.float32)\n",
      "    >>> np.asarray(a, dtype=np.float32) is a\n",
      "    True\n",
      "    >>> np.asarray(a, dtype=np.float64) is a\n",
      "    False\n",
      "\n",
      "    Contrary to `asanyarray`, ndarray subclasses are not passed through:\n",
      "\n",
      "    >>> issubclass(np.recarray, np.ndarray)\n",
      "    True\n",
      "    >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)\n",
      "    >>> np.asarray(a) is a\n",
      "    False\n",
      "    >>> np.asanyarray(a) is a\n",
      "    True\n",
      "code: asanyarray\n",
      "\n",
      "docstring: asanyarray\n",
      "asanyarray(a, dtype=None, order=None, *, like=None)\n",
      "\n",
      "    Convert the input to an ndarray, but pass ndarray subclasses through.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data, in any form that can be converted to an array.  This\n",
      "        includes scalars, lists, lists of tuples, tuples, tuples of tuples,\n",
      "        tuples of lists, and ndarrays.\n",
      "    dtype : data-type, optional\n",
      "        By default, the data-type is inferred from the input data.\n",
      "    order : {'C', 'F', 'A', 'K'}, optional\n",
      "        Memory layout.  'A' and 'K' depend on the order of input array a.\n",
      "        'C' row-major (C-style),\n",
      "        'F' column-major (Fortran-style) memory representation.\n",
      "        'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n",
      "        'K' (keep) preserve input order\n",
      "        Defaults to 'C'.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray or an ndarray subclass\n",
      "        Array interpretation of `a`.  If `a` is an ndarray or a subclass\n",
      "        of ndarray, it is returned as-is and no copy is performed.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    asarray : Similar function which always returns ndarrays.\n",
      "    ascontiguousarray : Convert input to a contiguous array.\n",
      "    asfarray : Convert input to a floating point ndarray.\n",
      "    asfortranarray : Convert input to an ndarray with column-major\n",
      "                     memory order.\n",
      "    asarray_chkfinite : Similar function which checks input for NaNs and\n",
      "                        Infs.\n",
      "    fromiter : Create an array from an iterator.\n",
      "    fromfunction : Construct an array by executing a function on grid\n",
      "                   positions.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Convert a list into an array:\n",
      "\n",
      "    >>> a = [1, 2]\n",
      "    >>> np.asanyarray(a)\n",
      "    array([1, 2])\n",
      "\n",
      "    Instances of `ndarray` subclasses are passed through as-is:\n",
      "\n",
      "    >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)\n",
      "    >>> np.asanyarray(a) is a\n",
      "    True\n",
      "code: ascontiguousarray\n",
      "\n",
      "docstring: ascontiguousarray\n",
      "ascontiguousarray(a, dtype=None, *, like=None)\n",
      "\n",
      "    Return a contiguous array (ndim >= 1) in memory (C order).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    dtype : str or dtype object, optional\n",
      "        Data-type of returned array.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Contiguous array of same shape and content as `a`, with type `dtype`\n",
      "        if specified.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    asfortranarray : Convert input to an ndarray with column-major\n",
      "                     memory order.\n",
      "    require : Return an ndarray that satisfies requirements.\n",
      "    ndarray.flags : Information about the memory layout of the array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Starting with a Fortran-contiguous array:\n",
      "\n",
      "    >>> x = np.ones((2, 3), order='F')\n",
      "    >>> x.flags['F_CONTIGUOUS']\n",
      "    True\n",
      "\n",
      "    Calling ``ascontiguousarray`` makes a C-contiguous copy:\n",
      "\n",
      "    >>> y = np.ascontiguousarray(x)\n",
      "    >>> y.flags['C_CONTIGUOUS']\n",
      "    True\n",
      "    >>> np.may_share_memory(x, y)\n",
      "    False\n",
      "\n",
      "    Now, starting with a C-contiguous array:\n",
      "\n",
      "    >>> x = np.ones((2, 3), order='C')\n",
      "    >>> x.flags['C_CONTIGUOUS']\n",
      "    True\n",
      "\n",
      "    Then, calling ``ascontiguousarray`` returns the same object:\n",
      "\n",
      "    >>> y = np.ascontiguousarray(x)\n",
      "    >>> x is y\n",
      "    True\n",
      "\n",
      "    Note: This function returns an array with at least one-dimension (1-d)\n",
      "    so it will not preserve 0-d arrays.\n",
      "code: asfortranarray\n",
      "\n",
      "docstring: asfortranarray\n",
      "asfortranarray(a, dtype=None, *, like=None)\n",
      "\n",
      "    Return an array (ndim >= 1) laid out in Fortran order in memory.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    dtype : str or dtype object, optional\n",
      "        By default, the data-type is inferred from the input data.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The input `a` in Fortran, or column-major, order.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ascontiguousarray : Convert input to a contiguous (C order) array.\n",
      "    asanyarray : Convert input to an ndarray with either row or\n",
      "        column-major memory order.\n",
      "    require : Return an ndarray that satisfies requirements.\n",
      "    ndarray.flags : Information about the memory layout of the array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Starting with a C-contiguous array:\n",
      "\n",
      "    >>> x = np.ones((2, 3), order='C')\n",
      "    >>> x.flags['C_CONTIGUOUS']\n",
      "    True\n",
      "\n",
      "    Calling ``asfortranarray`` makes a Fortran-contiguous copy:\n",
      "\n",
      "    >>> y = np.asfortranarray(x)\n",
      "    >>> y.flags['F_CONTIGUOUS']\n",
      "    True\n",
      "    >>> np.may_share_memory(x, y)\n",
      "    False\n",
      "\n",
      "    Now, starting with a Fortran-contiguous array:\n",
      "\n",
      "    >>> x = np.ones((2, 3), order='F')\n",
      "    >>> x.flags['F_CONTIGUOUS']\n",
      "    True\n",
      "\n",
      "    Then, calling ``asfortranarray`` returns the same object:\n",
      "\n",
      "    >>> y = np.asfortranarray(x)\n",
      "    >>> x is y\n",
      "    True\n",
      "\n",
      "    Note: This function returns an array with at least one-dimension (1-d)\n",
      "    so it will not preserve 0-d arrays.\n",
      "code: zeros\n",
      "\n",
      "docstring: zeros\n",
      "zeros(shape, dtype=float, order='C', *, like=None)\n",
      "\n",
      "    Return a new array of given shape and type, filled with zeros.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    shape : int or tuple of ints\n",
      "        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n",
      "    dtype : data-type, optional\n",
      "        The desired data-type for the array, e.g., `numpy.int8`.  Default is\n",
      "        `numpy.float64`.\n",
      "    order : {'C', 'F'}, optional, default: 'C'\n",
      "        Whether to store multi-dimensional data in row-major\n",
      "        (C-style) or column-major (Fortran-style) order in\n",
      "        memory.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of zeros with the given shape, dtype, and order.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    zeros_like : Return an array of zeros with shape and type of input.\n",
      "    empty : Return a new uninitialized array.\n",
      "    ones : Return a new array setting values to one.\n",
      "    full : Return a new array of given shape filled with value.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.zeros(5)\n",
      "    array([ 0.,  0.,  0.,  0.,  0.])\n",
      "\n",
      "    >>> np.zeros((5,), dtype=int)\n",
      "    array([0, 0, 0, 0, 0])\n",
      "\n",
      "    >>> np.zeros((2, 1))\n",
      "    array([[ 0.],\n",
      "           [ 0.]])\n",
      "\n",
      "    >>> s = (2,2)\n",
      "    >>> np.zeros(s)\n",
      "    array([[ 0.,  0.],\n",
      "           [ 0.,  0.]])\n",
      "\n",
      "    >>> np.zeros((2,), dtype=[('x', 'i4'), ('y', 'i4')]) # custom dtype\n",
      "    array([(0, 0), (0, 0)],\n",
      "          dtype=[('x', '<i4'), ('y', '<i4')])\n",
      "code: count_nonzero\n",
      "@array_function_dispatch(_count_nonzero_dispatcher)\n",
      "def count_nonzero(a, axis=None, *, keepdims=False):\n",
      "    if axis is None and not keepdims:\n",
      "        return multiarray.count_nonzero(a)\n",
      "    a = asanyarray(a)\n",
      "    # TODO: this works around .astype(bool) not working properly (gh-9847)\n",
      "    if np.issubdtype(a.dtype, np.character):\n",
      "        a_bool = a != a.dtype.type()\n",
      "    else:\n",
      "        a_bool = a.astype(np.bool_, copy=False)\n",
      "    return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims)\n",
      "docstring: count_nonzero\n",
      "\n",
      "    Counts the number of non-zero values in the array ``a``.\n",
      "\n",
      "    The word \"non-zero\" is in reference to the Python 2.x\n",
      "    built-in method ``__nonzero__()`` (renamed ``__bool__()``\n",
      "    in Python 3.x) of Python objects that tests an object's\n",
      "    \"truthfulness\". For example, any number is considered\n",
      "    truthful if it is nonzero, whereas any string is considered\n",
      "    truthful if it is not the empty string. Thus, this function\n",
      "    (recursively) counts how many elements in ``a`` (and in\n",
      "    sub-arrays thereof) have their ``__nonzero__()`` or ``__bool__()``\n",
      "    method evaluated to ``True``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        The array for which to count non-zeros.\n",
      "    axis : int or tuple, optional\n",
      "        Axis or tuple of axes along which to count non-zeros.\n",
      "        Default is None, meaning that non-zeros will be counted\n",
      "        along a flattened version of ``a``.\n",
      "\n",
      "        .. versionadded:: 1.12.0\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes that are counted are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        .. versionadded:: 1.19.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    count : int or array of int\n",
      "        Number of non-zero values in the array along a given axis.\n",
      "        Otherwise, the total number of non-zero values in the array\n",
      "        is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    nonzero : Return the coordinates of all the non-zero values.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.count_nonzero(np.eye(4))\n",
      "    4\n",
      "    >>> a = np.array([[0, 1, 7, 0],\n",
      "    ...               [3, 0, 2, 19]])\n",
      "    >>> np.count_nonzero(a)\n",
      "    5\n",
      "    >>> np.count_nonzero(a, axis=0)\n",
      "    array([1, 1, 2, 1])\n",
      "    >>> np.count_nonzero(a, axis=1)\n",
      "    array([2, 3])\n",
      "    >>> np.count_nonzero(a, axis=1, keepdims=True)\n",
      "    array([[2],\n",
      "           [3]])\n",
      "    \n",
      "code: empty\n",
      "\n",
      "docstring: empty\n",
      "empty(shape, dtype=float, order='C', *, like=None)\n",
      "\n",
      "    Return a new array of given shape and type, without initializing entries.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    shape : int or tuple of int\n",
      "        Shape of the empty array, e.g., ``(2, 3)`` or ``2``.\n",
      "    dtype : data-type, optional\n",
      "        Desired output data-type for the array, e.g, `numpy.int8`. Default is\n",
      "        `numpy.float64`.\n",
      "    order : {'C', 'F'}, optional, default: 'C'\n",
      "        Whether to store multi-dimensional data in row-major\n",
      "        (C-style) or column-major (Fortran-style) order in\n",
      "        memory.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of uninitialized (arbitrary) data of the given shape, dtype, and\n",
      "        order.  Object arrays will be initialized to None.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    empty_like : Return an empty array with shape and type of input.\n",
      "    ones : Return a new array setting values to one.\n",
      "    zeros : Return a new array setting values to zero.\n",
      "    full : Return a new array of given shape filled with value.\n",
      "\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    `empty`, unlike `zeros`, does not set the array values to zero,\n",
      "    and may therefore be marginally faster.  On the other hand, it requires\n",
      "    the user to manually set all the values in the array, and should be\n",
      "    used with caution.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.empty([2, 2])\n",
      "    array([[ -9.74499359e+001,   6.69583040e-309],\n",
      "           [  2.13182611e-314,   3.06959433e-309]])         #uninitialized\n",
      "\n",
      "    >>> np.empty([2, 2], dtype=int)\n",
      "    array([[-1073741821, -1067949133],\n",
      "           [  496041986,    19249760]])                     #uninitialized\n",
      "code: fromstring\n",
      "\n",
      "docstring: fromstring\n",
      "fromstring(string, dtype=float, count=-1, *, sep, like=None)\n",
      "\n",
      "    A new 1-D array initialized from text data in a string.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    string : str\n",
      "        A string containing the data.\n",
      "    dtype : data-type, optional\n",
      "        The data type of the array; default: float.  For binary input data,\n",
      "        the data must be in exactly this format. Most builtin numeric types are\n",
      "        supported and extension types may be supported.\n",
      "\n",
      "        .. versionadded:: 1.18.0\n",
      "            Complex dtypes.\n",
      "\n",
      "    count : int, optional\n",
      "        Read this number of `dtype` elements from the data.  If this is\n",
      "        negative (the default), the count will be determined from the\n",
      "        length of the data.\n",
      "    sep : str, optional\n",
      "        The string separating numbers in the data; extra whitespace between\n",
      "        elements is also ignored.\n",
      "\n",
      "        .. deprecated:: 1.14\n",
      "            Passing ``sep=''``, the default, is deprecated since it will\n",
      "            trigger the deprecated binary mode of this function. This mode\n",
      "            interprets `string` as binary bytes, rather than ASCII text with\n",
      "            decimal numbers, an operation which is better spelt\n",
      "            ``frombuffer(string, dtype, count)``. If `string` contains unicode\n",
      "            text, the binary mode of `fromstring` will first encode it into\n",
      "            bytes using utf-8, which will not produce sane results.\n",
      "\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    arr : ndarray\n",
      "        The constructed array.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If the string is not the correct size to satisfy the requested\n",
      "        `dtype` and `count`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    frombuffer, fromfile, fromiter\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.fromstring('1 2', dtype=int, sep=' ')\n",
      "    array([1, 2])\n",
      "    >>> np.fromstring('1, 2', dtype=int, sep=',')\n",
      "    array([1, 2])\n",
      "code: fromfile\n",
      "\n",
      "docstring: fromfile\n",
      "fromfile(file, dtype=float, count=-1, sep='', offset=0, *, like=None)\n",
      "\n",
      "    Construct an array from data in a text or binary file.\n",
      "\n",
      "    A highly efficient way of reading binary data with a known data-type,\n",
      "    as well as parsing simply formatted text files.  Data written using the\n",
      "    `tofile` method can be read using this function.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    file : file or str or Path\n",
      "        Open file object or filename.\n",
      "\n",
      "        .. versionchanged:: 1.17.0\n",
      "            `pathlib.Path` objects are now accepted.\n",
      "\n",
      "    dtype : data-type\n",
      "        Data type of the returned array.\n",
      "        For binary files, it is used to determine the size and byte-order\n",
      "        of the items in the file.\n",
      "        Most builtin numeric types are supported and extension types may be supported.\n",
      "\n",
      "        .. versionadded:: 1.18.0\n",
      "            Complex dtypes.\n",
      "\n",
      "    count : int\n",
      "        Number of items to read. ``-1`` means all items (i.e., the complete\n",
      "        file).\n",
      "    sep : str\n",
      "        Separator between items if file is a text file.\n",
      "        Empty (\"\") separator means the file should be treated as binary.\n",
      "        Spaces (\" \") in the separator match zero or more whitespace characters.\n",
      "        A separator consisting only of spaces must match at least one\n",
      "        whitespace.\n",
      "    offset : int\n",
      "        The offset (in bytes) from the file's current position. Defaults to 0.\n",
      "        Only permitted for binary files.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    load, save\n",
      "    ndarray.tofile\n",
      "    loadtxt : More flexible way of loading data from a text file.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Do not rely on the combination of `tofile` and `fromfile` for\n",
      "    data storage, as the binary files generated are not platform\n",
      "    independent.  In particular, no byte-order or data-type information is\n",
      "    saved.  Data can be stored in the platform independent ``.npy`` format\n",
      "    using `save` and `load` instead.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Construct an ndarray:\n",
      "\n",
      "    >>> dt = np.dtype([('time', [('min', np.int64), ('sec', np.int64)]),\n",
      "    ...                ('temp', float)])\n",
      "    >>> x = np.zeros((1,), dtype=dt)\n",
      "    >>> x['time']['min'] = 10; x['temp'] = 98.25\n",
      "    >>> x\n",
      "    array([((10, 0), 98.25)],\n",
      "          dtype=[('time', [('min', '<i8'), ('sec', '<i8')]), ('temp', '<f8')])\n",
      "\n",
      "    Save the raw data to disk:\n",
      "\n",
      "    >>> import tempfile\n",
      "    >>> fname = tempfile.mkstemp()[1]\n",
      "    >>> x.tofile(fname)\n",
      "\n",
      "    Read the raw data from disk:\n",
      "\n",
      "    >>> np.fromfile(fname, dtype=dt)\n",
      "    array([((10, 0), 98.25)],\n",
      "          dtype=[('time', [('min', '<i8'), ('sec', '<i8')]), ('temp', '<f8')])\n",
      "\n",
      "    The recommended way to store and load data:\n",
      "\n",
      "    >>> np.save(fname, x)\n",
      "    >>> np.load(fname + '.npy')\n",
      "    array([((10, 0), 98.25)],\n",
      "          dtype=[('time', [('min', '<i8'), ('sec', '<i8')]), ('temp', '<f8')])\n",
      "code: frombuffer\n",
      "\n",
      "docstring: frombuffer\n",
      "frombuffer(buffer, dtype=float, count=-1, offset=0, *, like=None)\n",
      "\n",
      "    Interpret a buffer as a 1-dimensional array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    buffer : buffer_like\n",
      "        An object that exposes the buffer interface.\n",
      "    dtype : data-type, optional\n",
      "        Data-type of the returned array; default: float.\n",
      "    count : int, optional\n",
      "        Number of items to read. ``-1`` means all data in the buffer.\n",
      "    offset : int, optional\n",
      "        Start reading the buffer from this offset (in bytes); default: 0.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    ndarray.tobytes\n",
      "        Inverse of this operation, construct Python bytes from the raw data\n",
      "        bytes in the array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    If the buffer has data that is not in machine byte-order, this should\n",
      "    be specified as part of the data-type, e.g.::\n",
      "\n",
      "      >>> dt = np.dtype(int)\n",
      "      >>> dt = dt.newbyteorder('>')\n",
      "      >>> np.frombuffer(buf, dtype=dt) # doctest: +SKIP\n",
      "\n",
      "    The data of the resulting array will not be byteswapped, but will be\n",
      "    interpreted correctly.\n",
      "\n",
      "    This function creates a view into the original object.  This should be safe\n",
      "    in general, but it may make sense to copy the result when the original\n",
      "    object is mutable or untrusted.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> s = b'hello world'\n",
      "    >>> np.frombuffer(s, dtype='S1', count=5, offset=6)\n",
      "    array([b'w', b'o', b'r', b'l', b'd'], dtype='|S1')\n",
      "\n",
      "    >>> np.frombuffer(b'\\x01\\x02', dtype=np.uint8)\n",
      "    array([1, 2], dtype=uint8)\n",
      "    >>> np.frombuffer(b'\\x01\\x02\\x03\\x04\\x05', dtype=np.uint8, count=3)\n",
      "    array([1, 2, 3], dtype=uint8)\n",
      "code: from_dlpack\n",
      "\n",
      "docstring: from_dlpack\n",
      "from_dlpack(x, /)\n",
      "\n",
      "    Create a NumPy array from an object implementing the ``__dlpack__``\n",
      "    protocol. Generally, the returned NumPy array is a read-only view\n",
      "    of the input object. See [1]_ and [2]_ for more details.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : object\n",
      "        A Python object that implements the ``__dlpack__`` and\n",
      "        ``__dlpack_device__`` methods.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Array API documentation,\n",
      "       https://data-apis.org/array-api/latest/design_topics/data_interchange.html#syntax-for-data-interchange-with-dlpack\n",
      "\n",
      "    .. [2] Python specification for DLPack,\n",
      "       https://dmlc.github.io/dlpack/latest/python_spec.html\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import torch\n",
      "    >>> x = torch.arange(10)\n",
      "    >>> # create a view of the torch tensor \"x\" in NumPy\n",
      "    >>> y = np.from_dlpack(x)\n",
      "code: where\n",
      "\n",
      "docstring: where\n",
      "\n",
      "    where(condition, [x, y], /)\n",
      "\n",
      "    Return elements chosen from `x` or `y` depending on `condition`.\n",
      "\n",
      "    .. note::\n",
      "        When only `condition` is provided, this function is a shorthand for\n",
      "        ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be\n",
      "        preferred, as it behaves correctly for subclasses. The rest of this\n",
      "        documentation covers only the case where all three arguments are\n",
      "        provided.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    condition : array_like, bool\n",
      "        Where True, yield `x`, otherwise yield `y`.\n",
      "    x, y : array_like\n",
      "        Values from which to choose. `x`, `y` and `condition` need to be\n",
      "        broadcastable to some shape.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        An array with elements from `x` where `condition` is True, and elements\n",
      "        from `y` elsewhere.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    choose\n",
      "    nonzero : The function that is called when x and y are omitted\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    If all the arrays are 1-D, `where` is equivalent to::\n",
      "\n",
      "        [xv if c else yv\n",
      "         for c, xv, yv in zip(condition, x, y)]\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(10)\n",
      "    >>> a\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "    >>> np.where(a < 5, a, 10*a)\n",
      "    array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])\n",
      "\n",
      "    This can be used on multidimensional arrays too:\n",
      "\n",
      "    >>> np.where([[True, False], [True, True]],\n",
      "    ...          [[1, 2], [3, 4]],\n",
      "    ...          [[9, 8], [7, 6]])\n",
      "    array([[1, 8],\n",
      "           [3, 4]])\n",
      "\n",
      "    The shapes of x, y, and the condition are broadcast together:\n",
      "\n",
      "    >>> x, y = np.ogrid[:3, :4]\n",
      "    >>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast\n",
      "    array([[10,  0,  0,  0],\n",
      "           [10, 11,  1,  1],\n",
      "           [10, 11, 12,  2]])\n",
      "\n",
      "    >>> a = np.array([[0, 1, 2],\n",
      "    ...               [0, 2, 4],\n",
      "    ...               [0, 3, 6]])\n",
      "    >>> np.where(a < 4, a, -1)  # -1 is broadcast\n",
      "    array([[ 0,  1,  2],\n",
      "           [ 0,  2, -1],\n",
      "           [ 0,  3, -1]])\n",
      "    \n",
      "code: argwhere\n",
      "@array_function_dispatch(_argwhere_dispatcher)\n",
      "def argwhere(a):\n",
      " then remove the added dimension\n",
      "        return argwhere(a)[:,:0]\n",
      "    return transpose(nonzero(a))\n",
      "docstring: argwhere\n",
      "\n",
      "    Find the indices of array elements that are non-zero, grouped by element.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    index_array : (N, a.ndim) ndarray\n",
      "        Indices of elements that are non-zero. Indices are grouped by element.\n",
      "        This array will have shape ``(N, a.ndim)`` where ``N`` is the number of\n",
      "        non-zero items.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    where, nonzero\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    ``np.argwhere(a)`` is almost the same as ``np.transpose(np.nonzero(a))``,\n",
      "    but produces a result of the correct shape for a 0D array.\n",
      "\n",
      "    The output of ``argwhere`` is not suitable for indexing arrays.\n",
      "    For this purpose use ``nonzero(a)`` instead.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(6).reshape(2,3)\n",
      "    >>> x\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.argwhere(x>1)\n",
      "    array([[0, 2],\n",
      "           [1, 0],\n",
      "           [1, 1],\n",
      "           [1, 2]])\n",
      "\n",
      "    \n",
      "code: copyto\n",
      "\n",
      "docstring: copyto\n",
      "\n",
      "    copyto(dst, src, casting='same_kind', where=True)\n",
      "\n",
      "    Copies values from one array to another, broadcasting as necessary.\n",
      "\n",
      "    Raises a TypeError if the `casting` rule is violated, and if\n",
      "    `where` is provided, it selects which elements to copy.\n",
      "\n",
      "    .. versionadded:: 1.7.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    dst : ndarray\n",
      "        The array into which values are copied.\n",
      "    src : array_like\n",
      "        The array from which values are copied.\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur when copying.\n",
      "\n",
      "          * 'no' means the data types should not be cast at all.\n",
      "          * 'equiv' means only byte-order changes are allowed.\n",
      "          * 'safe' means only casts which can preserve values are allowed.\n",
      "          * 'same_kind' means only safe casts or casts within a kind,\n",
      "            like float64 to float32, are allowed.\n",
      "          * 'unsafe' means any data conversions may be done.\n",
      "    where : array_like of bool, optional\n",
      "        A boolean array which is broadcasted to match the dimensions\n",
      "        of `dst`, and selects elements to copy from `src` to `dst`\n",
      "        wherever it contains the value True.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> A = np.array([4, 5, 6])\n",
      "    >>> B = [1, 2, 3]\n",
      "    >>> np.copyto(A, B)\n",
      "    >>> A\n",
      "    array([1, 2, 3])\n",
      "\n",
      "    >>> A = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "    >>> B = [[4, 5, 6], [7, 8, 9]]\n",
      "    >>> np.copyto(A, B)\n",
      "    >>> A\n",
      "    array([[4, 5, 6],\n",
      "           [7, 8, 9]])\n",
      "       \n",
      "    \n",
      "code: concatenate\n",
      "\n",
      "docstring: concatenate\n",
      "\n",
      "    concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting=\"same_kind\")\n",
      "\n",
      "    Join a sequence of arrays along an existing axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2, ... : sequence of array_like\n",
      "        The arrays must have the same shape, except in the dimension\n",
      "        corresponding to `axis` (the first, by default).\n",
      "    axis : int, optional\n",
      "        The axis along which the arrays will be joined.  If axis is None,\n",
      "        arrays are flattened before use.  Default is 0.\n",
      "    out : ndarray, optional\n",
      "        If provided, the destination to place the result. The shape must be\n",
      "        correct, matching that of what concatenate would have returned if no\n",
      "        out argument were specified.\n",
      "    dtype : str or dtype\n",
      "        If provided, the destination array will have this dtype. Cannot be\n",
      "        provided together with `out`.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    res : ndarray\n",
      "        The concatenated array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ma.concatenate : Concatenate function that preserves input masks.\n",
      "    array_split : Split an array into multiple sub-arrays of equal or\n",
      "                  near-equal size.\n",
      "    split : Split array into a list of multiple sub-arrays of equal size.\n",
      "    hsplit : Split array into multiple sub-arrays horizontally (column wise).\n",
      "    vsplit : Split array into multiple sub-arrays vertically (row wise).\n",
      "    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
      "    stack : Stack a sequence of arrays along a new axis.\n",
      "    block : Assemble arrays from blocks.\n",
      "    hstack : Stack arrays in sequence horizontally (column wise).\n",
      "    vstack : Stack arrays in sequence vertically (row wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third dimension).\n",
      "    column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When one or more of the arrays to be concatenated is a MaskedArray,\n",
      "    this function will return a MaskedArray object instead of an ndarray,\n",
      "    but the input masks are *not* preserved. In cases where a MaskedArray\n",
      "    is expected as input, use the ma.concatenate function from the masked\n",
      "    array module instead.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> b = np.array([[5, 6]])\n",
      "    >>> np.concatenate((a, b), axis=0)\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]])\n",
      "    >>> np.concatenate((a, b.T), axis=1)\n",
      "    array([[1, 2, 5],\n",
      "           [3, 4, 6]])\n",
      "    >>> np.concatenate((a, b), axis=None)\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "\n",
      "    This function will not preserve masking of MaskedArray inputs.\n",
      "\n",
      "    >>> a = np.ma.arange(3)\n",
      "    >>> a[1] = np.ma.masked\n",
      "    >>> b = np.arange(2, 5)\n",
      "    >>> a\n",
      "    masked_array(data=[0, --, 2],\n",
      "                 mask=[False,  True, False],\n",
      "           fill_value=999999)\n",
      "    >>> b\n",
      "    array([2, 3, 4])\n",
      "    >>> np.concatenate([a, b])\n",
      "    masked_array(data=[0, 1, 2, 2, 3, 4],\n",
      "                 mask=False,\n",
      "           fill_value=999999)\n",
      "    >>> np.ma.concatenate([a, b])\n",
      "    masked_array(data=[0, --, 2, 2, 3, 4],\n",
      "                 mask=[False,  True, False, False, False, False],\n",
      "           fill_value=999999)\n",
      "\n",
      "    \n",
      "code: fastCopyAndTranspose\n",
      "\n",
      "docstring: fastCopyAndTranspose\n",
      "fastCopyAndTranspose(a)\n",
      "\n",
      "    .. deprecated:: 1.24\n",
      "\n",
      "       fastCopyAndTranspose is deprecated and will be removed. Use the copy and\n",
      "       transpose methods instead, e.g. ``arr.T.copy()``\n",
      "code: lexsort\n",
      "\n",
      "docstring: lexsort\n",
      "\n",
      "    lexsort(keys, axis=-1)\n",
      "\n",
      "    Perform an indirect stable sort using a sequence of keys.\n",
      "\n",
      "    Given multiple sorting keys, which can be interpreted as columns in a\n",
      "    spreadsheet, lexsort returns an array of integer indices that describes\n",
      "    the sort order by multiple columns. The last key in the sequence is used\n",
      "    for the primary sort order, the second-to-last key for the secondary sort\n",
      "    order, and so on. The keys argument must be a sequence of objects that\n",
      "    can be converted to arrays of the same shape. If a 2D array is provided\n",
      "    for the keys argument, its rows are interpreted as the sorting keys and\n",
      "    sorting is according to the last row, second last row etc.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    keys : (k, N) array or tuple containing k (N,)-shaped sequences\n",
      "        The `k` different \"columns\" to be sorted.  The last column (or row if\n",
      "        `keys` is a 2D array) is the primary sort key.\n",
      "    axis : int, optional\n",
      "        Axis to be indirectly sorted.  By default, sort over the last axis.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    indices : (N,) ndarray of ints\n",
      "        Array of indices that sort the keys along the specified axis.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    argsort : Indirect sort.\n",
      "    ndarray.sort : In-place sort.\n",
      "    sort : Return a sorted copy of an array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Sort names: first by surname, then by name.\n",
      "\n",
      "    >>> surnames =    ('Hertz',    'Galilei', 'Hertz')\n",
      "    >>> first_names = ('Heinrich', 'Galileo', 'Gustav')\n",
      "    >>> ind = np.lexsort((first_names, surnames))\n",
      "    >>> ind\n",
      "    array([1, 2, 0])\n",
      "\n",
      "    >>> [surnames[i] + \", \" + first_names[i] for i in ind]\n",
      "    ['Galilei, Galileo', 'Hertz, Gustav', 'Hertz, Heinrich']\n",
      "\n",
      "    Sort two columns of numbers:\n",
      "\n",
      "    >>> a = [1,5,1,4,3,4,4] # First column\n",
      "    >>> b = [9,4,0,4,0,2,1] # Second column\n",
      "    >>> ind = np.lexsort((b,a)) # Sort by a, then by b\n",
      "    >>> ind\n",
      "    array([2, 0, 4, 6, 5, 3, 1])\n",
      "\n",
      "    >>> [(a[i],b[i]) for i in ind]\n",
      "    [(1, 0), (1, 9), (3, 0), (4, 1), (4, 2), (4, 4), (5, 4)]\n",
      "\n",
      "    Note that sorting is first according to the elements of ``a``.\n",
      "    Secondary sorting is according to the elements of ``b``.\n",
      "\n",
      "    A normal ``argsort`` would have yielded:\n",
      "\n",
      "    >>> [(a[i],b[i]) for i in np.argsort(a)]\n",
      "    [(1, 9), (1, 0), (3, 0), (4, 4), (4, 2), (4, 1), (5, 4)]\n",
      "\n",
      "    Structured arrays are sorted lexically by ``argsort``:\n",
      "\n",
      "    >>> x = np.array([(1,9), (5,4), (1,0), (4,4), (3,0), (4,2), (4,1)],\n",
      "    ...              dtype=np.dtype([('x', int), ('y', int)]))\n",
      "\n",
      "    >>> np.argsort(x) # or np.argsort(x, order=('x', 'y'))\n",
      "    array([2, 0, 4, 6, 5, 3, 1])\n",
      "\n",
      "    \n",
      "code: set_numeric_ops\n",
      "\n",
      "docstring: set_numeric_ops\n",
      "set_numeric_ops(op1=func1, op2=func2, ...)\n",
      "\n",
      "    Set numerical operators for array objects.\n",
      "\n",
      "    .. deprecated:: 1.16\n",
      "\n",
      "        For the general case, use :c:func:`PyUFunc_ReplaceLoopBySignature`.\n",
      "        For ndarray subclasses, define the ``__array_ufunc__`` method and\n",
      "        override the relevant ufunc.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    op1, op2, ... : callable\n",
      "        Each ``op = func`` pair describes an operator to be replaced.\n",
      "        For example, ``add = lambda x, y: np.add(x, y) % 5`` would replace\n",
      "        addition by modulus 5 addition.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    saved_ops : list of callables\n",
      "        A list of all operators, stored before making replacements.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. warning::\n",
      "       Use with care!  Incorrect usage may lead to memory errors.\n",
      "\n",
      "    A function replacing an operator cannot make use of that operator.\n",
      "    For example, when replacing add, you may not use ``+``.  Instead,\n",
      "    directly call ufuncs.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> def add_mod5(x, y):\n",
      "    ...     return np.add(x, y) % 5\n",
      "    ...\n",
      "    >>> old_funcs = np.set_numeric_ops(add=add_mod5)\n",
      "\n",
      "    >>> x = np.arange(12).reshape((3, 4))\n",
      "    >>> x + x\n",
      "    array([[0, 2, 4, 1],\n",
      "           [3, 0, 2, 4],\n",
      "           [1, 3, 0, 2]])\n",
      "\n",
      "    >>> ignore = np.set_numeric_ops(**old_funcs) # restore operators\n",
      "code: can_cast\n",
      "\n",
      "docstring: can_cast\n",
      "\n",
      "    can_cast(from_, to, casting='safe')\n",
      "\n",
      "    Returns True if cast between data types can occur according to the\n",
      "    casting rule.  If from is a scalar or array scalar, also returns\n",
      "    True if the scalar value can be cast without overflow or truncation\n",
      "    to an integer.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    from_ : dtype, dtype specifier, scalar, or array\n",
      "        Data type, scalar, or array to cast from.\n",
      "    to : dtype or dtype specifier\n",
      "        Data type to cast to.\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur.\n",
      "\n",
      "          * 'no' means the data types should not be cast at all.\n",
      "          * 'equiv' means only byte-order changes are allowed.\n",
      "          * 'safe' means only casts which can preserve values are allowed.\n",
      "          * 'same_kind' means only safe casts or casts within a kind,\n",
      "            like float64 to float32, are allowed.\n",
      "          * 'unsafe' means any data conversions may be done.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "        True if cast can occur according to the casting rule.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionchanged:: 1.17.0\n",
      "       Casting between a simple data type and a structured one is possible only\n",
      "       for \"unsafe\" casting.  Casting to multiple fields is allowed, but\n",
      "       casting from multiple fields is not.\n",
      "\n",
      "    .. versionchanged:: 1.9.0\n",
      "       Casting from numeric to string types in 'safe' casting mode requires\n",
      "       that the string dtype length is long enough to store the maximum\n",
      "       integer/float value converted.\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    dtype, result_type\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Basic examples\n",
      "\n",
      "    >>> np.can_cast(np.int32, np.int64)\n",
      "    True\n",
      "    >>> np.can_cast(np.float64, complex)\n",
      "    True\n",
      "    >>> np.can_cast(complex, float)\n",
      "    False\n",
      "\n",
      "    >>> np.can_cast('i8', 'f8')\n",
      "    True\n",
      "    >>> np.can_cast('i8', 'f4')\n",
      "    False\n",
      "    >>> np.can_cast('i4', 'S4')\n",
      "    False\n",
      "\n",
      "    Casting scalars\n",
      "\n",
      "    >>> np.can_cast(100, 'i1')\n",
      "    True\n",
      "    >>> np.can_cast(150, 'i1')\n",
      "    False\n",
      "    >>> np.can_cast(150, 'u1')\n",
      "    True\n",
      "\n",
      "    >>> np.can_cast(3.5e100, np.float32)\n",
      "    False\n",
      "    >>> np.can_cast(1000.0, np.float32)\n",
      "    True\n",
      "\n",
      "    Array scalar checks the value, array does not\n",
      "\n",
      "    >>> np.can_cast(np.array(1000.0), np.float32)\n",
      "    True\n",
      "    >>> np.can_cast(np.array([1000.0]), np.float32)\n",
      "    False\n",
      "\n",
      "    Using the casting rules\n",
      "\n",
      "    >>> np.can_cast('i8', 'i8', 'no')\n",
      "    True\n",
      "    >>> np.can_cast('<i8', '>i8', 'no')\n",
      "    False\n",
      "\n",
      "    >>> np.can_cast('<i8', '>i8', 'equiv')\n",
      "    True\n",
      "    >>> np.can_cast('<i4', '>i8', 'equiv')\n",
      "    False\n",
      "\n",
      "    >>> np.can_cast('<i4', '>i8', 'safe')\n",
      "    True\n",
      "    >>> np.can_cast('<i8', '>i4', 'safe')\n",
      "    False\n",
      "\n",
      "    >>> np.can_cast('<i8', '>i4', 'same_kind')\n",
      "    True\n",
      "    >>> np.can_cast('<i8', '>u4', 'same_kind')\n",
      "    False\n",
      "\n",
      "    >>> np.can_cast('<i8', '>u4', 'unsafe')\n",
      "    True\n",
      "\n",
      "    \n",
      "code: promote_types\n",
      "\n",
      "docstring: promote_types\n",
      "promote_types(type1, type2)\n",
      "\n",
      "    Returns the data type with the smallest size and smallest scalar\n",
      "    kind to which both ``type1`` and ``type2`` may be safely cast.\n",
      "    The returned data type is always considered \"canonical\", this mainly\n",
      "    means that the promoted dtype will always be in native byte order.\n",
      "\n",
      "    This function is symmetric, but rarely associative.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    type1 : dtype or dtype specifier\n",
      "        First data type.\n",
      "    type2 : dtype or dtype specifier\n",
      "        Second data type.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : dtype\n",
      "        The promoted data type.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Please see `numpy.result_type` for additional information about promotion.\n",
      "\n",
      "    .. versionadded:: 1.6.0\n",
      "\n",
      "    Starting in NumPy 1.9, promote_types function now returns a valid string\n",
      "    length when given an integer or float dtype as one argument and a string\n",
      "    dtype as another argument. Previously it always returned the input string\n",
      "    dtype, even if it wasn't long enough to store the max integer/float value\n",
      "    converted to a string.\n",
      "\n",
      "    .. versionchanged:: 1.23.0\n",
      "\n",
      "    NumPy now supports promotion for more structured dtypes.  It will now\n",
      "    remove unnecessary padding from a structure dtype and promote included\n",
      "    fields individually.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    result_type, dtype, can_cast\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.promote_types('f4', 'f8')\n",
      "    dtype('float64')\n",
      "\n",
      "    >>> np.promote_types('i8', 'f4')\n",
      "    dtype('float64')\n",
      "\n",
      "    >>> np.promote_types('>i8', '<c8')\n",
      "    dtype('complex128')\n",
      "\n",
      "    >>> np.promote_types('i4', 'S8')\n",
      "    dtype('S11')\n",
      "\n",
      "    An example of a non-associative case:\n",
      "\n",
      "    >>> p = np.promote_types\n",
      "    >>> p('S', p('i1', 'u1'))\n",
      "    dtype('S6')\n",
      "    >>> p(p('S', 'i1'), 'u1')\n",
      "    dtype('S4')\n",
      "code: min_scalar_type\n",
      "\n",
      "docstring: min_scalar_type\n",
      "\n",
      "    min_scalar_type(a, /)\n",
      "\n",
      "    For scalar ``a``, returns the data type with the smallest size\n",
      "    and smallest scalar kind which can hold its value.  For non-scalar\n",
      "    array ``a``, returns the vector's dtype unmodified.\n",
      "\n",
      "    Floating point values are not demoted to integers,\n",
      "    and complex values are not demoted to floats.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : scalar or array_like\n",
      "        The value whose minimal data type is to be found.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : dtype\n",
      "        The minimal data type.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.6.0\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    result_type, promote_types, dtype, can_cast\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.min_scalar_type(10)\n",
      "    dtype('uint8')\n",
      "\n",
      "    >>> np.min_scalar_type(-260)\n",
      "    dtype('int16')\n",
      "\n",
      "    >>> np.min_scalar_type(3.1)\n",
      "    dtype('float16')\n",
      "\n",
      "    >>> np.min_scalar_type(1e50)\n",
      "    dtype('float64')\n",
      "\n",
      "    >>> np.min_scalar_type(np.arange(4,dtype='f8'))\n",
      "    dtype('float64')\n",
      "\n",
      "    \n",
      "code: result_type\n",
      "\n",
      "docstring: result_type\n",
      "\n",
      "    result_type(*arrays_and_dtypes)\n",
      "\n",
      "    Returns the type that results from applying the NumPy\n",
      "    type promotion rules to the arguments.\n",
      "\n",
      "    Type promotion in NumPy works similarly to the rules in languages\n",
      "    like C++, with some slight differences.  When both scalars and\n",
      "    arrays are used, the array's type takes precedence and the actual value\n",
      "    of the scalar is taken into account.\n",
      "\n",
      "    For example, calculating 3*a, where a is an array of 32-bit floats,\n",
      "    intuitively should result in a 32-bit float output.  If the 3 is a\n",
      "    32-bit integer, the NumPy rules indicate it can't convert losslessly\n",
      "    into a 32-bit float, so a 64-bit float should be the result type.\n",
      "    By examining the value of the constant, '3', we see that it fits in\n",
      "    an 8-bit integer, which can be cast losslessly into the 32-bit float.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arrays_and_dtypes : list of arrays and dtypes\n",
      "        The operands of some operation whose result type is needed.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : dtype\n",
      "        The result type.\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    dtype, promote_types, min_scalar_type, can_cast\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.6.0\n",
      "\n",
      "    The specific algorithm used is as follows.\n",
      "\n",
      "    Categories are determined by first checking which of boolean,\n",
      "    integer (int/uint), or floating point (float/complex) the maximum\n",
      "    kind of all the arrays and the scalars are.\n",
      "\n",
      "    If there are only scalars or the maximum category of the scalars\n",
      "    is higher than the maximum category of the arrays,\n",
      "    the data types are combined with :func:`promote_types`\n",
      "    to produce the return value.\n",
      "\n",
      "    Otherwise, `min_scalar_type` is called on each array, and\n",
      "    the resulting data types are all combined with :func:`promote_types`\n",
      "    to produce the return value.\n",
      "\n",
      "    The set of int values is not a subset of the uint values for types\n",
      "    with the same number of bits, something not reflected in\n",
      "    :func:`min_scalar_type`, but handled as a special case in `result_type`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.result_type(3, np.arange(7, dtype='i1'))\n",
      "    dtype('int8')\n",
      "\n",
      "    >>> np.result_type('i4', 'c8')\n",
      "    dtype('complex128')\n",
      "\n",
      "    >>> np.result_type(3.0, -2)\n",
      "    dtype('float64')\n",
      "\n",
      "    \n",
      "code: isfortran\n",
      "@set_module('numpy')\n",
      "def isfortran(a):\n",
      "    return a.flags.fnc\n",
      "docstring: isfortran\n",
      "\n",
      "    Check if the array is Fortran contiguous but *not* C contiguous.\n",
      "\n",
      "    This function is obsolete and, because of changes due to relaxed stride\n",
      "    checking, its return value for the same array may differ for versions\n",
      "    of NumPy >= 1.10.0 and previous versions. If you only want to check if an\n",
      "    array is Fortran contiguous use ``a.flags.f_contiguous`` instead.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : ndarray\n",
      "        Input array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    isfortran : bool\n",
      "        Returns True if the array is Fortran contiguous but *not* C contiguous.\n",
      "\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    np.array allows to specify whether the array is written in C-contiguous\n",
      "    order (last index varies the fastest), or FORTRAN-contiguous order in\n",
      "    memory (first index varies the fastest).\n",
      "\n",
      "    >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C')\n",
      "    >>> a\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "    >>> np.isfortran(a)\n",
      "    False\n",
      "\n",
      "    >>> b = np.array([[1, 2, 3], [4, 5, 6]], order='F')\n",
      "    >>> b\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "    >>> np.isfortran(b)\n",
      "    True\n",
      "\n",
      "\n",
      "    The transpose of a C-ordered array is a FORTRAN-ordered array.\n",
      "\n",
      "    >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C')\n",
      "    >>> a\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "    >>> np.isfortran(a)\n",
      "    False\n",
      "    >>> b = a.T\n",
      "    >>> b\n",
      "    array([[1, 4],\n",
      "           [2, 5],\n",
      "           [3, 6]])\n",
      "    >>> np.isfortran(b)\n",
      "    True\n",
      "\n",
      "    C-ordered arrays evaluate as False even if they are also FORTRAN-ordered.\n",
      "\n",
      "    >>> np.isfortran(np.array([1, 2], order='F'))\n",
      "    False\n",
      "\n",
      "    \n",
      "code: empty_like\n",
      "\n",
      "docstring: empty_like\n",
      "\n",
      "    empty_like(prototype, dtype=None, order='K', subok=True, shape=None)\n",
      "\n",
      "    Return a new array with the same shape and type as a given array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    prototype : array_like\n",
      "        The shape and data-type of `prototype` define these same attributes\n",
      "        of the returned array.\n",
      "    dtype : data-type, optional\n",
      "        Overrides the data type of the result.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "    order : {'C', 'F', 'A', or 'K'}, optional\n",
      "        Overrides the memory layout of the result. 'C' means C-order,\n",
      "        'F' means F-order, 'A' means 'F' if `prototype` is Fortran\n",
      "        contiguous, 'C' otherwise. 'K' means match the layout of `prototype`\n",
      "        as closely as possible.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "    subok : bool, optional.\n",
      "        If True, then the newly created array will use the sub-class\n",
      "        type of `prototype`, otherwise it will be a base-class array. Defaults\n",
      "        to True.\n",
      "    shape : int or sequence of ints, optional.\n",
      "        Overrides the shape of the result. If order='K' and the number of\n",
      "        dimensions is unchanged, will try to keep order, otherwise,\n",
      "        order='C' is implied.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of uninitialized (arbitrary) data with the same\n",
      "        shape and type as `prototype`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ones_like : Return an array of ones with shape and type of input.\n",
      "    zeros_like : Return an array of zeros with shape and type of input.\n",
      "    full_like : Return a new array with shape of input filled with value.\n",
      "    empty : Return a new uninitialized array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This function does *not* initialize the returned array; to do that use\n",
      "    `zeros_like` or `ones_like` instead.  It may be marginally faster than\n",
      "    the functions that do set the array values.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = ([1,2,3], [4,5,6])                         # a is array-like\n",
      "    >>> np.empty_like(a)\n",
      "    array([[-1073741821, -1073741821,           3],    # uninitialized\n",
      "           [          0,           0, -1073741821]])\n",
      "    >>> a = np.array([[1., 2., 3.],[4.,5.,6.]])\n",
      "    >>> np.empty_like(a)\n",
      "    array([[ -2.00000715e+000,   1.48219694e-323,  -2.00000572e+000], # uninitialized\n",
      "           [  4.38791518e-305,  -2.00000715e+000,   4.17269252e-309]])\n",
      "\n",
      "    \n",
      "code: zeros_like\n",
      "@array_function_dispatch(_zeros_like_dispatcher)\n",
      "def zeros_like(a, dtype=None, order='K', subok=True, shape=None):\n",
      "    res = empty_like(a, dtype=dtype, order=order, subok=subok, shape=shape)\n",
      "    # needed instead of a 0 to get same result as zeros for string dtypes\n",
      "    z = zeros(1, dtype=res.dtype)\n",
      "    multiarray.copyto(res, z, casting='unsafe')\n",
      "    return res\n",
      "docstring: zeros_like\n",
      "\n",
      "    Return an array of zeros with the same shape and type as a given array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        The shape and data-type of `a` define these same attributes of\n",
      "        the returned array.\n",
      "    dtype : data-type, optional\n",
      "        Overrides the data type of the result.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "    order : {'C', 'F', 'A', or 'K'}, optional\n",
      "        Overrides the memory layout of the result. 'C' means C-order,\n",
      "        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n",
      "        'C' otherwise. 'K' means match the layout of `a` as closely\n",
      "        as possible.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "    subok : bool, optional.\n",
      "        If True, then the newly created array will use the sub-class\n",
      "        type of `a`, otherwise it will be a base-class array. Defaults\n",
      "        to True.\n",
      "    shape : int or sequence of ints, optional.\n",
      "        Overrides the shape of the result. If order='K' and the number of\n",
      "        dimensions is unchanged, will try to keep order, otherwise,\n",
      "        order='C' is implied.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of zeros with the same shape and type as `a`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    empty_like : Return an empty array with shape and type of input.\n",
      "    ones_like : Return an array of ones with shape and type of input.\n",
      "    full_like : Return a new array with shape of input filled with value.\n",
      "    zeros : Return a new array setting values to zero.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(6)\n",
      "    >>> x = x.reshape((2, 3))\n",
      "    >>> x\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.zeros_like(x)\n",
      "    array([[0, 0, 0],\n",
      "           [0, 0, 0]])\n",
      "\n",
      "    >>> y = np.arange(3, dtype=float)\n",
      "    >>> y\n",
      "    array([0., 1., 2.])\n",
      "    >>> np.zeros_like(y)\n",
      "    array([0.,  0.,  0.])\n",
      "\n",
      "    \n",
      "code: ones_like\n",
      "@array_function_dispatch(_ones_like_dispatcher)\n",
      "def ones_like(a, dtype=None, order='K', subok=True, shape=None):\n",
      "    res = empty_like(a, dtype=dtype, order=order, subok=subok, shape=shape)\n",
      "    multiarray.copyto(res, 1, casting='unsafe')\n",
      "    return res\n",
      "docstring: ones_like\n",
      "\n",
      "    Return an array of ones with the same shape and type as a given array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        The shape and data-type of `a` define these same attributes of\n",
      "        the returned array.\n",
      "    dtype : data-type, optional\n",
      "        Overrides the data type of the result.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "    order : {'C', 'F', 'A', or 'K'}, optional\n",
      "        Overrides the memory layout of the result. 'C' means C-order,\n",
      "        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n",
      "        'C' otherwise. 'K' means match the layout of `a` as closely\n",
      "        as possible.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "    subok : bool, optional.\n",
      "        If True, then the newly created array will use the sub-class\n",
      "        type of `a`, otherwise it will be a base-class array. Defaults\n",
      "        to True.\n",
      "    shape : int or sequence of ints, optional.\n",
      "        Overrides the shape of the result. If order='K' and the number of\n",
      "        dimensions is unchanged, will try to keep order, otherwise,\n",
      "        order='C' is implied.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of ones with the same shape and type as `a`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    empty_like : Return an empty array with shape and type of input.\n",
      "    zeros_like : Return an array of zeros with shape and type of input.\n",
      "    full_like : Return a new array with shape of input filled with value.\n",
      "    ones : Return a new array setting values to one.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(6)\n",
      "    >>> x = x.reshape((2, 3))\n",
      "    >>> x\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.ones_like(x)\n",
      "    array([[1, 1, 1],\n",
      "           [1, 1, 1]])\n",
      "\n",
      "    >>> y = np.arange(3, dtype=float)\n",
      "    >>> y\n",
      "    array([0., 1., 2.])\n",
      "    >>> np.ones_like(y)\n",
      "    array([1.,  1.,  1.])\n",
      "\n",
      "    \n",
      "code: correlate\n",
      "@array_function_dispatch(_correlate_dispatcher)\n",
      "def correlate(a, v, mode='valid'):\n",
      "    r\"\"\"\n",
      "    Cross-correlation of two 1-dimensional sequences.\n",
      "    This function computes the correlation as generally defined in signal\n",
      "    processing texts:\n",
      "    .. math:: c_k = \\sum_n a_{n+k} \\cdot \\overline{v}_n\n",
      "    with a and v sequences being zero-padded where necessary and\n",
      "    :math:`\\overline x` denoting complex conjugation.\n",
      "    Parameters\n",
      "    ----------\n",
      "    a, v : array_like\n",
      "        Input sequences.\n",
      "    mode : {'valid', 'same', 'full'}, optional\n",
      "        Refer to the `convolve` docstring.  Note that the default\n",
      "        is 'valid', unlike `convolve`, which uses 'full'.\n",
      "    old_behavior : bool\n",
      "        `old_behavior` was removed in NumPy 1.10. If you need the old\n",
      "        behavior, use `multiarray.correlate`.\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Discrete cross-correlation of `a` and `v`.\n",
      "    See Also\n",
      "    --------\n",
      "    convolve : Discrete, linear convolution of two one-dimensional sequences.\n",
      "    multiarray.correlate : Old, no conjugate, version of correlate.\n",
      "    scipy.signal.correlate : uses FFT which has superior performance on large arrays.\n",
      "    Notes\n",
      "    -----\n",
      "    The definition of correlation above is not unique and sometimes correlation\n",
      "    may be defined differently. Another common definition is:\n",
      "    .. math:: c'_k = \\sum_n a_{n} \\cdot \\overline{v_{n+k}}\n",
      "    which is related to :math:`c_k` by :math:`c'_k = c_{-k}`.\n",
      "    `numpy.correlate` may perform slowly in large arrays (i.e. n = 1e5) because it does\n",
      "    not use the FFT to compute the convolution; in that case, `scipy.signal.correlate` might\n",
      "    be preferable.\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.correlate([1, 2, 3], [0, 1, 0.5])\n",
      "    array([3.5])\n",
      "    >>> np.correlate([1, 2, 3], [0, 1, 0.5], \"same\")\n",
      "    array([2. ,  3.5,  3. ])\n",
      "    >>> np.correlate([1, 2, 3], [0, 1, 0.5], \"full\")\n",
      "    array([0.5,  2. ,  3.5,  3. ,  0. ])\n",
      "    Using complex sequences:\n",
      "    >>> np.correlate([1+1j, 2, 3-1j], [0, 1, 0.5j], 'full')\n",
      "    array([ 0.5-0.5j,  1.0+0.j ,  1.5-1.5j,  3.0-1.j ,  0.0+0.j ])\n",
      "    Note that you get the time reversed, complex conjugated result\n",
      "    (:math:`\\overline{c_{-k}}`) when the two input sequences a and v change\n",
      "    places:\n",
      "    >>> np.correlate([0, 1, 0.5j], [1+1j, 2, 3-1j], 'full')\n",
      "    array([ 0.0+0.j ,  3.0+1.j ,  1.5+1.5j,  1.0+0.j ,  0.5+0.5j])\n",
      "    \"\"\"\n",
      "    return multiarray.correlate2(a, v, mode)\n",
      "docstring: correlate\n",
      "\n",
      "    Cross-correlation of two 1-dimensional sequences.\n",
      "\n",
      "    This function computes the correlation as generally defined in signal\n",
      "    processing texts:\n",
      "\n",
      "    .. math:: c_k = \\sum_n a_{n+k} \\cdot \\overline{v}_n\n",
      "\n",
      "    with a and v sequences being zero-padded where necessary and\n",
      "    :math:`\\overline x` denoting complex conjugation.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a, v : array_like\n",
      "        Input sequences.\n",
      "    mode : {'valid', 'same', 'full'}, optional\n",
      "        Refer to the `convolve` docstring.  Note that the default\n",
      "        is 'valid', unlike `convolve`, which uses 'full'.\n",
      "    old_behavior : bool\n",
      "        `old_behavior` was removed in NumPy 1.10. If you need the old\n",
      "        behavior, use `multiarray.correlate`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Discrete cross-correlation of `a` and `v`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    convolve : Discrete, linear convolution of two one-dimensional sequences.\n",
      "    multiarray.correlate : Old, no conjugate, version of correlate.\n",
      "    scipy.signal.correlate : uses FFT which has superior performance on large arrays. \n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The definition of correlation above is not unique and sometimes correlation\n",
      "    may be defined differently. Another common definition is:\n",
      "\n",
      "    .. math:: c'_k = \\sum_n a_{n} \\cdot \\overline{v_{n+k}}\n",
      "\n",
      "    which is related to :math:`c_k` by :math:`c'_k = c_{-k}`.\n",
      "\n",
      "    `numpy.correlate` may perform slowly in large arrays (i.e. n = 1e5) because it does\n",
      "    not use the FFT to compute the convolution; in that case, `scipy.signal.correlate` might\n",
      "    be preferable.\n",
      "    \n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.correlate([1, 2, 3], [0, 1, 0.5])\n",
      "    array([3.5])\n",
      "    >>> np.correlate([1, 2, 3], [0, 1, 0.5], \"same\")\n",
      "    array([2. ,  3.5,  3. ])\n",
      "    >>> np.correlate([1, 2, 3], [0, 1, 0.5], \"full\")\n",
      "    array([0.5,  2. ,  3.5,  3. ,  0. ])\n",
      "\n",
      "    Using complex sequences:\n",
      "\n",
      "    >>> np.correlate([1+1j, 2, 3-1j], [0, 1, 0.5j], 'full')\n",
      "    array([ 0.5-0.5j,  1.0+0.j ,  1.5-1.5j,  3.0-1.j ,  0.0+0.j ])\n",
      "\n",
      "    Note that you get the time reversed, complex conjugated result\n",
      "    (:math:`\\overline{c_{-k}}`) when the two input sequences a and v change \n",
      "    places:\n",
      "\n",
      "    >>> np.correlate([0, 1, 0.5j], [1+1j, 2, 3-1j], 'full')\n",
      "    array([ 0.0+0.j ,  3.0+1.j ,  1.5+1.5j,  1.0+0.j ,  0.5+0.5j])\n",
      "\n",
      "    \n",
      "code: convolve\n",
      "@array_function_dispatch(_convolve_dispatcher)\n",
      "def convolve(a, v, mode='full'):\n",
      "    a, v = array(a, copy=False, ndmin=1), array(v, copy=False, ndmin=1)\n",
      "    if (len(v) > len(a)):\n",
      "        a, v = v, a\n",
      "    if len(a) == 0:\n",
      "        raise ValueError('a cannot be empty')\n",
      "    if len(v) == 0:\n",
      "        raise ValueError('v cannot be empty')\n",
      "    return multiarray.correlate(a, v[::-1], mode)\n",
      "docstring: convolve\n",
      "\n",
      "    Returns the discrete, linear convolution of two one-dimensional sequences.\n",
      "\n",
      "    The convolution operator is often seen in signal processing, where it\n",
      "    models the effect of a linear time-invariant system on a signal [1]_.  In\n",
      "    probability theory, the sum of two independent random variables is\n",
      "    distributed according to the convolution of their individual\n",
      "    distributions.\n",
      "\n",
      "    If `v` is longer than `a`, the arrays are swapped before computation.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : (N,) array_like\n",
      "        First one-dimensional input array.\n",
      "    v : (M,) array_like\n",
      "        Second one-dimensional input array.\n",
      "    mode : {'full', 'valid', 'same'}, optional\n",
      "        'full':\n",
      "          By default, mode is 'full'.  This returns the convolution\n",
      "          at each point of overlap, with an output shape of (N+M-1,). At\n",
      "          the end-points of the convolution, the signals do not overlap\n",
      "          completely, and boundary effects may be seen.\n",
      "\n",
      "        'same':\n",
      "          Mode 'same' returns output of length ``max(M, N)``.  Boundary\n",
      "          effects are still visible.\n",
      "\n",
      "        'valid':\n",
      "          Mode 'valid' returns output of length\n",
      "          ``max(M, N) - min(M, N) + 1``.  The convolution product is only given\n",
      "          for points where the signals overlap completely.  Values outside\n",
      "          the signal boundary have no effect.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Discrete, linear convolution of `a` and `v`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    scipy.signal.fftconvolve : Convolve two arrays using the Fast Fourier\n",
      "                               Transform.\n",
      "    scipy.linalg.toeplitz : Used to construct the convolution operator.\n",
      "    polymul : Polynomial multiplication. Same output as convolve, but also\n",
      "              accepts poly1d objects as input.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The discrete convolution operation is defined as\n",
      "\n",
      "    .. math:: (a * v)_n = \\sum_{m = -\\infty}^{\\infty} a_m v_{n - m}\n",
      "\n",
      "    It can be shown that a convolution :math:`x(t) * y(t)` in time/space\n",
      "    is equivalent to the multiplication :math:`X(f) Y(f)` in the Fourier\n",
      "    domain, after appropriate padding (padding is necessary to prevent\n",
      "    circular convolution).  Since multiplication is more efficient (faster)\n",
      "    than convolution, the function `scipy.signal.fftconvolve` exploits the\n",
      "    FFT to calculate the convolution of large data-sets.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Wikipedia, \"Convolution\",\n",
      "        https://en.wikipedia.org/wiki/Convolution\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Note how the convolution operator flips the second array\n",
      "    before \"sliding\" the two across one another:\n",
      "\n",
      "    >>> np.convolve([1, 2, 3], [0, 1, 0.5])\n",
      "    array([0. , 1. , 2.5, 4. , 1.5])\n",
      "\n",
      "    Only return the middle values of the convolution.\n",
      "    Contains boundary effects, where zeros are taken\n",
      "    into account:\n",
      "\n",
      "    >>> np.convolve([1,2,3],[0,1,0.5], 'same')\n",
      "    array([1. ,  2.5,  4. ])\n",
      "\n",
      "    The two arrays are of the same length, so there\n",
      "    is only one position where they completely overlap:\n",
      "\n",
      "    >>> np.convolve([1,2,3],[0,1,0.5], 'valid')\n",
      "    array([2.5])\n",
      "\n",
      "    \n",
      "code: inner\n",
      "\n",
      "docstring: inner\n",
      "\n",
      "    inner(a, b, /)\n",
      "\n",
      "    Inner product of two arrays.\n",
      "\n",
      "    Ordinary inner product of vectors for 1-D arrays (without complex\n",
      "    conjugation), in higher dimensions a sum product over the last axes.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a, b : array_like\n",
      "        If `a` and `b` are nonscalar, their last dimensions must match.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        If `a` and `b` are both\n",
      "        scalars or both 1-D arrays then a scalar is returned; otherwise\n",
      "        an array is returned.\n",
      "        ``out.shape = (*a.shape[:-1], *b.shape[:-1])``\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If both `a` and `b` are nonscalar and their last dimensions have\n",
      "        different sizes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    tensordot : Sum products over arbitrary axes.\n",
      "    dot : Generalised matrix product, using second last dimension of `b`.\n",
      "    einsum : Einstein summation convention.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    For vectors (1-D arrays) it computes the ordinary inner-product::\n",
      "\n",
      "        np.inner(a, b) = sum(a[:]*b[:])\n",
      "\n",
      "    More generally, if ``ndim(a) = r > 0`` and ``ndim(b) = s > 0``::\n",
      "\n",
      "        np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))\n",
      "\n",
      "    or explicitly::\n",
      "\n",
      "        np.inner(a, b)[i0,...,ir-2,j0,...,js-2]\n",
      "             = sum(a[i0,...,ir-2,:]*b[j0,...,js-2,:])\n",
      "\n",
      "    In addition `a` or `b` may be scalars, in which case::\n",
      "\n",
      "       np.inner(a,b) = a*b\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Ordinary inner product for vectors:\n",
      "\n",
      "    >>> a = np.array([1,2,3])\n",
      "    >>> b = np.array([0,1,0])\n",
      "    >>> np.inner(a, b)\n",
      "    2\n",
      "\n",
      "    Some multidimensional examples:\n",
      "\n",
      "    >>> a = np.arange(24).reshape((2,3,4))\n",
      "    >>> b = np.arange(4)\n",
      "    >>> c = np.inner(a, b)\n",
      "    >>> c.shape\n",
      "    (2, 3)\n",
      "    >>> c\n",
      "    array([[ 14,  38,  62],\n",
      "           [ 86, 110, 134]])\n",
      "\n",
      "    >>> a = np.arange(2).reshape((1,1,2))\n",
      "    >>> b = np.arange(6).reshape((3,2))\n",
      "    >>> c = np.inner(a, b)\n",
      "    >>> c.shape\n",
      "    (1, 1, 3)\n",
      "    >>> c\n",
      "    array([[[1, 3, 5]]])\n",
      "\n",
      "    An example where `b` is a scalar:\n",
      "\n",
      "    >>> np.inner(np.eye(2), 7)\n",
      "    array([[7., 0.],\n",
      "           [0., 7.]])\n",
      "\n",
      "    \n",
      "code: dot\n",
      "\n",
      "docstring: dot\n",
      "\n",
      "    dot(a, b, out=None)\n",
      "\n",
      "    Dot product of two arrays. Specifically,\n",
      "\n",
      "    - If both `a` and `b` are 1-D arrays, it is inner product of vectors\n",
      "      (without complex conjugation).\n",
      "\n",
      "    - If both `a` and `b` are 2-D arrays, it is matrix multiplication,\n",
      "      but using :func:`matmul` or ``a @ b`` is preferred.\n",
      "\n",
      "    - If either `a` or `b` is 0-D (scalar), it is equivalent to\n",
      "      :func:`multiply` and using ``numpy.multiply(a, b)`` or ``a * b`` is\n",
      "      preferred.\n",
      "\n",
      "    - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over\n",
      "      the last axis of `a` and `b`.\n",
      "\n",
      "    - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a\n",
      "      sum product over the last axis of `a` and the second-to-last axis of\n",
      "      `b`::\n",
      "\n",
      "        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n",
      "\n",
      "    It uses an optimized BLAS library when possible (see `numpy.linalg`).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        First argument.\n",
      "    b : array_like\n",
      "        Second argument.\n",
      "    out : ndarray, optional\n",
      "        Output argument. This must have the exact kind that would be returned\n",
      "        if it was not used. In particular, it must have the right type, must be\n",
      "        C-contiguous, and its dtype must be the dtype that would be returned\n",
      "        for `dot(a,b)`. This is a performance feature. Therefore, if these\n",
      "        conditions are not met, an exception is raised, instead of attempting\n",
      "        to be flexible.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        Returns the dot product of `a` and `b`.  If `a` and `b` are both\n",
      "        scalars or both 1-D arrays then a scalar is returned; otherwise\n",
      "        an array is returned.\n",
      "        If `out` is given, then it is returned.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If the last dimension of `a` is not the same size as\n",
      "        the second-to-last dimension of `b`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    vdot : Complex-conjugating dot product.\n",
      "    tensordot : Sum products over arbitrary axes.\n",
      "    einsum : Einstein summation convention.\n",
      "    matmul : '@' operator as method with out parameter.\n",
      "    linalg.multi_dot : Chained dot product.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.dot(3, 4)\n",
      "    12\n",
      "\n",
      "    Neither argument is complex-conjugated:\n",
      "\n",
      "    >>> np.dot([2j, 3j], [2j, 3j])\n",
      "    (-13+0j)\n",
      "\n",
      "    For 2-D arrays it is the matrix product:\n",
      "\n",
      "    >>> a = [[1, 0], [0, 1]]\n",
      "    >>> b = [[4, 1], [2, 2]]\n",
      "    >>> np.dot(a, b)\n",
      "    array([[4, 1],\n",
      "           [2, 2]])\n",
      "\n",
      "    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))\n",
      "    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))\n",
      "    >>> np.dot(a, b)[2,3,2,1,2,2]\n",
      "    499128\n",
      "    >>> sum(a[2,3,2,:] * b[1,2,:,2])\n",
      "    499128\n",
      "\n",
      "    \n",
      "code: outer\n",
      "@array_function_dispatch(_outer_dispatcher)\n",
      "def outer(a, b, out=None):\n",
      "    a = asarray(a)\n",
      "    b = asarray(b)\n",
      "    return multiply(a.ravel()[:, newaxis], b.ravel()[newaxis, :], out)\n",
      "docstring: outer\n",
      "\n",
      "    Compute the outer product of two vectors.\n",
      "\n",
      "    Given two vectors, ``a = [a0, a1, ..., aM]`` and\n",
      "    ``b = [b0, b1, ..., bN]``,\n",
      "    the outer product [1]_ is::\n",
      "\n",
      "      [[a0*b0  a0*b1 ... a0*bN ]\n",
      "       [a1*b0    .\n",
      "       [ ...          .\n",
      "       [aM*b0            aM*bN ]]\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : (M,) array_like\n",
      "        First input vector.  Input is flattened if\n",
      "        not already 1-dimensional.\n",
      "    b : (N,) array_like\n",
      "        Second input vector.  Input is flattened if\n",
      "        not already 1-dimensional.\n",
      "    out : (M, N) ndarray, optional\n",
      "        A location where the result is stored\n",
      "\n",
      "        .. versionadded:: 1.9.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : (M, N) ndarray\n",
      "        ``out[i, j] = a[i] * b[j]``\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    inner\n",
      "    einsum : ``einsum('i,j->ij', a.ravel(), b.ravel())`` is the equivalent.\n",
      "    ufunc.outer : A generalization to dimensions other than 1D and other\n",
      "                  operations. ``np.multiply.outer(a.ravel(), b.ravel())``\n",
      "                  is the equivalent.\n",
      "    tensordot : ``np.tensordot(a.ravel(), b.ravel(), axes=((), ()))``\n",
      "                is the equivalent.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] : G. H. Golub and C. F. Van Loan, *Matrix Computations*, 3rd\n",
      "             ed., Baltimore, MD, Johns Hopkins University Press, 1996,\n",
      "             pg. 8.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Make a (*very* coarse) grid for computing a Mandelbrot set:\n",
      "\n",
      "    >>> rl = np.outer(np.ones((5,)), np.linspace(-2, 2, 5))\n",
      "    >>> rl\n",
      "    array([[-2., -1.,  0.,  1.,  2.],\n",
      "           [-2., -1.,  0.,  1.,  2.],\n",
      "           [-2., -1.,  0.,  1.,  2.],\n",
      "           [-2., -1.,  0.,  1.,  2.],\n",
      "           [-2., -1.,  0.,  1.,  2.]])\n",
      "    >>> im = np.outer(1j*np.linspace(2, -2, 5), np.ones((5,)))\n",
      "    >>> im\n",
      "    array([[0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j],\n",
      "           [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],\n",
      "           [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "           [0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j],\n",
      "           [0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j]])\n",
      "    >>> grid = rl + im\n",
      "    >>> grid\n",
      "    array([[-2.+2.j, -1.+2.j,  0.+2.j,  1.+2.j,  2.+2.j],\n",
      "           [-2.+1.j, -1.+1.j,  0.+1.j,  1.+1.j,  2.+1.j],\n",
      "           [-2.+0.j, -1.+0.j,  0.+0.j,  1.+0.j,  2.+0.j],\n",
      "           [-2.-1.j, -1.-1.j,  0.-1.j,  1.-1.j,  2.-1.j],\n",
      "           [-2.-2.j, -1.-2.j,  0.-2.j,  1.-2.j,  2.-2.j]])\n",
      "\n",
      "    An example using a \"vector\" of letters:\n",
      "\n",
      "    >>> x = np.array(['a', 'b', 'c'], dtype=object)\n",
      "    >>> np.outer(x, [1, 2, 3])\n",
      "    array([['a', 'aa', 'aaa'],\n",
      "           ['b', 'bb', 'bbb'],\n",
      "           ['c', 'cc', 'ccc']], dtype=object)\n",
      "\n",
      "    \n",
      "code: vdot\n",
      "\n",
      "docstring: vdot\n",
      "\n",
      "    vdot(a, b, /)\n",
      "\n",
      "    Return the dot product of two vectors.\n",
      "\n",
      "    The vdot(`a`, `b`) function handles complex numbers differently than\n",
      "    dot(`a`, `b`).  If the first argument is complex the complex conjugate\n",
      "    of the first argument is used for the calculation of the dot product.\n",
      "\n",
      "    Note that `vdot` handles multidimensional arrays differently than `dot`:\n",
      "    it does *not* perform a matrix product, but flattens input arguments\n",
      "    to 1-D vectors first. Consequently, it should only be used for vectors.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        If `a` is complex the complex conjugate is taken before calculation\n",
      "        of the dot product.\n",
      "    b : array_like\n",
      "        Second argument to the dot product.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        Dot product of `a` and `b`.  Can be an int, float, or\n",
      "        complex depending on the types of `a` and `b`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    dot : Return the dot product without using the complex conjugate of the\n",
      "          first argument.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1+2j,3+4j])\n",
      "    >>> b = np.array([5+6j,7+8j])\n",
      "    >>> np.vdot(a, b)\n",
      "    (70-8j)\n",
      "    >>> np.vdot(b, a)\n",
      "    (70+8j)\n",
      "\n",
      "    Note that higher-dimensional arrays are flattened!\n",
      "\n",
      "    >>> a = np.array([[1, 4], [5, 6]])\n",
      "    >>> b = np.array([[4, 1], [2, 2]])\n",
      "    >>> np.vdot(a, b)\n",
      "    30\n",
      "    >>> np.vdot(b, a)\n",
      "    30\n",
      "    >>> 1*4 + 4*1 + 5*2 + 6*2\n",
      "    30\n",
      "\n",
      "    \n",
      "code: roll\n",
      "@array_function_dispatch(_roll_dispatcher)\n",
      "def roll(a, shift, axis=None):\n",
      "    a = asanyarray(a)\n",
      "    if axis is None:\n",
      "        return roll(a.ravel(), shift, 0).reshape(a.shape)\n",
      "    else:\n",
      "        axis = normalize_axis_tuple(axis, a.ndim, allow_duplicate=True)\n",
      "        broadcasted = broadcast(shift, axis)\n",
      "        if broadcasted.ndim > 1:\n",
      "            raise ValueError(\n",
      "                \"'shift' and 'axis' should be scalars or 1D sequences\")\n",
      "        shifts = {ax: 0 for ax in range(a.ndim)}\n",
      "        for sh, ax in broadcasted:\n",
      "            shifts[ax] += sh\n",
      "        rolls = [((slice(None), slice(None)),)] * a.ndim\n",
      "        for ax, offset in shifts.items():\n",
      "            offset %= a.shape[ax] or 1  # If `a` is empty, nothing matters.\n",
      "            if offset:\n",
      "                # (original, result), (original, result)\n",
      "                rolls[ax] = ((slice(None, -offset), slice(offset, None)),\n",
      "                             (slice(-offset, None), slice(None, offset)))\n",
      "        result = empty_like(a)\n",
      "        for indices in itertools.product(*rolls):\n",
      "            arr_index, res_index = zip(*indices)\n",
      "            result[res_index] = a[arr_index]\n",
      "        return result\n",
      "docstring: roll\n",
      "\n",
      "    Roll array elements along a given axis.\n",
      "\n",
      "    Elements that roll beyond the last position are re-introduced at\n",
      "    the first.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    shift : int or tuple of ints\n",
      "        The number of places by which elements are shifted.  If a tuple,\n",
      "        then `axis` must be a tuple of the same size, and each of the\n",
      "        given axes is shifted by the corresponding number.  If an int\n",
      "        while `axis` is a tuple of ints, then the same value is used for\n",
      "        all given axes.\n",
      "    axis : int or tuple of ints, optional\n",
      "        Axis or axes along which elements are shifted.  By default, the\n",
      "        array is flattened before shifting, after which the original\n",
      "        shape is restored.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    res : ndarray\n",
      "        Output array, with the same shape as `a`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    rollaxis : Roll the specified axis backwards, until it lies in a\n",
      "               given position.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.12.0\n",
      "\n",
      "    Supports rolling over multiple dimensions simultaneously.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(10)\n",
      "    >>> np.roll(x, 2)\n",
      "    array([8, 9, 0, 1, 2, 3, 4, 5, 6, 7])\n",
      "    >>> np.roll(x, -2)\n",
      "    array([2, 3, 4, 5, 6, 7, 8, 9, 0, 1])\n",
      "\n",
      "    >>> x2 = np.reshape(x, (2, 5))\n",
      "    >>> x2\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [5, 6, 7, 8, 9]])\n",
      "    >>> np.roll(x2, 1)\n",
      "    array([[9, 0, 1, 2, 3],\n",
      "           [4, 5, 6, 7, 8]])\n",
      "    >>> np.roll(x2, -1)\n",
      "    array([[1, 2, 3, 4, 5],\n",
      "           [6, 7, 8, 9, 0]])\n",
      "    >>> np.roll(x2, 1, axis=0)\n",
      "    array([[5, 6, 7, 8, 9],\n",
      "           [0, 1, 2, 3, 4]])\n",
      "    >>> np.roll(x2, -1, axis=0)\n",
      "    array([[5, 6, 7, 8, 9],\n",
      "           [0, 1, 2, 3, 4]])\n",
      "    >>> np.roll(x2, 1, axis=1)\n",
      "    array([[4, 0, 1, 2, 3],\n",
      "           [9, 5, 6, 7, 8]])\n",
      "    >>> np.roll(x2, -1, axis=1)\n",
      "    array([[1, 2, 3, 4, 0],\n",
      "           [6, 7, 8, 9, 5]])\n",
      "    >>> np.roll(x2, (1, 1), axis=(1, 0))\n",
      "    array([[9, 5, 6, 7, 8],\n",
      "           [4, 0, 1, 2, 3]])\n",
      "    >>> np.roll(x2, (2, 1), axis=(1, 0))\n",
      "    array([[8, 9, 5, 6, 7],\n",
      "           [3, 4, 0, 1, 2]])\n",
      "\n",
      "    \n",
      "code: rollaxis\n",
      "@array_function_dispatch(_rollaxis_dispatcher)\n",
      "def rollaxis(a, axis, start=0):\n",
      "    n = a.ndim\n",
      "    axis = normalize_axis_index(axis, n)\n",
      "    if start < 0:\n",
      "        start += n\n",
      "    msg = \"'%s' arg requires %d <= %s < %d, but %d was passed in\"\n",
      "    if not (0 <= start < n + 1):\n",
      "        raise AxisError(msg % ('start', -n, 'start', n + 1, start))\n",
      "    if axis < start:\n",
      "        # it's been removed\n",
      "        start -= 1\n",
      "    if axis == start:\n",
      "        return a[...]\n",
      "    axes = list(range(0, n))\n",
      "    axes.remove(axis)\n",
      "    axes.insert(start, axis)\n",
      "    return a.transpose(axes)\n",
      "docstring: rollaxis\n",
      "\n",
      "    Roll the specified axis backwards, until it lies in a given position.\n",
      "\n",
      "    This function continues to be supported for backward compatibility, but you\n",
      "    should prefer `moveaxis`. The `moveaxis` function was added in NumPy\n",
      "    1.11.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : ndarray\n",
      "        Input array.\n",
      "    axis : int\n",
      "        The axis to be rolled. The positions of the other axes do not\n",
      "        change relative to one another.\n",
      "    start : int, optional\n",
      "        When ``start <= axis``, the axis is rolled back until it lies in\n",
      "        this position. When ``start > axis``, the axis is rolled until it\n",
      "        lies before this position. The default, 0, results in a \"complete\"\n",
      "        roll. The following table describes how negative values of ``start``\n",
      "        are interpreted:\n",
      "\n",
      "        .. table::\n",
      "           :align: left\n",
      "\n",
      "           +-------------------+----------------------+\n",
      "           |     ``start``     | Normalized ``start`` |\n",
      "           +===================+======================+\n",
      "           | ``-(arr.ndim+1)`` | raise ``AxisError``  |\n",
      "           +-------------------+----------------------+\n",
      "           | ``-arr.ndim``     | 0                    |\n",
      "           +-------------------+----------------------+\n",
      "           | |vdots|           | |vdots|              |\n",
      "           +-------------------+----------------------+\n",
      "           | ``-1``            | ``arr.ndim-1``       |\n",
      "           +-------------------+----------------------+\n",
      "           | ``0``             | ``0``                |\n",
      "           +-------------------+----------------------+\n",
      "           | |vdots|           | |vdots|              |\n",
      "           +-------------------+----------------------+\n",
      "           | ``arr.ndim``      | ``arr.ndim``         |\n",
      "           +-------------------+----------------------+\n",
      "           | ``arr.ndim + 1``  | raise ``AxisError``  |\n",
      "           +-------------------+----------------------+\n",
      "           \n",
      "        .. |vdots|   unicode:: U+22EE .. Vertical Ellipsis\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    res : ndarray\n",
      "        For NumPy >= 1.10.0 a view of `a` is always returned. For earlier\n",
      "        NumPy versions a view of `a` is returned only if the order of the\n",
      "        axes is changed, otherwise the input array is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    moveaxis : Move array axes to new positions.\n",
      "    roll : Roll the elements of an array by a number of positions along a\n",
      "        given axis.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.ones((3,4,5,6))\n",
      "    >>> np.rollaxis(a, 3, 1).shape\n",
      "    (3, 6, 4, 5)\n",
      "    >>> np.rollaxis(a, 2).shape\n",
      "    (5, 3, 4, 6)\n",
      "    >>> np.rollaxis(a, 1, 4).shape\n",
      "    (3, 5, 6, 4)\n",
      "\n",
      "    \n",
      "code: moveaxis\n",
      "@array_function_dispatch(_moveaxis_dispatcher)\n",
      "def moveaxis(a, source, destination):\n",
      "    try:\n",
      "        # allow duck-array types if they define transpose\n",
      "        transpose = a.transpose\n",
      "    except AttributeError:\n",
      "        a = asarray(a)\n",
      "        transpose = a.transpose\n",
      "    source = normalize_axis_tuple(source, a.ndim, 'source')\n",
      "    destination = normalize_axis_tuple(destination, a.ndim, 'destination')\n",
      "    if len(source) != len(destination):\n",
      "        raise ValueError('`source` and `destination` arguments must have '\n",
      "                         'the same number of elements')\n",
      "    order = [n for n in range(a.ndim) if n not in source]\n",
      "    for dest, src in sorted(zip(destination, source)):\n",
      "        order.insert(dest, src)\n",
      "    result = transpose(order)\n",
      "    return result\n",
      "docstring: moveaxis\n",
      "\n",
      "    Move axes of an array to new positions.\n",
      "\n",
      "    Other axes remain in their original order.\n",
      "\n",
      "    .. versionadded:: 1.11.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : np.ndarray\n",
      "        The array whose axes should be reordered.\n",
      "    source : int or sequence of int\n",
      "        Original positions of the axes to move. These must be unique.\n",
      "    destination : int or sequence of int\n",
      "        Destination positions for each of the original axes. These must also be\n",
      "        unique.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    result : np.ndarray\n",
      "        Array with moved axes. This array is a view of the input array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    transpose : Permute the dimensions of an array.\n",
      "    swapaxes : Interchange two axes of an array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.zeros((3, 4, 5))\n",
      "    >>> np.moveaxis(x, 0, -1).shape\n",
      "    (4, 5, 3)\n",
      "    >>> np.moveaxis(x, -1, 0).shape\n",
      "    (5, 3, 4)\n",
      "\n",
      "    These all achieve the same result:\n",
      "\n",
      "    >>> np.transpose(x).shape\n",
      "    (5, 4, 3)\n",
      "    >>> np.swapaxes(x, 0, -1).shape\n",
      "    (5, 4, 3)\n",
      "    >>> np.moveaxis(x, [0, 1], [-1, -2]).shape\n",
      "    (5, 4, 3)\n",
      "    >>> np.moveaxis(x, [0, 1, 2], [-1, -2, -3]).shape\n",
      "    (5, 4, 3)\n",
      "\n",
      "    \n",
      "code: cross\n",
      "@array_function_dispatch(_cross_dispatcher)\n",
      "def cross(a, b, axisa=-1, axisb=-1, axisc=-1, axis=None):\n",
      "    if axis is not None:\n",
      "        axisa, axisb, axisc = (axis,) * 3\n",
      "    a = asarray(a)\n",
      "    b = asarray(b)\n",
      " Move working axis to the end of the shape\n",
      "    a = moveaxis(a, axisa, -1)\n",
      "    b = moveaxis(b, axisb, -1)\n",
      "    msg = (\"incompatible dimensions for cross product\\n\"\n",
      "           \"(dimension must be 2 or 3)\")\n",
      "    if a.shape[-1] not in (2, 3) or b.shape[-1] not in (2, 3):\n",
      "        raise ValueError(msg)\n",
      " Check axisc is within bounds\n",
      "        axisc = normalize_axis_index(axisc, len(shape), msg_prefix='axisc')\n",
      "    dtype = promote_types(a.dtype, b.dtype)\n",
      "    cp = empty(shape, dtype)\n",
      " create local aliases for readability\n",
      "    a0 = a[..., 0]\n",
      "    a1 = a[..., 1]\n",
      "    if a.shape[-1] == 3:\n",
      "        a2 = a[..., 2]\n",
      "    b0 = b[..., 0]\n",
      "    b1 = b[..., 1]\n",
      "    if b.shape[-1] == 3:\n",
      "        b2 = b[..., 2]\n",
      "    if cp.ndim != 0 and cp.shape[-1] == 3:\n",
      "        cp0 = cp[..., 0]\n",
      "        cp1 = cp[..., 1]\n",
      "        cp2 = cp[..., 2]\n",
      "    if a.shape[-1] == 2:\n",
      "        if b.shape[-1] == 2:\n",
      " cp0 = a1 * b2 - 0  (a2 = 0)\n",
      " cp2 = a0 * b1 - a1 * b0\n",
      "            multiply(a1, b2, out=cp0)\n",
      "            multiply(a0, b2, out=cp1)\n",
      "            negative(cp1, out=cp1)\n",
      "            multiply(a0, b1, out=cp2)\n",
      "            cp2 -= a1 * b0\n",
      "    else:\n",
      "        assert a.shape[-1] == 3\n",
      "        if b.shape[-1] == 3:\n",
      " cp1 = a2 * b0 - a0 * b2\n",
      " cp0 = 0 - a2 * b1  (b2 = 0)\n",
      " cp2 = a0 * b1 - a1 * b0\n",
      "            multiply(a2, b1, out=cp0)\n",
      "            negative(cp0, out=cp0)\n",
      "            multiply(a2, b0, out=cp1)\n",
      "            multiply(a0, b1, out=cp2)\n",
      "            cp2 -= a1 * b0\n",
      "    return moveaxis(cp, -1, axisc)\n",
      "docstring: cross\n",
      "\n",
      "    Return the cross product of two (arrays of) vectors.\n",
      "\n",
      "    The cross product of `a` and `b` in :math:`R^3` is a vector perpendicular\n",
      "    to both `a` and `b`.  If `a` and `b` are arrays of vectors, the vectors\n",
      "    are defined by the last axis of `a` and `b` by default, and these axes\n",
      "    can have dimensions 2 or 3.  Where the dimension of either `a` or `b` is\n",
      "    2, the third component of the input vector is assumed to be zero and the\n",
      "    cross product calculated accordingly.  In cases where both input vectors\n",
      "    have dimension 2, the z-component of the cross product is returned.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Components of the first vector(s).\n",
      "    b : array_like\n",
      "        Components of the second vector(s).\n",
      "    axisa : int, optional\n",
      "        Axis of `a` that defines the vector(s).  By default, the last axis.\n",
      "    axisb : int, optional\n",
      "        Axis of `b` that defines the vector(s).  By default, the last axis.\n",
      "    axisc : int, optional\n",
      "        Axis of `c` containing the cross product vector(s).  Ignored if\n",
      "        both input vectors have dimension 2, as the return is scalar.\n",
      "        By default, the last axis.\n",
      "    axis : int, optional\n",
      "        If defined, the axis of `a`, `b` and `c` that defines the vector(s)\n",
      "        and cross product(s).  Overrides `axisa`, `axisb` and `axisc`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    c : ndarray\n",
      "        Vector cross product(s).\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        When the dimension of the vector(s) in `a` and/or `b` does not\n",
      "        equal 2 or 3.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    inner : Inner product\n",
      "    outer : Outer product.\n",
      "    ix_ : Construct index arrays.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.9.0\n",
      "\n",
      "    Supports full broadcasting of the inputs.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Vector cross-product.\n",
      "\n",
      "    >>> x = [1, 2, 3]\n",
      "    >>> y = [4, 5, 6]\n",
      "    >>> np.cross(x, y)\n",
      "    array([-3,  6, -3])\n",
      "\n",
      "    One vector with dimension 2.\n",
      "\n",
      "    >>> x = [1, 2]\n",
      "    >>> y = [4, 5, 6]\n",
      "    >>> np.cross(x, y)\n",
      "    array([12, -6, -3])\n",
      "\n",
      "    Equivalently:\n",
      "\n",
      "    >>> x = [1, 2, 0]\n",
      "    >>> y = [4, 5, 6]\n",
      "    >>> np.cross(x, y)\n",
      "    array([12, -6, -3])\n",
      "\n",
      "    Both vectors with dimension 2.\n",
      "\n",
      "    >>> x = [1,2]\n",
      "    >>> y = [4,5]\n",
      "    >>> np.cross(x, y)\n",
      "    array(-3)\n",
      "\n",
      "    Multiple vector cross-products. Note that the direction of the cross\n",
      "    product vector is defined by the *right-hand rule*.\n",
      "\n",
      "    >>> x = np.array([[1,2,3], [4,5,6]])\n",
      "    >>> y = np.array([[4,5,6], [1,2,3]])\n",
      "    >>> np.cross(x, y)\n",
      "    array([[-3,  6, -3],\n",
      "           [ 3, -6,  3]])\n",
      "\n",
      "    The orientation of `c` can be changed using the `axisc` keyword.\n",
      "\n",
      "    >>> np.cross(x, y, axisc=0)\n",
      "    array([[-3,  3],\n",
      "           [ 6, -6],\n",
      "           [-3,  3]])\n",
      "\n",
      "    Change the vector definition of `x` and `y` using `axisa` and `axisb`.\n",
      "\n",
      "    >>> x = np.array([[1,2,3], [4,5,6], [7, 8, 9]])\n",
      "    >>> y = np.array([[7, 8, 9], [4,5,6], [1,2,3]])\n",
      "    >>> np.cross(x, y)\n",
      "    array([[ -6,  12,  -6],\n",
      "           [  0,   0,   0],\n",
      "           [  6, -12,   6]])\n",
      "    >>> np.cross(x, y, axisa=0, axisb=0)\n",
      "    array([[-24,  48, -24],\n",
      "           [-30,  60, -30],\n",
      "           [-36,  72, -36]])\n",
      "\n",
      "    \n",
      "code: tensordot\n",
      "@array_function_dispatch(_tensordot_dispatcher)\n",
      "def tensordot(a, b, axes=2):\n",
      "    try:\n",
      "        iter(axes)\n",
      "    except Exception:\n",
      "        axes_a = list(range(-axes, 0))\n",
      "        axes_b = list(range(0, axes))\n",
      "    else:\n",
      "        axes_a, axes_b = axes\n",
      "    try:\n",
      "        na = len(axes_a)\n",
      "        axes_a = list(axes_a)\n",
      "    except TypeError:\n",
      "        axes_a = [axes_a]\n",
      "        na = 1\n",
      "    try:\n",
      "        nb = len(axes_b)\n",
      "        axes_b = list(axes_b)\n",
      "    except TypeError:\n",
      "        axes_b = [axes_b]\n",
      "        nb = 1\n",
      "    a, b = asarray(a), asarray(b)\n",
      "    as_ = a.shape\n",
      "    nda = a.ndim\n",
      "    bs = b.shape\n",
      "    ndb = b.ndim\n",
      "    equal = True\n",
      "    if na != nb:\n",
      "        equal = False\n",
      "    else:\n",
      "        for k in range(na):\n",
      "            if as_[axes_a[k]] != bs[axes_b[k]]:\n",
      "                equal = False\n",
      "                break\n",
      "            if axes_a[k] < 0:\n",
      "                axes_a[k] += nda\n",
      "            if axes_b[k] < 0:\n",
      "                axes_b[k] += ndb\n",
      "    if not equal:\n",
      "        raise ValueError(\"shape-mismatch for sum\")\n",
      " and to the front of \"b\"\n",
      "    notin = [k for k in range(nda) if k not in axes_a]\n",
      "    newaxes_a = notin + axes_a\n",
      "    N2 = 1\n",
      "    for axis in axes_a:\n",
      "        N2 *= as_[axis]\n",
      "    newshape_a = (int(multiply.reduce([as_[ax] for ax in notin])), N2)\n",
      "    olda = [as_[axis] for axis in notin]\n",
      "    notin = [k for k in range(ndb) if k not in axes_b]\n",
      "    newaxes_b = axes_b + notin\n",
      "    N2 = 1\n",
      "    for axis in axes_b:\n",
      "        N2 *= bs[axis]\n",
      "    newshape_b = (N2, int(multiply.reduce([bs[ax] for ax in notin])))\n",
      "    oldb = [bs[axis] for axis in notin]\n",
      "    at = a.transpose(newaxes_a).reshape(newshape_a)\n",
      "    bt = b.transpose(newaxes_b).reshape(newshape_b)\n",
      "    res = dot(at, bt)\n",
      "    return res.reshape(olda + oldb)\n",
      "docstring: tensordot\n",
      "\n",
      "    Compute tensor dot product along specified axes.\n",
      "\n",
      "    Given two tensors, `a` and `b`, and an array_like object containing\n",
      "    two array_like objects, ``(a_axes, b_axes)``, sum the products of\n",
      "    `a`'s and `b`'s elements (components) over the axes specified by\n",
      "    ``a_axes`` and ``b_axes``. The third argument can be a single non-negative\n",
      "    integer_like scalar, ``N``; if it is such, then the last ``N`` dimensions\n",
      "    of `a` and the first ``N`` dimensions of `b` are summed over.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a, b : array_like\n",
      "        Tensors to \"dot\".\n",
      "\n",
      "    axes : int or (2,) array_like\n",
      "        * integer_like\n",
      "          If an int N, sum over the last N axes of `a` and the first N axes\n",
      "          of `b` in order. The sizes of the corresponding axes must match.\n",
      "        * (2,) array_like\n",
      "          Or, a list of axes to be summed over, first sequence applying to `a`,\n",
      "          second to `b`. Both elements array_like must be of the same length.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        The tensor dot product of the input.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    dot, einsum\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Three common use cases are:\n",
      "        * ``axes = 0`` : tensor product :math:`a\\otimes b`\n",
      "        * ``axes = 1`` : tensor dot product :math:`a\\cdot b`\n",
      "        * ``axes = 2`` : (default) tensor double contraction :math:`a:b`\n",
      "\n",
      "    When `axes` is integer_like, the sequence for evaluation will be: first\n",
      "    the -Nth axis in `a` and 0th axis in `b`, and the -1th axis in `a` and\n",
      "    Nth axis in `b` last.\n",
      "\n",
      "    When there is more than one axis to sum over - and they are not the last\n",
      "    (first) axes of `a` (`b`) - the argument `axes` should consist of\n",
      "    two sequences of the same length, with the first axis to sum over given\n",
      "    first in both sequences, the second axis second, and so forth.\n",
      "\n",
      "    The shape of the result consists of the non-contracted axes of the\n",
      "    first tensor, followed by the non-contracted axes of the second.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    A \"traditional\" example:\n",
      "\n",
      "    >>> a = np.arange(60.).reshape(3,4,5)\n",
      "    >>> b = np.arange(24.).reshape(4,3,2)\n",
      "    >>> c = np.tensordot(a,b, axes=([1,0],[0,1]))\n",
      "    >>> c.shape\n",
      "    (5, 2)\n",
      "    >>> c\n",
      "    array([[4400., 4730.],\n",
      "           [4532., 4874.],\n",
      "           [4664., 5018.],\n",
      "           [4796., 5162.],\n",
      "           [4928., 5306.]])\n",
      "    >>> # A slower but equivalent way of computing the same...\n",
      "    >>> d = np.zeros((5,2))\n",
      "    >>> for i in range(5):\n",
      "    ...   for j in range(2):\n",
      "    ...     for k in range(3):\n",
      "    ...       for n in range(4):\n",
      "    ...         d[i,j] += a[k,n,i] * b[n,k,j]\n",
      "    >>> c == d\n",
      "    array([[ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True],\n",
      "           [ True,  True]])\n",
      "\n",
      "    An extended example taking advantage of the overloading of + and \\*:\n",
      "\n",
      "    >>> a = np.array(range(1, 9))\n",
      "    >>> a.shape = (2, 2, 2)\n",
      "    >>> A = np.array(('a', 'b', 'c', 'd'), dtype=object)\n",
      "    >>> A.shape = (2, 2)\n",
      "    >>> a; A\n",
      "    array([[[1, 2],\n",
      "            [3, 4]],\n",
      "           [[5, 6],\n",
      "            [7, 8]]])\n",
      "    array([['a', 'b'],\n",
      "           ['c', 'd']], dtype=object)\n",
      "\n",
      "    >>> np.tensordot(a, A) # third argument default is 2 for double-contraction\n",
      "    array(['abbcccdddd', 'aaaaabbbbbbcccccccdddddddd'], dtype=object)\n",
      "\n",
      "    >>> np.tensordot(a, A, 1)\n",
      "    array([[['acc', 'bdd'],\n",
      "            ['aaacccc', 'bbbdddd']],\n",
      "           [['aaaaacccccc', 'bbbbbdddddd'],\n",
      "            ['aaaaaaacccccccc', 'bbbbbbbdddddddd']]], dtype=object)\n",
      "\n",
      "    >>> np.tensordot(a, A, 0) # tensor product (result too long to incl.)\n",
      "    array([[[[['a', 'b'],\n",
      "              ['c', 'd']],\n",
      "              ...\n",
      "\n",
      "    >>> np.tensordot(a, A, (0, 1))\n",
      "    array([[['abbbbb', 'cddddd'],\n",
      "            ['aabbbbbb', 'ccdddddd']],\n",
      "           [['aaabbbbbbb', 'cccddddddd'],\n",
      "            ['aaaabbbbbbbb', 'ccccdddddddd']]], dtype=object)\n",
      "\n",
      "    >>> np.tensordot(a, A, (2, 1))\n",
      "    array([[['abb', 'cdd'],\n",
      "            ['aaabbbb', 'cccdddd']],\n",
      "           [['aaaaabbbbbb', 'cccccdddddd'],\n",
      "            ['aaaaaaabbbbbbbb', 'cccccccdddddddd']]], dtype=object)\n",
      "\n",
      "    >>> np.tensordot(a, A, ((0, 1), (0, 1)))\n",
      "    array(['abbbcccccddddddd', 'aabbbbccccccdddddddd'], dtype=object)\n",
      "\n",
      "    >>> np.tensordot(a, A, ((2, 1), (1, 0)))\n",
      "    array(['acccbbdddd', 'aaaaacccccccbbbbbbdddddddd'], dtype=object)\n",
      "\n",
      "    \n",
      "code: fromiter\n",
      "\n",
      "docstring: fromiter\n",
      "fromiter(iter, dtype, count=-1, *, like=None)\n",
      "\n",
      "    Create a new 1-dimensional array from an iterable object.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    iter : iterable object\n",
      "        An iterable object providing data for the array.\n",
      "    dtype : data-type\n",
      "        The data-type of the returned array.\n",
      "\n",
      "        .. versionchanged:: 1.23\n",
      "            Object and subarray dtypes are now supported (note that the final\n",
      "            result is not 1-D for a subarray dtype).\n",
      "\n",
      "    count : int, optional\n",
      "        The number of items to read from *iterable*.  The default is -1,\n",
      "        which means all data is read.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The output array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Specify `count` to improve performance.  It allows ``fromiter`` to\n",
      "    pre-allocate the output array, instead of resizing it on demand.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> iterable = (x*x for x in range(5))\n",
      "    >>> np.fromiter(iterable, float)\n",
      "    array([  0.,   1.,   4.,   9.,  16.])\n",
      "\n",
      "    A carefully constructed subarray dtype will lead to higher dimensional\n",
      "    results:\n",
      "\n",
      "    >>> iterable = ((x+1, x+2) for x in range(5))\n",
      "    >>> np.fromiter(iterable, dtype=np.dtype((int, 2)))\n",
      "    array([[1, 2],\n",
      "           [2, 3],\n",
      "           [3, 4],\n",
      "           [4, 5],\n",
      "           [5, 6]])\n",
      "code: array_equal\n",
      "@array_function_dispatch(_array_equal_dispatcher)\n",
      "def array_equal(a1, a2, equal_nan=False):\n",
      "    try:\n",
      "        a1, a2 = asarray(a1), asarray(a2)\n",
      "    except Exception:\n",
      "        return False\n",
      "    if a1.shape != a2.shape:\n",
      "        return False\n",
      "    if not equal_nan:\n",
      "        return bool(asarray(a1 == a2).all())\n",
      " NaN's occur at different locations\n",
      "    if not (a1nan == a2nan).all():\n",
      "        return False\n",
      "    # Shapes of a1, a2 and masks are guaranteed to be consistent by this point\n",
      "    return bool(asarray(a1[~a1nan] == a2[~a1nan]).all())\n",
      "docstring: array_equal\n",
      "\n",
      "    True if two arrays have the same shape and elements, False otherwise.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2 : array_like\n",
      "        Input arrays.\n",
      "    equal_nan : bool\n",
      "        Whether to compare NaN's as equal. If the dtype of a1 and a2 is\n",
      "        complex, values will be considered equal if either the real or the\n",
      "        imaginary component of a given value is ``nan``.\n",
      "\n",
      "        .. versionadded:: 1.19.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    b : bool\n",
      "        Returns True if the arrays are equal.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    allclose: Returns True if two arrays are element-wise equal within a\n",
      "              tolerance.\n",
      "    array_equiv: Returns True if input arrays are shape consistent and all\n",
      "                 elements equal.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.array_equal([1, 2], [1, 2])\n",
      "    True\n",
      "    >>> np.array_equal(np.array([1, 2]), np.array([1, 2]))\n",
      "    True\n",
      "    >>> np.array_equal([1, 2], [1, 2, 3])\n",
      "    False\n",
      "    >>> np.array_equal([1, 2], [1, 4])\n",
      "    False\n",
      "    >>> a = np.array([1, np.nan])\n",
      "    >>> np.array_equal(a, a)\n",
      "    False\n",
      "    >>> np.array_equal(a, a, equal_nan=True)\n",
      "    True\n",
      "\n",
      "    When ``equal_nan`` is True, complex values with nan components are\n",
      "    considered equal if either the real *or* the imaginary components are nan.\n",
      "\n",
      "    >>> a = np.array([1 + 1j])\n",
      "    >>> b = a.copy()\n",
      "    >>> a.real = np.nan\n",
      "    >>> b.imag = np.nan\n",
      "    >>> np.array_equal(a, b, equal_nan=True)\n",
      "    True\n",
      "    \n",
      "code: array_equiv\n",
      "@array_function_dispatch(_array_equiv_dispatcher)\n",
      "def array_equiv(a1, a2):\n",
      "    try:\n",
      "        a1, a2 = asarray(a1), asarray(a2)\n",
      "    except Exception:\n",
      "        return False\n",
      "    try:\n",
      "        multiarray.broadcast(a1, a2)\n",
      "    except Exception:\n",
      "        return False\n",
      "    return bool(asarray(a1 == a2).all())\n",
      "docstring: array_equiv\n",
      "\n",
      "    Returns True if input arrays are shape consistent and all elements equal.\n",
      "\n",
      "    Shape consistent means they are either the same shape, or one input array\n",
      "    can be broadcasted to create the same shape as the other one.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2 : array_like\n",
      "        Input arrays.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "        True if equivalent, False otherwise.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.array_equiv([1, 2], [1, 2])\n",
      "    True\n",
      "    >>> np.array_equiv([1, 2], [1, 3])\n",
      "    False\n",
      "\n",
      "    Showing the shape equivalence:\n",
      "\n",
      "    >>> np.array_equiv([1, 2], [[1, 2], [1, 2]])\n",
      "    True\n",
      "    >>> np.array_equiv([1, 2], [[1, 2, 1, 2], [1, 2, 1, 2]])\n",
      "    False\n",
      "\n",
      "    >>> np.array_equiv([1, 2], [[1, 2], [1, 3]])\n",
      "    False\n",
      "\n",
      "    \n",
      "code: indices\n",
      "@set_module('numpy')\n",
      "def indices(dimensions, dtype=int, sparse=False):\n",
      "    dimensions = tuple(dimensions)\n",
      "    N = len(dimensions)\n",
      "    shape = (1,)*N\n",
      "    if sparse:\n",
      "        res = tuple()\n",
      "    else:\n",
      "        res = empty((N,)+dimensions, dtype=dtype)\n",
      "    for i, dim in enumerate(dimensions):\n",
      "        idx = arange(dim, dtype=dtype).reshape(\n",
      "            shape[:i] + (dim,) + shape[i+1:]\n",
      "        )\n",
      "        if sparse:\n",
      "            res = res + (idx,)\n",
      "        else:\n",
      "            res[i] = idx\n",
      "    return res\n",
      "docstring: indices\n",
      "\n",
      "    Return an array representing the indices of a grid.\n",
      "\n",
      "    Compute an array where the subarrays contain index values 0, 1, ...\n",
      "    varying only along the corresponding axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    dimensions : sequence of ints\n",
      "        The shape of the grid.\n",
      "    dtype : dtype, optional\n",
      "        Data type of the result.\n",
      "    sparse : boolean, optional\n",
      "        Return a sparse representation of the grid instead of a dense\n",
      "        representation. Default is False.\n",
      "\n",
      "        .. versionadded:: 1.17\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    grid : one ndarray or tuple of ndarrays\n",
      "        If sparse is False:\n",
      "            Returns one array of grid indices,\n",
      "            ``grid.shape = (len(dimensions),) + tuple(dimensions)``.\n",
      "        If sparse is True:\n",
      "            Returns a tuple of arrays, with\n",
      "            ``grid[i].shape = (1, ..., 1, dimensions[i], 1, ..., 1)`` with\n",
      "            dimensions[i] in the ith place\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    mgrid, ogrid, meshgrid\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The output shape in the dense case is obtained by prepending the number\n",
      "    of dimensions in front of the tuple of dimensions, i.e. if `dimensions`\n",
      "    is a tuple ``(r0, ..., rN-1)`` of length ``N``, the output shape is\n",
      "    ``(N, r0, ..., rN-1)``.\n",
      "\n",
      "    The subarrays ``grid[k]`` contains the N-D array of indices along the\n",
      "    ``k-th`` axis. Explicitly::\n",
      "\n",
      "        grid[k, i0, i1, ..., iN-1] = ik\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> grid = np.indices((2, 3))\n",
      "    >>> grid.shape\n",
      "    (2, 2, 3)\n",
      "    >>> grid[0]        # row indices\n",
      "    array([[0, 0, 0],\n",
      "           [1, 1, 1]])\n",
      "    >>> grid[1]        # column indices\n",
      "    array([[0, 1, 2],\n",
      "           [0, 1, 2]])\n",
      "\n",
      "    The indices can be used as an index into an array.\n",
      "\n",
      "    >>> x = np.arange(20).reshape(5, 4)\n",
      "    >>> row, col = np.indices((2, 3))\n",
      "    >>> x[row, col]\n",
      "    array([[0, 1, 2],\n",
      "           [4, 5, 6]])\n",
      "\n",
      "    Note that it would be more straightforward in the above example to\n",
      "    extract the required elements directly with ``x[:2, :3]``.\n",
      "\n",
      "    If sparse is set to true, the grid will be returned in a sparse\n",
      "    representation.\n",
      "\n",
      "    >>> i, j = np.indices((2, 3), sparse=True)\n",
      "    >>> i.shape\n",
      "    (2, 1)\n",
      "    >>> j.shape\n",
      "    (1, 3)\n",
      "    >>> i        # row indices\n",
      "    array([[0],\n",
      "           [1]])\n",
      "    >>> j        # column indices\n",
      "    array([[0, 1, 2]])\n",
      "\n",
      "    \n",
      "code: fromfunction\n",
      "@set_array_function_like_doc\n",
      "@set_module('numpy')\n",
      "def fromfunction(function, shape, *, dtype=float, like=None, **kwargs):\n",
      "    if like is not None:\n",
      "        return _fromfunction_with_like(function, shape, dtype=dtype, like=like, **kwargs)\n",
      "    args = indices(shape, dtype=dtype)\n",
      "    return function(*args, **kwargs)\n",
      "docstring: fromfunction\n",
      "\n",
      "    Construct an array by executing a function over each coordinate.\n",
      "\n",
      "    The resulting array therefore has a value ``fn(x, y, z)`` at\n",
      "    coordinate ``(x, y, z)``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    function : callable\n",
      "        The function is called with N parameters, where N is the rank of\n",
      "        `shape`.  Each parameter represents the coordinates of the array\n",
      "        varying along a specific axis.  For example, if `shape`\n",
      "        were ``(2, 2)``, then the parameters would be\n",
      "        ``array([[0, 0], [1, 1]])`` and ``array([[0, 1], [0, 1]])``\n",
      "    shape : (N,) tuple of ints\n",
      "        Shape of the output array, which also determines the shape of\n",
      "        the coordinate arrays passed to `function`.\n",
      "    dtype : data-type, optional\n",
      "        Data-type of the coordinate arrays passed to `function`.\n",
      "        By default, `dtype` is float.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    fromfunction : any\n",
      "        The result of the call to `function` is passed back directly.\n",
      "        Therefore the shape of `fromfunction` is completely determined by\n",
      "        `function`.  If `function` returns a scalar value, the shape of\n",
      "        `fromfunction` would not match the `shape` parameter.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    indices, meshgrid\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Keywords other than `dtype` and `like` are passed to `function`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.fromfunction(lambda i, j: i, (2, 2), dtype=float)\n",
      "    array([[0., 0.],\n",
      "           [1., 1.]])\n",
      "           \n",
      "    >>> np.fromfunction(lambda i, j: j, (2, 2), dtype=float)    \n",
      "    array([[0., 1.],\n",
      "           [0., 1.]])\n",
      "           \n",
      "    >>> np.fromfunction(lambda i, j: i == j, (3, 3), dtype=int)\n",
      "    array([[ True, False, False],\n",
      "           [False,  True, False],\n",
      "           [False, False,  True]])\n",
      "\n",
      "    >>> np.fromfunction(lambda i, j: i + j, (3, 3), dtype=int)\n",
      "    array([[0, 1, 2],\n",
      "           [1, 2, 3],\n",
      "           [2, 3, 4]])\n",
      "\n",
      "    \n",
      "code: isclose\n",
      "@array_function_dispatch(_isclose_dispatcher)\n",
      "def isclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):\n",
      "    def within_tol(x, y, atol, rtol):\n",
      "        with errstate(invalid='ignore'), _no_nep50_warning():\n",
      "            return less_equal(abs(x-y), atol + rtol * abs(y))\n",
      "    x = asanyarray(a)\n",
      "    y = asanyarray(b)\n",
      " This will cause casting of x later. Also, make sure to allow subclasses\n",
      " NOTE: We explicitly allow timedelta, which used to work. This could\n",
      "       timedelta works if `atol` is an integer or also a timedelta.\n",
      " Because we're using boolean indexing, x & y must be the same shape.\n",
      " lib.stride_tricks, though, so we can't import it here.\n",
      "        x = x * ones_like(cond)\n",
      "        y = y * ones_like(cond)\n",
      " Check for equality of infinite values...\n",
      "        cond[~finite] = (x[~finite] == y[~finite])\n",
      "        if equal_nan:\n",
      " Needed to treat masked arrays correctly. = True would not work.\n",
      "            cond[both_nan] = both_nan[both_nan]\n",
      "        return cond[()]  # Flatten 0d arrays to scalars\n",
      "docstring: isclose\n",
      "\n",
      "    Returns a boolean array where two arrays are element-wise equal within a\n",
      "    tolerance.\n",
      "\n",
      "    The tolerance values are positive, typically very small numbers.  The\n",
      "    relative difference (`rtol` * abs(`b`)) and the absolute difference\n",
      "    `atol` are added together to compare against the absolute difference\n",
      "    between `a` and `b`.\n",
      "\n",
      "    .. warning:: The default `atol` is not appropriate for comparing numbers\n",
      "                 that are much smaller than one (see Notes).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a, b : array_like\n",
      "        Input arrays to compare.\n",
      "    rtol : float\n",
      "        The relative tolerance parameter (see Notes).\n",
      "    atol : float\n",
      "        The absolute tolerance parameter (see Notes).\n",
      "    equal_nan : bool\n",
      "        Whether to compare NaN's as equal.  If True, NaN's in `a` will be\n",
      "        considered equal to NaN's in `b` in the output array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    y : array_like\n",
      "        Returns a boolean array of where `a` and `b` are equal within the\n",
      "        given tolerance. If both `a` and `b` are scalars, returns a single\n",
      "        boolean value.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    allclose\n",
      "    math.isclose\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.7.0\n",
      "\n",
      "    For finite values, isclose uses the following equation to test whether\n",
      "    two floating point values are equivalent.\n",
      "\n",
      "     absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))\n",
      "\n",
      "    Unlike the built-in `math.isclose`, the above equation is not symmetric\n",
      "    in `a` and `b` -- it assumes `b` is the reference value -- so that\n",
      "    `isclose(a, b)` might be different from `isclose(b, a)`. Furthermore,\n",
      "    the default value of atol is not zero, and is used to determine what\n",
      "    small values should be considered close to zero. The default value is\n",
      "    appropriate for expected values of order unity: if the expected values\n",
      "    are significantly smaller than one, it can result in false positives.\n",
      "    `atol` should be carefully selected for the use case at hand. A zero value\n",
      "    for `atol` will result in `False` if either `a` or `b` is zero.\n",
      "\n",
      "    `isclose` is not defined for non-numeric data types.\n",
      "    `bool` is considered a numeric data-type for this purpose.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.isclose([1e10,1e-7], [1.00001e10,1e-8])\n",
      "    array([ True, False])\n",
      "    >>> np.isclose([1e10,1e-8], [1.00001e10,1e-9])\n",
      "    array([ True, True])\n",
      "    >>> np.isclose([1e10,1e-8], [1.0001e10,1e-9])\n",
      "    array([False,  True])\n",
      "    >>> np.isclose([1.0, np.nan], [1.0, np.nan])\n",
      "    array([ True, False])\n",
      "    >>> np.isclose([1.0, np.nan], [1.0, np.nan], equal_nan=True)\n",
      "    array([ True, True])\n",
      "    >>> np.isclose([1e-8, 1e-7], [0.0, 0.0])\n",
      "    array([ True, False])\n",
      "    >>> np.isclose([1e-100, 1e-7], [0.0, 0.0], atol=0.0)\n",
      "    array([False, False])\n",
      "    >>> np.isclose([1e-10, 1e-10], [1e-20, 0.0])\n",
      "    array([ True,  True])\n",
      "    >>> np.isclose([1e-10, 1e-10], [1e-20, 0.999999e-10], atol=0.0)\n",
      "    array([False,  True])\n",
      "    \n",
      "code: isscalar\n",
      "@set_module('numpy')\n",
      "def isscalar(element):\n",
      "    return (isinstance(element, generic)\n",
      "            or type(element) in ScalarType\n",
      "            or isinstance(element, numbers.Number))\n",
      "docstring: isscalar\n",
      "\n",
      "    Returns True if the type of `element` is a scalar type.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    element : any\n",
      "        Input argument, can be of any type and shape.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    val : bool\n",
      "        True if `element` is a scalar type, False if it is not.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndim : Get the number of dimensions of an array\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    If you need a stricter way to identify a *numerical* scalar, use\n",
      "    ``isinstance(x, numbers.Number)``, as that returns ``False`` for most\n",
      "    non-numerical elements such as strings.\n",
      "\n",
      "    In most cases ``np.ndim(x) == 0`` should be used instead of this function,\n",
      "    as that will also return true for 0d arrays. This is how numpy overloads\n",
      "    functions in the style of the ``dx`` arguments to `gradient` and the ``bins``\n",
      "    argument to `histogram`. Some key differences:\n",
      "\n",
      "    +--------------------------------------+---------------+-------------------+\n",
      "    | x                                    |``isscalar(x)``|``np.ndim(x) == 0``|\n",
      "    +======================================+===============+===================+\n",
      "    | PEP 3141 numeric objects (including  | ``True``      | ``True``          |\n",
      "    | builtins)                            |               |                   |\n",
      "    +--------------------------------------+---------------+-------------------+\n",
      "    | builtin string and buffer objects    | ``True``      | ``True``          |\n",
      "    +--------------------------------------+---------------+-------------------+\n",
      "    | other builtin objects, like          | ``False``     | ``True``          |\n",
      "    | `pathlib.Path`, `Exception`,         |               |                   |\n",
      "    | the result of `re.compile`           |               |                   |\n",
      "    +--------------------------------------+---------------+-------------------+\n",
      "    | third-party objects like             | ``False``     | ``True``          |\n",
      "    | `matplotlib.figure.Figure`           |               |                   |\n",
      "    +--------------------------------------+---------------+-------------------+\n",
      "    | zero-dimensional numpy arrays        | ``False``     | ``True``          |\n",
      "    +--------------------------------------+---------------+-------------------+\n",
      "    | other numpy arrays                   | ``False``     | ``False``         |\n",
      "    +--------------------------------------+---------------+-------------------+\n",
      "    | `list`, `tuple`, and other sequence  | ``False``     | ``False``         |\n",
      "    | objects                              |               |                   |\n",
      "    +--------------------------------------+---------------+-------------------+\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.isscalar(3.1)\n",
      "    True\n",
      "    >>> np.isscalar(np.array(3.1))\n",
      "    False\n",
      "    >>> np.isscalar([3.1])\n",
      "    False\n",
      "    >>> np.isscalar(False)\n",
      "    True\n",
      "    >>> np.isscalar('numpy')\n",
      "    True\n",
      "\n",
      "    NumPy supports PEP 3141 numbers:\n",
      "\n",
      "    >>> from fractions import Fraction\n",
      "    >>> np.isscalar(Fraction(5, 17))\n",
      "    True\n",
      "    >>> from numbers import Number\n",
      "    >>> np.isscalar(Number())\n",
      "    True\n",
      "\n",
      "    \n",
      "code: binary_repr\n",
      "@set_module('numpy')\n",
      "def binary_repr(num, width=None):\n",
      "    def warn_if_insufficient(width, binwidth):\n",
      "        if width is not None and width < binwidth:\n",
      "            warnings.warn(\n",
      "                \"Insufficient bit width provided. This behavior \"\n",
      "                \"will raise an error in the future.\", DeprecationWarning,\n",
      "                stacklevel=3)\n",
      " casts to floating point.\n",
      "    num = operator.index(num)\n",
      "    if num == 0:\n",
      "        return '0' * (width or 1)\n",
      "    elif num > 0:\n",
      "        binary = bin(num)[2:]\n",
      "        binwidth = len(binary)\n",
      "        outwidth = (binwidth if width is None\n",
      "                    else max(binwidth, width))\n",
      "        warn_if_insufficient(width, binwidth)\n",
      "        return binary.zfill(outwidth)\n",
      "    else:\n",
      "        if width is None:\n",
      "            return '-' + bin(-num)[2:]\n",
      "        else:\n",
      "            poswidth = len(bin(-num)[2:])\n",
      " for numbers at boundaries.\n",
      "            if 2**(poswidth - 1) == -num:\n",
      "                poswidth -= 1\n",
      "            twocomp = 2**(poswidth + 1) + num\n",
      "            binary = bin(twocomp)[2:]\n",
      "            binwidth = len(binary)\n",
      "            outwidth = max(binwidth, width)\n",
      "            warn_if_insufficient(width, binwidth)\n",
      "            return '1' * (outwidth - binwidth) + binary\n",
      "docstring: binary_repr\n",
      "\n",
      "    Return the binary representation of the input number as a string.\n",
      "\n",
      "    For negative numbers, if width is not given, a minus sign is added to the\n",
      "    front. If width is given, the two's complement of the number is\n",
      "    returned, with respect to that width.\n",
      "\n",
      "    In a two's-complement system negative numbers are represented by the two's\n",
      "    complement of the absolute value. This is the most common method of\n",
      "    representing signed integers on computers [1]_. A N-bit two's-complement\n",
      "    system can represent every integer in the range\n",
      "    :math:`-2^{N-1}` to :math:`+2^{N-1}-1`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    num : int\n",
      "        Only an integer decimal number can be used.\n",
      "    width : int, optional\n",
      "        The length of the returned string if `num` is positive, or the length\n",
      "        of the two's complement if `num` is negative, provided that `width` is\n",
      "        at least a sufficient number of bits for `num` to be represented in the\n",
      "        designated form.\n",
      "\n",
      "        If the `width` value is insufficient, it will be ignored, and `num` will\n",
      "        be returned in binary (`num` > 0) or two's complement (`num` < 0) form\n",
      "        with its width equal to the minimum number of bits needed to represent\n",
      "        the number in the designated form. This behavior is deprecated and will\n",
      "        later raise an error.\n",
      "\n",
      "        .. deprecated:: 1.12.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    bin : str\n",
      "        Binary representation of `num` or two's complement of `num`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    base_repr: Return a string representation of a number in the given base\n",
      "               system.\n",
      "    bin: Python's built-in binary representation generator of an integer.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    `binary_repr` is equivalent to using `base_repr` with base 2, but about 25x\n",
      "    faster.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Wikipedia, \"Two's complement\",\n",
      "        https://en.wikipedia.org/wiki/Two's_complement\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.binary_repr(3)\n",
      "    '11'\n",
      "    >>> np.binary_repr(-3)\n",
      "    '-11'\n",
      "    >>> np.binary_repr(3, width=4)\n",
      "    '0011'\n",
      "\n",
      "    The two's complement is returned when the input number is negative and\n",
      "    width is specified:\n",
      "\n",
      "    >>> np.binary_repr(-3, width=3)\n",
      "    '101'\n",
      "    >>> np.binary_repr(-3, width=5)\n",
      "    '11101'\n",
      "\n",
      "    \n",
      "code: base_repr\n",
      "@set_module('numpy')\n",
      "def base_repr(number, base=2, padding=0):\n",
      "    digits = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
      "    if base > len(digits):\n",
      "        raise ValueError(\"Bases greater than 36 not handled in base_repr.\")\n",
      "    elif base < 2:\n",
      "        raise ValueError(\"Bases less than 2 not handled in base_repr.\")\n",
      "    num = abs(number)\n",
      "    res = []\n",
      "    while num:\n",
      "        res.append(digits[num % base])\n",
      "        num //= base\n",
      "    if padding:\n",
      "        res.append('0' * padding)\n",
      "    if number < 0:\n",
      "        res.append('-')\n",
      "    return ''.join(reversed(res or '0'))\n",
      "docstring: base_repr\n",
      "\n",
      "    Return a string representation of a number in the given base system.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    number : int\n",
      "        The value to convert. Positive and negative values are handled.\n",
      "    base : int, optional\n",
      "        Convert `number` to the `base` number system. The valid range is 2-36,\n",
      "        the default value is 2.\n",
      "    padding : int, optional\n",
      "        Number of zeros padded on the left. Default is 0 (no padding).\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : str\n",
      "        String representation of `number` in `base` system.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    binary_repr : Faster version of `base_repr` for base 2.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.base_repr(5)\n",
      "    '101'\n",
      "    >>> np.base_repr(6, 5)\n",
      "    '11'\n",
      "    >>> np.base_repr(7, base=5, padding=3)\n",
      "    '00012'\n",
      "\n",
      "    >>> np.base_repr(10, base=16)\n",
      "    'A'\n",
      "    >>> np.base_repr(32, base=16)\n",
      "    '20'\n",
      "\n",
      "    \n",
      "code: ones\n",
      "@set_array_function_like_doc\n",
      "@set_module('numpy')\n",
      "def ones(shape, dtype=None, order='C', *, like=None):\n",
      "    if like is not None:\n",
      "        return _ones_with_like(shape, dtype=dtype, order=order, like=like)\n",
      "    a = empty(shape, dtype, order)\n",
      "    multiarray.copyto(a, 1, casting='unsafe')\n",
      "    return a\n",
      "docstring: ones\n",
      "\n",
      "    Return a new array of given shape and type, filled with ones.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    shape : int or sequence of ints\n",
      "        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n",
      "    dtype : data-type, optional\n",
      "        The desired data-type for the array, e.g., `numpy.int8`.  Default is\n",
      "        `numpy.float64`.\n",
      "    order : {'C', 'F'}, optional, default: C\n",
      "        Whether to store multi-dimensional data in row-major\n",
      "        (C-style) or column-major (Fortran-style) order in\n",
      "        memory.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of ones with the given shape, dtype, and order.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ones_like : Return an array of ones with shape and type of input.\n",
      "    empty : Return a new uninitialized array.\n",
      "    zeros : Return a new array setting values to zero.\n",
      "    full : Return a new array of given shape filled with value.\n",
      "\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.ones(5)\n",
      "    array([1., 1., 1., 1., 1.])\n",
      "\n",
      "    >>> np.ones((5,), dtype=int)\n",
      "    array([1, 1, 1, 1, 1])\n",
      "\n",
      "    >>> np.ones((2, 1))\n",
      "    array([[1.],\n",
      "           [1.]])\n",
      "\n",
      "    >>> s = (2,2)\n",
      "    >>> np.ones(s)\n",
      "    array([[1.,  1.],\n",
      "           [1.,  1.]])\n",
      "\n",
      "    \n",
      "code: identity\n",
      "@set_array_function_like_doc\n",
      "@set_module('numpy')\n",
      "def identity(n, dtype=None, *, like=None):\n",
      "    if like is not None:\n",
      "        return _identity_with_like(n, dtype=dtype, like=like)\n",
      "    from numpy import eye\n",
      "    return eye(n, dtype=dtype, like=like)\n",
      "docstring: identity\n",
      "\n",
      "    Return the identity array.\n",
      "\n",
      "    The identity array is a square array with ones on\n",
      "    the main diagonal.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n : int\n",
      "        Number of rows (and columns) in `n` x `n` output.\n",
      "    dtype : data-type, optional\n",
      "        Data-type of the output.  Defaults to ``float``.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        `n` x `n` array with its main diagonal set to one,\n",
      "        and all other elements 0.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.identity(3)\n",
      "    array([[1.,  0.,  0.],\n",
      "           [0.,  1.,  0.],\n",
      "           [0.,  0.,  1.]])\n",
      "\n",
      "    \n",
      "code: allclose\n",
      "@array_function_dispatch(_allclose_dispatcher)\n",
      "def allclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):\n",
      "    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n",
      "    return bool(res)\n",
      "docstring: allclose\n",
      "\n",
      "    Returns True if two arrays are element-wise equal within a tolerance.\n",
      "\n",
      "    The tolerance values are positive, typically very small numbers.  The\n",
      "    relative difference (`rtol` * abs(`b`)) and the absolute difference\n",
      "    `atol` are added together to compare against the absolute difference\n",
      "    between `a` and `b`.\n",
      "\n",
      "    NaNs are treated as equal if they are in the same place and if\n",
      "    ``equal_nan=True``.  Infs are treated as equal if they are in the same\n",
      "    place and of the same sign in both arrays.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a, b : array_like\n",
      "        Input arrays to compare.\n",
      "    rtol : float\n",
      "        The relative tolerance parameter (see Notes).\n",
      "    atol : float\n",
      "        The absolute tolerance parameter (see Notes).\n",
      "    equal_nan : bool\n",
      "        Whether to compare NaN's as equal.  If True, NaN's in `a` will be\n",
      "        considered equal to NaN's in `b` in the output array.\n",
      "\n",
      "        .. versionadded:: 1.10.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    allclose : bool\n",
      "        Returns True if the two arrays are equal within the given\n",
      "        tolerance; False otherwise.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    isclose, all, any, equal\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    If the following equation is element-wise True, then allclose returns\n",
      "    True.\n",
      "\n",
      "     absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))\n",
      "\n",
      "    The above equation is not symmetric in `a` and `b`, so that\n",
      "    ``allclose(a, b)`` might be different from ``allclose(b, a)`` in\n",
      "    some rare cases.\n",
      "\n",
      "    The comparison of `a` and `b` uses standard broadcasting, which\n",
      "    means that `a` and `b` need not have the same shape in order for\n",
      "    ``allclose(a, b)`` to evaluate to True.  The same is true for\n",
      "    `equal` but not `array_equal`.\n",
      "\n",
      "    `allclose` is not defined for non-numeric data types.\n",
      "    `bool` is considered a numeric data-type for this purpose.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.allclose([1e10,1e-7], [1.00001e10,1e-8])\n",
      "    False\n",
      "    >>> np.allclose([1e10,1e-8], [1.00001e10,1e-9])\n",
      "    True\n",
      "    >>> np.allclose([1e10,1e-8], [1.0001e10,1e-9])\n",
      "    False\n",
      "    >>> np.allclose([1.0, np.nan], [1.0, np.nan])\n",
      "    False\n",
      "    >>> np.allclose([1.0, np.nan], [1.0, np.nan], equal_nan=True)\n",
      "    True\n",
      "\n",
      "    \n",
      "code: compare_chararrays\n",
      "\n",
      "docstring: compare_chararrays\n",
      "compare_chararrays(a1, a2, cmp, rstrip)\n",
      "\n",
      "    Performs element-wise comparison of two string arrays using the\n",
      "    comparison operator specified by `cmp_op`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2 : array_like\n",
      "        Arrays to be compared.\n",
      "    cmp : {\"<\", \"<=\", \"==\", \">=\", \">\", \"!=\"}\n",
      "        Type of comparison.\n",
      "    rstrip : Boolean\n",
      "        If True, the spaces at the end of Strings are removed before the comparison.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The output array of type Boolean with the same shape as a and b.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If `cmp_op` is not valid.\n",
      "    TypeError\n",
      "        If at least one of `a` or `b` is a non-string array\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([\"a\", \"b\", \"cde\"])\n",
      "    >>> b = np.array([\"a\", \"a\", \"dec\"])\n",
      "    >>> np.compare_chararrays(a, b, \">\", True)\n",
      "    array([False,  True, False])\n",
      "code: putmask\n",
      "\n",
      "docstring: putmask\n",
      "\n",
      "    putmask(a, mask, values)\n",
      "\n",
      "    Changes elements of an array based on conditional and input values.\n",
      "\n",
      "    Sets ``a.flat[n] = values[n]`` for each n where ``mask.flat[n]==True``.\n",
      "\n",
      "    If `values` is not the same size as `a` and `mask` then it will repeat.\n",
      "    This gives behavior different from ``a[mask] = values``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : ndarray\n",
      "        Target array.\n",
      "    mask : array_like\n",
      "        Boolean mask array. It has to be the same shape as `a`.\n",
      "    values : array_like\n",
      "        Values to put into `a` where `mask` is True. If `values` is smaller\n",
      "        than `a` it will be repeated.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    place, put, take, copyto\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(6).reshape(2, 3)\n",
      "    >>> np.putmask(x, x>2, x**2)\n",
      "    >>> x\n",
      "    array([[ 0,  1,  2],\n",
      "           [ 9, 16, 25]])\n",
      "\n",
      "    If `values` is smaller than `a` it is repeated:\n",
      "\n",
      "    >>> x = np.arange(5)\n",
      "    >>> np.putmask(x, x>1, [-33, -44])\n",
      "    >>> x\n",
      "    array([  0,   1, -33, -44, -33])\n",
      "\n",
      "    \n",
      "code: flatnonzero\n",
      "@array_function_dispatch(_flatnonzero_dispatcher)\n",
      "def flatnonzero(a):\n",
      "    return np.nonzero(np.ravel(a))[0]\n",
      "docstring: flatnonzero\n",
      "\n",
      "    Return indices that are non-zero in the flattened version of a.\n",
      "\n",
      "    This is equivalent to ``np.nonzero(np.ravel(a))[0]``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    res : ndarray\n",
      "        Output array, containing the indices of the elements of ``a.ravel()``\n",
      "        that are non-zero.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    nonzero : Return the indices of the non-zero elements of the input array.\n",
      "    ravel : Return a 1-D array containing the elements of the input array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(-2, 3)\n",
      "    >>> x\n",
      "    array([-2, -1,  0,  1,  2])\n",
      "    >>> np.flatnonzero(x)\n",
      "    array([0, 1, 3, 4])\n",
      "\n",
      "    Use the indices of the non-zero elements as an index array to extract\n",
      "    these elements:\n",
      "\n",
      "    >>> x.ravel()[np.flatnonzero(x)]\n",
      "    array([-2, -1,  1,  2])\n",
      "\n",
      "    \n",
      "code: full\n",
      "@set_array_function_like_doc\n",
      "@set_module('numpy')\n",
      "def full(shape, fill_value, dtype=None, order='C', *, like=None):\n",
      "    if like is not None:\n",
      "        return _full_with_like(shape, fill_value, dtype=dtype, order=order, like=like)\n",
      "    if dtype is None:\n",
      "        fill_value = asarray(fill_value)\n",
      "        dtype = fill_value.dtype\n",
      "    a = empty(shape, dtype, order)\n",
      "    multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "    return a\n",
      "docstring: full\n",
      "\n",
      "    Return a new array of given shape and type, filled with `fill_value`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    shape : int or sequence of ints\n",
      "        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n",
      "    fill_value : scalar or array_like\n",
      "        Fill value.\n",
      "    dtype : data-type, optional\n",
      "        The desired data-type for the array  The default, None, means\n",
      "         ``np.array(fill_value).dtype``.\n",
      "    order : {'C', 'F'}, optional\n",
      "        Whether to store multidimensional data in C- or Fortran-contiguous\n",
      "        (row- or column-wise) order in memory.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of `fill_value` with the given shape, dtype, and order.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    full_like : Return a new array with shape of input filled with value.\n",
      "    empty : Return a new uninitialized array.\n",
      "    ones : Return a new array setting values to one.\n",
      "    zeros : Return a new array setting values to zero.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.full((2, 2), np.inf)\n",
      "    array([[inf, inf],\n",
      "           [inf, inf]])\n",
      "    >>> np.full((2, 2), 10)\n",
      "    array([[10, 10],\n",
      "           [10, 10]])\n",
      "\n",
      "    >>> np.full((2, 2), [1, 2])\n",
      "    array([[1, 2],\n",
      "           [1, 2]])\n",
      "\n",
      "    \n",
      "code: full_like\n",
      "@array_function_dispatch(_full_like_dispatcher)\n",
      "def full_like(a, fill_value, dtype=None, order='K', subok=True, shape=None):\n",
      "    res = empty_like(a, dtype=dtype, order=order, subok=subok, shape=shape)\n",
      "    multiarray.copyto(res, fill_value, casting='unsafe')\n",
      "    return res\n",
      "docstring: full_like\n",
      "\n",
      "    Return a full array with the same shape and type as a given array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        The shape and data-type of `a` define these same attributes of\n",
      "        the returned array.\n",
      "    fill_value : array_like\n",
      "        Fill value.\n",
      "    dtype : data-type, optional\n",
      "        Overrides the data type of the result.\n",
      "    order : {'C', 'F', 'A', or 'K'}, optional\n",
      "        Overrides the memory layout of the result. 'C' means C-order,\n",
      "        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n",
      "        'C' otherwise. 'K' means match the layout of `a` as closely\n",
      "        as possible.\n",
      "    subok : bool, optional.\n",
      "        If True, then the newly created array will use the sub-class\n",
      "        type of `a`, otherwise it will be a base-class array. Defaults\n",
      "        to True.\n",
      "    shape : int or sequence of ints, optional.\n",
      "        Overrides the shape of the result. If order='K' and the number of\n",
      "        dimensions is unchanged, will try to keep order, otherwise,\n",
      "        order='C' is implied.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of `fill_value` with the same shape and type as `a`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    empty_like : Return an empty array with shape and type of input.\n",
      "    ones_like : Return an array of ones with shape and type of input.\n",
      "    zeros_like : Return an array of zeros with shape and type of input.\n",
      "    full : Return a new array of given shape filled with value.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(6, dtype=int)\n",
      "    >>> np.full_like(x, 1)\n",
      "    array([1, 1, 1, 1, 1, 1])\n",
      "    >>> np.full_like(x, 0.1)\n",
      "    array([0, 0, 0, 0, 0, 0])\n",
      "    >>> np.full_like(x, 0.1, dtype=np.double)\n",
      "    array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
      "    >>> np.full_like(x, np.nan, dtype=np.double)\n",
      "    array([nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "    >>> y = np.arange(6, dtype=np.double)\n",
      "    >>> np.full_like(y, 0.1)\n",
      "    array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
      "\n",
      "    >>> y = np.zeros([2, 2, 3], dtype=int)\n",
      "    >>> np.full_like(y, [0, 0, 255])\n",
      "    array([[[  0,   0, 255],\n",
      "            [  0,   0, 255]],\n",
      "           [[  0,   0, 255],\n",
      "            [  0,   0, 255]]])\n",
      "    \n",
      "code: shares_memory\n",
      "\n",
      "docstring: shares_memory\n",
      "\n",
      "    shares_memory(a, b, /, max_work=None)\n",
      "\n",
      "    Determine if two arrays share memory.\n",
      "\n",
      "    .. warning::\n",
      "\n",
      "       This function can be exponentially slow for some inputs, unless\n",
      "       `max_work` is set to a finite number or ``MAY_SHARE_BOUNDS``.\n",
      "       If in doubt, use `numpy.may_share_memory` instead.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a, b : ndarray\n",
      "        Input arrays\n",
      "    max_work : int, optional\n",
      "        Effort to spend on solving the overlap problem (maximum number\n",
      "        of candidate solutions to consider). The following special\n",
      "        values are recognized:\n",
      "\n",
      "        max_work=MAY_SHARE_EXACT  (default)\n",
      "            The problem is solved exactly. In this case, the function returns\n",
      "            True only if there is an element shared between the arrays. Finding\n",
      "            the exact solution may take extremely long in some cases.\n",
      "        max_work=MAY_SHARE_BOUNDS\n",
      "            Only the memory bounds of a and b are checked.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    numpy.TooHardError\n",
      "        Exceeded max_work.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    may_share_memory\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([1, 2, 3, 4])\n",
      "    >>> np.shares_memory(x, np.array([5, 6, 7]))\n",
      "    False\n",
      "    >>> np.shares_memory(x[::2], x)\n",
      "    True\n",
      "    >>> np.shares_memory(x[::2], x[1::2])\n",
      "    False\n",
      "\n",
      "    Checking whether two arrays share memory is NP-complete, and\n",
      "    runtime may increase exponentially in the number of\n",
      "    dimensions. Hence, `max_work` should generally be set to a finite\n",
      "    number, as it is possible to construct examples that take\n",
      "    extremely long to run:\n",
      "\n",
      "    >>> from numpy.lib.stride_tricks import as_strided\n",
      "    >>> x = np.zeros([192163377], dtype=np.int8)\n",
      "    >>> x1 = as_strided(x, strides=(36674, 61119, 85569), shape=(1049, 1049, 1049))\n",
      "    >>> x2 = as_strided(x[64023025:], strides=(12223, 12224, 1), shape=(1049, 1049, 1))\n",
      "    >>> np.shares_memory(x1, x2, max_work=1000)\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    numpy.TooHardError: Exceeded max_work\n",
      "\n",
      "    Running ``np.shares_memory(x1, x2)`` without `max_work` set takes\n",
      "    around 1 minute for this case. It is possible to find problems\n",
      "    that take still significantly longer.\n",
      "\n",
      "    \n",
      "code: may_share_memory\n",
      "\n",
      "docstring: may_share_memory\n",
      "\n",
      "    may_share_memory(a, b, /, max_work=None)\n",
      "\n",
      "    Determine if two arrays might share memory\n",
      "\n",
      "    A return of True does not necessarily mean that the two arrays\n",
      "    share any element.  It just means that they *might*.\n",
      "\n",
      "    Only the memory bounds of a and b are checked by default.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a, b : ndarray\n",
      "        Input arrays\n",
      "    max_work : int, optional\n",
      "        Effort to spend on solving the overlap problem.  See\n",
      "        `shares_memory` for details.  Default for ``may_share_memory``\n",
      "        is to do a bounds check.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    shares_memory\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.may_share_memory(np.array([1,2]), np.array([5,8,9]))\n",
      "    False\n",
      "    >>> x = np.zeros([3, 4])\n",
      "    >>> np.may_share_memory(x[:,0], x[:,1])\n",
      "    True\n",
      "\n",
      "    \n",
      "code: _get_promotion_state\n",
      "\n",
      "docstring: _get_promotion_state\n",
      "Get the current NEP 50 promotion state.\n",
      "code: _set_promotion_state\n",
      "\n",
      "docstring: _set_promotion_state\n",
      "Set the NEP 50 promotion state.  This is not thread-safe.\n",
      "The optional warnings can be safely silenced using the \n",
      "`np._no_nep50_warning()` context manager.\n",
      "code: all\n",
      "@array_function_dispatch(_all_dispatcher)\n",
      "def all(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):\n",
      "    return _wrapreduction(a, np.logical_and, 'all', axis, None, out,\n",
      "                          keepdims=keepdims, where=where)\n",
      "docstring: all\n",
      "\n",
      "    Test whether all array elements along a given axis evaluate to True.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array or object that can be converted to an array.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which a logical AND reduction is performed.\n",
      "        The default (``axis=None``) is to perform a logical AND over all\n",
      "        the dimensions of the input array. `axis` may be negative, in\n",
      "        which case it counts from the last to the first axis.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If this is a tuple of ints, a reduction is performed on multiple\n",
      "        axes, instead of a single axis or all the axes as before.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.\n",
      "        It must have the same shape as the expected output and its\n",
      "        type is preserved (e.g., if ``dtype(out)`` is float, the result\n",
      "        will consist of 0.0's and 1.0's). See :ref:`ufuncs-output-type` for more\n",
      "        details.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `all` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in checking for all `True` values.\n",
      "        See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    all : ndarray, bool\n",
      "        A new boolean or array is returned unless `out` is specified,\n",
      "        in which case a reference to `out` is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.all : equivalent method\n",
      "\n",
      "    any : Test whether any element along a given axis evaluates to True.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Not a Number (NaN), positive infinity and negative infinity\n",
      "    evaluate to `True` because these are not equal to zero.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.all([[True,False],[True,True]])\n",
      "    False\n",
      "\n",
      "    >>> np.all([[True,False],[True,True]], axis=0)\n",
      "    array([ True, False])\n",
      "\n",
      "    >>> np.all([-1, 4, 5])\n",
      "    True\n",
      "\n",
      "    >>> np.all([1.0, np.nan])\n",
      "    True\n",
      "\n",
      "    >>> np.all([[True, True], [False, True]], where=[[True], [False]])\n",
      "    True\n",
      "\n",
      "    >>> o=np.array(False)\n",
      "    >>> z=np.all([-1, 4, 5], out=o)\n",
      "    >>> id(z), id(o), z\n",
      "    (28293632, 28293632, array(True)) # may vary\n",
      "\n",
      "    \n",
      "code: alltrue\n",
      "@array_function_dispatch(_all_dispatcher, verify=False)\n",
      "def alltrue(*args, **kwargs):\n",
      "    return all(*args, **kwargs)\n",
      "docstring: alltrue\n",
      "\n",
      "    Check if all elements of input array are true.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.all : Equivalent function; see for details.\n",
      "    \n",
      "code: amax\n",
      "@array_function_dispatch(_amax_dispatcher)\n",
      "def amax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n",
      "         where=np._NoValue):\n",
      "    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n",
      "                          keepdims=keepdims, initial=initial, where=where)\n",
      "docstring: amax\n",
      "\n",
      "    Return the maximum of an array or maximum along an axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which to operate.  By default, flattened input is\n",
      "        used.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If this is a tuple of ints, the maximum is selected over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result.  Must\n",
      "        be of the same shape and buffer length as the expected output.\n",
      "        See :ref:`ufuncs-output-type` for more details.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `amax` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    initial : scalar, optional\n",
      "        The minimum value of an output element. Must be present to allow\n",
      "        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.15.0\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to compare for the maximum. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    amax : ndarray or scalar\n",
      "        Maximum of `a`. If `axis` is None, the result is a scalar value.\n",
      "        If `axis` is an int, the result is an array of dimension\n",
      "        ``a.ndim - 1``. If `axis` is a tuple, the result is an array of \n",
      "        dimension ``a.ndim - len(axis)``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    amin :\n",
      "        The minimum value of an array along a given axis, propagating any NaNs.\n",
      "    nanmax :\n",
      "        The maximum value of an array along a given axis, ignoring any NaNs.\n",
      "    maximum :\n",
      "        Element-wise maximum of two arrays, propagating any NaNs.\n",
      "    fmax :\n",
      "        Element-wise maximum of two arrays, ignoring any NaNs.\n",
      "    argmax :\n",
      "        Return the indices of the maximum values.\n",
      "\n",
      "    nanmin, minimum, fmin\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NaN values are propagated, that is if at least one item is NaN, the\n",
      "    corresponding max value will be NaN as well. To ignore NaN values\n",
      "    (MATLAB behavior), please use nanmax.\n",
      "\n",
      "    Don't use `amax` for element-wise comparison of 2 arrays; when\n",
      "    ``a.shape[0]`` is 2, ``maximum(a[0], a[1])`` is faster than\n",
      "    ``amax(a, axis=0)``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(4).reshape((2,2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3]])\n",
      "    >>> np.amax(a)           # Maximum of the flattened array\n",
      "    3\n",
      "    >>> np.amax(a, axis=0)   # Maxima along the first axis\n",
      "    array([2, 3])\n",
      "    >>> np.amax(a, axis=1)   # Maxima along the second axis\n",
      "    array([1, 3])\n",
      "    >>> np.amax(a, where=[False, True], initial=-1, axis=0)\n",
      "    array([-1,  3])\n",
      "    >>> b = np.arange(5, dtype=float)\n",
      "    >>> b[2] = np.NaN\n",
      "    >>> np.amax(b)\n",
      "    nan\n",
      "    >>> np.amax(b, where=~np.isnan(b), initial=-1)\n",
      "    4.0\n",
      "    >>> np.nanmax(b)\n",
      "    4.0\n",
      "\n",
      "    You can use an initial value to compute the maximum of an empty slice, or\n",
      "    to initialize it to a different value:\n",
      "\n",
      "    >>> np.amax([[-50], [10]], axis=-1, initial=0)\n",
      "    array([ 0, 10])\n",
      "\n",
      "    Notice that the initial value is used as one of the elements for which the\n",
      "    maximum is determined, unlike for the default argument Python's max\n",
      "    function, which is only used for empty iterables.\n",
      "\n",
      "    >>> np.amax([5], initial=6)\n",
      "    6\n",
      "    >>> max([5], default=6)\n",
      "    5\n",
      "    \n",
      "code: amin\n",
      "@array_function_dispatch(_amin_dispatcher)\n",
      "def amin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n",
      "         where=np._NoValue):\n",
      "    return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n",
      "                          keepdims=keepdims, initial=initial, where=where)\n",
      "docstring: amin\n",
      "\n",
      "    Return the minimum of an array or minimum along an axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which to operate.  By default, flattened input is\n",
      "        used.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If this is a tuple of ints, the minimum is selected over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result.  Must\n",
      "        be of the same shape and buffer length as the expected output.\n",
      "        See :ref:`ufuncs-output-type` for more details.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `amin` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    initial : scalar, optional\n",
      "        The maximum value of an output element. Must be present to allow\n",
      "        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.15.0\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to compare for the minimum. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    amin : ndarray or scalar\n",
      "        Minimum of `a`. If `axis` is None, the result is a scalar value.\n",
      "        If `axis` is an int, the result is an array of dimension\n",
      "        ``a.ndim - 1``.  If `axis` is a tuple, the result is an array of \n",
      "        dimension ``a.ndim - len(axis)``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    amax :\n",
      "        The maximum value of an array along a given axis, propagating any NaNs.\n",
      "    nanmin :\n",
      "        The minimum value of an array along a given axis, ignoring any NaNs.\n",
      "    minimum :\n",
      "        Element-wise minimum of two arrays, propagating any NaNs.\n",
      "    fmin :\n",
      "        Element-wise minimum of two arrays, ignoring any NaNs.\n",
      "    argmin :\n",
      "        Return the indices of the minimum values.\n",
      "\n",
      "    nanmax, maximum, fmax\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NaN values are propagated, that is if at least one item is NaN, the\n",
      "    corresponding min value will be NaN as well. To ignore NaN values\n",
      "    (MATLAB behavior), please use nanmin.\n",
      "\n",
      "    Don't use `amin` for element-wise comparison of 2 arrays; when\n",
      "    ``a.shape[0]`` is 2, ``minimum(a[0], a[1])`` is faster than\n",
      "    ``amin(a, axis=0)``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(4).reshape((2,2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3]])\n",
      "    >>> np.amin(a)           # Minimum of the flattened array\n",
      "    0\n",
      "    >>> np.amin(a, axis=0)   # Minima along the first axis\n",
      "    array([0, 1])\n",
      "    >>> np.amin(a, axis=1)   # Minima along the second axis\n",
      "    array([0, 2])\n",
      "    >>> np.amin(a, where=[False, True], initial=10, axis=0)\n",
      "    array([10,  1])\n",
      "\n",
      "    >>> b = np.arange(5, dtype=float)\n",
      "    >>> b[2] = np.NaN\n",
      "    >>> np.amin(b)\n",
      "    nan\n",
      "    >>> np.amin(b, where=~np.isnan(b), initial=10)\n",
      "    0.0\n",
      "    >>> np.nanmin(b)\n",
      "    0.0\n",
      "\n",
      "    >>> np.amin([[-50], [10]], axis=-1, initial=0)\n",
      "    array([-50,   0])\n",
      "\n",
      "    Notice that the initial value is used as one of the elements for which the\n",
      "    minimum is determined, unlike for the default argument Python's max\n",
      "    function, which is only used for empty iterables.\n",
      "\n",
      "    Notice that this isn't the same as Python's ``default`` argument.\n",
      "\n",
      "    >>> np.amin([6], initial=5)\n",
      "    5\n",
      "    >>> min([6], default=5)\n",
      "    6\n",
      "    \n",
      "code: any\n",
      "@array_function_dispatch(_any_dispatcher)\n",
      "def any(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):\n",
      "    return _wrapreduction(a, np.logical_or, 'any', axis, None, out,\n",
      "                          keepdims=keepdims, where=where)\n",
      "docstring: any\n",
      "\n",
      "    Test whether any array element along a given axis evaluates to True.\n",
      "\n",
      "    Returns single boolean if `axis` is ``None``\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array or object that can be converted to an array.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which a logical OR reduction is performed.\n",
      "        The default (``axis=None``) is to perform a logical OR over all\n",
      "        the dimensions of the input array. `axis` may be negative, in\n",
      "        which case it counts from the last to the first axis.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If this is a tuple of ints, a reduction is performed on multiple\n",
      "        axes, instead of a single axis or all the axes as before.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  It must have\n",
      "        the same shape as the expected output and its type is preserved\n",
      "        (e.g., if it is of type float, then it will remain so, returning\n",
      "        1.0 for True and 0.0 for False, regardless of the type of `a`).\n",
      "        See :ref:`ufuncs-output-type` for more details.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `any` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in checking for any `True` values.\n",
      "        See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    any : bool or ndarray\n",
      "        A new boolean or `ndarray` is returned unless `out` is specified,\n",
      "        in which case a reference to `out` is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.any : equivalent method\n",
      "\n",
      "    all : Test whether all elements along a given axis evaluate to True.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Not a Number (NaN), positive infinity and negative infinity evaluate\n",
      "    to `True` because these are not equal to zero.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.any([[True, False], [True, True]])\n",
      "    True\n",
      "\n",
      "    >>> np.any([[True, False], [False, False]], axis=0)\n",
      "    array([ True, False])\n",
      "\n",
      "    >>> np.any([-1, 0, 5])\n",
      "    True\n",
      "\n",
      "    >>> np.any(np.nan)\n",
      "    True\n",
      "\n",
      "    >>> np.any([[True, False], [False, False]], where=[[False], [True]])\n",
      "    False\n",
      "\n",
      "    >>> o=np.array(False)\n",
      "    >>> z=np.any([-1, 4, 5], out=o)\n",
      "    >>> z, o\n",
      "    (array(True), array(True))\n",
      "    >>> # Check now that z is a reference to o\n",
      "    >>> z is o\n",
      "    True\n",
      "    >>> id(z), id(o) # identity of z and o              # doctest: +SKIP\n",
      "    (191614240, 191614240)\n",
      "\n",
      "    \n",
      "code: argmax\n",
      "@array_function_dispatch(_argmax_dispatcher)\n",
      "def argmax(a, axis=None, out=None, *, keepdims=np._NoValue):\n",
      "    kwds = {'keepdims': keepdims} if keepdims is not np._NoValue else {}\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out, **kwds)\n",
      "docstring: argmax\n",
      "\n",
      "    Returns the indices of the maximum values along an axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axis : int, optional\n",
      "        By default, the index is into the flattened array, otherwise\n",
      "        along the specified axis.\n",
      "    out : array, optional\n",
      "        If provided, the result will be inserted into this array. It should\n",
      "        be of the appropriate shape and dtype.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the array.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    index_array : ndarray of ints\n",
      "        Array of indices into the array. It has the same shape as `a.shape`\n",
      "        with the dimension along `axis` removed. If `keepdims` is set to True,\n",
      "        then the size of `axis` will be 1 with the resulting array having same\n",
      "        shape as `a.shape`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.argmax, argmin\n",
      "    amax : The maximum value along a given axis.\n",
      "    unravel_index : Convert a flat index into an index tuple.\n",
      "    take_along_axis : Apply ``np.expand_dims(index_array, axis)``\n",
      "                      from argmax to an array as if by calling max.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    In case of multiple occurrences of the maximum values, the indices\n",
      "    corresponding to the first occurrence are returned.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(6).reshape(2,3) + 10\n",
      "    >>> a\n",
      "    array([[10, 11, 12],\n",
      "           [13, 14, 15]])\n",
      "    >>> np.argmax(a)\n",
      "    5\n",
      "    >>> np.argmax(a, axis=0)\n",
      "    array([1, 1, 1])\n",
      "    >>> np.argmax(a, axis=1)\n",
      "    array([2, 2])\n",
      "\n",
      "    Indexes of the maximal elements of a N-dimensional array:\n",
      "\n",
      "    >>> ind = np.unravel_index(np.argmax(a, axis=None), a.shape)\n",
      "    >>> ind\n",
      "    (1, 2)\n",
      "    >>> a[ind]\n",
      "    15\n",
      "\n",
      "    >>> b = np.arange(6)\n",
      "    >>> b[1] = 5\n",
      "    >>> b\n",
      "    array([0, 5, 2, 3, 4, 5])\n",
      "    >>> np.argmax(b)  # Only the first occurrence is returned.\n",
      "    1\n",
      "\n",
      "    >>> x = np.array([[4,2,3], [1,0,3]])\n",
      "    >>> index_array = np.argmax(x, axis=-1)\n",
      "    >>> # Same as np.amax(x, axis=-1, keepdims=True)\n",
      "    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)\n",
      "    array([[4],\n",
      "           [3]])\n",
      "    >>> # Same as np.amax(x, axis=-1)\n",
      "    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)\n",
      "    array([4, 3])\n",
      "\n",
      "    Setting `keepdims` to `True`,\n",
      "\n",
      "    >>> x = np.arange(24).reshape((2, 3, 4))\n",
      "    >>> res = np.argmax(x, axis=1, keepdims=True)\n",
      "    >>> res.shape\n",
      "    (2, 1, 4)\n",
      "    \n",
      "code: argmin\n",
      "@array_function_dispatch(_argmin_dispatcher)\n",
      "def argmin(a, axis=None, out=None, *, keepdims=np._NoValue):\n",
      "    kwds = {'keepdims': keepdims} if keepdims is not np._NoValue else {}\n",
      "    return _wrapfunc(a, 'argmin', axis=axis, out=out, **kwds)\n",
      "docstring: argmin\n",
      "\n",
      "    Returns the indices of the minimum values along an axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axis : int, optional\n",
      "        By default, the index is into the flattened array, otherwise\n",
      "        along the specified axis.\n",
      "    out : array, optional\n",
      "        If provided, the result will be inserted into this array. It should\n",
      "        be of the appropriate shape and dtype.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the array.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    index_array : ndarray of ints\n",
      "        Array of indices into the array. It has the same shape as `a.shape`\n",
      "        with the dimension along `axis` removed. If `keepdims` is set to True,\n",
      "        then the size of `axis` will be 1 with the resulting array having same\n",
      "        shape as `a.shape`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.argmin, argmax\n",
      "    amin : The minimum value along a given axis.\n",
      "    unravel_index : Convert a flat index into an index tuple.\n",
      "    take_along_axis : Apply ``np.expand_dims(index_array, axis)``\n",
      "                      from argmin to an array as if by calling min.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    In case of multiple occurrences of the minimum values, the indices\n",
      "    corresponding to the first occurrence are returned.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(6).reshape(2,3) + 10\n",
      "    >>> a\n",
      "    array([[10, 11, 12],\n",
      "           [13, 14, 15]])\n",
      "    >>> np.argmin(a)\n",
      "    0\n",
      "    >>> np.argmin(a, axis=0)\n",
      "    array([0, 0, 0])\n",
      "    >>> np.argmin(a, axis=1)\n",
      "    array([0, 0])\n",
      "\n",
      "    Indices of the minimum elements of a N-dimensional array:\n",
      "\n",
      "    >>> ind = np.unravel_index(np.argmin(a, axis=None), a.shape)\n",
      "    >>> ind\n",
      "    (0, 0)\n",
      "    >>> a[ind]\n",
      "    10\n",
      "\n",
      "    >>> b = np.arange(6) + 10\n",
      "    >>> b[4] = 10\n",
      "    >>> b\n",
      "    array([10, 11, 12, 13, 10, 15])\n",
      "    >>> np.argmin(b)  # Only the first occurrence is returned.\n",
      "    0\n",
      "\n",
      "    >>> x = np.array([[4,2,3], [1,0,3]])\n",
      "    >>> index_array = np.argmin(x, axis=-1)\n",
      "    >>> # Same as np.amin(x, axis=-1, keepdims=True)\n",
      "    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)\n",
      "    array([[2],\n",
      "           [0]])\n",
      "    >>> # Same as np.amax(x, axis=-1)\n",
      "    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)\n",
      "    array([2, 0])\n",
      "\n",
      "    Setting `keepdims` to `True`,\n",
      "\n",
      "    >>> x = np.arange(24).reshape((2, 3, 4))\n",
      "    >>> res = np.argmin(x, axis=1, keepdims=True)\n",
      "    >>> res.shape\n",
      "    (2, 1, 4)\n",
      "    \n",
      "code: argpartition\n",
      "@array_function_dispatch(_argpartition_dispatcher)\n",
      "def argpartition(a, kth, axis=-1, kind='introselect', order=None):\n",
      "    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n",
      "docstring: argpartition\n",
      "\n",
      "    Perform an indirect partition along the given axis using the\n",
      "    algorithm specified by the `kind` keyword. It returns an array of\n",
      "    indices of the same shape as `a` that index data along the given\n",
      "    axis in partitioned order.\n",
      "\n",
      "    .. versionadded:: 1.8.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to sort.\n",
      "    kth : int or sequence of ints\n",
      "        Element index to partition by. The k-th element will be in its\n",
      "        final sorted position and all smaller elements will be moved\n",
      "        before it and all larger elements behind it. The order of all\n",
      "        elements in the partitions is undefined. If provided with a\n",
      "        sequence of k-th it will partition all of them into their sorted\n",
      "        position at once.\n",
      "\n",
      "        .. deprecated:: 1.22.0\n",
      "            Passing booleans as index is deprecated.\n",
      "    axis : int or None, optional\n",
      "        Axis along which to sort. The default is -1 (the last axis). If\n",
      "        None, the flattened array is used.\n",
      "    kind : {'introselect'}, optional\n",
      "        Selection algorithm. Default is 'introselect'\n",
      "    order : str or list of str, optional\n",
      "        When `a` is an array with fields defined, this argument\n",
      "        specifies which fields to compare first, second, etc. A single\n",
      "        field can be specified as a string, and not all fields need be\n",
      "        specified, but unspecified fields will still be used, in the\n",
      "        order in which they come up in the dtype, to break ties.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    index_array : ndarray, int\n",
      "        Array of indices that partition `a` along the specified axis.\n",
      "        If `a` is one-dimensional, ``a[index_array]`` yields a partitioned `a`.\n",
      "        More generally, ``np.take_along_axis(a, index_array, axis=axis)``\n",
      "        always yields the partitioned `a`, irrespective of dimensionality.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    partition : Describes partition algorithms used.\n",
      "    ndarray.partition : Inplace partition.\n",
      "    argsort : Full indirect sort.\n",
      "    take_along_axis : Apply ``index_array`` from argpartition\n",
      "                      to an array as if by calling partition.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    See `partition` for notes on the different selection algorithms.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    One dimensional array:\n",
      "\n",
      "    >>> x = np.array([3, 4, 2, 1])\n",
      "    >>> x[np.argpartition(x, 3)]\n",
      "    array([2, 1, 3, 4])\n",
      "    >>> x[np.argpartition(x, (1, 3))]\n",
      "    array([1, 2, 3, 4])\n",
      "\n",
      "    >>> x = [3, 4, 2, 1]\n",
      "    >>> np.array(x)[np.argpartition(x, 3)]\n",
      "    array([2, 1, 3, 4])\n",
      "\n",
      "    Multi-dimensional array:\n",
      "\n",
      "    >>> x = np.array([[3, 4, 2], [1, 3, 1]])\n",
      "    >>> index_array = np.argpartition(x, kth=1, axis=-1)\n",
      "    >>> np.take_along_axis(x, index_array, axis=-1)  # same as np.partition(x, kth=1)\n",
      "    array([[2, 3, 4],\n",
      "           [1, 1, 3]])\n",
      "\n",
      "    \n",
      "code: argsort\n",
      "@array_function_dispatch(_argsort_dispatcher)\n",
      "def argsort(a, axis=-1, kind=None, order=None):\n",
      "    return _wrapfunc(a, 'argsort', axis=axis, kind=kind, order=order)\n",
      "docstring: argsort\n",
      "\n",
      "    Returns the indices that would sort an array.\n",
      "\n",
      "    Perform an indirect sort along the given axis using the algorithm specified\n",
      "    by the `kind` keyword. It returns an array of indices of the same shape as\n",
      "    `a` that index data along the given axis in sorted order.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to sort.\n",
      "    axis : int or None, optional\n",
      "        Axis along which to sort.  The default is -1 (the last axis). If None,\n",
      "        the flattened array is used.\n",
      "    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n",
      "        Sorting algorithm. The default is 'quicksort'. Note that both 'stable'\n",
      "        and 'mergesort' use timsort under the covers and, in general, the\n",
      "        actual implementation will vary with data type. The 'mergesort' option\n",
      "        is retained for backwards compatibility.\n",
      "\n",
      "        .. versionchanged:: 1.15.0.\n",
      "           The 'stable' option was added.\n",
      "    order : str or list of str, optional\n",
      "        When `a` is an array with fields defined, this argument specifies\n",
      "        which fields to compare first, second, etc.  A single field can\n",
      "        be specified as a string, and not all fields need be specified,\n",
      "        but unspecified fields will still be used, in the order in which\n",
      "        they come up in the dtype, to break ties.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    index_array : ndarray, int\n",
      "        Array of indices that sort `a` along the specified `axis`.\n",
      "        If `a` is one-dimensional, ``a[index_array]`` yields a sorted `a`.\n",
      "        More generally, ``np.take_along_axis(a, index_array, axis=axis)``\n",
      "        always yields the sorted `a`, irrespective of dimensionality.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    sort : Describes sorting algorithms used.\n",
      "    lexsort : Indirect stable sort with multiple keys.\n",
      "    ndarray.sort : Inplace sort.\n",
      "    argpartition : Indirect partial sort.\n",
      "    take_along_axis : Apply ``index_array`` from argsort\n",
      "                      to an array as if by calling sort.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    See `sort` for notes on the different sorting algorithms.\n",
      "\n",
      "    As of NumPy 1.4.0 `argsort` works with real/complex arrays containing\n",
      "    nan values. The enhanced sort order is documented in `sort`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    One dimensional array:\n",
      "\n",
      "    >>> x = np.array([3, 1, 2])\n",
      "    >>> np.argsort(x)\n",
      "    array([1, 2, 0])\n",
      "\n",
      "    Two-dimensional array:\n",
      "\n",
      "    >>> x = np.array([[0, 3], [2, 2]])\n",
      "    >>> x\n",
      "    array([[0, 3],\n",
      "           [2, 2]])\n",
      "\n",
      "    >>> ind = np.argsort(x, axis=0)  # sorts along first axis (down)\n",
      "    >>> ind\n",
      "    array([[0, 1],\n",
      "           [1, 0]])\n",
      "    >>> np.take_along_axis(x, ind, axis=0)  # same as np.sort(x, axis=0)\n",
      "    array([[0, 2],\n",
      "           [2, 3]])\n",
      "\n",
      "    >>> ind = np.argsort(x, axis=1)  # sorts along last axis (across)\n",
      "    >>> ind\n",
      "    array([[0, 1],\n",
      "           [0, 1]])\n",
      "    >>> np.take_along_axis(x, ind, axis=1)  # same as np.sort(x, axis=1)\n",
      "    array([[0, 3],\n",
      "           [2, 2]])\n",
      "\n",
      "    Indices of the sorted elements of a N-dimensional array:\n",
      "\n",
      "    >>> ind = np.unravel_index(np.argsort(x, axis=None), x.shape)\n",
      "    >>> ind\n",
      "    (array([0, 1, 1, 0]), array([0, 0, 1, 1]))\n",
      "    >>> x[ind]  # same as np.sort(x, axis=None)\n",
      "    array([0, 2, 2, 3])\n",
      "\n",
      "    Sorting with keys:\n",
      "\n",
      "    >>> x = np.array([(1, 0), (0, 1)], dtype=[('x', '<i4'), ('y', '<i4')])\n",
      "    >>> x\n",
      "    array([(1, 0), (0, 1)],\n",
      "          dtype=[('x', '<i4'), ('y', '<i4')])\n",
      "\n",
      "    >>> np.argsort(x, order=('x','y'))\n",
      "    array([1, 0])\n",
      "\n",
      "    >>> np.argsort(x, order=('y','x'))\n",
      "    array([0, 1])\n",
      "\n",
      "    \n",
      "code: around\n",
      "@array_function_dispatch(_around_dispatcher)\n",
      "def around(a, decimals=0, out=None):\n",
      "    return _wrapfunc(a, 'round', decimals=decimals, out=out)\n",
      "docstring: around\n",
      "\n",
      "    Evenly round to the given number of decimals.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    decimals : int, optional\n",
      "        Number of decimal places to round to (default: 0).  If\n",
      "        decimals is negative, it specifies the number of positions to\n",
      "        the left of the decimal point.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output, but the type of the output\n",
      "        values will be cast if necessary. See :ref:`ufuncs-output-type` for more\n",
      "        details.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    rounded_array : ndarray\n",
      "        An array of the same type as `a`, containing the rounded values.\n",
      "        Unless `out` was specified, a new array is created.  A reference to\n",
      "        the result is returned.\n",
      "\n",
      "        The real and imaginary parts of complex numbers are rounded\n",
      "        separately.  The result of rounding a float is a float.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.round : equivalent method\n",
      "    ceil, fix, floor, rint, trunc\n",
      "\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    `~numpy.round` is often used as an alias for `~numpy.around`.\n",
      "    \n",
      "    For values exactly halfway between rounded decimal values, NumPy\n",
      "    rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,\n",
      "    -0.5 and 0.5 round to 0.0, etc.\n",
      "\n",
      "    ``np.around`` uses a fast but sometimes inexact algorithm to round\n",
      "    floating-point datatypes. For positive `decimals` it is equivalent to\n",
      "    ``np.true_divide(np.rint(a * 10**decimals), 10**decimals)``, which has\n",
      "    error due to the inexact representation of decimal fractions in the IEEE\n",
      "    floating point standard [1]_ and errors introduced when scaling by powers\n",
      "    of ten. For instance, note the extra \"1\" in the following:\n",
      "\n",
      "        >>> np.round(56294995342131.5, 3)\n",
      "        56294995342131.51\n",
      "\n",
      "    If your goal is to print such values with a fixed number of decimals, it is\n",
      "    preferable to use numpy's float printing routines to limit the number of\n",
      "    printed decimals:\n",
      "\n",
      "        >>> np.format_float_positional(56294995342131.5, precision=3)\n",
      "        '56294995342131.5'\n",
      "\n",
      "    The float printing routines use an accurate but much more computationally\n",
      "    demanding algorithm to compute the number of digits after the decimal\n",
      "    point.\n",
      "\n",
      "    Alternatively, Python's builtin `round` function uses a more accurate\n",
      "    but slower algorithm for 64-bit floating point values:\n",
      "\n",
      "        >>> round(56294995342131.5, 3)\n",
      "        56294995342131.5\n",
      "        >>> np.round(16.055, 2), round(16.055, 2)  # equals 16.0549999999999997\n",
      "        (16.06, 16.05)\n",
      "\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] \"Lecture Notes on the Status of IEEE 754\", William Kahan,\n",
      "           https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.around([0.37, 1.64])\n",
      "    array([0., 2.])\n",
      "    >>> np.around([0.37, 1.64], decimals=1)\n",
      "    array([0.4, 1.6])\n",
      "    >>> np.around([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value\n",
      "    array([0., 2., 2., 4., 4.])\n",
      "    >>> np.around([1,2,3,11], decimals=1) # ndarray of ints is returned\n",
      "    array([ 1,  2,  3, 11])\n",
      "    >>> np.around([1,2,3,11], decimals=-1)\n",
      "    array([ 0,  0,  0, 10])\n",
      "\n",
      "    \n",
      "code: choose\n",
      "@array_function_dispatch(_choose_dispatcher)\n",
      "def choose(a, choices, out=None, mode='raise'):\n",
      "    return _wrapfunc(a, 'choose', choices, out=out, mode=mode)\n",
      "docstring: choose\n",
      "\n",
      "    Construct an array from an index array and a list of arrays to choose from.\n",
      "\n",
      "    First of all, if confused or uncertain, definitely look at the Examples -\n",
      "    in its full generality, this function is less simple than it might\n",
      "    seem from the following code description (below ndi =\n",
      "    `numpy.lib.index_tricks`):\n",
      "\n",
      "    ``np.choose(a,c) == np.array([c[a[I]][I] for I in ndi.ndindex(a.shape)])``.\n",
      "\n",
      "    But this omits some subtleties.  Here is a fully general summary:\n",
      "\n",
      "    Given an \"index\" array (`a`) of integers and a sequence of ``n`` arrays\n",
      "    (`choices`), `a` and each choice array are first broadcast, as necessary,\n",
      "    to arrays of a common shape; calling these *Ba* and *Bchoices[i], i =\n",
      "    0,...,n-1* we have that, necessarily, ``Ba.shape == Bchoices[i].shape``\n",
      "    for each ``i``.  Then, a new array with shape ``Ba.shape`` is created as\n",
      "    follows:\n",
      "\n",
      "    * if ``mode='raise'`` (the default), then, first of all, each element of\n",
      "      ``a`` (and thus ``Ba``) must be in the range ``[0, n-1]``; now, suppose\n",
      "      that ``i`` (in that range) is the value at the ``(j0, j1, ..., jm)``\n",
      "      position in ``Ba`` - then the value at the same position in the new array\n",
      "      is the value in ``Bchoices[i]`` at that same position;\n",
      "\n",
      "    * if ``mode='wrap'``, values in `a` (and thus `Ba`) may be any (signed)\n",
      "      integer; modular arithmetic is used to map integers outside the range\n",
      "      `[0, n-1]` back into that range; and then the new array is constructed\n",
      "      as above;\n",
      "\n",
      "    * if ``mode='clip'``, values in `a` (and thus ``Ba``) may be any (signed)\n",
      "      integer; negative integers are mapped to 0; values greater than ``n-1``\n",
      "      are mapped to ``n-1``; and then the new array is constructed as above.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : int array\n",
      "        This array must contain integers in ``[0, n-1]``, where ``n`` is the\n",
      "        number of choices, unless ``mode=wrap`` or ``mode=clip``, in which\n",
      "        cases any integers are permissible.\n",
      "    choices : sequence of arrays\n",
      "        Choice arrays. `a` and all of the choices must be broadcastable to the\n",
      "        same shape.  If `choices` is itself an array (not recommended), then\n",
      "        its outermost dimension (i.e., the one corresponding to\n",
      "        ``choices.shape[0]``) is taken as defining the \"sequence\".\n",
      "    out : array, optional\n",
      "        If provided, the result will be inserted into this array. It should\n",
      "        be of the appropriate shape and dtype. Note that `out` is always\n",
      "        buffered if ``mode='raise'``; use other modes for better performance.\n",
      "    mode : {'raise' (default), 'wrap', 'clip'}, optional\n",
      "        Specifies how indices outside ``[0, n-1]`` will be treated:\n",
      "\n",
      "          * 'raise' : an exception is raised\n",
      "          * 'wrap' : value becomes value mod ``n``\n",
      "          * 'clip' : values < 0 are mapped to 0, values > n-1 are mapped to n-1\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    merged_array : array\n",
      "        The merged result.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError: shape mismatch\n",
      "        If `a` and each choice array are not all broadcastable to the same\n",
      "        shape.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.choose : equivalent method\n",
      "    numpy.take_along_axis : Preferable if `choices` is an array\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    To reduce the chance of misinterpretation, even though the following\n",
      "    \"abuse\" is nominally supported, `choices` should neither be, nor be\n",
      "    thought of as, a single array, i.e., the outermost sequence-like container\n",
      "    should be either a list or a tuple.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    >>> choices = [[0, 1, 2, 3], [10, 11, 12, 13],\n",
      "    ...   [20, 21, 22, 23], [30, 31, 32, 33]]\n",
      "    >>> np.choose([2, 3, 1, 0], choices\n",
      "    ... # the first element of the result will be the first element of the\n",
      "    ... # third (2+1) \"array\" in choices, namely, 20; the second element\n",
      "    ... # will be the second element of the fourth (3+1) choice array, i.e.,\n",
      "    ... # 31, etc.\n",
      "    ... )\n",
      "    array([20, 31, 12,  3])\n",
      "    >>> np.choose([2, 4, 1, 0], choices, mode='clip') # 4 goes to 3 (4-1)\n",
      "    array([20, 31, 12,  3])\n",
      "    >>> # because there are 4 choice arrays\n",
      "    >>> np.choose([2, 4, 1, 0], choices, mode='wrap') # 4 goes to (4 mod 4)\n",
      "    array([20,  1, 12,  3])\n",
      "    >>> # i.e., 0\n",
      "\n",
      "    A couple examples illustrating how choose broadcasts:\n",
      "\n",
      "    >>> a = [[1, 0, 1], [0, 1, 0], [1, 0, 1]]\n",
      "    >>> choices = [-10, 10]\n",
      "    >>> np.choose(a, choices)\n",
      "    array([[ 10, -10,  10],\n",
      "           [-10,  10, -10],\n",
      "           [ 10, -10,  10]])\n",
      "\n",
      "    >>> # With thanks to Anne Archibald\n",
      "    >>> a = np.array([0, 1]).reshape((2,1,1))\n",
      "    >>> c1 = np.array([1, 2, 3]).reshape((1,3,1))\n",
      "    >>> c2 = np.array([-1, -2, -3, -4, -5]).reshape((1,1,5))\n",
      "    >>> np.choose(a, (c1, c2)) # result is 2x3x5, res[0,:,:]=c1, res[1,:,:]=c2\n",
      "    array([[[ 1,  1,  1,  1,  1],\n",
      "            [ 2,  2,  2,  2,  2],\n",
      "            [ 3,  3,  3,  3,  3]],\n",
      "           [[-1, -2, -3, -4, -5],\n",
      "            [-1, -2, -3, -4, -5],\n",
      "            [-1, -2, -3, -4, -5]]])\n",
      "\n",
      "    \n",
      "code: clip\n",
      "@array_function_dispatch(_clip_dispatcher)\n",
      "def clip(a, a_min, a_max, out=None, **kwargs):\n",
      "    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)\n",
      "docstring: clip\n",
      "\n",
      "    Clip (limit) the values in an array.\n",
      "\n",
      "    Given an interval, values outside the interval are clipped to\n",
      "    the interval edges.  For example, if an interval of ``[0, 1]``\n",
      "    is specified, values smaller than 0 become 0, and values larger\n",
      "    than 1 become 1.\n",
      "\n",
      "    Equivalent to but faster than ``np.minimum(a_max, np.maximum(a, a_min))``.\n",
      "\n",
      "    No check is performed to ensure ``a_min < a_max``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing elements to clip.\n",
      "    a_min, a_max : array_like or None\n",
      "        Minimum and maximum value. If ``None``, clipping is not performed on\n",
      "        the corresponding edge. Only one of `a_min` and `a_max` may be\n",
      "        ``None``. Both are broadcast against `a`.\n",
      "    out : ndarray, optional\n",
      "        The results will be placed in this array. It may be the input\n",
      "        array for in-place clipping.  `out` must be of the right shape\n",
      "        to hold the output.  Its type is preserved.\n",
      "    **kwargs\n",
      "        For other keyword-only arguments, see the\n",
      "        :ref:`ufunc docs <ufuncs.kwargs>`.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    clipped_array : ndarray\n",
      "        An array with the elements of `a`, but where values\n",
      "        < `a_min` are replaced with `a_min`, and those > `a_max`\n",
      "        with `a_max`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    :ref:`ufuncs-output-type`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When `a_min` is greater than `a_max`, `clip` returns an\n",
      "    array in which all values are equal to `a_max`,\n",
      "    as shown in the second example.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(10)\n",
      "    >>> a\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "    >>> np.clip(a, 1, 8)\n",
      "    array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])\n",
      "    >>> np.clip(a, 8, 1)\n",
      "    array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "    >>> np.clip(a, 3, 6, out=a)\n",
      "    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])\n",
      "    >>> a\n",
      "    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])\n",
      "    >>> a = np.arange(10)\n",
      "    >>> a\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "    >>> np.clip(a, [3, 4, 1, 1, 1, 4, 4, 4, 4, 4], 8)\n",
      "    array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])\n",
      "\n",
      "    \n",
      "code: compress\n",
      "@array_function_dispatch(_compress_dispatcher)\n",
      "def compress(condition, a, axis=None, out=None):\n",
      "    return _wrapfunc(a, 'compress', condition, axis=axis, out=out)\n",
      "docstring: compress\n",
      "\n",
      "    Return selected slices of an array along given axis.\n",
      "\n",
      "    When working along a given axis, a slice along that axis is returned in\n",
      "    `output` for each index where `condition` evaluates to True. When\n",
      "    working on a 1-D array, `compress` is equivalent to `extract`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    condition : 1-D array of bools\n",
      "        Array that selects which entries to return. If len(condition)\n",
      "        is less than the size of `a` along the given axis, then output is\n",
      "        truncated to the length of the condition array.\n",
      "    a : array_like\n",
      "        Array from which to extract a part.\n",
      "    axis : int, optional\n",
      "        Axis along which to take slices. If None (default), work on the\n",
      "        flattened array.\n",
      "    out : ndarray, optional\n",
      "        Output array.  Its type is preserved and it must be of the right\n",
      "        shape to hold the output.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    compressed_array : ndarray\n",
      "        A copy of `a` without the slices along axis for which `condition`\n",
      "        is false.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    take, choose, diag, diagonal, select\n",
      "    ndarray.compress : Equivalent method in ndarray\n",
      "    extract : Equivalent method when working on 1-D arrays\n",
      "    :ref:`ufuncs-output-type`\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4], [5, 6]])\n",
      "    >>> a\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]])\n",
      "    >>> np.compress([0, 1], a, axis=0)\n",
      "    array([[3, 4]])\n",
      "    >>> np.compress([False, True, True], a, axis=0)\n",
      "    array([[3, 4],\n",
      "           [5, 6]])\n",
      "    >>> np.compress([False, True], a, axis=1)\n",
      "    array([[2],\n",
      "           [4],\n",
      "           [6]])\n",
      "\n",
      "    Working on the flattened array does not return slices along an axis but\n",
      "    selects elements.\n",
      "\n",
      "    >>> np.compress([False, True], a)\n",
      "    array([2])\n",
      "\n",
      "    \n",
      "code: cumprod\n",
      "@array_function_dispatch(_cumprod_dispatcher)\n",
      "def cumprod(a, axis=None, dtype=None, out=None):\n",
      "    return _wrapfunc(a, 'cumprod', axis=axis, dtype=dtype, out=out)\n",
      "docstring: cumprod\n",
      "\n",
      "    Return the cumulative product of elements along a given axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axis : int, optional\n",
      "        Axis along which the cumulative product is computed.  By default\n",
      "        the input is flattened.\n",
      "    dtype : dtype, optional\n",
      "        Type of the returned array, as well as of the accumulator in which\n",
      "        the elements are multiplied.  If *dtype* is not specified, it\n",
      "        defaults to the dtype of `a`, unless `a` has an integer dtype with\n",
      "        a precision less than that of the default platform integer.  In\n",
      "        that case, the default platform integer is used instead.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must\n",
      "        have the same shape and buffer length as the expected output\n",
      "        but the type of the resulting values will be cast if necessary.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    cumprod : ndarray\n",
      "        A new array holding the result is returned unless `out` is\n",
      "        specified, in which case a reference to out is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    :ref:`ufuncs-output-type`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Arithmetic is modular when using integer types, and no error is\n",
      "    raised on overflow.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1,2,3])\n",
      "    >>> np.cumprod(a) # intermediate results 1, 1*2\n",
      "    ...               # total product 1*2*3 = 6\n",
      "    array([1, 2, 6])\n",
      "    >>> a = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "    >>> np.cumprod(a, dtype=float) # specify type of output\n",
      "    array([   1.,    2.,    6.,   24.,  120.,  720.])\n",
      "\n",
      "    The cumulative product for each column (i.e., over the rows) of `a`:\n",
      "\n",
      "    >>> np.cumprod(a, axis=0)\n",
      "    array([[ 1,  2,  3],\n",
      "           [ 4, 10, 18]])\n",
      "\n",
      "    The cumulative product for each row (i.e. over the columns) of `a`:\n",
      "\n",
      "    >>> np.cumprod(a,axis=1)\n",
      "    array([[  1,   2,   6],\n",
      "           [  4,  20, 120]])\n",
      "\n",
      "    \n",
      "code: cumproduct\n",
      "@array_function_dispatch(_cumprod_dispatcher, verify=False)\n",
      "def cumproduct(*args, **kwargs):\n",
      "    return cumprod(*args, **kwargs)\n",
      "docstring: cumproduct\n",
      "\n",
      "    Return the cumulative product over the given axis.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    cumprod : equivalent function; see for details.\n",
      "    \n",
      "code: cumsum\n",
      "@array_function_dispatch(_cumsum_dispatcher)\n",
      "def cumsum(a, axis=None, dtype=None, out=None):\n",
      "    return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out)\n",
      "docstring: cumsum\n",
      "\n",
      "    Return the cumulative sum of the elements along a given axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axis : int, optional\n",
      "        Axis along which the cumulative sum is computed. The default\n",
      "        (None) is to compute the cumsum over the flattened array.\n",
      "    dtype : dtype, optional\n",
      "        Type of the returned array and of the accumulator in which the\n",
      "        elements are summed.  If `dtype` is not specified, it defaults\n",
      "        to the dtype of `a`, unless `a` has an integer dtype with a\n",
      "        precision less than that of the default platform integer.  In\n",
      "        that case, the default platform integer is used.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must\n",
      "        have the same shape and buffer length as the expected output\n",
      "        but the type will be cast if necessary. See :ref:`ufuncs-output-type` for\n",
      "        more details.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    cumsum_along_axis : ndarray.\n",
      "        A new array holding the result is returned unless `out` is\n",
      "        specified, in which case a reference to `out` is returned. The\n",
      "        result has the same size as `a`, and the same shape as `a` if\n",
      "        `axis` is not None or `a` is a 1-d array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    sum : Sum array elements.\n",
      "    trapz : Integration of array values using the composite trapezoidal rule.\n",
      "    diff : Calculate the n-th discrete difference along given axis.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Arithmetic is modular when using integer types, and no error is\n",
      "    raised on overflow.\n",
      "\n",
      "    ``cumsum(a)[-1]`` may not be equal to ``sum(a)`` for floating-point\n",
      "    values since ``sum`` may use a pairwise summation routine, reducing\n",
      "    the roundoff-error. See `sum` for more information.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1,2,3], [4,5,6]])\n",
      "    >>> a\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "    >>> np.cumsum(a)\n",
      "    array([ 1,  3,  6, 10, 15, 21])\n",
      "    >>> np.cumsum(a, dtype=float)     # specifies type of output value(s)\n",
      "    array([  1.,   3.,   6.,  10.,  15.,  21.])\n",
      "\n",
      "    >>> np.cumsum(a,axis=0)      # sum over rows for each of the 3 columns\n",
      "    array([[1, 2, 3],\n",
      "           [5, 7, 9]])\n",
      "    >>> np.cumsum(a,axis=1)      # sum over columns for each of the 2 rows\n",
      "    array([[ 1,  3,  6],\n",
      "           [ 4,  9, 15]])\n",
      "\n",
      "    ``cumsum(b)[-1]`` may not be equal to ``sum(b)``\n",
      "\n",
      "    >>> b = np.array([1, 2e-9, 3e-9] * 1000000)\n",
      "    >>> b.cumsum()[-1]\n",
      "    1000000.0050045159\n",
      "    >>> b.sum()\n",
      "    1000000.0050000029\n",
      "\n",
      "    \n",
      "code: diagonal\n",
      "@array_function_dispatch(_diagonal_dispatcher)\n",
      "def diagonal(a, offset=0, axis1=0, axis2=1):\n",
      "    if isinstance(a, np.matrix):\n",
      "        # Make diagonal of matrix 1-D to preserve backward compatibility.\n",
      "        return asarray(a).diagonal(offset=offset, axis1=axis1, axis2=axis2)\n",
      "    else:\n",
      "        return asanyarray(a).diagonal(offset=offset, axis1=axis1, axis2=axis2)\n",
      "docstring: diagonal\n",
      "\n",
      "    Return specified diagonals.\n",
      "\n",
      "    If `a` is 2-D, returns the diagonal of `a` with the given offset,\n",
      "    i.e., the collection of elements of the form ``a[i, i+offset]``.  If\n",
      "    `a` has more than two dimensions, then the axes specified by `axis1`\n",
      "    and `axis2` are used to determine the 2-D sub-array whose diagonal is\n",
      "    returned.  The shape of the resulting array can be determined by\n",
      "    removing `axis1` and `axis2` and appending an index to the right equal\n",
      "    to the size of the resulting diagonals.\n",
      "\n",
      "    In versions of NumPy prior to 1.7, this function always returned a new,\n",
      "    independent array containing a copy of the values in the diagonal.\n",
      "\n",
      "    In NumPy 1.7 and 1.8, it continues to return a copy of the diagonal,\n",
      "    but depending on this fact is deprecated. Writing to the resulting\n",
      "    array continues to work as it used to, but a FutureWarning is issued.\n",
      "\n",
      "    Starting in NumPy 1.9 it returns a read-only view on the original array.\n",
      "    Attempting to write to the resulting array will produce an error.\n",
      "\n",
      "    In some future release, it will return a read/write view and writing to\n",
      "    the returned array will alter your original array.  The returned array\n",
      "    will have the same type as the input array.\n",
      "\n",
      "    If you don't write to the array returned by this function, then you can\n",
      "    just ignore all of the above.\n",
      "\n",
      "    If you depend on the current behavior, then we suggest copying the\n",
      "    returned array explicitly, i.e., use ``np.diagonal(a).copy()`` instead\n",
      "    of just ``np.diagonal(a)``. This will work with both past and future\n",
      "    versions of NumPy.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array from which the diagonals are taken.\n",
      "    offset : int, optional\n",
      "        Offset of the diagonal from the main diagonal.  Can be positive or\n",
      "        negative.  Defaults to main diagonal (0).\n",
      "    axis1 : int, optional\n",
      "        Axis to be used as the first axis of the 2-D sub-arrays from which\n",
      "        the diagonals should be taken.  Defaults to first axis (0).\n",
      "    axis2 : int, optional\n",
      "        Axis to be used as the second axis of the 2-D sub-arrays from\n",
      "        which the diagonals should be taken. Defaults to second axis (1).\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    array_of_diagonals : ndarray\n",
      "        If `a` is 2-D, then a 1-D array containing the diagonal and of the\n",
      "        same type as `a` is returned unless `a` is a `matrix`, in which case\n",
      "        a 1-D array rather than a (2-D) `matrix` is returned in order to\n",
      "        maintain backward compatibility.\n",
      "\n",
      "        If ``a.ndim > 2``, then the dimensions specified by `axis1` and `axis2`\n",
      "        are removed, and a new axis inserted at the end corresponding to the\n",
      "        diagonal.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If the dimension of `a` is less than 2.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    diag : MATLAB work-a-like for 1-D and 2-D arrays.\n",
      "    diagflat : Create diagonal arrays.\n",
      "    trace : Sum along diagonals.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(4).reshape(2,2)\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3]])\n",
      "    >>> a.diagonal()\n",
      "    array([0, 3])\n",
      "    >>> a.diagonal(1)\n",
      "    array([1])\n",
      "\n",
      "    A 3-D example:\n",
      "\n",
      "    >>> a = np.arange(8).reshape(2,2,2); a\n",
      "    array([[[0, 1],\n",
      "            [2, 3]],\n",
      "           [[4, 5],\n",
      "            [6, 7]]])\n",
      "    >>> a.diagonal(0,  # Main diagonals of two arrays created by skipping\n",
      "    ...            0,  # across the outer(left)-most axis last and\n",
      "    ...            1)  # the \"middle\" (row) axis first.\n",
      "    array([[0, 6],\n",
      "           [1, 7]])\n",
      "\n",
      "    The sub-arrays whose main diagonals we just obtained; note that each\n",
      "    corresponds to fixing the right-most (column) axis, and that the\n",
      "    diagonals are \"packed\" in rows.\n",
      "\n",
      "    >>> a[:,:,0]  # main diagonal is [0 6]\n",
      "    array([[0, 2],\n",
      "           [4, 6]])\n",
      "    >>> a[:,:,1]  # main diagonal is [1 7]\n",
      "    array([[1, 3],\n",
      "           [5, 7]])\n",
      "\n",
      "    The anti-diagonal can be obtained by reversing the order of elements\n",
      "    using either `numpy.flipud` or `numpy.fliplr`.\n",
      "\n",
      "    >>> a = np.arange(9).reshape(3, 3)\n",
      "    >>> a\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5],\n",
      "           [6, 7, 8]])\n",
      "    >>> np.fliplr(a).diagonal()  # Horizontal flip\n",
      "    array([2, 4, 6])\n",
      "    >>> np.flipud(a).diagonal()  # Vertical flip\n",
      "    array([6, 4, 2])\n",
      "\n",
      "    Note that the order in which the diagonal is retrieved varies depending\n",
      "    on the flip function.\n",
      "    \n",
      "code: mean\n",
      "@array_function_dispatch(_mean_dispatcher)\n",
      "def mean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue, *,\n",
      "         where=np._NoValue):\n",
      "    kwargs = {}\n",
      "    if keepdims is not np._NoValue:\n",
      "        kwargs['keepdims'] = keepdims\n",
      "    if where is not np._NoValue:\n",
      "        kwargs['where'] = where\n",
      "    if type(a) is not mu.ndarray:\n",
      "        try:\n",
      "            mean = a.mean\n",
      "        except AttributeError:\n",
      "            pass\n",
      "        else:\n",
      "            return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "    return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "                          out=out, **kwargs)\n",
      "docstring: mean\n",
      "\n",
      "    Compute the arithmetic mean along the specified axis.\n",
      "\n",
      "    Returns the average of the array elements.  The average is taken over\n",
      "    the flattened array by default, otherwise over the specified axis.\n",
      "    `float64` intermediate and return values are used for integer inputs.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose mean is desired. If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which the means are computed. The default is to\n",
      "        compute the mean of the flattened array.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If this is a tuple of ints, a mean is performed over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    dtype : data-type, optional\n",
      "        Type to use in computing the mean.  For integer inputs, the default\n",
      "        is `float64`; for floating point inputs, it is the same as the\n",
      "        input dtype.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  The default\n",
      "        is ``None``; if provided, it must have the same shape as the\n",
      "        expected output, but the type will be cast if necessary.\n",
      "        See :ref:`ufuncs-output-type` for more details.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `mean` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the mean. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    m : ndarray, see dtype parameter above\n",
      "        If `out=None`, returns a new array containing the mean values,\n",
      "        otherwise a reference to the output array is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    average : Weighted average\n",
      "    std, var, nanmean, nanstd, nanvar\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The arithmetic mean is the sum of the elements along the axis divided\n",
      "    by the number of elements.\n",
      "\n",
      "    Note that for floating-point input, the mean is computed using the\n",
      "    same precision the input has.  Depending on the input data, this can\n",
      "    cause the results to be inaccurate, especially for `float32` (see\n",
      "    example below).  Specifying a higher-precision accumulator using the\n",
      "    `dtype` keyword can alleviate this issue.\n",
      "\n",
      "    By default, `float16` results are computed using `float32` intermediates\n",
      "    for extra precision.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> np.mean(a)\n",
      "    2.5\n",
      "    >>> np.mean(a, axis=0)\n",
      "    array([2., 3.])\n",
      "    >>> np.mean(a, axis=1)\n",
      "    array([1.5, 3.5])\n",
      "\n",
      "    In single precision, `mean` can be inaccurate:\n",
      "\n",
      "    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n",
      "    >>> a[0, :] = 1.0\n",
      "    >>> a[1, :] = 0.1\n",
      "    >>> np.mean(a)\n",
      "    0.54999924\n",
      "\n",
      "    Computing the mean in float64 is more accurate:\n",
      "\n",
      "    >>> np.mean(a, dtype=np.float64)\n",
      "    0.55000000074505806 # may vary\n",
      "\n",
      "    Specifying a where argument:\n",
      "\n",
      "    >>> a = np.array([[5, 9, 13], [14, 10, 12], [11, 15, 19]])\n",
      "    >>> np.mean(a)\n",
      "    12.0\n",
      "    >>> np.mean(a, where=[[True], [False], [False]])\n",
      "    9.0\n",
      "\n",
      "    \n",
      "code: ndim\n",
      "@array_function_dispatch(_ndim_dispatcher)\n",
      "def ndim(a):\n",
      "    try:\n",
      "        return a.ndim\n",
      "    except AttributeError:\n",
      "        return asarray(a).ndim\n",
      "docstring: ndim\n",
      "\n",
      "    Return the number of dimensions of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.  If it is not already an ndarray, a conversion is\n",
      "        attempted.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    number_of_dimensions : int\n",
      "        The number of dimensions in `a`.  Scalars are zero-dimensional.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.ndim : equivalent method\n",
      "    shape : dimensions of array\n",
      "    ndarray.shape : dimensions of array\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.ndim([[1,2,3],[4,5,6]])\n",
      "    2\n",
      "    >>> np.ndim(np.array([[1,2,3],[4,5,6]]))\n",
      "    2\n",
      "    >>> np.ndim(1)\n",
      "    0\n",
      "\n",
      "    \n",
      "code: nonzero\n",
      "@array_function_dispatch(_nonzero_dispatcher)\n",
      "def nonzero(a):\n",
      "    return _wrapfunc(a, 'nonzero')\n",
      "docstring: nonzero\n",
      "\n",
      "    Return the indices of the elements that are non-zero.\n",
      "\n",
      "    Returns a tuple of arrays, one for each dimension of `a`,\n",
      "    containing the indices of the non-zero elements in that\n",
      "    dimension. The values in `a` are always tested and returned in\n",
      "    row-major, C-style order.\n",
      "\n",
      "    To group the indices by element, rather than dimension, use `argwhere`,\n",
      "    which returns a row for each non-zero element.\n",
      "\n",
      "    .. note::\n",
      "\n",
      "       When called on a zero-d array or scalar, ``nonzero(a)`` is treated\n",
      "       as ``nonzero(atleast_1d(a))``.\n",
      "\n",
      "       .. deprecated:: 1.17.0\n",
      "\n",
      "          Use `atleast_1d` explicitly if this behavior is deliberate.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    tuple_of_arrays : tuple\n",
      "        Indices of elements that are non-zero.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    flatnonzero :\n",
      "        Return indices that are non-zero in the flattened version of the input\n",
      "        array.\n",
      "    ndarray.nonzero :\n",
      "        Equivalent ndarray method.\n",
      "    count_nonzero :\n",
      "        Counts the number of non-zero elements in the input array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    While the nonzero values can be obtained with ``a[nonzero(a)]``, it is\n",
      "    recommended to use ``x[x.astype(bool)]`` or ``x[x != 0]`` instead, which\n",
      "    will correctly handle 0-d arrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([[3, 0, 0], [0, 4, 0], [5, 6, 0]])\n",
      "    >>> x\n",
      "    array([[3, 0, 0],\n",
      "           [0, 4, 0],\n",
      "           [5, 6, 0]])\n",
      "    >>> np.nonzero(x)\n",
      "    (array([0, 1, 2, 2]), array([0, 1, 0, 1]))\n",
      "\n",
      "    >>> x[np.nonzero(x)]\n",
      "    array([3, 4, 5, 6])\n",
      "    >>> np.transpose(np.nonzero(x))\n",
      "    array([[0, 0],\n",
      "           [1, 1],\n",
      "           [2, 0],\n",
      "           [2, 1]])\n",
      "\n",
      "    A common use for ``nonzero`` is to find the indices of an array, where\n",
      "    a condition is True.  Given an array `a`, the condition `a` > 3 is a\n",
      "    boolean array and since False is interpreted as 0, np.nonzero(a > 3)\n",
      "    yields the indices of the `a` where the condition is true.\n",
      "\n",
      "    >>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "    >>> a > 3\n",
      "    array([[False, False, False],\n",
      "           [ True,  True,  True],\n",
      "           [ True,  True,  True]])\n",
      "    >>> np.nonzero(a > 3)\n",
      "    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))\n",
      "\n",
      "    Using this result to index `a` is equivalent to using the mask directly:\n",
      "\n",
      "    >>> a[np.nonzero(a > 3)]\n",
      "    array([4, 5, 6, 7, 8, 9])\n",
      "    >>> a[a > 3]  # prefer this spelling\n",
      "    array([4, 5, 6, 7, 8, 9])\n",
      "\n",
      "    ``nonzero`` can also be called as a method of the array.\n",
      "\n",
      "    >>> (a > 3).nonzero()\n",
      "    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))\n",
      "\n",
      "    \n",
      "code: partition\n",
      "@array_function_dispatch(_partition_dispatcher)\n",
      "def partition(a, kth, axis=-1, kind='introselect', order=None):\n",
      "    if axis is None:\n",
      "        # flatten returns (1, N) for np.matrix, so always use the last axis\n",
      "        a = asanyarray(a).flatten()\n",
      "        axis = -1\n",
      "    else:\n",
      "        a = asanyarray(a).copy(order=\"K\")\n",
      "    a.partition(kth, axis=axis, kind=kind, order=order)\n",
      "    return a\n",
      "docstring: partition\n",
      "\n",
      "    Return a partitioned copy of an array.\n",
      "\n",
      "    Creates a copy of the array with its elements rearranged in such a\n",
      "    way that the value of the element in k-th position is in the position\n",
      "    the value would be in a sorted array.  In the partitioned array, all\n",
      "    elements before the k-th element are less than or equal to that\n",
      "    element, and all the elements after the k-th element are greater than\n",
      "    or equal to that element.  The ordering of the elements in the two\n",
      "    partitions is undefined.\n",
      "\n",
      "    .. versionadded:: 1.8.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to be sorted.\n",
      "    kth : int or sequence of ints\n",
      "        Element index to partition by. The k-th value of the element\n",
      "        will be in its final sorted position and all smaller elements\n",
      "        will be moved before it and all equal or greater elements behind\n",
      "        it. The order of all elements in the partitions is undefined. If\n",
      "        provided with a sequence of k-th it will partition all elements\n",
      "        indexed by k-th  of them into their sorted position at once.\n",
      "\n",
      "        .. deprecated:: 1.22.0\n",
      "            Passing booleans as index is deprecated.\n",
      "    axis : int or None, optional\n",
      "        Axis along which to sort. If None, the array is flattened before\n",
      "        sorting. The default is -1, which sorts along the last axis.\n",
      "    kind : {'introselect'}, optional\n",
      "        Selection algorithm. Default is 'introselect'.\n",
      "    order : str or list of str, optional\n",
      "        When `a` is an array with fields defined, this argument\n",
      "        specifies which fields to compare first, second, etc.  A single\n",
      "        field can be specified as a string.  Not all fields need be\n",
      "        specified, but unspecified fields will still be used, in the\n",
      "        order in which they come up in the dtype, to break ties.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    partitioned_array : ndarray\n",
      "        Array of the same type and shape as `a`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.partition : Method to sort an array in-place.\n",
      "    argpartition : Indirect partition.\n",
      "    sort : Full sorting\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The various selection algorithms are characterized by their average\n",
      "    speed, worst case performance, work space size, and whether they are\n",
      "    stable. A stable sort keeps items with the same key in the same\n",
      "    relative order. The available algorithms have the following\n",
      "    properties:\n",
      "\n",
      "    ================= ======= ============= ============ =======\n",
      "       kind            speed   worst case    work space  stable\n",
      "    ================= ======= ============= ============ =======\n",
      "    'introselect'        1        O(n)           0         no\n",
      "    ================= ======= ============= ============ =======\n",
      "\n",
      "    All the partition algorithms make temporary copies of the data when\n",
      "    partitioning along any but the last axis.  Consequently,\n",
      "    partitioning along the last axis is faster and uses less space than\n",
      "    partitioning along any other axis.\n",
      "\n",
      "    The sort order for complex numbers is lexicographic. If both the\n",
      "    real and imaginary parts are non-nan then the order is determined by\n",
      "    the real parts except when they are equal, in which case the order\n",
      "    is determined by the imaginary parts.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([7, 1, 7, 7, 1, 5, 7, 2, 3, 2, 6, 2, 3, 0])\n",
      "    >>> p = np.partition(a, 4)\n",
      "    >>> p\n",
      "    array([0, 1, 2, 1, 2, 5, 2, 3, 3, 6, 7, 7, 7, 7])\n",
      "\n",
      "    ``p[4]`` is 2;  all elements in ``p[:4]`` are less than or equal\n",
      "    to ``p[4]``, and all elements in ``p[5:]`` are greater than or\n",
      "    equal to ``p[4]``.  The partition is::\n",
      "\n",
      "        [0, 1, 2, 1], [2], [5, 2, 3, 3, 6, 7, 7, 7, 7]\n",
      "\n",
      "    The next example shows the use of multiple values passed to `kth`.\n",
      "\n",
      "    >>> p2 = np.partition(a, (4, 8))\n",
      "    >>> p2\n",
      "    array([0, 1, 2, 1, 2, 3, 3, 2, 5, 6, 7, 7, 7, 7])\n",
      "\n",
      "    ``p2[4]`` is 2  and ``p2[8]`` is 5.  All elements in ``p2[:4]``\n",
      "    are less than or equal to ``p2[4]``, all elements in ``p2[5:8]``\n",
      "    are greater than or equal to ``p2[4]`` and less than or equal to\n",
      "    ``p2[8]``, and all elements in ``p2[9:]`` are greater than or\n",
      "    equal to ``p2[8]``.  The partition is::\n",
      "\n",
      "        [0, 1, 2, 1], [2], [3, 3, 2], [5], [6, 7, 7, 7, 7]\n",
      "    \n",
      "code: prod\n",
      "@array_function_dispatch(_prod_dispatcher)\n",
      "def prod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n",
      "         initial=np._NoValue, where=np._NoValue):\n",
      "    return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n",
      "                          keepdims=keepdims, initial=initial, where=where)\n",
      "docstring: prod\n",
      "\n",
      "    Return the product of array elements over a given axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which a product is performed.  The default,\n",
      "        axis=None, will calculate the product of all the elements in the\n",
      "        input array. If axis is negative it counts from the last to the\n",
      "        first axis.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If axis is a tuple of ints, a product is performed on all of the\n",
      "        axes specified in the tuple instead of a single axis or all the\n",
      "        axes as before.\n",
      "    dtype : dtype, optional\n",
      "        The type of the returned array, as well as of the accumulator in\n",
      "        which the elements are multiplied.  The dtype of `a` is used by\n",
      "        default unless `a` has an integer dtype of less precision than the\n",
      "        default platform integer.  In that case, if `a` is signed then the\n",
      "        platform integer is used while if `a` is unsigned then an unsigned\n",
      "        integer of the same precision as the platform integer is used.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output, but the type of the output\n",
      "        values will be cast if necessary.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left in the\n",
      "        result as dimensions with size one. With this option, the result\n",
      "        will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `prod` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    initial : scalar, optional\n",
      "        The starting value for this product. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.15.0\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the product. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    product_along_axis : ndarray, see `dtype` parameter above.\n",
      "        An array shaped as `a` but with the specified axis removed.\n",
      "        Returns a reference to `out` if specified.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.prod : equivalent method\n",
      "    :ref:`ufuncs-output-type`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Arithmetic is modular when using integer types, and no error is\n",
      "    raised on overflow.  That means that, on a 32-bit platform:\n",
      "\n",
      "    >>> x = np.array([536870910, 536870910, 536870910, 536870910])\n",
      "    >>> np.prod(x)\n",
      "    16 # may vary\n",
      "\n",
      "    The product of an empty array is the neutral element 1:\n",
      "\n",
      "    >>> np.prod([])\n",
      "    1.0\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    By default, calculate the product of all elements:\n",
      "\n",
      "    >>> np.prod([1.,2.])\n",
      "    2.0\n",
      "\n",
      "    Even when the input array is two-dimensional:\n",
      "\n",
      "    >>> a = np.array([[1., 2.], [3., 4.]])\n",
      "    >>> np.prod(a)\n",
      "    24.0\n",
      "\n",
      "    But we can also specify the axis over which to multiply:\n",
      "\n",
      "    >>> np.prod(a, axis=1)\n",
      "    array([  2.,  12.])\n",
      "    >>> np.prod(a, axis=0)\n",
      "    array([3., 8.])\n",
      "    \n",
      "    Or select specific elements to include:\n",
      "\n",
      "    >>> np.prod([1., np.nan, 3.], where=[True, False, True])\n",
      "    3.0\n",
      "\n",
      "    If the type of `x` is unsigned, then the output type is\n",
      "    the unsigned platform integer:\n",
      "\n",
      "    >>> x = np.array([1, 2, 3], dtype=np.uint8)\n",
      "    >>> np.prod(x).dtype == np.uint\n",
      "    True\n",
      "\n",
      "    If `x` is of a signed integer type, then the output type\n",
      "    is the default platform integer:\n",
      "\n",
      "    >>> x = np.array([1, 2, 3], dtype=np.int8)\n",
      "    >>> np.prod(x).dtype == int\n",
      "    True\n",
      "\n",
      "    You can also start the product with a value other than one:\n",
      "\n",
      "    >>> np.prod([1, 2], initial=5)\n",
      "    10\n",
      "    \n",
      "code: product\n",
      "@array_function_dispatch(_prod_dispatcher, verify=False)\n",
      "def product(*args, **kwargs):\n",
      "    return prod(*args, **kwargs)\n",
      "docstring: product\n",
      "\n",
      "    Return the product of array elements over a given axis.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    prod : equivalent function; see for details.\n",
      "    \n",
      "code: ptp\n",
      "@array_function_dispatch(_ptp_dispatcher)\n",
      "def ptp(a, axis=None, out=None, keepdims=np._NoValue):\n",
      "    kwargs = {}\n",
      "    if keepdims is not np._NoValue:\n",
      "        kwargs['keepdims'] = keepdims\n",
      "    if type(a) is not mu.ndarray:\n",
      "        try:\n",
      "            ptp = a.ptp\n",
      "        except AttributeError:\n",
      "            pass\n",
      "        else:\n",
      "            return ptp(axis=axis, out=out, **kwargs)\n",
      "    return _methods._ptp(a, axis=axis, out=out, **kwargs)\n",
      "docstring: ptp\n",
      "\n",
      "    Range of values (maximum - minimum) along an axis.\n",
      "\n",
      "    The name of the function comes from the acronym for 'peak to peak'.\n",
      "\n",
      "    .. warning::\n",
      "        `ptp` preserves the data type of the array. This means the\n",
      "        return value for an input of signed integers with n bits\n",
      "        (e.g. `np.int8`, `np.int16`, etc) is also a signed integer\n",
      "        with n bits.  In that case, peak-to-peak values greater than\n",
      "        ``2**(n-1)-1`` will be returned as negative values. An example\n",
      "        with a work-around is shown below.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input values.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis along which to find the peaks.  By default, flatten the\n",
      "        array.  `axis` may be negative, in\n",
      "        which case it counts from the last to the first axis.\n",
      "\n",
      "        .. versionadded:: 1.15.0\n",
      "\n",
      "        If this is a tuple of ints, a reduction is performed on multiple\n",
      "        axes, instead of a single axis or all the axes as before.\n",
      "    out : array_like\n",
      "        Alternative output array in which to place the result. It must\n",
      "        have the same shape and buffer length as the expected output,\n",
      "        but the type of the output values will be cast if necessary.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `ptp` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    ptp : ndarray or scalar\n",
      "        The range of a given array - `scalar` if array is one-dimensional\n",
      "        or a new array holding the result along the given axis\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([[4, 9, 2, 10],\n",
      "    ...               [6, 9, 7, 12]])\n",
      "\n",
      "    >>> np.ptp(x, axis=1)\n",
      "    array([8, 6])\n",
      "\n",
      "    >>> np.ptp(x, axis=0)\n",
      "    array([2, 0, 5, 2])\n",
      "\n",
      "    >>> np.ptp(x)\n",
      "    10\n",
      "\n",
      "    This example shows that a negative value can be returned when\n",
      "    the input is an array of signed integers.\n",
      "\n",
      "    >>> y = np.array([[1, 127],\n",
      "    ...               [0, 127],\n",
      "    ...               [-1, 127],\n",
      "    ...               [-2, 127]], dtype=np.int8)\n",
      "    >>> np.ptp(y, axis=1)\n",
      "    array([ 126,  127, -128, -127], dtype=int8)\n",
      "\n",
      "    A work-around is to use the `view()` method to view the result as\n",
      "    unsigned integers with the same bit width:\n",
      "\n",
      "    >>> np.ptp(y, axis=1).view(np.uint8)\n",
      "    array([126, 127, 128, 129], dtype=uint8)\n",
      "\n",
      "    \n",
      "code: put\n",
      "@array_function_dispatch(_put_dispatcher)\n",
      "def put(a, ind, v, mode='raise'):\n",
      "    try:\n",
      "        put = a.put\n",
      "    except AttributeError as e:\n",
      "        raise TypeError(\"argument 1 must be numpy.ndarray, \"\n",
      "                        \"not {name}\".format(name=type(a).__name__)) from e\n",
      "    return put(ind, v, mode=mode)\n",
      "docstring: put\n",
      "\n",
      "    Replaces specified elements of an array with given values.\n",
      "\n",
      "    The indexing works on the flattened target array. `put` is roughly\n",
      "    equivalent to:\n",
      "\n",
      "    ::\n",
      "\n",
      "        a.flat[ind] = v\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : ndarray\n",
      "        Target array.\n",
      "    ind : array_like\n",
      "        Target indices, interpreted as integers.\n",
      "    v : array_like\n",
      "        Values to place in `a` at target indices. If `v` is shorter than\n",
      "        `ind` it will be repeated as necessary.\n",
      "    mode : {'raise', 'wrap', 'clip'}, optional\n",
      "        Specifies how out-of-bounds indices will behave.\n",
      "\n",
      "        * 'raise' -- raise an error (default)\n",
      "        * 'wrap' -- wrap around\n",
      "        * 'clip' -- clip to the range\n",
      "\n",
      "        'clip' mode means that all indices that are too large are replaced\n",
      "        by the index that addresses the last element along that axis. Note\n",
      "        that this disables indexing with negative numbers. In 'raise' mode,\n",
      "        if an exception occurs the target array may still be modified.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    putmask, place\n",
      "    put_along_axis : Put elements by matching the array and the index arrays\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(5)\n",
      "    >>> np.put(a, [0, 2], [-44, -55])\n",
      "    >>> a\n",
      "    array([-44,   1, -55,   3,   4])\n",
      "\n",
      "    >>> a = np.arange(5)\n",
      "    >>> np.put(a, 22, -5, mode='clip')\n",
      "    >>> a\n",
      "    array([ 0,  1,  2,  3, -5])\n",
      "\n",
      "    \n",
      "code: ravel\n",
      "@array_function_dispatch(_ravel_dispatcher)\n",
      "def ravel(a, order='C'):\n",
      "    if isinstance(a, np.matrix):\n",
      "        return asarray(a).ravel(order=order)\n",
      "    else:\n",
      "        return asanyarray(a).ravel(order=order)\n",
      "docstring: ravel\n",
      "Return a contiguous flattened array.\n",
      "\n",
      "    A 1-D array, containing the elements of the input, is returned.  A copy is\n",
      "    made only if needed.\n",
      "\n",
      "    As of NumPy 1.10, the returned array will have the same type as the input\n",
      "    array. (for example, a masked array will be returned for a masked array\n",
      "    input)\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.  The elements in `a` are read in the order specified by\n",
      "        `order`, and packed as a 1-D array.\n",
      "    order : {'C','F', 'A', 'K'}, optional\n",
      "\n",
      "        The elements of `a` are read using this index order. 'C' means\n",
      "        to index the elements in row-major, C-style order,\n",
      "        with the last axis index changing fastest, back to the first\n",
      "        axis index changing slowest.  'F' means to index the elements\n",
      "        in column-major, Fortran-style order, with the\n",
      "        first index changing fastest, and the last index changing\n",
      "        slowest. Note that the 'C' and 'F' options take no account of\n",
      "        the memory layout of the underlying array, and only refer to\n",
      "        the order of axis indexing.  'A' means to read the elements in\n",
      "        Fortran-like index order if `a` is Fortran *contiguous* in\n",
      "        memory, C-like order otherwise.  'K' means to read the\n",
      "        elements in the order they occur in memory, except for\n",
      "        reversing the data when strides are negative.  By default, 'C'\n",
      "        index order is used.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    y : array_like\n",
      "        y is an array of the same subtype as `a`, with shape ``(a.size,)``.\n",
      "        Note that matrices are special cased for backward compatibility, if `a`\n",
      "        is a matrix, then y is a 1-D ndarray.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.flat : 1-D iterator over an array.\n",
      "    ndarray.flatten : 1-D array copy of the elements of an array\n",
      "                      in row-major order.\n",
      "    ndarray.reshape : Change the shape of an array without changing its data.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    In row-major, C-style order, in two dimensions, the row index\n",
      "    varies the slowest, and the column index the quickest.  This can\n",
      "    be generalized to multiple dimensions, where row-major order\n",
      "    implies that the index along the first axis varies slowest, and\n",
      "    the index along the last quickest.  The opposite holds for\n",
      "    column-major, Fortran-style index ordering.\n",
      "\n",
      "    When a view is desired in as many cases as possible, ``arr.reshape(-1)``\n",
      "    may be preferable.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    It is equivalent to ``reshape(-1, order=order)``.\n",
      "\n",
      "    >>> x = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "    >>> np.ravel(x)\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "\n",
      "    >>> x.reshape(-1)\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "\n",
      "    >>> np.ravel(x, order='F')\n",
      "    array([1, 4, 2, 5, 3, 6])\n",
      "\n",
      "    When ``order`` is 'A', it will preserve the array's 'C' or 'F' ordering:\n",
      "\n",
      "    >>> np.ravel(x.T)\n",
      "    array([1, 4, 2, 5, 3, 6])\n",
      "    >>> np.ravel(x.T, order='A')\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "\n",
      "    When ``order`` is 'K', it will preserve orderings that are neither 'C'\n",
      "    nor 'F', but won't reverse axes:\n",
      "\n",
      "    >>> a = np.arange(3)[::-1]; a\n",
      "    array([2, 1, 0])\n",
      "    >>> a.ravel(order='C')\n",
      "    array([2, 1, 0])\n",
      "    >>> a.ravel(order='K')\n",
      "    array([2, 1, 0])\n",
      "\n",
      "    >>> a = np.arange(12).reshape(2,3,2).swapaxes(1,2); a\n",
      "    array([[[ 0,  2,  4],\n",
      "            [ 1,  3,  5]],\n",
      "           [[ 6,  8, 10],\n",
      "            [ 7,  9, 11]]])\n",
      "    >>> a.ravel(order='C')\n",
      "    array([ 0,  2,  4,  1,  3,  5,  6,  8, 10,  7,  9, 11])\n",
      "    >>> a.ravel(order='K')\n",
      "    array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "\n",
      "    \n",
      "code: repeat\n",
      "@array_function_dispatch(_repeat_dispatcher)\n",
      "def repeat(a, repeats, axis=None):\n",
      "    return _wrapfunc(a, 'repeat', repeats, axis=axis)\n",
      "docstring: repeat\n",
      "\n",
      "    Repeat elements of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    repeats : int or array of ints\n",
      "        The number of repetitions for each element.  `repeats` is broadcasted\n",
      "        to fit the shape of the given axis.\n",
      "    axis : int, optional\n",
      "        The axis along which to repeat values.  By default, use the\n",
      "        flattened input array, and return a flat output array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    repeated_array : ndarray\n",
      "        Output array which has the same shape as `a`, except along\n",
      "        the given axis.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    tile : Tile an array.\n",
      "    unique : Find the unique elements of an array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.repeat(3, 4)\n",
      "    array([3, 3, 3, 3])\n",
      "    >>> x = np.array([[1,2],[3,4]])\n",
      "    >>> np.repeat(x, 2)\n",
      "    array([1, 1, 2, 2, 3, 3, 4, 4])\n",
      "    >>> np.repeat(x, 3, axis=1)\n",
      "    array([[1, 1, 1, 2, 2, 2],\n",
      "           [3, 3, 3, 4, 4, 4]])\n",
      "    >>> np.repeat(x, [1, 2], axis=0)\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [3, 4]])\n",
      "\n",
      "    \n",
      "code: reshape\n",
      "@array_function_dispatch(_reshape_dispatcher)\n",
      "def reshape(a, newshape, order='C'):\n",
      "    return _wrapfunc(a, 'reshape', newshape, order=order)\n",
      "docstring: reshape\n",
      "\n",
      "    Gives a new shape to an array without changing its data.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to be reshaped.\n",
      "    newshape : int or tuple of ints\n",
      "        The new shape should be compatible with the original shape. If\n",
      "        an integer, then the result will be a 1-D array of that length.\n",
      "        One shape dimension can be -1. In this case, the value is\n",
      "        inferred from the length of the array and remaining dimensions.\n",
      "    order : {'C', 'F', 'A'}, optional\n",
      "        Read the elements of `a` using this index order, and place the\n",
      "        elements into the reshaped array using this index order.  'C'\n",
      "        means to read / write the elements using C-like index order,\n",
      "        with the last axis index changing fastest, back to the first\n",
      "        axis index changing slowest. 'F' means to read / write the\n",
      "        elements using Fortran-like index order, with the first index\n",
      "        changing fastest, and the last index changing slowest. Note that\n",
      "        the 'C' and 'F' options take no account of the memory layout of\n",
      "        the underlying array, and only refer to the order of indexing.\n",
      "        'A' means to read / write the elements in Fortran-like index\n",
      "        order if `a` is Fortran *contiguous* in memory, C-like order\n",
      "        otherwise.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    reshaped_array : ndarray\n",
      "        This will be a new view object if possible; otherwise, it will\n",
      "        be a copy.  Note there is no guarantee of the *memory layout* (C- or\n",
      "        Fortran- contiguous) of the returned array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.reshape : Equivalent method.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    It is not always possible to change the shape of an array without\n",
      "    copying the data. If you want an error to be raised when the data is copied,\n",
      "    you should assign the new shape to the shape attribute of the array::\n",
      "\n",
      "     >>> a = np.zeros((10, 2))\n",
      "\n",
      "     # A transpose makes the array non-contiguous\n",
      "     >>> b = a.T\n",
      "\n",
      "     # Taking a view makes it possible to modify the shape without modifying\n",
      "     # the initial object.\n",
      "     >>> c = b.view()\n",
      "     >>> c.shape = (20)\n",
      "     Traceback (most recent call last):\n",
      "        ...\n",
      "     AttributeError: Incompatible shape for in-place modification. Use\n",
      "     `.reshape()` to make a copy with the desired shape.\n",
      "\n",
      "    The `order` keyword gives the index ordering both for *fetching* the values\n",
      "    from `a`, and then *placing* the values into the output array.\n",
      "    For example, let's say you have an array:\n",
      "\n",
      "    >>> a = np.arange(6).reshape((3, 2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5]])\n",
      "\n",
      "    You can think of reshaping as first raveling the array (using the given\n",
      "    index order), then inserting the elements from the raveled array into the\n",
      "    new array using the same kind of index ordering as was used for the\n",
      "    raveling.\n",
      "\n",
      "    >>> np.reshape(a, (2, 3)) # C-like index ordering\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering\n",
      "    array([[0, 4, 3],\n",
      "           [2, 1, 5]])\n",
      "    >>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F')\n",
      "    array([[0, 4, 3],\n",
      "           [2, 1, 5]])\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1,2,3], [4,5,6]])\n",
      "    >>> np.reshape(a, 6)\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "    >>> np.reshape(a, 6, order='F')\n",
      "    array([1, 4, 2, 5, 3, 6])\n",
      "\n",
      "    >>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]])\n",
      "    \n",
      "code: resize\n",
      "@array_function_dispatch(_resize_dispatcher)\n",
      "def resize(a, new_shape):\n",
      "    if isinstance(new_shape, (int, nt.integer)):\n",
      "        new_shape = (new_shape,)\n",
      "    a = ravel(a)\n",
      "    new_size = 1\n",
      "    for dim_length in new_shape:\n",
      "        new_size *= dim_length\n",
      "        if dim_length < 0:\n",
      "            raise ValueError('all elements of `new_shape` must be non-negative')\n",
      "    if a.size == 0 or new_size == 0:\n",
      " ceil division\n",
      "    a = concatenate((a,) * repeats)[:new_size]\n",
      "    return reshape(a, new_shape)\n",
      "docstring: resize\n",
      "\n",
      "    Return a new array with the specified shape.\n",
      "\n",
      "    If the new array is larger than the original array, then the new\n",
      "    array is filled with repeated copies of `a`.  Note that this behavior\n",
      "    is different from a.resize(new_shape) which fills with zeros instead\n",
      "    of repeated copies of `a`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to be resized.\n",
      "\n",
      "    new_shape : int or tuple of int\n",
      "        Shape of resized array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    reshaped_array : ndarray\n",
      "        The new array is formed from the data in the old array, repeated\n",
      "        if necessary to fill out the required number of elements.  The\n",
      "        data are repeated iterating over the array in C-order.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.reshape : Reshape an array without changing the total size.\n",
      "    numpy.pad : Enlarge and pad an array.\n",
      "    numpy.repeat : Repeat elements of an array.\n",
      "    ndarray.resize : resize an array in-place.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When the total size of the array does not change `~numpy.reshape` should\n",
      "    be used.  In most other cases either indexing (to reduce the size)\n",
      "    or padding (to increase the size) may be a more appropriate solution.\n",
      "\n",
      "    Warning: This functionality does **not** consider axes separately,\n",
      "    i.e. it does not apply interpolation/extrapolation.\n",
      "    It fills the return array with the required number of elements, iterating\n",
      "    over `a` in C-order, disregarding axes (and cycling back from the start if\n",
      "    the new shape is larger).  This functionality is therefore not suitable to\n",
      "    resize images, or data where each axis represents a separate and distinct\n",
      "    entity.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a=np.array([[0,1],[2,3]])\n",
      "    >>> np.resize(a,(2,3))\n",
      "    array([[0, 1, 2],\n",
      "           [3, 0, 1]])\n",
      "    >>> np.resize(a,(1,4))\n",
      "    array([[0, 1, 2, 3]])\n",
      "    >>> np.resize(a,(2,4))\n",
      "    array([[0, 1, 2, 3],\n",
      "           [0, 1, 2, 3]])\n",
      "\n",
      "    \n",
      "code: round_\n",
      "@array_function_dispatch(_around_dispatcher)\n",
      "def round_(a, decimals=0, out=None):\n",
      "    return around(a, decimals=decimals, out=out)\n",
      "docstring: round_\n",
      "\n",
      "    Round an array to the given number of decimals.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    around : equivalent function; see for details.\n",
      "    \n",
      "code: searchsorted\n",
      "@array_function_dispatch(_searchsorted_dispatcher)\n",
      "def searchsorted(a, v, side='left', sorter=None):\n",
      "    return _wrapfunc(a, 'searchsorted', v, side=side, sorter=sorter)\n",
      "docstring: searchsorted\n",
      "\n",
      "    Find indices where elements should be inserted to maintain order.\n",
      "\n",
      "    Find the indices into a sorted array `a` such that, if the\n",
      "    corresponding elements in `v` were inserted before the indices, the\n",
      "    order of `a` would be preserved.\n",
      "\n",
      "    Assuming that `a` is sorted:\n",
      "\n",
      "    ======  ============================\n",
      "    `side`  returned index `i` satisfies\n",
      "    ======  ============================\n",
      "    left    ``a[i-1] < v <= a[i]``\n",
      "    right   ``a[i-1] <= v < a[i]``\n",
      "    ======  ============================\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : 1-D array_like\n",
      "        Input array. If `sorter` is None, then it must be sorted in\n",
      "        ascending order, otherwise `sorter` must be an array of indices\n",
      "        that sort it.\n",
      "    v : array_like\n",
      "        Values to insert into `a`.\n",
      "    side : {'left', 'right'}, optional\n",
      "        If 'left', the index of the first suitable location found is given.\n",
      "        If 'right', return the last such index.  If there is no suitable\n",
      "        index, return either 0 or N (where N is the length of `a`).\n",
      "    sorter : 1-D array_like, optional\n",
      "        Optional array of integer indices that sort array a into ascending\n",
      "        order. They are typically the result of argsort.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    indices : int or array of ints\n",
      "        Array of insertion points with the same shape as `v`,\n",
      "        or an integer if `v` is a scalar.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    sort : Return a sorted copy of an array.\n",
      "    histogram : Produce histogram from 1-D data.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Binary search is used to find the required insertion points.\n",
      "\n",
      "    As of NumPy 1.4.0 `searchsorted` works with real/complex arrays containing\n",
      "    `nan` values. The enhanced sort order is documented in `sort`.\n",
      "\n",
      "    This function uses the same algorithm as the builtin python `bisect.bisect_left`\n",
      "    (``side='left'``) and `bisect.bisect_right` (``side='right'``) functions,\n",
      "    which is also vectorized in the `v` argument.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.searchsorted([1,2,3,4,5], 3)\n",
      "    2\n",
      "    >>> np.searchsorted([1,2,3,4,5], 3, side='right')\n",
      "    3\n",
      "    >>> np.searchsorted([1,2,3,4,5], [-10, 10, 2, 3])\n",
      "    array([0, 5, 1, 2])\n",
      "\n",
      "    \n",
      "code: shape\n",
      "@array_function_dispatch(_shape_dispatcher)\n",
      "def shape(a):\n",
      "    try:\n",
      "        result = a.shape\n",
      "    except AttributeError:\n",
      "        result = asarray(a).shape\n",
      "    return result\n",
      "docstring: shape\n",
      "\n",
      "    Return the shape of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    shape : tuple of ints\n",
      "        The elements of the shape tuple give the lengths of the\n",
      "        corresponding array dimensions.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    len : ``len(a)`` is equivalent to ``np.shape(a)[0]`` for N-D arrays with\n",
      "          ``N>=1``.\n",
      "    ndarray.shape : Equivalent array method.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.shape(np.eye(3))\n",
      "    (3, 3)\n",
      "    >>> np.shape([[1, 3]])\n",
      "    (1, 2)\n",
      "    >>> np.shape([0])\n",
      "    (1,)\n",
      "    >>> np.shape(0)\n",
      "    ()\n",
      "\n",
      "    >>> a = np.array([(1, 2), (3, 4), (5, 6)],\n",
      "    ...              dtype=[('x', 'i4'), ('y', 'i4')])\n",
      "    >>> np.shape(a)\n",
      "    (3,)\n",
      "    >>> a.shape\n",
      "    (3,)\n",
      "\n",
      "    \n",
      "code: size\n",
      "@array_function_dispatch(_size_dispatcher)\n",
      "def size(a, axis=None):\n",
      "    if axis is None:\n",
      "        try:\n",
      "            return a.size\n",
      "        except AttributeError:\n",
      "            return asarray(a).size\n",
      "    else:\n",
      "        try:\n",
      "            return a.shape[axis]\n",
      "        except AttributeError:\n",
      "            return asarray(a).shape[axis]\n",
      "docstring: size\n",
      "\n",
      "    Return the number of elements along a given axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : int, optional\n",
      "        Axis along which the elements are counted.  By default, give\n",
      "        the total number of elements.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    element_count : int\n",
      "        Number of elements along the specified axis.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    shape : dimensions of array\n",
      "    ndarray.shape : dimensions of array\n",
      "    ndarray.size : number of elements in array\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1,2,3],[4,5,6]])\n",
      "    >>> np.size(a)\n",
      "    6\n",
      "    >>> np.size(a,1)\n",
      "    3\n",
      "    >>> np.size(a,0)\n",
      "    2\n",
      "\n",
      "    \n",
      "code: sometrue\n",
      "@array_function_dispatch(_any_dispatcher, verify=False)\n",
      "def sometrue(*args, **kwargs):\n",
      "    return any(*args, **kwargs)\n",
      "docstring: sometrue\n",
      "\n",
      "    Check whether some values are true.\n",
      "\n",
      "    Refer to `any` for full documentation.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    any : equivalent function; see for details.\n",
      "    \n",
      "code: sort\n",
      "@array_function_dispatch(_sort_dispatcher)\n",
      "def sort(a, axis=-1, kind=None, order=None):\n",
      "    if axis is None:\n",
      "        # flatten returns (1, N) for np.matrix, so always use the last axis\n",
      "        a = asanyarray(a).flatten()\n",
      "        axis = -1\n",
      "    else:\n",
      "        a = asanyarray(a).copy(order=\"K\")\n",
      "    a.sort(axis=axis, kind=kind, order=order)\n",
      "    return a\n",
      "docstring: sort\n",
      "\n",
      "    Return a sorted copy of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to be sorted.\n",
      "    axis : int or None, optional\n",
      "        Axis along which to sort. If None, the array is flattened before\n",
      "        sorting. The default is -1, which sorts along the last axis.\n",
      "    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n",
      "        Sorting algorithm. The default is 'quicksort'. Note that both 'stable'\n",
      "        and 'mergesort' use timsort or radix sort under the covers and, in general,\n",
      "        the actual implementation will vary with data type. The 'mergesort' option\n",
      "        is retained for backwards compatibility.\n",
      "\n",
      "        .. versionchanged:: 1.15.0.\n",
      "           The 'stable' option was added.\n",
      "\n",
      "    order : str or list of str, optional\n",
      "        When `a` is an array with fields defined, this argument specifies\n",
      "        which fields to compare first, second, etc.  A single field can\n",
      "        be specified as a string, and not all fields need be specified,\n",
      "        but unspecified fields will still be used, in the order in which\n",
      "        they come up in the dtype, to break ties.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    sorted_array : ndarray\n",
      "        Array of the same type and shape as `a`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.sort : Method to sort an array in-place.\n",
      "    argsort : Indirect sort.\n",
      "    lexsort : Indirect stable sort on multiple keys.\n",
      "    searchsorted : Find elements in a sorted array.\n",
      "    partition : Partial sort.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The various sorting algorithms are characterized by their average speed,\n",
      "    worst case performance, work space size, and whether they are stable. A\n",
      "    stable sort keeps items with the same key in the same relative\n",
      "    order. The four algorithms implemented in NumPy have the following\n",
      "    properties:\n",
      "\n",
      "    =========== ======= ============= ============ ========\n",
      "       kind      speed   worst case    work space   stable\n",
      "    =========== ======= ============= ============ ========\n",
      "    'quicksort'    1     O(n^2)            0          no\n",
      "    'heapsort'     3     O(n*log(n))       0          no\n",
      "    'mergesort'    2     O(n*log(n))      ~n/2        yes\n",
      "    'timsort'      2     O(n*log(n))      ~n/2        yes\n",
      "    =========== ======= ============= ============ ========\n",
      "\n",
      "    .. note:: The datatype determines which of 'mergesort' or 'timsort'\n",
      "       is actually used, even if 'mergesort' is specified. User selection\n",
      "       at a finer scale is not currently available.\n",
      "\n",
      "    All the sort algorithms make temporary copies of the data when\n",
      "    sorting along any but the last axis.  Consequently, sorting along\n",
      "    the last axis is faster and uses less space than sorting along\n",
      "    any other axis.\n",
      "\n",
      "    The sort order for complex numbers is lexicographic. If both the real\n",
      "    and imaginary parts are non-nan then the order is determined by the\n",
      "    real parts except when they are equal, in which case the order is\n",
      "    determined by the imaginary parts.\n",
      "\n",
      "    Previous to numpy 1.4.0 sorting real and complex arrays containing nan\n",
      "    values led to undefined behaviour. In numpy versions >= 1.4.0 nan\n",
      "    values are sorted to the end. The extended sort order is:\n",
      "\n",
      "      * Real: [R, nan]\n",
      "      * Complex: [R + Rj, R + nanj, nan + Rj, nan + nanj]\n",
      "\n",
      "    where R is a non-nan real value. Complex values with the same nan\n",
      "    placements are sorted according to the non-nan part if it exists.\n",
      "    Non-nan values are sorted as before.\n",
      "\n",
      "    .. versionadded:: 1.12.0\n",
      "\n",
      "    quicksort has been changed to `introsort <https://en.wikipedia.org/wiki/Introsort>`_.\n",
      "    When sorting does not make enough progress it switches to\n",
      "    `heapsort <https://en.wikipedia.org/wiki/Heapsort>`_.\n",
      "    This implementation makes quicksort O(n*log(n)) in the worst case.\n",
      "\n",
      "    'stable' automatically chooses the best stable sorting algorithm\n",
      "    for the data type being sorted.\n",
      "    It, along with 'mergesort' is currently mapped to\n",
      "    `timsort <https://en.wikipedia.org/wiki/Timsort>`_\n",
      "    or `radix sort <https://en.wikipedia.org/wiki/Radix_sort>`_\n",
      "    depending on the data type.\n",
      "    API forward compatibility currently limits the\n",
      "    ability to select the implementation and it is hardwired for the different\n",
      "    data types.\n",
      "\n",
      "    .. versionadded:: 1.17.0\n",
      "\n",
      "    Timsort is added for better performance on already or nearly\n",
      "    sorted data. On random data timsort is almost identical to\n",
      "    mergesort. It is now used for stable sort while quicksort is still the\n",
      "    default sort if none is chosen. For timsort details, refer to\n",
      "    `CPython listsort.txt <https://github.com/python/cpython/blob/3.7/Objects/listsort.txt>`_.\n",
      "    'mergesort' and 'stable' are mapped to radix sort for integer data types. Radix sort is an\n",
      "    O(n) sort instead of O(n log n).\n",
      "\n",
      "    .. versionchanged:: 1.18.0\n",
      "\n",
      "    NaT now sorts to the end of arrays for consistency with NaN.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1,4],[3,1]])\n",
      "    >>> np.sort(a)                # sort along the last axis\n",
      "    array([[1, 4],\n",
      "           [1, 3]])\n",
      "    >>> np.sort(a, axis=None)     # sort the flattened array\n",
      "    array([1, 1, 3, 4])\n",
      "    >>> np.sort(a, axis=0)        # sort along the first axis\n",
      "    array([[1, 1],\n",
      "           [3, 4]])\n",
      "\n",
      "    Use the `order` keyword to specify a field to use when sorting a\n",
      "    structured array:\n",
      "\n",
      "    >>> dtype = [('name', 'S10'), ('height', float), ('age', int)]\n",
      "    >>> values = [('Arthur', 1.8, 41), ('Lancelot', 1.9, 38),\n",
      "    ...           ('Galahad', 1.7, 38)]\n",
      "    >>> a = np.array(values, dtype=dtype)       # create a structured array\n",
      "    >>> np.sort(a, order='height')                        # doctest: +SKIP\n",
      "    array([('Galahad', 1.7, 38), ('Arthur', 1.8, 41),\n",
      "           ('Lancelot', 1.8999999999999999, 38)],\n",
      "          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])\n",
      "\n",
      "    Sort by age, then height if ages are equal:\n",
      "\n",
      "    >>> np.sort(a, order=['age', 'height'])               # doctest: +SKIP\n",
      "    array([('Galahad', 1.7, 38), ('Lancelot', 1.8999999999999999, 38),\n",
      "           ('Arthur', 1.8, 41)],\n",
      "          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])\n",
      "\n",
      "    \n",
      "code: squeeze\n",
      "@array_function_dispatch(_squeeze_dispatcher)\n",
      "def squeeze(a, axis=None):\n",
      "    try:\n",
      "        squeeze = a.squeeze\n",
      "    except AttributeError:\n",
      "        return _wrapit(a, 'squeeze', axis=axis)\n",
      "    if axis is None:\n",
      "        return squeeze()\n",
      "    else:\n",
      "        return squeeze(axis=axis)\n",
      "docstring: squeeze\n",
      "\n",
      "    Remove axes of length one from `a`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        Selects a subset of the entries of length one in the\n",
      "        shape. If an axis is selected with shape entry greater than\n",
      "        one, an error is raised.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    squeezed : ndarray\n",
      "        The input array, but with all or a subset of the\n",
      "        dimensions of length 1 removed. This is always `a` itself\n",
      "        or a view into `a`. Note that if all axes are squeezed,\n",
      "        the result is a 0d array and not a scalar.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If `axis` is not None, and an axis being squeezed is not of length 1\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    expand_dims : The inverse operation, adding entries of length one\n",
      "    reshape : Insert, remove, and combine dimensions, and resize existing ones\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([[[0], [1], [2]]])\n",
      "    >>> x.shape\n",
      "    (1, 3, 1)\n",
      "    >>> np.squeeze(x).shape\n",
      "    (3,)\n",
      "    >>> np.squeeze(x, axis=0).shape\n",
      "    (3, 1)\n",
      "    >>> np.squeeze(x, axis=1).shape\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    ValueError: cannot select an axis to squeeze out which has size not equal to one\n",
      "    >>> np.squeeze(x, axis=2).shape\n",
      "    (1, 3)\n",
      "    >>> x = np.array([[1234]])\n",
      "    >>> x.shape\n",
      "    (1, 1)\n",
      "    >>> np.squeeze(x)\n",
      "    array(1234)  # 0d array\n",
      "    >>> np.squeeze(x).shape\n",
      "    ()\n",
      "    >>> np.squeeze(x)[()]\n",
      "    1234\n",
      "\n",
      "    \n",
      "code: std\n",
      "@array_function_dispatch(_std_dispatcher)\n",
      "def std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue, *,\n",
      "        where=np._NoValue):\n",
      "    kwargs = {}\n",
      "    if keepdims is not np._NoValue:\n",
      "        kwargs['keepdims'] = keepdims\n",
      "    if where is not np._NoValue:\n",
      "        kwargs['where'] = where\n",
      "    if type(a) is not mu.ndarray:\n",
      "        try:\n",
      "            std = a.std\n",
      "        except AttributeError:\n",
      "            pass\n",
      "        else:\n",
      "            return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n",
      "    return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "                         **kwargs)\n",
      "docstring: std\n",
      "\n",
      "    Compute the standard deviation along the specified axis.\n",
      "\n",
      "    Returns the standard deviation, a measure of the spread of a distribution,\n",
      "    of the array elements. The standard deviation is computed for the\n",
      "    flattened array by default, otherwise over the specified axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Calculate the standard deviation of these values.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which the standard deviation is computed. The\n",
      "        default is to compute the standard deviation of the flattened array.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If this is a tuple of ints, a standard deviation is performed over\n",
      "        multiple axes, instead of a single axis or all the axes as before.\n",
      "    dtype : dtype, optional\n",
      "        Type to use in computing the standard deviation. For arrays of\n",
      "        integer type the default is float64, for arrays of float types it is\n",
      "        the same as the array type.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output but the type (of the calculated\n",
      "        values) will be cast if necessary.\n",
      "    ddof : int, optional\n",
      "        Means Delta Degrees of Freedom.  The divisor used in calculations\n",
      "        is ``N - ddof``, where ``N`` represents the number of elements.\n",
      "        By default `ddof` is zero.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `std` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the standard deviation.\n",
      "        See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    standard_deviation : ndarray, see dtype parameter above.\n",
      "        If `out` is None, return a new array containing the standard deviation,\n",
      "        otherwise return a reference to the output array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    var, mean, nanmean, nanstd, nanvar\n",
      "    :ref:`ufuncs-output-type`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The standard deviation is the square root of the average of the squared\n",
      "    deviations from the mean, i.e., ``std = sqrt(mean(x))``, where\n",
      "    ``x = abs(a - a.mean())**2``.\n",
      "\n",
      "    The average squared deviation is typically calculated as ``x.sum() / N``,\n",
      "    where ``N = len(x)``. If, however, `ddof` is specified, the divisor\n",
      "    ``N - ddof`` is used instead. In standard statistical practice, ``ddof=1``\n",
      "    provides an unbiased estimator of the variance of the infinite population.\n",
      "    ``ddof=0`` provides a maximum likelihood estimate of the variance for\n",
      "    normally distributed variables. The standard deviation computed in this\n",
      "    function is the square root of the estimated variance, so even with\n",
      "    ``ddof=1``, it will not be an unbiased estimate of the standard deviation\n",
      "    per se.\n",
      "\n",
      "    Note that, for complex numbers, `std` takes the absolute\n",
      "    value before squaring, so that the result is always real and nonnegative.\n",
      "\n",
      "    For floating-point input, the *std* is computed using the same\n",
      "    precision the input has. Depending on the input data, this can cause\n",
      "    the results to be inaccurate, especially for float32 (see example below).\n",
      "    Specifying a higher-accuracy accumulator using the `dtype` keyword can\n",
      "    alleviate this issue.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> np.std(a)\n",
      "    1.1180339887498949 # may vary\n",
      "    >>> np.std(a, axis=0)\n",
      "    array([1.,  1.])\n",
      "    >>> np.std(a, axis=1)\n",
      "    array([0.5,  0.5])\n",
      "\n",
      "    In single precision, std() can be inaccurate:\n",
      "\n",
      "    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n",
      "    >>> a[0, :] = 1.0\n",
      "    >>> a[1, :] = 0.1\n",
      "    >>> np.std(a)\n",
      "    0.45000005\n",
      "\n",
      "    Computing the standard deviation in float64 is more accurate:\n",
      "\n",
      "    >>> np.std(a, dtype=np.float64)\n",
      "    0.44999999925494177 # may vary\n",
      "\n",
      "    Specifying a where argument:\n",
      "\n",
      "    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])\n",
      "    >>> np.std(a)\n",
      "    2.614064523559687 # may vary\n",
      "    >>> np.std(a, where=[[True], [True], [False]])\n",
      "    2.0\n",
      "\n",
      "    \n",
      "code: sum\n",
      "@array_function_dispatch(_sum_dispatcher)\n",
      "def sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n",
      "        initial=np._NoValue, where=np._NoValue):\n",
      "    if isinstance(a, _gentype):\n",
      "        # 2018-02-25, 1.15.0\n",
      "        warnings.warn(\n",
      "            \"Calling np.sum(generator) is deprecated, and in the future will give a different result. \"\n",
      "            \"Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\",\n",
      "            DeprecationWarning, stacklevel=3)\n",
      "        res = _sum_(a)\n",
      "        if out is not None:\n",
      "            out[...] = res\n",
      "            return out\n",
      "        return res\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "                          initial=initial, where=where)\n",
      "docstring: sum\n",
      "\n",
      "    Sum of array elements over a given axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Elements to sum.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which a sum is performed.  The default,\n",
      "        axis=None, will sum all of the elements of the input array.  If\n",
      "        axis is negative it counts from the last to the first axis.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If axis is a tuple of ints, a sum is performed on all of the axes\n",
      "        specified in the tuple instead of a single axis or all the axes as\n",
      "        before.\n",
      "    dtype : dtype, optional\n",
      "        The type of the returned array and of the accumulator in which the\n",
      "        elements are summed.  The dtype of `a` is used by default unless `a`\n",
      "        has an integer dtype of less precision than the default platform\n",
      "        integer.  In that case, if `a` is signed then the platform integer\n",
      "        is used while if `a` is unsigned then an unsigned integer of the\n",
      "        same precision as the platform integer is used.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output, but the type of the output\n",
      "        values will be cast if necessary.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `sum` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    initial : scalar, optional\n",
      "        Starting value for the sum. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.15.0\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the sum. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    sum_along_axis : ndarray\n",
      "        An array with the same shape as `a`, with the specified\n",
      "        axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar\n",
      "        is returned.  If an output array is specified, a reference to\n",
      "        `out` is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.sum : Equivalent method.\n",
      "\n",
      "    add.reduce : Equivalent functionality of `add`.\n",
      "\n",
      "    cumsum : Cumulative sum of array elements.\n",
      "\n",
      "    trapz : Integration of array values using the composite trapezoidal rule.\n",
      "\n",
      "    mean, average\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Arithmetic is modular when using integer types, and no error is\n",
      "    raised on overflow.\n",
      "\n",
      "    The sum of an empty array is the neutral element 0:\n",
      "\n",
      "    >>> np.sum([])\n",
      "    0.0\n",
      "\n",
      "    For floating point numbers the numerical precision of sum (and\n",
      "    ``np.add.reduce``) is in general limited by directly adding each number\n",
      "    individually to the result causing rounding errors in every step.\n",
      "    However, often numpy will use a  numerically better approach (partial\n",
      "    pairwise summation) leading to improved precision in many use-cases.\n",
      "    This improved precision is always provided when no ``axis`` is given.\n",
      "    When ``axis`` is given, it will depend on which axis is summed.\n",
      "    Technically, to provide the best speed possible, the improved precision\n",
      "    is only used when the summation is along the fast axis in memory.\n",
      "    Note that the exact precision may vary depending on other parameters.\n",
      "    In contrast to NumPy, Python's ``math.fsum`` function uses a slower but\n",
      "    more precise approach to summation.\n",
      "    Especially when summing a large number of lower precision floating point\n",
      "    numbers, such as ``float32``, numerical errors can become significant.\n",
      "    In such cases it can be advisable to use `dtype=\"float64\"` to use a higher\n",
      "    precision for the output.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.sum([0.5, 1.5])\n",
      "    2.0\n",
      "    >>> np.sum([0.5, 0.7, 0.2, 1.5], dtype=np.int32)\n",
      "    1\n",
      "    >>> np.sum([[0, 1], [0, 5]])\n",
      "    6\n",
      "    >>> np.sum([[0, 1], [0, 5]], axis=0)\n",
      "    array([0, 6])\n",
      "    >>> np.sum([[0, 1], [0, 5]], axis=1)\n",
      "    array([1, 5])\n",
      "    >>> np.sum([[0, 1], [np.nan, 5]], where=[False, True], axis=1)\n",
      "    array([1., 5.])\n",
      "\n",
      "    If the accumulator is too small, overflow occurs:\n",
      "\n",
      "    >>> np.ones(128, dtype=np.int8).sum(dtype=np.int8)\n",
      "    -128\n",
      "\n",
      "    You can also start the sum with a value other than zero:\n",
      "\n",
      "    >>> np.sum([10], initial=5)\n",
      "    15\n",
      "    \n",
      "code: swapaxes\n",
      "@array_function_dispatch(_swapaxes_dispatcher)\n",
      "def swapaxes(a, axis1, axis2):\n",
      "    return _wrapfunc(a, 'swapaxes', axis1, axis2)\n",
      "docstring: swapaxes\n",
      "\n",
      "    Interchange two axes of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axis1 : int\n",
      "        First axis.\n",
      "    axis2 : int\n",
      "        Second axis.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    a_swapped : ndarray\n",
      "        For NumPy >= 1.10.0, if `a` is an ndarray, then a view of `a` is\n",
      "        returned; otherwise a new array is created. For earlier NumPy\n",
      "        versions a view of `a` is returned only if the order of the\n",
      "        axes is changed, otherwise the input array is returned.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([[1,2,3]])\n",
      "    >>> np.swapaxes(x,0,1)\n",
      "    array([[1],\n",
      "           [2],\n",
      "           [3]])\n",
      "\n",
      "    >>> x = np.array([[[0,1],[2,3]],[[4,5],[6,7]]])\n",
      "    >>> x\n",
      "    array([[[0, 1],\n",
      "            [2, 3]],\n",
      "           [[4, 5],\n",
      "            [6, 7]]])\n",
      "\n",
      "    >>> np.swapaxes(x,0,2)\n",
      "    array([[[0, 4],\n",
      "            [2, 6]],\n",
      "           [[1, 5],\n",
      "            [3, 7]]])\n",
      "\n",
      "    \n",
      "code: take\n",
      "@array_function_dispatch(_take_dispatcher)\n",
      "def take(a, indices, axis=None, out=None, mode='raise'):\n",
      "    return _wrapfunc(a, 'take', indices, axis=axis, out=out, mode=mode)\n",
      "docstring: take\n",
      "\n",
      "    Take elements from an array along an axis.\n",
      "\n",
      "    When axis is not None, this function does the same thing as \"fancy\"\n",
      "    indexing (indexing arrays using arrays); however, it can be easier to use\n",
      "    if you need elements along a given axis. A call such as\n",
      "    ``np.take(arr, indices, axis=3)`` is equivalent to\n",
      "    ``arr[:,:,:,indices,...]``.\n",
      "\n",
      "    Explained without fancy indexing, this is equivalent to the following use\n",
      "    of `ndindex`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of\n",
      "    indices::\n",
      "\n",
      "        Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n",
      "        Nj = indices.shape\n",
      "        for ii in ndindex(Ni):\n",
      "            for jj in ndindex(Nj):\n",
      "                for kk in ndindex(Nk):\n",
      "                    out[ii + jj + kk] = a[ii + (indices[jj],) + kk]\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like (Ni..., M, Nk...)\n",
      "        The source array.\n",
      "    indices : array_like (Nj...)\n",
      "        The indices of the values to extract.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "\n",
      "        Also allow scalars for indices.\n",
      "    axis : int, optional\n",
      "        The axis over which to select values. By default, the flattened\n",
      "        input array is used.\n",
      "    out : ndarray, optional (Ni..., Nj..., Nk...)\n",
      "        If provided, the result will be placed in this array. It should\n",
      "        be of the appropriate shape and dtype. Note that `out` is always\n",
      "        buffered if `mode='raise'`; use other modes for better performance.\n",
      "    mode : {'raise', 'wrap', 'clip'}, optional\n",
      "        Specifies how out-of-bounds indices will behave.\n",
      "\n",
      "        * 'raise' -- raise an error (default)\n",
      "        * 'wrap' -- wrap around\n",
      "        * 'clip' -- clip to the range\n",
      "\n",
      "        'clip' mode means that all indices that are too large are replaced\n",
      "        by the index that addresses the last element along that axis. Note\n",
      "        that this disables indexing with negative numbers.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray (Ni..., Nj..., Nk...)\n",
      "        The returned array has the same type as `a`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    compress : Take elements using a boolean mask\n",
      "    ndarray.take : equivalent method\n",
      "    take_along_axis : Take elements by matching the array and the index arrays\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "\n",
      "    By eliminating the inner loop in the description above, and using `s_` to\n",
      "    build simple slice objects, `take` can be expressed  in terms of applying\n",
      "    fancy indexing to each 1-d slice::\n",
      "\n",
      "        Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n",
      "        for ii in ndindex(Ni):\n",
      "            for kk in ndindex(Nj):\n",
      "                out[ii + s_[...,] + kk] = a[ii + s_[:,] + kk][indices]\n",
      "\n",
      "    For this reason, it is equivalent to (but faster than) the following use\n",
      "    of `apply_along_axis`::\n",
      "\n",
      "        out = np.apply_along_axis(lambda a_1d: a_1d[indices], axis, a)\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = [4, 3, 5, 7, 6, 8]\n",
      "    >>> indices = [0, 1, 4]\n",
      "    >>> np.take(a, indices)\n",
      "    array([4, 3, 6])\n",
      "\n",
      "    In this example if `a` is an ndarray, \"fancy\" indexing can be used.\n",
      "\n",
      "    >>> a = np.array(a)\n",
      "    >>> a[indices]\n",
      "    array([4, 3, 6])\n",
      "\n",
      "    If `indices` is not one dimensional, the output also has these dimensions.\n",
      "\n",
      "    >>> np.take(a, [[0, 1], [2, 3]])\n",
      "    array([[4, 3],\n",
      "           [5, 7]])\n",
      "    \n",
      "code: trace\n",
      "@array_function_dispatch(_trace_dispatcher)\n",
      "def trace(a, offset=0, axis1=0, axis2=1, dtype=None, out=None):\n",
      "    if isinstance(a, np.matrix):\n",
      "        # Get trace of matrix via an array to preserve backward compatibility.\n",
      "        return asarray(a).trace(offset=offset, axis1=axis1, axis2=axis2, dtype=dtype, out=out)\n",
      "    else:\n",
      "        return asanyarray(a).trace(offset=offset, axis1=axis1, axis2=axis2, dtype=dtype, out=out)\n",
      "docstring: trace\n",
      "\n",
      "    Return the sum along diagonals of the array.\n",
      "\n",
      "    If `a` is 2-D, the sum along its diagonal with the given offset\n",
      "    is returned, i.e., the sum of elements ``a[i,i+offset]`` for all i.\n",
      "\n",
      "    If `a` has more than two dimensions, then the axes specified by axis1 and\n",
      "    axis2 are used to determine the 2-D sub-arrays whose traces are returned.\n",
      "    The shape of the resulting array is the same as that of `a` with `axis1`\n",
      "    and `axis2` removed.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array, from which the diagonals are taken.\n",
      "    offset : int, optional\n",
      "        Offset of the diagonal from the main diagonal. Can be both positive\n",
      "        and negative. Defaults to 0.\n",
      "    axis1, axis2 : int, optional\n",
      "        Axes to be used as the first and second axis of the 2-D sub-arrays\n",
      "        from which the diagonals should be taken. Defaults are the first two\n",
      "        axes of `a`.\n",
      "    dtype : dtype, optional\n",
      "        Determines the data-type of the returned array and of the accumulator\n",
      "        where the elements are summed. If dtype has the value None and `a` is\n",
      "        of integer type of precision less than the default integer\n",
      "        precision, then the default integer precision is used. Otherwise,\n",
      "        the precision is the same as that of `a`.\n",
      "    out : ndarray, optional\n",
      "        Array into which the output is placed. Its type is preserved and\n",
      "        it must be of the right shape to hold the output.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    sum_along_diagonals : ndarray\n",
      "        If `a` is 2-D, the sum along the diagonal is returned.  If `a` has\n",
      "        larger dimensions, then an array of sums along diagonals is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    diag, diagonal, diagflat\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.trace(np.eye(3))\n",
      "    3.0\n",
      "    >>> a = np.arange(8).reshape((2,2,2))\n",
      "    >>> np.trace(a)\n",
      "    array([6, 8])\n",
      "\n",
      "    >>> a = np.arange(24).reshape((2,2,2,3))\n",
      "    >>> np.trace(a).shape\n",
      "    (2, 3)\n",
      "\n",
      "    \n",
      "code: transpose\n",
      "@array_function_dispatch(_transpose_dispatcher)\n",
      "def transpose(a, axes=None):\n",
      "    return _wrapfunc(a, 'transpose', axes)\n",
      "docstring: transpose\n",
      "\n",
      "    Returns an array with axes transposed.\n",
      "\n",
      "    For a 1-D array, this returns an unchanged view of the original array, as a\n",
      "    transposed vector is simply the same vector.\n",
      "    To convert a 1-D array into a 2-D column vector, an additional dimension\n",
      "    must be added, e.g., ``np.atleast2d(a).T`` achieves this, as does\n",
      "    ``a[:, np.newaxis]``.\n",
      "    For a 2-D array, this is the standard matrix transpose.\n",
      "    For an n-D array, if axes are given, their order indicates how the\n",
      "    axes are permuted (see Examples). If axes are not provided, then\n",
      "    ``transpose(a).shape == a.shape[::-1]``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axes : tuple or list of ints, optional\n",
      "        If specified, it must be a tuple or list which contains a permutation\n",
      "        of [0,1,...,N-1] where N is the number of axes of `a`. The `i`'th axis\n",
      "        of the returned array will correspond to the axis numbered ``axes[i]``\n",
      "        of the input. If not specified, defaults to ``range(a.ndim)[::-1]``,\n",
      "        which reverses the order of the axes.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    p : ndarray\n",
      "        `a` with its axes permuted. A view is returned whenever possible.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.transpose : Equivalent method.\n",
      "    moveaxis : Move axes of an array to new positions.\n",
      "    argsort : Return the indices that would sort an array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Use ``transpose(a, argsort(axes))`` to invert the transposition of tensors\n",
      "    when using the `axes` keyword argument.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> a\n",
      "    array([[1, 2],\n",
      "           [3, 4]])\n",
      "    >>> np.transpose(a)\n",
      "    array([[1, 3],\n",
      "           [2, 4]])\n",
      "\n",
      "    >>> a = np.array([1, 2, 3, 4])\n",
      "    >>> a\n",
      "    array([1, 2, 3, 4])\n",
      "    >>> np.transpose(a)\n",
      "    array([1, 2, 3, 4])\n",
      "\n",
      "    >>> a = np.ones((1, 2, 3))\n",
      "    >>> np.transpose(a, (1, 0, 2)).shape\n",
      "    (2, 1, 3)\n",
      "\n",
      "    >>> a = np.ones((2, 3, 4, 5))\n",
      "    >>> np.transpose(a).shape\n",
      "    (5, 4, 3, 2)\n",
      "\n",
      "    \n",
      "code: var\n",
      "@array_function_dispatch(_var_dispatcher)\n",
      "def var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue, *,\n",
      "        where=np._NoValue):\n",
      "    kwargs = {}\n",
      "    if keepdims is not np._NoValue:\n",
      "        kwargs['keepdims'] = keepdims\n",
      "    if where is not np._NoValue:\n",
      "        kwargs['where'] = where\n",
      "    if type(a) is not mu.ndarray:\n",
      "        try:\n",
      "            var = a.var\n",
      "        except AttributeError:\n",
      "            pass\n",
      "        else:\n",
      "            return var(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n",
      "    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "                         **kwargs)\n",
      "docstring: var\n",
      "\n",
      "    Compute the variance along the specified axis.\n",
      "\n",
      "    Returns the variance of the array elements, a measure of the spread of a\n",
      "    distribution.  The variance is computed for the flattened array by\n",
      "    default, otherwise over the specified axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose variance is desired.  If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which the variance is computed.  The default is to\n",
      "        compute the variance of the flattened array.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If this is a tuple of ints, a variance is performed over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    dtype : data-type, optional\n",
      "        Type to use in computing the variance.  For arrays of integer type\n",
      "        the default is `float64`; for arrays of float types it is the same as\n",
      "        the array type.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  It must have\n",
      "        the same shape as the expected output, but the type is cast if\n",
      "        necessary.\n",
      "    ddof : int, optional\n",
      "        \"Delta Degrees of Freedom\": the divisor used in the calculation is\n",
      "        ``N - ddof``, where ``N`` represents the number of elements. By\n",
      "        default `ddof` is zero.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `var` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the variance. See `~numpy.ufunc.reduce` for\n",
      "        details.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    variance : ndarray, see dtype parameter above\n",
      "        If ``out=None``, returns a new array containing the variance;\n",
      "        otherwise, a reference to the output array is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    std, mean, nanmean, nanstd, nanvar\n",
      "    :ref:`ufuncs-output-type`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The variance is the average of the squared deviations from the mean,\n",
      "    i.e.,  ``var = mean(x)``, where ``x = abs(a - a.mean())**2``.\n",
      "\n",
      "    The mean is typically calculated as ``x.sum() / N``, where ``N = len(x)``.\n",
      "    If, however, `ddof` is specified, the divisor ``N - ddof`` is used\n",
      "    instead.  In standard statistical practice, ``ddof=1`` provides an\n",
      "    unbiased estimator of the variance of a hypothetical infinite population.\n",
      "    ``ddof=0`` provides a maximum likelihood estimate of the variance for\n",
      "    normally distributed variables.\n",
      "\n",
      "    Note that for complex numbers, the absolute value is taken before\n",
      "    squaring, so that the result is always real and nonnegative.\n",
      "\n",
      "    For floating-point input, the variance is computed using the same\n",
      "    precision the input has.  Depending on the input data, this can cause\n",
      "    the results to be inaccurate, especially for `float32` (see example\n",
      "    below).  Specifying a higher-accuracy accumulator using the ``dtype``\n",
      "    keyword can alleviate this issue.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> np.var(a)\n",
      "    1.25\n",
      "    >>> np.var(a, axis=0)\n",
      "    array([1.,  1.])\n",
      "    >>> np.var(a, axis=1)\n",
      "    array([0.25,  0.25])\n",
      "\n",
      "    In single precision, var() can be inaccurate:\n",
      "\n",
      "    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n",
      "    >>> a[0, :] = 1.0\n",
      "    >>> a[1, :] = 0.1\n",
      "    >>> np.var(a)\n",
      "    0.20250003\n",
      "\n",
      "    Computing the variance in float64 is more accurate:\n",
      "\n",
      "    >>> np.var(a, dtype=np.float64)\n",
      "    0.20249999932944759 # may vary\n",
      "    >>> ((1-0.55)**2 + (0.1-0.55)**2)/2\n",
      "    0.2025\n",
      "\n",
      "    Specifying a where argument:\n",
      "\n",
      "    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])\n",
      "    >>> np.var(a)\n",
      "    6.833333333333333 # may vary\n",
      "    >>> np.var(a, where=[[True], [True], [False]])\n",
      "    4.0\n",
      "\n",
      "    \n",
      "code: _add_newdoc_ufunc\n",
      "\n",
      "docstring: _add_newdoc_ufunc\n",
      "add_ufunc_docstring(ufunc, new_docstring)\n",
      "\n",
      "    Replace the docstring for a ufunc with new_docstring.\n",
      "    This method will only work if the current docstring for\n",
      "    the ufunc is NULL. (At the C level, i.e. when ufunc->doc is NULL.)\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ufunc : numpy.ufunc\n",
      "        A ufunc whose current doc is NULL.\n",
      "    new_docstring : string\n",
      "        The new docstring for the ufunc.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This method allocates memory for new_docstring on\n",
      "    the heap. Technically this creates a mempory leak, since this\n",
      "    memory will not be reclaimed until the end of the program\n",
      "    even if the ufunc itself is removed. However this will only\n",
      "    be a problem if the user is repeatedly creating ufuncs with\n",
      "    no documentation, adding documentation via add_newdoc_ufunc,\n",
      "    and then throwing away the ufunc.\n",
      "code: frompyfunc\n",
      "\n",
      "docstring: frompyfunc\n",
      "frompyfunc(func, /, nin, nout, *[, identity])\n",
      "\n",
      "    Takes an arbitrary Python function and returns a NumPy ufunc.\n",
      "\n",
      "    Can be used, for example, to add broadcasting to a built-in Python\n",
      "    function (see Examples section).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    func : Python function object\n",
      "        An arbitrary Python function.\n",
      "    nin : int\n",
      "        The number of input arguments.\n",
      "    nout : int\n",
      "        The number of objects returned by `func`.\n",
      "    identity : object, optional\n",
      "        The value to use for the `~numpy.ufunc.identity` attribute of the resulting\n",
      "        object. If specified, this is equivalent to setting the underlying\n",
      "        C ``identity`` field to ``PyUFunc_IdentityValue``.\n",
      "        If omitted, the identity is set to ``PyUFunc_None``. Note that this is\n",
      "        _not_ equivalent to setting the identity to ``None``, which implies the\n",
      "        operation is reorderable.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ufunc\n",
      "        Returns a NumPy universal function (``ufunc``) object.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    vectorize : Evaluates pyfunc over input arrays using broadcasting rules of numpy.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The returned ufunc always returns PyObject arrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Use frompyfunc to add broadcasting to the Python function ``oct``:\n",
      "\n",
      "    >>> oct_array = np.frompyfunc(oct, 1, 1)\n",
      "    >>> oct_array(np.array((10, 30, 100)))\n",
      "    array(['0o12', '0o36', '0o144'], dtype=object)\n",
      "    >>> np.array((oct(10), oct(30), oct(100))) # for comparison\n",
      "    array(['0o12', '0o36', '0o144'], dtype='<U5')\n",
      "code: geterrobj\n",
      "\n",
      "docstring: geterrobj\n",
      "geterrobj()\n",
      "\n",
      "    Return the current object that defines floating-point error handling.\n",
      "\n",
      "    The error object contains all information that defines the error handling\n",
      "    behavior in NumPy. `geterrobj` is used internally by the other\n",
      "    functions that get and set error handling behavior (`geterr`, `seterr`,\n",
      "    `geterrcall`, `seterrcall`).\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    errobj : list\n",
      "        The error object, a list containing three elements:\n",
      "        [internal numpy buffer size, error mask, error callback function].\n",
      "\n",
      "        The error mask is a single integer that holds the treatment information\n",
      "        on all four floating point errors. The information for each error type\n",
      "        is contained in three bits of the integer. If we print it in base 8, we\n",
      "        can see what treatment is set for \"invalid\", \"under\", \"over\", and\n",
      "        \"divide\" (in that order). The printed string can be interpreted with\n",
      "\n",
      "        * 0 : 'ignore'\n",
      "        * 1 : 'warn'\n",
      "        * 2 : 'raise'\n",
      "        * 3 : 'call'\n",
      "        * 4 : 'print'\n",
      "        * 5 : 'log'\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    seterrobj, seterr, geterr, seterrcall, geterrcall\n",
      "    getbufsize, setbufsize\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    For complete documentation of the types of floating-point exceptions and\n",
      "    treatment options, see `seterr`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.geterrobj()  # first get the defaults\n",
      "    [8192, 521, None]\n",
      "\n",
      "    >>> def err_handler(type, flag):\n",
      "    ...     print(\"Floating point error (%s), with flag %s\" % (type, flag))\n",
      "    ...\n",
      "    >>> old_bufsize = np.setbufsize(20000)\n",
      "    >>> old_err = np.seterr(divide='raise')\n",
      "    >>> old_handler = np.seterrcall(err_handler)\n",
      "    >>> np.geterrobj()\n",
      "    [8192, 521, <function err_handler at 0x91dcaac>]\n",
      "\n",
      "    >>> old_err = np.seterr(all='ignore')\n",
      "    >>> np.base_repr(np.geterrobj()[1], 8)\n",
      "    '0'\n",
      "    >>> old_err = np.seterr(divide='warn', over='log', under='call',\n",
      "    ...                     invalid='print')\n",
      "    >>> np.base_repr(np.geterrobj()[1], 8)\n",
      "    '4351'\n",
      "code: seterrobj\n",
      "\n",
      "docstring: seterrobj\n",
      "seterrobj(errobj, /)\n",
      "\n",
      "    Set the object that defines floating-point error handling.\n",
      "\n",
      "    The error object contains all information that defines the error handling\n",
      "    behavior in NumPy. `seterrobj` is used internally by the other\n",
      "    functions that set error handling behavior (`seterr`, `seterrcall`).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    errobj : list\n",
      "        The error object, a list containing three elements:\n",
      "        [internal numpy buffer size, error mask, error callback function].\n",
      "\n",
      "        The error mask is a single integer that holds the treatment information\n",
      "        on all four floating point errors. The information for each error type\n",
      "        is contained in three bits of the integer. If we print it in base 8, we\n",
      "        can see what treatment is set for \"invalid\", \"under\", \"over\", and\n",
      "        \"divide\" (in that order). The printed string can be interpreted with\n",
      "\n",
      "        * 0 : 'ignore'\n",
      "        * 1 : 'warn'\n",
      "        * 2 : 'raise'\n",
      "        * 3 : 'call'\n",
      "        * 4 : 'print'\n",
      "        * 5 : 'log'\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    geterrobj, seterr, geterr, seterrcall, geterrcall\n",
      "    getbufsize, setbufsize\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    For complete documentation of the types of floating-point exceptions and\n",
      "    treatment options, see `seterr`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> old_errobj = np.geterrobj()  # first get the defaults\n",
      "    >>> old_errobj\n",
      "    [8192, 521, None]\n",
      "\n",
      "    >>> def err_handler(type, flag):\n",
      "    ...     print(\"Floating point error (%s), with flag %s\" % (type, flag))\n",
      "    ...\n",
      "    >>> new_errobj = [20000, 12, err_handler]\n",
      "    >>> np.seterrobj(new_errobj)\n",
      "    >>> np.base_repr(12, 8)  # int for divide=4 ('print') and over=1 ('warn')\n",
      "    '14'\n",
      "    >>> np.geterr()\n",
      "    {'over': 'warn', 'divide': 'print', 'invalid': 'ignore', 'under': 'ignore'}\n",
      "    >>> np.geterrcall() is err_handler\n",
      "    True\n",
      "code: obj2sctype\n",
      "@set_module('numpy')\n",
      "def obj2sctype(rep, default=None):\n",
      " extract dtype from arrays\n",
      "    if isinstance(rep, ndarray):\n",
      "        return rep.dtype.type\n",
      "    # fall back on dtype to convert\n",
      "    try:\n",
      "        res = dtype(rep)\n",
      "    except Exception:\n",
      "        return default\n",
      "    else:\n",
      "        return res.type\n",
      "docstring: obj2sctype\n",
      "\n",
      "    Return the scalar dtype or NumPy equivalent of Python type of an object.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    rep : any\n",
      "        The object of which the type is returned.\n",
      "    default : any, optional\n",
      "        If given, this is returned for objects whose types can not be\n",
      "        determined. If not given, None is returned for those objects.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    dtype : dtype or Python type\n",
      "        The data type of `rep`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    sctype2char, issctype, issubsctype, issubdtype, maximum_sctype\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.obj2sctype(np.int32)\n",
      "    <class 'numpy.int32'>\n",
      "    >>> np.obj2sctype(np.array([1., 2.]))\n",
      "    <class 'numpy.float64'>\n",
      "    >>> np.obj2sctype(np.array([1.j]))\n",
      "    <class 'numpy.complex128'>\n",
      "\n",
      "    >>> np.obj2sctype(dict)\n",
      "    <class 'numpy.object_'>\n",
      "    >>> np.obj2sctype('string')\n",
      "\n",
      "    >>> np.obj2sctype(1, default=list)\n",
      "    <class 'list'>\n",
      "\n",
      "    \n",
      "code: sctype2char\n",
      "@set_module('numpy')\n",
      "def sctype2char(sctype):\n",
      "    sctype = obj2sctype(sctype)\n",
      "    if sctype is None:\n",
      "        raise ValueError(\"unrecognized type\")\n",
      "    if sctype not in _concrete_types:\n",
      "        # for compatibility\n",
      "        raise KeyError(sctype)\n",
      "    return dtype(sctype).char\n",
      "docstring: sctype2char\n",
      "\n",
      "    Return the string representation of a scalar dtype.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    sctype : scalar dtype or object\n",
      "        If a scalar dtype, the corresponding string character is\n",
      "        returned. If an object, `sctype2char` tries to infer its scalar type\n",
      "        and then return the corresponding string character.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    typechar : str\n",
      "        The string character corresponding to the scalar type.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If `sctype` is an object for which the type can not be inferred.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    obj2sctype, issctype, issubsctype, mintypecode\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> for sctype in [np.int32, np.double, np.complex_, np.string_, np.ndarray]:\n",
      "    ...     print(np.sctype2char(sctype))\n",
      "    l # may vary\n",
      "    d\n",
      "    D\n",
      "    S\n",
      "    O\n",
      "\n",
      "    >>> x = np.array([1., 2-1.j])\n",
      "    >>> np.sctype2char(x)\n",
      "    'D'\n",
      "    >>> np.sctype2char(list)\n",
      "    'O'\n",
      "\n",
      "    \n",
      "code: maximum_sctype\n",
      "@set_module('numpy')\n",
      "def maximum_sctype(t):\n",
      "    g = obj2sctype(t)\n",
      "    if g is None:\n",
      "        return t\n",
      "    t = g\n",
      "    base = _kind_name(dtype(t))\n",
      "    if base in sctypes:\n",
      "        return sctypes[base][-1]\n",
      "    else:\n",
      "        return t\n",
      "docstring: maximum_sctype\n",
      "\n",
      "    Return the scalar type of highest precision of the same kind as the input.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    t : dtype or dtype specifier\n",
      "        The input data type. This can be a `dtype` object or an object that\n",
      "        is convertible to a `dtype`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : dtype\n",
      "        The highest precision data type of the same kind (`dtype.kind`) as `t`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    obj2sctype, mintypecode, sctype2char\n",
      "    dtype\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.maximum_sctype(int)\n",
      "    <class 'numpy.int64'>\n",
      "    >>> np.maximum_sctype(np.uint8)\n",
      "    <class 'numpy.uint64'>\n",
      "    >>> np.maximum_sctype(complex)\n",
      "    <class 'numpy.complex256'> # may vary\n",
      "\n",
      "    >>> np.maximum_sctype(str)\n",
      "    <class 'numpy.str_'>\n",
      "\n",
      "    >>> np.maximum_sctype('i2')\n",
      "    <class 'numpy.int64'>\n",
      "    >>> np.maximum_sctype('f4')\n",
      "    <class 'numpy.float128'> # may vary\n",
      "\n",
      "    \n",
      "code: issctype\n",
      "@set_module('numpy')\n",
      "def issctype(rep):\n",
      "    if not isinstance(rep, (type, dtype)):\n",
      "        return False\n",
      "    try:\n",
      "        res = obj2sctype(rep)\n",
      "        if res and res != object_:\n",
      "            return True\n",
      "        return False\n",
      "    except Exception:\n",
      "        return False\n",
      "docstring: issctype\n",
      "\n",
      "    Determines whether the given object represents a scalar data-type.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    rep : any\n",
      "        If `rep` is an instance of a scalar dtype, True is returned. If not,\n",
      "        False is returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "        Boolean result of check whether `rep` is a scalar dtype.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    issubsctype, issubdtype, obj2sctype, sctype2char\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.issctype(np.int32)\n",
      "    True\n",
      "    >>> np.issctype(list)\n",
      "    False\n",
      "    >>> np.issctype(1.1)\n",
      "    False\n",
      "\n",
      "    Strings are also a scalar type:\n",
      "\n",
      "    >>> np.issctype(np.dtype('str'))\n",
      "    True\n",
      "\n",
      "    \n",
      "code: find_common_type\n",
      "@set_module('numpy')\n",
      "def find_common_type(array_types, scalar_types):\n",
      "    array_types = [dtype(x) for x in array_types]\n",
      "    scalar_types = [dtype(x) for x in scalar_types]\n",
      "    maxa = _can_coerce_all(array_types)\n",
      "    maxsc = _can_coerce_all(scalar_types)\n",
      "    if maxa is None:\n",
      "        return maxsc\n",
      "    if maxsc is None:\n",
      "        return maxa\n",
      "    try:\n",
      "        index_a = _kind_list.index(maxa.kind)\n",
      "        index_sc = _kind_list.index(maxsc.kind)\n",
      "    except ValueError:\n",
      "        return None\n",
      "    if index_sc > index_a:\n",
      "        return _find_common_coerce(maxsc, maxa)\n",
      "    else:\n",
      "        return maxa\n",
      "docstring: find_common_type\n",
      "\n",
      "    Determine common type following standard coercion rules.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    array_types : sequence\n",
      "        A list of dtypes or dtype convertible objects representing arrays.\n",
      "    scalar_types : sequence\n",
      "        A list of dtypes or dtype convertible objects representing scalars.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    datatype : dtype\n",
      "        The common data type, which is the maximum of `array_types` ignoring\n",
      "        `scalar_types`, unless the maximum of `scalar_types` is of a\n",
      "        different kind (`dtype.kind`). If the kind is not understood, then\n",
      "        None is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    dtype, common_type, can_cast, mintypecode\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.find_common_type([], [np.int64, np.float32, complex])\n",
      "    dtype('complex128')\n",
      "    >>> np.find_common_type([np.int64, np.float32], [])\n",
      "    dtype('float64')\n",
      "\n",
      "    The standard casting rules ensure that a scalar cannot up-cast an\n",
      "    array unless the scalar is of a fundamentally different kind of data\n",
      "    (i.e. under a different hierarchy in the data type hierarchy) then\n",
      "    the array:\n",
      "\n",
      "    >>> np.find_common_type([np.float32], [np.int64, np.float64])\n",
      "    dtype('float32')\n",
      "\n",
      "    Complex is of a different type, so it up-casts the float in the\n",
      "    `array_types` argument:\n",
      "\n",
      "    >>> np.find_common_type([np.float32], [complex])\n",
      "    dtype('complex128')\n",
      "\n",
      "    Type specifier strings are convertible to dtypes and can therefore\n",
      "    be used instead of dtypes:\n",
      "\n",
      "    >>> np.find_common_type(['f4', 'f4', 'i4'], ['c8'])\n",
      "    dtype('complex128')\n",
      "\n",
      "    \n",
      "code: issubdtype\n",
      "@set_module('numpy')\n",
      "def issubdtype(arg1, arg2):\n",
      "    r\"\"\"\n",
      "    Returns True if first argument is a typecode lower/equal in type hierarchy.\n",
      "    This is like the builtin :func:`issubclass`, but for `dtype`\\ s.\n",
      "    Parameters\n",
      "    ----------\n",
      "    arg1, arg2 : dtype_like\n",
      "        `dtype` or object coercible to one\n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "    See Also\n",
      "    --------\n",
      "    :ref:`arrays.scalars` : Overview of the numpy type hierarchy.\n",
      "    issubsctype, issubclass_\n",
      "    Examples\n",
      "    --------\n",
      "    `issubdtype` can be used to check the type of arrays:\n",
      "    >>> ints = np.array([1, 2, 3], dtype=np.int32)\n",
      "    >>> np.issubdtype(ints.dtype, np.integer)\n",
      "    True\n",
      "    >>> np.issubdtype(ints.dtype, np.floating)\n",
      "    False\n",
      "    >>> floats = np.array([1, 2, 3], dtype=np.float32)\n",
      "    >>> np.issubdtype(floats.dtype, np.integer)\n",
      "    False\n",
      "    >>> np.issubdtype(floats.dtype, np.floating)\n",
      "    True\n",
      "    Similar types of different sizes are not subdtypes of each other:\n",
      "    >>> np.issubdtype(np.float64, np.float32)\n",
      "    False\n",
      "    >>> np.issubdtype(np.float32, np.float64)\n",
      "    False\n",
      "    but both are subtypes of `floating`:\n",
      "    >>> np.issubdtype(np.float64, np.floating)\n",
      "    True\n",
      "    >>> np.issubdtype(np.float32, np.floating)\n",
      "    True\n",
      "    For convenience, dtype-like objects are allowed too:\n",
      "    >>> np.issubdtype('S1', np.string_)\n",
      "    True\n",
      "    >>> np.issubdtype('i4', np.signedinteger)\n",
      "    True\n",
      "    \"\"\"\n",
      "    if not issubclass_(arg1, generic):\n",
      "        arg1 = dtype(arg1).type\n",
      "    if not issubclass_(arg2, generic):\n",
      "        arg2 = dtype(arg2).type\n",
      "    return issubclass(arg1, arg2)\n",
      "docstring: issubdtype\n",
      "\n",
      "    Returns True if first argument is a typecode lower/equal in type hierarchy.\n",
      "\n",
      "    This is like the builtin :func:`issubclass`, but for `dtype`\\ s.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arg1, arg2 : dtype_like\n",
      "        `dtype` or object coercible to one\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    :ref:`arrays.scalars` : Overview of the numpy type hierarchy.\n",
      "    issubsctype, issubclass_\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    `issubdtype` can be used to check the type of arrays:\n",
      "\n",
      "    >>> ints = np.array([1, 2, 3], dtype=np.int32)\n",
      "    >>> np.issubdtype(ints.dtype, np.integer)\n",
      "    True\n",
      "    >>> np.issubdtype(ints.dtype, np.floating)\n",
      "    False\n",
      "\n",
      "    >>> floats = np.array([1, 2, 3], dtype=np.float32)\n",
      "    >>> np.issubdtype(floats.dtype, np.integer)\n",
      "    False\n",
      "    >>> np.issubdtype(floats.dtype, np.floating)\n",
      "    True\n",
      "\n",
      "    Similar types of different sizes are not subdtypes of each other:\n",
      "\n",
      "    >>> np.issubdtype(np.float64, np.float32)\n",
      "    False\n",
      "    >>> np.issubdtype(np.float32, np.float64)\n",
      "    False\n",
      "\n",
      "    but both are subtypes of `floating`:\n",
      "\n",
      "    >>> np.issubdtype(np.float64, np.floating)\n",
      "    True\n",
      "    >>> np.issubdtype(np.float32, np.floating)\n",
      "    True\n",
      "\n",
      "    For convenience, dtype-like objects are allowed too:\n",
      "\n",
      "    >>> np.issubdtype('S1', np.string_)\n",
      "    True\n",
      "    >>> np.issubdtype('i4', np.signedinteger)\n",
      "    True\n",
      "\n",
      "    \n",
      "code: datetime_data\n",
      "\n",
      "docstring: datetime_data\n",
      "datetime_data(dtype, /)\n",
      "\n",
      "    Get information about the step size of a date or time type.\n",
      "\n",
      "    The returned tuple can be passed as the second argument of `numpy.datetime64` and\n",
      "    `numpy.timedelta64`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    dtype : dtype\n",
      "        The dtype object, which must be a `datetime64` or `timedelta64` type.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    unit : str\n",
      "        The :ref:`datetime unit <arrays.dtypes.dateunits>` on which this dtype\n",
      "        is based.\n",
      "    count : int\n",
      "        The number of base units in a step.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> dt_25s = np.dtype('timedelta64[25s]')\n",
      "    >>> np.datetime_data(dt_25s)\n",
      "    ('s', 25)\n",
      "    >>> np.array(10, dt_25s).astype('timedelta64[s]')\n",
      "    array(250, dtype='timedelta64[s]')\n",
      "\n",
      "    The result can be used to construct a datetime that uses the same units\n",
      "    as a timedelta\n",
      "\n",
      "    >>> np.datetime64('2010', np.datetime_data(dt_25s))\n",
      "    numpy.datetime64('2010-01-01T00:00:00','25s')\n",
      "code: datetime_as_string\n",
      "\n",
      "docstring: datetime_as_string\n",
      "\n",
      "    datetime_as_string(arr, unit=None, timezone='naive', casting='same_kind')\n",
      "\n",
      "    Convert an array of datetimes into an array of strings.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : array_like of datetime64\n",
      "        The array of UTC timestamps to format.\n",
      "    unit : str\n",
      "        One of None, 'auto', or a :ref:`datetime unit <arrays.dtypes.dateunits>`.\n",
      "    timezone : {'naive', 'UTC', 'local'} or tzinfo\n",
      "        Timezone information to use when displaying the datetime. If 'UTC', end\n",
      "        with a Z to indicate UTC time. If 'local', convert to the local timezone\n",
      "        first, and suffix with a +-#### timezone offset. If a tzinfo object,\n",
      "        then do as with 'local', but use the specified timezone.\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}\n",
      "        Casting to allow when changing between datetime units.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    str_arr : ndarray\n",
      "        An array of strings the same shape as `arr`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import pytz\n",
      "    >>> d = np.arange('2002-10-27T04:30', 4*60, 60, dtype='M8[m]')\n",
      "    >>> d\n",
      "    array(['2002-10-27T04:30', '2002-10-27T05:30', '2002-10-27T06:30',\n",
      "           '2002-10-27T07:30'], dtype='datetime64[m]')\n",
      "\n",
      "    Setting the timezone to UTC shows the same information, but with a Z suffix\n",
      "\n",
      "    >>> np.datetime_as_string(d, timezone='UTC')\n",
      "    array(['2002-10-27T04:30Z', '2002-10-27T05:30Z', '2002-10-27T06:30Z',\n",
      "           '2002-10-27T07:30Z'], dtype='<U35')\n",
      "\n",
      "    Note that we picked datetimes that cross a DST boundary. Passing in a\n",
      "    ``pytz`` timezone object will print the appropriate offset\n",
      "\n",
      "    >>> np.datetime_as_string(d, timezone=pytz.timezone('US/Eastern'))\n",
      "    array(['2002-10-27T00:30-0400', '2002-10-27T01:30-0400',\n",
      "           '2002-10-27T01:30-0500', '2002-10-27T02:30-0500'], dtype='<U39')\n",
      "\n",
      "    Passing in a unit will change the precision\n",
      "\n",
      "    >>> np.datetime_as_string(d, unit='h')\n",
      "    array(['2002-10-27T04', '2002-10-27T05', '2002-10-27T06', '2002-10-27T07'],\n",
      "          dtype='<U32')\n",
      "    >>> np.datetime_as_string(d, unit='s')\n",
      "    array(['2002-10-27T04:30:00', '2002-10-27T05:30:00', '2002-10-27T06:30:00',\n",
      "           '2002-10-27T07:30:00'], dtype='<U38')\n",
      "\n",
      "    'casting' can be used to specify whether precision can be changed\n",
      "\n",
      "    >>> np.datetime_as_string(d, unit='h', casting='safe')\n",
      "    Traceback (most recent call last):\n",
      "        ...\n",
      "    TypeError: Cannot create a datetime string as units 'h' from a NumPy\n",
      "    datetime with units 'm' according to the rule 'safe'\n",
      "    \n",
      "code: busday_offset\n",
      "\n",
      "docstring: busday_offset\n",
      "\n",
      "    busday_offset(dates, offsets, roll='raise', weekmask='1111100', holidays=None, busdaycal=None, out=None)\n",
      "\n",
      "    First adjusts the date to fall on a valid day according to\n",
      "    the ``roll`` rule, then applies offsets to the given dates\n",
      "    counted in valid days.\n",
      "\n",
      "    .. versionadded:: 1.7.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    dates : array_like of datetime64[D]\n",
      "        The array of dates to process.\n",
      "    offsets : array_like of int\n",
      "        The array of offsets, which is broadcast with ``dates``.\n",
      "    roll : {'raise', 'nat', 'forward', 'following', 'backward', 'preceding', 'modifiedfollowing', 'modifiedpreceding'}, optional\n",
      "        How to treat dates that do not fall on a valid day. The default\n",
      "        is 'raise'.\n",
      "\n",
      "          * 'raise' means to raise an exception for an invalid day.\n",
      "          * 'nat' means to return a NaT (not-a-time) for an invalid day.\n",
      "          * 'forward' and 'following' mean to take the first valid day\n",
      "            later in time.\n",
      "          * 'backward' and 'preceding' mean to take the first valid day\n",
      "            earlier in time.\n",
      "          * 'modifiedfollowing' means to take the first valid day\n",
      "            later in time unless it is across a Month boundary, in which\n",
      "            case to take the first valid day earlier in time.\n",
      "          * 'modifiedpreceding' means to take the first valid day\n",
      "            earlier in time unless it is across a Month boundary, in which\n",
      "            case to take the first valid day later in time.\n",
      "    weekmask : str or array_like of bool, optional\n",
      "        A seven-element array indicating which of Monday through Sunday are\n",
      "        valid days. May be specified as a length-seven list or array, like\n",
      "        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n",
      "        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n",
      "        weekdays, optionally separated by white space. Valid abbreviations\n",
      "        are: Mon Tue Wed Thu Fri Sat Sun\n",
      "    holidays : array_like of datetime64[D], optional\n",
      "        An array of dates to consider as invalid dates.  They may be\n",
      "        specified in any order, and NaT (not-a-time) dates are ignored.\n",
      "        This list is saved in a normalized form that is suited for\n",
      "        fast calculations of valid days.\n",
      "    busdaycal : busdaycalendar, optional\n",
      "        A `busdaycalendar` object which specifies the valid days. If this\n",
      "        parameter is provided, neither weekmask nor holidays may be\n",
      "        provided.\n",
      "    out : array of datetime64[D], optional\n",
      "        If provided, this array is filled with the result.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : array of datetime64[D]\n",
      "        An array with a shape from broadcasting ``dates`` and ``offsets``\n",
      "        together, containing the dates with offsets applied.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    busdaycalendar : An object that specifies a custom set of valid days.\n",
      "    is_busday : Returns a boolean array indicating valid days.\n",
      "    busday_count : Counts how many valid days are in a half-open date range.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> # First business day in October 2011 (not accounting for holidays)\n",
      "    ... np.busday_offset('2011-10', 0, roll='forward')\n",
      "    numpy.datetime64('2011-10-03')\n",
      "    >>> # Last business day in February 2012 (not accounting for holidays)\n",
      "    ... np.busday_offset('2012-03', -1, roll='forward')\n",
      "    numpy.datetime64('2012-02-29')\n",
      "    >>> # Third Wednesday in January 2011\n",
      "    ... np.busday_offset('2011-01', 2, roll='forward', weekmask='Wed')\n",
      "    numpy.datetime64('2011-01-19')\n",
      "    >>> # 2012 Mother's Day in Canada and the U.S.\n",
      "    ... np.busday_offset('2012-05', 1, roll='forward', weekmask='Sun')\n",
      "    numpy.datetime64('2012-05-13')\n",
      "\n",
      "    >>> # First business day on or after a date\n",
      "    ... np.busday_offset('2011-03-20', 0, roll='forward')\n",
      "    numpy.datetime64('2011-03-21')\n",
      "    >>> np.busday_offset('2011-03-22', 0, roll='forward')\n",
      "    numpy.datetime64('2011-03-22')\n",
      "    >>> # First business day after a date\n",
      "    ... np.busday_offset('2011-03-20', 1, roll='backward')\n",
      "    numpy.datetime64('2011-03-21')\n",
      "    >>> np.busday_offset('2011-03-22', 1, roll='backward')\n",
      "    numpy.datetime64('2011-03-23')\n",
      "    \n",
      "code: busday_count\n",
      "\n",
      "docstring: busday_count\n",
      "\n",
      "    busday_count(begindates, enddates, weekmask='1111100', holidays=[], busdaycal=None, out=None)\n",
      "\n",
      "    Counts the number of valid days between `begindates` and\n",
      "    `enddates`, not including the day of `enddates`.\n",
      "\n",
      "    If ``enddates`` specifies a date value that is earlier than the\n",
      "    corresponding ``begindates`` date value, the count will be negative.\n",
      "\n",
      "    .. versionadded:: 1.7.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    begindates : array_like of datetime64[D]\n",
      "        The array of the first dates for counting.\n",
      "    enddates : array_like of datetime64[D]\n",
      "        The array of the end dates for counting, which are excluded\n",
      "        from the count themselves.\n",
      "    weekmask : str or array_like of bool, optional\n",
      "        A seven-element array indicating which of Monday through Sunday are\n",
      "        valid days. May be specified as a length-seven list or array, like\n",
      "        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n",
      "        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n",
      "        weekdays, optionally separated by white space. Valid abbreviations\n",
      "        are: Mon Tue Wed Thu Fri Sat Sun\n",
      "    holidays : array_like of datetime64[D], optional\n",
      "        An array of dates to consider as invalid dates.  They may be\n",
      "        specified in any order, and NaT (not-a-time) dates are ignored.\n",
      "        This list is saved in a normalized form that is suited for\n",
      "        fast calculations of valid days.\n",
      "    busdaycal : busdaycalendar, optional\n",
      "        A `busdaycalendar` object which specifies the valid days. If this\n",
      "        parameter is provided, neither weekmask nor holidays may be\n",
      "        provided.\n",
      "    out : array of int, optional\n",
      "        If provided, this array is filled with the result.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : array of int\n",
      "        An array with a shape from broadcasting ``begindates`` and ``enddates``\n",
      "        together, containing the number of valid days between\n",
      "        the begin and end dates.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    busdaycalendar : An object that specifies a custom set of valid days.\n",
      "    is_busday : Returns a boolean array indicating valid days.\n",
      "    busday_offset : Applies an offset counted in valid days.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> # Number of weekdays in January 2011\n",
      "    ... np.busday_count('2011-01', '2011-02')\n",
      "    21\n",
      "    >>> # Number of weekdays in 2011\n",
      "    >>> np.busday_count('2011', '2012')\n",
      "    260\n",
      "    >>> # Number of Saturdays in 2011\n",
      "    ... np.busday_count('2011', '2012', weekmask='Sat')\n",
      "    53\n",
      "    \n",
      "code: is_busday\n",
      "\n",
      "docstring: is_busday\n",
      "\n",
      "    is_busday(dates, weekmask='1111100', holidays=None, busdaycal=None, out=None)\n",
      "\n",
      "    Calculates which of the given dates are valid days, and which are not.\n",
      "\n",
      "    .. versionadded:: 1.7.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    dates : array_like of datetime64[D]\n",
      "        The array of dates to process.\n",
      "    weekmask : str or array_like of bool, optional\n",
      "        A seven-element array indicating which of Monday through Sunday are\n",
      "        valid days. May be specified as a length-seven list or array, like\n",
      "        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n",
      "        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n",
      "        weekdays, optionally separated by white space. Valid abbreviations\n",
      "        are: Mon Tue Wed Thu Fri Sat Sun\n",
      "    holidays : array_like of datetime64[D], optional\n",
      "        An array of dates to consider as invalid dates.  They may be\n",
      "        specified in any order, and NaT (not-a-time) dates are ignored.\n",
      "        This list is saved in a normalized form that is suited for\n",
      "        fast calculations of valid days.\n",
      "    busdaycal : busdaycalendar, optional\n",
      "        A `busdaycalendar` object which specifies the valid days. If this\n",
      "        parameter is provided, neither weekmask nor holidays may be\n",
      "        provided.\n",
      "    out : array of bool, optional\n",
      "        If provided, this array is filled with the result.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : array of bool\n",
      "        An array with the same shape as ``dates``, containing True for\n",
      "        each valid day, and False for each invalid day.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    busdaycalendar : An object that specifies a custom set of valid days.\n",
      "    busday_offset : Applies an offset counted in valid days.\n",
      "    busday_count : Counts how many valid days are in a half-open date range.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> # The weekdays are Friday, Saturday, and Monday\n",
      "    ... np.is_busday(['2011-07-01', '2011-07-02', '2011-07-18'],\n",
      "    ...                 holidays=['2011-07-01', '2011-07-04', '2011-07-17'])\n",
      "    array([False, False,  True])\n",
      "    \n",
      "code: array2string\n",
      "@array_function_dispatch(_array2string_dispatcher, module='numpy')\n",
      "def array2string(a, max_line_width=None, precision=None,\n",
      "                 suppress_small=None, separator=' ', prefix=\"\",\n",
      "                 style=np._NoValue, formatter=None, threshold=None,\n",
      "                 edgeitems=None, sign=None, floatmode=None, suffix=\"\",\n",
      "                 *, legacy=None):\n",
      "    overrides = _make_options_dict(precision, threshold, edgeitems,\n",
      "                                   max_line_width, suppress_small, None, None,\n",
      "                                   sign, formatter, floatmode, legacy)\n",
      "    options = _format_options.copy()\n",
      "    options.update(overrides)\n",
      "    if options['legacy'] <= 113:\n",
      "        if style is np._NoValue:\n",
      "            style = repr\n",
      "        if a.shape == () and a.dtype.names is None:\n",
      "            return style(a.item())\n",
      "    elif style is not np._NoValue:\n",
      " treat as a null array if any of shape elements == 0\n",
      "    if a.size == 0:\n",
      "        return \"[]\"\n",
      "    return _array2string(a, options, separator, prefix)\n",
      "docstring: array2string\n",
      "\n",
      "    Return a string representation of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : ndarray\n",
      "        Input array.\n",
      "    max_line_width : int, optional\n",
      "        Inserts newlines if text is longer than `max_line_width`.\n",
      "        Defaults to ``numpy.get_printoptions()['linewidth']``.\n",
      "    precision : int or None, optional\n",
      "        Floating point precision.\n",
      "        Defaults to ``numpy.get_printoptions()['precision']``.\n",
      "    suppress_small : bool, optional\n",
      "        Represent numbers \"very close\" to zero as zero; default is False.\n",
      "        Very close is defined by precision: if the precision is 8, e.g.,\n",
      "        numbers smaller (in absolute value) than 5e-9 are represented as\n",
      "        zero.\n",
      "        Defaults to ``numpy.get_printoptions()['suppress']``.\n",
      "    separator : str, optional\n",
      "        Inserted between elements.\n",
      "    prefix : str, optional\n",
      "    suffix : str, optional\n",
      "        The length of the prefix and suffix strings are used to respectively\n",
      "        align and wrap the output. An array is typically printed as::\n",
      "\n",
      "          prefix + array2string(a) + suffix\n",
      "\n",
      "        The output is left-padded by the length of the prefix string, and\n",
      "        wrapping is forced at the column ``max_line_width - len(suffix)``.\n",
      "        It should be noted that the content of prefix and suffix strings are\n",
      "        not included in the output.\n",
      "    style : _NoValue, optional\n",
      "        Has no effect, do not use.\n",
      "\n",
      "        .. deprecated:: 1.14.0\n",
      "    formatter : dict of callables, optional\n",
      "        If not None, the keys should indicate the type(s) that the respective\n",
      "        formatting function applies to.  Callables should return a string.\n",
      "        Types that are not specified (by their corresponding keys) are handled\n",
      "        by the default formatters.  Individual types for which a formatter\n",
      "        can be set are:\n",
      "\n",
      "        - 'bool'\n",
      "        - 'int'\n",
      "        - 'timedelta' : a `numpy.timedelta64`\n",
      "        - 'datetime' : a `numpy.datetime64`\n",
      "        - 'float'\n",
      "        - 'longfloat' : 128-bit floats\n",
      "        - 'complexfloat'\n",
      "        - 'longcomplexfloat' : composed of two 128-bit floats\n",
      "        - 'void' : type `numpy.void`\n",
      "        - 'numpystr' : types `numpy.string_` and `numpy.unicode_`\n",
      "\n",
      "        Other keys that can be used to set a group of types at once are:\n",
      "\n",
      "        - 'all' : sets all types\n",
      "        - 'int_kind' : sets 'int'\n",
      "        - 'float_kind' : sets 'float' and 'longfloat'\n",
      "        - 'complex_kind' : sets 'complexfloat' and 'longcomplexfloat'\n",
      "        - 'str_kind' : sets 'numpystr'\n",
      "    threshold : int, optional\n",
      "        Total number of array elements which trigger summarization\n",
      "        rather than full repr.\n",
      "        Defaults to ``numpy.get_printoptions()['threshold']``.\n",
      "    edgeitems : int, optional\n",
      "        Number of array items in summary at beginning and end of\n",
      "        each dimension.\n",
      "        Defaults to ``numpy.get_printoptions()['edgeitems']``.\n",
      "    sign : string, either '-', '+', or ' ', optional\n",
      "        Controls printing of the sign of floating-point types. If '+', always\n",
      "        print the sign of positive values. If ' ', always prints a space\n",
      "        (whitespace character) in the sign position of positive values.  If\n",
      "        '-', omit the sign character of positive values.\n",
      "        Defaults to ``numpy.get_printoptions()['sign']``.\n",
      "    floatmode : str, optional\n",
      "        Controls the interpretation of the `precision` option for\n",
      "        floating-point types.\n",
      "        Defaults to ``numpy.get_printoptions()['floatmode']``.\n",
      "        Can take the following values:\n",
      "\n",
      "        - 'fixed': Always print exactly `precision` fractional digits,\n",
      "          even if this would print more or fewer digits than\n",
      "          necessary to specify the value uniquely.\n",
      "        - 'unique': Print the minimum number of fractional digits necessary\n",
      "          to represent each value uniquely. Different elements may\n",
      "          have a different number of digits.  The value of the\n",
      "          `precision` option is ignored.\n",
      "        - 'maxprec': Print at most `precision` fractional digits, but if\n",
      "          an element can be uniquely represented with fewer digits\n",
      "          only print it with that many.\n",
      "        - 'maxprec_equal': Print at most `precision` fractional digits,\n",
      "          but if every element in the array can be uniquely\n",
      "          represented with an equal number of fewer digits, use that\n",
      "          many digits for all elements.\n",
      "    legacy : string or `False`, optional\n",
      "        If set to the string `'1.13'` enables 1.13 legacy printing mode. This\n",
      "        approximates numpy 1.13 print output by including a space in the sign\n",
      "        position of floats and different behavior for 0d arrays. If set to\n",
      "        `False`, disables legacy mode. Unrecognized strings will be ignored\n",
      "        with a warning for forward compatibility.\n",
      "\n",
      "        .. versionadded:: 1.14.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    array_str : str\n",
      "        String representation of the array.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    TypeError\n",
      "        if a callable in `formatter` does not return a string.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    array_str, array_repr, set_printoptions, get_printoptions\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    If a formatter is specified for a certain type, the `precision` keyword is\n",
      "    ignored for that type.\n",
      "\n",
      "    This is a very flexible function; `array_repr` and `array_str` are using\n",
      "    `array2string` internally so keywords with the same name should work\n",
      "    identically in all three functions.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([1e-16,1,2,3])\n",
      "    >>> np.array2string(x, precision=2, separator=',',\n",
      "    ...                       suppress_small=True)\n",
      "    '[0.,1.,2.,3.]'\n",
      "\n",
      "    >>> x  = np.arange(3.)\n",
      "    >>> np.array2string(x, formatter={'float_kind':lambda x: \"%.2f\" % x})\n",
      "    '[0.00 1.00 2.00]'\n",
      "\n",
      "    >>> x  = np.arange(3)\n",
      "    >>> np.array2string(x, formatter={'int':lambda x: hex(x)})\n",
      "    '[0x0 0x1 0x2]'\n",
      "\n",
      "    \n",
      "code: array_str\n",
      "@array_function_dispatch(_array_str_dispatcher, module='numpy')\n",
      "def array_str(a, max_line_width=None, precision=None, suppress_small=None):\n",
      "    return _array_str_implementation(\n",
      "        a, max_line_width, precision, suppress_small)\n",
      "docstring: array_str\n",
      "\n",
      "    Return a string representation of the data in an array.\n",
      "\n",
      "    The data in the array is returned as a single string.  This function is\n",
      "    similar to `array_repr`, the difference being that `array_repr` also\n",
      "    returns information on the kind of array and its data type.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : ndarray\n",
      "        Input array.\n",
      "    max_line_width : int, optional\n",
      "        Inserts newlines if text is longer than `max_line_width`.\n",
      "        Defaults to ``numpy.get_printoptions()['linewidth']``.\n",
      "    precision : int, optional\n",
      "        Floating point precision.\n",
      "        Defaults to ``numpy.get_printoptions()['precision']``.\n",
      "    suppress_small : bool, optional\n",
      "        Represent numbers \"very close\" to zero as zero; default is False.\n",
      "        Very close is defined by precision: if the precision is 8, e.g.,\n",
      "        numbers smaller (in absolute value) than 5e-9 are represented as\n",
      "        zero.\n",
      "        Defaults to ``numpy.get_printoptions()['suppress']``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    array2string, array_repr, set_printoptions\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.array_str(np.arange(3))\n",
      "    '[0 1 2]'\n",
      "\n",
      "    \n",
      "code: array_repr\n",
      "@array_function_dispatch(_array_repr_dispatcher, module='numpy')\n",
      "def array_repr(arr, max_line_width=None, precision=None, suppress_small=None):\n",
      "    return _array_repr_implementation(\n",
      "        arr, max_line_width, precision, suppress_small)\n",
      "docstring: array_repr\n",
      "\n",
      "    Return the string representation of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : ndarray\n",
      "        Input array.\n",
      "    max_line_width : int, optional\n",
      "        Inserts newlines if text is longer than `max_line_width`.\n",
      "        Defaults to ``numpy.get_printoptions()['linewidth']``.\n",
      "    precision : int, optional\n",
      "        Floating point precision.\n",
      "        Defaults to ``numpy.get_printoptions()['precision']``.\n",
      "    suppress_small : bool, optional\n",
      "        Represent numbers \"very close\" to zero as zero; default is False.\n",
      "        Very close is defined by precision: if the precision is 8, e.g.,\n",
      "        numbers smaller (in absolute value) than 5e-9 are represented as\n",
      "        zero.\n",
      "        Defaults to ``numpy.get_printoptions()['suppress']``.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    string : str\n",
      "      The string representation of an array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    array_str, array2string, set_printoptions\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.array_repr(np.array([1,2]))\n",
      "    'array([1, 2])'\n",
      "    >>> np.array_repr(np.ma.array([0.]))\n",
      "    'MaskedArray([0.])'\n",
      "    >>> np.array_repr(np.array([], np.int32))\n",
      "    'array([], dtype=int32)'\n",
      "\n",
      "    >>> x = np.array([1e-6, 4e-7, 2, 3])\n",
      "    >>> np.array_repr(x, precision=6, suppress_small=True)\n",
      "    'array([0.000001,  0.      ,  2.      ,  3.      ])'\n",
      "\n",
      "    \n",
      "code: set_string_function\n",
      "def set_string_function(f, repr=True):\n",
      "    if f is None:\n",
      "        if repr:\n",
      "            return multiarray.set_string_function(_default_array_repr, 1)\n",
      "        else:\n",
      "            return multiarray.set_string_function(_default_array_str, 0)\n",
      "    else:\n",
      "        return multiarray.set_string_function(f, repr)\n",
      "docstring: set_string_function\n",
      "\n",
      "    Set a Python function to be used when pretty printing arrays.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    f : function or None\n",
      "        Function to be used to pretty print arrays. The function should expect\n",
      "        a single array argument and return a string of the representation of\n",
      "        the array. If None, the function is reset to the default NumPy function\n",
      "        to print arrays.\n",
      "    repr : bool, optional\n",
      "        If True (default), the function for pretty printing (``__repr__``)\n",
      "        is set, if False the function that returns the default string\n",
      "        representation (``__str__``) is set.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    set_printoptions, get_printoptions\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> def pprint(arr):\n",
      "    ...     return 'HA! - What are you going to do now?'\n",
      "    ...\n",
      "    >>> np.set_string_function(pprint)\n",
      "    >>> a = np.arange(10)\n",
      "    >>> a\n",
      "    HA! - What are you going to do now?\n",
      "    >>> _ = a\n",
      "    >>> # [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "    We can reset the function to the default:\n",
      "\n",
      "    >>> np.set_string_function(None)\n",
      "    >>> a\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "    `repr` affects either pretty printing or normal string representation.\n",
      "    Note that ``__repr__`` is still affected by setting ``__str__``\n",
      "    because the width of each array element in the returned string becomes\n",
      "    equal to the length of the result of ``__str__()``.\n",
      "\n",
      "    >>> x = np.arange(4)\n",
      "    >>> np.set_string_function(lambda x:'random', repr=False)\n",
      "    >>> x.__str__()\n",
      "    'random'\n",
      "    >>> x.__repr__()\n",
      "    'array([0, 1, 2, 3])'\n",
      "\n",
      "    \n",
      "code: set_printoptions\n",
      "@set_module('numpy')\n",
      "def set_printoptions(precision=None, threshold=None, edgeitems=None,\n",
      "                     linewidth=None, suppress=None, nanstr=None, infstr=None,\n",
      "                     formatter=None, sign=None, floatmode=None, *, legacy=None):\n",
      "    opt = _make_options_dict(precision, threshold, edgeitems, linewidth,\n",
      "                             suppress, nanstr, infstr, sign, formatter,\n",
      "                             floatmode, legacy)\n",
      " set the C variable for legacy mode\n",
      "    if _format_options['legacy'] == 113:\n",
      "        set_legacy_print_mode(113)\n",
      "        # reset the sign option in legacy mode to avoid confusion\n",
      "        _format_options['sign'] = '-'\n",
      "    elif _format_options['legacy'] == 121:\n",
      "        set_legacy_print_mode(121)\n",
      "    elif _format_options['legacy'] == sys.maxsize:\n",
      "        set_legacy_print_mode(0)\n",
      "docstring: set_printoptions\n",
      "\n",
      "    Set printing options.\n",
      "\n",
      "    These options determine the way floating point numbers, arrays and\n",
      "    other NumPy objects are displayed.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    precision : int or None, optional\n",
      "        Number of digits of precision for floating point output (default 8).\n",
      "        May be None if `floatmode` is not `fixed`, to print as many digits as\n",
      "        necessary to uniquely specify the value.\n",
      "    threshold : int, optional\n",
      "        Total number of array elements which trigger summarization\n",
      "        rather than full repr (default 1000).\n",
      "        To always use the full repr without summarization, pass `sys.maxsize`.\n",
      "    edgeitems : int, optional\n",
      "        Number of array items in summary at beginning and end of\n",
      "        each dimension (default 3).\n",
      "    linewidth : int, optional\n",
      "        The number of characters per line for the purpose of inserting\n",
      "        line breaks (default 75).\n",
      "    suppress : bool, optional\n",
      "        If True, always print floating point numbers using fixed point\n",
      "        notation, in which case numbers equal to zero in the current precision\n",
      "        will print as zero.  If False, then scientific notation is used when\n",
      "        absolute value of the smallest number is < 1e-4 or the ratio of the\n",
      "        maximum absolute value to the minimum is > 1e3. The default is False.\n",
      "    nanstr : str, optional\n",
      "        String representation of floating point not-a-number (default nan).\n",
      "    infstr : str, optional\n",
      "        String representation of floating point infinity (default inf).\n",
      "    sign : string, either '-', '+', or ' ', optional\n",
      "        Controls printing of the sign of floating-point types. If '+', always\n",
      "        print the sign of positive values. If ' ', always prints a space\n",
      "        (whitespace character) in the sign position of positive values.  If\n",
      "        '-', omit the sign character of positive values. (default '-')\n",
      "    formatter : dict of callables, optional\n",
      "        If not None, the keys should indicate the type(s) that the respective\n",
      "        formatting function applies to.  Callables should return a string.\n",
      "        Types that are not specified (by their corresponding keys) are handled\n",
      "        by the default formatters.  Individual types for which a formatter\n",
      "        can be set are:\n",
      "\n",
      "        - 'bool'\n",
      "        - 'int'\n",
      "        - 'timedelta' : a `numpy.timedelta64`\n",
      "        - 'datetime' : a `numpy.datetime64`\n",
      "        - 'float'\n",
      "        - 'longfloat' : 128-bit floats\n",
      "        - 'complexfloat'\n",
      "        - 'longcomplexfloat' : composed of two 128-bit floats\n",
      "        - 'numpystr' : types `numpy.string_` and `numpy.unicode_`\n",
      "        - 'object' : `np.object_` arrays\n",
      "\n",
      "        Other keys that can be used to set a group of types at once are:\n",
      "\n",
      "        - 'all' : sets all types\n",
      "        - 'int_kind' : sets 'int'\n",
      "        - 'float_kind' : sets 'float' and 'longfloat'\n",
      "        - 'complex_kind' : sets 'complexfloat' and 'longcomplexfloat'\n",
      "        - 'str_kind' : sets 'numpystr'\n",
      "    floatmode : str, optional\n",
      "        Controls the interpretation of the `precision` option for\n",
      "        floating-point types. Can take the following values\n",
      "        (default maxprec_equal):\n",
      "\n",
      "        * 'fixed': Always print exactly `precision` fractional digits,\n",
      "                even if this would print more or fewer digits than\n",
      "                necessary to specify the value uniquely.\n",
      "        * 'unique': Print the minimum number of fractional digits necessary\n",
      "                to represent each value uniquely. Different elements may\n",
      "                have a different number of digits. The value of the\n",
      "                `precision` option is ignored.\n",
      "        * 'maxprec': Print at most `precision` fractional digits, but if\n",
      "                an element can be uniquely represented with fewer digits\n",
      "                only print it with that many.\n",
      "        * 'maxprec_equal': Print at most `precision` fractional digits,\n",
      "                but if every element in the array can be uniquely\n",
      "                represented with an equal number of fewer digits, use that\n",
      "                many digits for all elements.\n",
      "    legacy : string or `False`, optional\n",
      "        If set to the string `'1.13'` enables 1.13 legacy printing mode. This\n",
      "        approximates numpy 1.13 print output by including a space in the sign\n",
      "        position of floats and different behavior for 0d arrays. This also\n",
      "        enables 1.21 legacy printing mode (described below).\n",
      "\n",
      "        If set to the string `'1.21'` enables 1.21 legacy printing mode. This\n",
      "        approximates numpy 1.21 print output of complex structured dtypes\n",
      "        by not inserting spaces after commas that separate fields and after\n",
      "        colons.\n",
      "\n",
      "        If set to `False`, disables legacy mode.\n",
      "\n",
      "        Unrecognized strings will be ignored with a warning for forward\n",
      "        compatibility.\n",
      "\n",
      "        .. versionadded:: 1.14.0\n",
      "        .. versionchanged:: 1.22.0\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    get_printoptions, printoptions, set_string_function, array2string\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    `formatter` is always reset with a call to `set_printoptions`.\n",
      "\n",
      "    Use `printoptions` as a context manager to set the values temporarily.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Floating point precision can be set:\n",
      "\n",
      "    >>> np.set_printoptions(precision=4)\n",
      "    >>> np.array([1.123456789])\n",
      "    [1.1235]\n",
      "\n",
      "    Long arrays can be summarised:\n",
      "\n",
      "    >>> np.set_printoptions(threshold=5)\n",
      "    >>> np.arange(10)\n",
      "    array([0, 1, 2, ..., 7, 8, 9])\n",
      "\n",
      "    Small results can be suppressed:\n",
      "\n",
      "    >>> eps = np.finfo(float).eps\n",
      "    >>> x = np.arange(4.)\n",
      "    >>> x**2 - (x + eps)**2\n",
      "    array([-4.9304e-32, -4.4409e-16,  0.0000e+00,  0.0000e+00])\n",
      "    >>> np.set_printoptions(suppress=True)\n",
      "    >>> x**2 - (x + eps)**2\n",
      "    array([-0., -0.,  0.,  0.])\n",
      "\n",
      "    A custom formatter can be used to display array elements as desired:\n",
      "\n",
      "    >>> np.set_printoptions(formatter={'all':lambda x: 'int: '+str(-x)})\n",
      "    >>> x = np.arange(3)\n",
      "    >>> x\n",
      "    array([int: 0, int: -1, int: -2])\n",
      "    >>> np.set_printoptions()  # formatter gets reset\n",
      "    >>> x\n",
      "    array([0, 1, 2])\n",
      "\n",
      "    To put back the default options, you can use:\n",
      "\n",
      "    >>> np.set_printoptions(edgeitems=3, infstr='inf',\n",
      "    ... linewidth=75, nanstr='nan', precision=8,\n",
      "    ... suppress=False, threshold=1000, formatter=None)\n",
      "\n",
      "    Also to temporarily override options, use `printoptions` as a context manager:\n",
      "\n",
      "    >>> with np.printoptions(precision=2, suppress=True, threshold=5):\n",
      "    ...     np.linspace(0, 10, 10)\n",
      "    array([ 0.  ,  1.11,  2.22, ...,  7.78,  8.89, 10.  ])\n",
      "\n",
      "    \n",
      "code: get_printoptions\n",
      "@set_module('numpy')\n",
      "def get_printoptions():\n",
      "    opts = _format_options.copy()\n",
      "    opts['legacy'] = {\n",
      "        113: '1.13', 121: '1.21', sys.maxsize: False,\n",
      "    }[opts['legacy']]\n",
      "    return opts\n",
      "docstring: get_printoptions\n",
      "\n",
      "    Return the current print options.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    print_opts : dict\n",
      "        Dictionary of current print options with keys\n",
      "\n",
      "          - precision : int\n",
      "          - threshold : int\n",
      "          - edgeitems : int\n",
      "          - linewidth : int\n",
      "          - suppress : bool\n",
      "          - nanstr : str\n",
      "          - infstr : str\n",
      "          - formatter : dict of callables\n",
      "          - sign : str\n",
      "\n",
      "        For a full description of these options, see `set_printoptions`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    set_printoptions, printoptions, set_string_function\n",
      "\n",
      "    \n",
      "code: printoptions\n",
      "@set_module('numpy')\n",
      "@contextlib.contextmanager\n",
      "def printoptions(*args, **kwargs):\n",
      "    opts = np.get_printoptions()\n",
      "    try:\n",
      "        np.set_printoptions(*args, **kwargs)\n",
      "        yield np.get_printoptions()\n",
      "    finally:\n",
      "        np.set_printoptions(**opts)\n",
      "docstring: printoptions\n",
      "Context manager for setting print options.\n",
      "\n",
      "    Set print options for the scope of the `with` block, and restore the old\n",
      "    options at the end. See `set_printoptions` for the full description of\n",
      "    available options.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    >>> from numpy.testing import assert_equal\n",
      "    >>> with np.printoptions(precision=2):\n",
      "    ...     np.array([2.0]) / 3\n",
      "    array([0.67])\n",
      "\n",
      "    The `as`-clause of the `with`-statement gives the current print options:\n",
      "\n",
      "    >>> with np.printoptions(precision=2) as opts:\n",
      "    ...      assert_equal(opts, np.get_printoptions())\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    set_printoptions, get_printoptions\n",
      "\n",
      "    \n",
      "code: format_float_positional\n",
      "@set_module('numpy')\n",
      "def format_float_positional(x, precision=None, unique=True,\n",
      "                            fractional=True, trim='k', sign=False,\n",
      "                            pad_left=None, pad_right=None, min_digits=None):\n",
      "    precision = _none_or_positive_arg(precision, 'precision')\n",
      "    pad_left = _none_or_positive_arg(pad_left, 'pad_left')\n",
      "    pad_right = _none_or_positive_arg(pad_right, 'pad_right')\n",
      "    min_digits = _none_or_positive_arg(min_digits, 'min_digits')\n",
      "    if not fractional and precision == 0:\n",
      "        raise ValueError(\"precision must be greater than 0 if \"\n",
      "                         \"fractional=False\")\n",
      "    if min_digits > 0 and precision > 0 and min_digits > precision:\n",
      "        raise ValueError(\"min_digits must be less than or equal to precision\")\n",
      "    return dragon4_positional(x, precision=precision, unique=unique,\n",
      "                              fractional=fractional, trim=trim,\n",
      "                              sign=sign, pad_left=pad_left,\n",
      "                              pad_right=pad_right, min_digits=min_digits)\n",
      "docstring: format_float_positional\n",
      "\n",
      "    Format a floating-point scalar as a decimal string in positional notation.\n",
      "\n",
      "    Provides control over rounding, trimming and padding. Uses and assumes\n",
      "    IEEE unbiased rounding. Uses the \"Dragon4\" algorithm.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : python float or numpy floating scalar\n",
      "        Value to format.\n",
      "    precision : non-negative integer or None, optional\n",
      "        Maximum number of digits to print. May be None if `unique` is\n",
      "        `True`, but must be an integer if unique is `False`.\n",
      "    unique : boolean, optional\n",
      "        If `True`, use a digit-generation strategy which gives the shortest\n",
      "        representation which uniquely identifies the floating-point number from\n",
      "        other values of the same type, by judicious rounding. If `precision`\n",
      "        is given fewer digits than necessary can be printed, or if `min_digits`\n",
      "        is given more can be printed, in which cases the last digit is rounded\n",
      "        with unbiased rounding.\n",
      "        If `False`, digits are generated as if printing an infinite-precision\n",
      "        value and stopping after `precision` digits, rounding the remaining\n",
      "        value with unbiased rounding\n",
      "    fractional : boolean, optional\n",
      "        If `True`, the cutoffs of `precision` and `min_digits` refer to the\n",
      "        total number of digits after the decimal point, including leading\n",
      "        zeros.\n",
      "        If `False`, `precision` and `min_digits` refer to the total number of\n",
      "        significant digits, before or after the decimal point, ignoring leading\n",
      "        zeros.\n",
      "    trim : one of 'k', '.', '0', '-', optional\n",
      "        Controls post-processing trimming of trailing digits, as follows:\n",
      "\n",
      "        * 'k' : keep trailing zeros, keep decimal point (no trimming)\n",
      "        * '.' : trim all trailing zeros, leave decimal point\n",
      "        * '0' : trim all but the zero before the decimal point. Insert the\n",
      "          zero if it is missing.\n",
      "        * '-' : trim trailing zeros and any trailing decimal point\n",
      "    sign : boolean, optional\n",
      "        Whether to show the sign for positive values.\n",
      "    pad_left : non-negative integer, optional\n",
      "        Pad the left side of the string with whitespace until at least that\n",
      "        many characters are to the left of the decimal point.\n",
      "    pad_right : non-negative integer, optional\n",
      "        Pad the right side of the string with whitespace until at least that\n",
      "        many characters are to the right of the decimal point.\n",
      "    min_digits : non-negative integer or None, optional\n",
      "        Minimum number of digits to print. Only has an effect if `unique=True`\n",
      "        in which case additional digits past those necessary to uniquely\n",
      "        identify the value may be printed, rounding the last additional digit.\n",
      "        \n",
      "        -- versionadded:: 1.21.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    rep : string\n",
      "        The string representation of the floating point value\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    format_float_scientific\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.format_float_positional(np.float32(np.pi))\n",
      "    '3.1415927'\n",
      "    >>> np.format_float_positional(np.float16(np.pi))\n",
      "    '3.14'\n",
      "    >>> np.format_float_positional(np.float16(0.3))\n",
      "    '0.3'\n",
      "    >>> np.format_float_positional(np.float16(0.3), unique=False, precision=10)\n",
      "    '0.3000488281'\n",
      "    \n",
      "code: format_float_scientific\n",
      "@set_module('numpy')\n",
      "def format_float_scientific(x, precision=None, unique=True, trim='k',\n",
      "                            sign=False, pad_left=None, exp_digits=None,\n",
      "                            min_digits=None):\n",
      "    precision = _none_or_positive_arg(precision, 'precision')\n",
      "    pad_left = _none_or_positive_arg(pad_left, 'pad_left')\n",
      "    exp_digits = _none_or_positive_arg(exp_digits, 'exp_digits')\n",
      "    min_digits = _none_or_positive_arg(min_digits, 'min_digits')\n",
      "    if min_digits > 0 and precision > 0 and min_digits > precision:\n",
      "        raise ValueError(\"min_digits must be less than or equal to precision\")\n",
      "    return dragon4_scientific(x, precision=precision, unique=unique,\n",
      "                              trim=trim, sign=sign, pad_left=pad_left,\n",
      "                              exp_digits=exp_digits, min_digits=min_digits)\n",
      "docstring: format_float_scientific\n",
      "\n",
      "    Format a floating-point scalar as a decimal string in scientific notation.\n",
      "\n",
      "    Provides control over rounding, trimming and padding. Uses and assumes\n",
      "    IEEE unbiased rounding. Uses the \"Dragon4\" algorithm.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : python float or numpy floating scalar\n",
      "        Value to format.\n",
      "    precision : non-negative integer or None, optional\n",
      "        Maximum number of digits to print. May be None if `unique` is\n",
      "        `True`, but must be an integer if unique is `False`.\n",
      "    unique : boolean, optional\n",
      "        If `True`, use a digit-generation strategy which gives the shortest\n",
      "        representation which uniquely identifies the floating-point number from\n",
      "        other values of the same type, by judicious rounding. If `precision`\n",
      "        is given fewer digits than necessary can be printed. If `min_digits`\n",
      "        is given more can be printed, in which cases the last digit is rounded\n",
      "        with unbiased rounding.\n",
      "        If `False`, digits are generated as if printing an infinite-precision\n",
      "        value and stopping after `precision` digits, rounding the remaining\n",
      "        value with unbiased rounding\n",
      "    trim : one of 'k', '.', '0', '-', optional\n",
      "        Controls post-processing trimming of trailing digits, as follows:\n",
      "\n",
      "        * 'k' : keep trailing zeros, keep decimal point (no trimming)\n",
      "        * '.' : trim all trailing zeros, leave decimal point\n",
      "        * '0' : trim all but the zero before the decimal point. Insert the\n",
      "          zero if it is missing.\n",
      "        * '-' : trim trailing zeros and any trailing decimal point\n",
      "    sign : boolean, optional\n",
      "        Whether to show the sign for positive values.\n",
      "    pad_left : non-negative integer, optional\n",
      "        Pad the left side of the string with whitespace until at least that\n",
      "        many characters are to the left of the decimal point.\n",
      "    exp_digits : non-negative integer, optional\n",
      "        Pad the exponent with zeros until it contains at least this many digits.\n",
      "        If omitted, the exponent will be at least 2 digits.\n",
      "    min_digits : non-negative integer or None, optional\n",
      "        Minimum number of digits to print. This only has an effect for\n",
      "        `unique=True`. In that case more digits than necessary to uniquely\n",
      "        identify the value may be printed and rounded unbiased.\n",
      "\n",
      "        -- versionadded:: 1.21.0\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    rep : string\n",
      "        The string representation of the floating point value\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    format_float_positional\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.format_float_scientific(np.float32(np.pi))\n",
      "    '3.1415927e+00'\n",
      "    >>> s = np.float32(1.23e24)\n",
      "    >>> np.format_float_scientific(s, unique=False, precision=15)\n",
      "    '1.230000071797338e+24'\n",
      "    >>> np.format_float_scientific(s, exp_digits=4)\n",
      "    '1.23e+0024'\n",
      "    \n",
      "code: require\n",
      "@set_array_function_like_doc\n",
      "@set_module('numpy')\n",
      "def require(a, dtype=None, requirements=None, *, like=None):\n",
      "    if like is not None:\n",
      "        return _require_with_like(\n",
      "            a,\n",
      "            dtype=dtype,\n",
      "            requirements=requirements,\n",
      "            like=like,\n",
      "        )\n",
      "    if not requirements:\n",
      "        return asanyarray(a, dtype=dtype)\n",
      "    requirements = {POSSIBLE_FLAGS[x.upper()] for x in requirements}\n",
      "    if 'E' in requirements:\n",
      "        requirements.remove('E')\n",
      "        subok = False\n",
      "    else:\n",
      "        subok = True\n",
      "    order = 'A'\n",
      "    if requirements >= {'C', 'F'}:\n",
      "        raise ValueError('Cannot specify both \"C\" and \"F\" order')\n",
      "    elif 'F' in requirements:\n",
      "        order = 'F'\n",
      "        requirements.remove('F')\n",
      "    elif 'C' in requirements:\n",
      "        order = 'C'\n",
      "        requirements.remove('C')\n",
      "    arr = array(a, dtype=dtype, order=order, copy=False, subok=subok)\n",
      "    for prop in requirements:\n",
      "        if not arr.flags[prop]:\n",
      "            return arr.copy(order)\n",
      "    return arr\n",
      "docstring: require\n",
      "\n",
      "    Return an ndarray of the provided type that satisfies requirements.\n",
      "\n",
      "    This function is useful to be sure that an array with the correct flags\n",
      "    is returned for passing to compiled code (perhaps through ctypes).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "       The object to be converted to a type-and-requirement-satisfying array.\n",
      "    dtype : data-type\n",
      "       The required data-type. If None preserve the current dtype. If your\n",
      "       application requires the data to be in native byteorder, include\n",
      "       a byteorder specification as a part of the dtype specification.\n",
      "    requirements : str or sequence of str\n",
      "       The requirements list can be any of the following\n",
      "\n",
      "       * 'F_CONTIGUOUS' ('F') - ensure a Fortran-contiguous array\n",
      "       * 'C_CONTIGUOUS' ('C') - ensure a C-contiguous array\n",
      "       * 'ALIGNED' ('A')      - ensure a data-type aligned array\n",
      "       * 'WRITEABLE' ('W')    - ensure a writable array\n",
      "       * 'OWNDATA' ('O')      - ensure an array that owns its own data\n",
      "       * 'ENSUREARRAY', ('E') - ensure a base array, instead of a subclass\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array with specified requirements and type if given.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    asarray : Convert input to an ndarray.\n",
      "    asanyarray : Convert to an ndarray, but pass through ndarray subclasses.\n",
      "    ascontiguousarray : Convert input to a contiguous array.\n",
      "    asfortranarray : Convert input to an ndarray with column-major\n",
      "                     memory order.\n",
      "    ndarray.flags : Information about the memory layout of the array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The returned array will be guaranteed to have the listed requirements\n",
      "    by making a copy if needed.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(6).reshape(2,3)\n",
      "    >>> x.flags\n",
      "      C_CONTIGUOUS : True\n",
      "      F_CONTIGUOUS : False\n",
      "      OWNDATA : False\n",
      "      WRITEABLE : True\n",
      "      ALIGNED : True\n",
      "      WRITEBACKIFCOPY : False\n",
      "\n",
      "    >>> y = np.require(x, dtype=np.float32, requirements=['A', 'O', 'W', 'F'])\n",
      "    >>> y.flags\n",
      "      C_CONTIGUOUS : False\n",
      "      F_CONTIGUOUS : True\n",
      "      OWNDATA : True\n",
      "      WRITEABLE : True\n",
      "      ALIGNED : True\n",
      "      WRITEBACKIFCOPY : False\n",
      "\n",
      "    \n",
      "code: seterr\n",
      "@set_module('numpy')\n",
      "def seterr(all=None, divide=None, over=None, under=None, invalid=None):\n",
      "    pyvals = umath.geterrobj()\n",
      "    old = geterr()\n",
      "    if divide is None:\n",
      "        divide = all or old['divide']\n",
      "    if over is None:\n",
      "        over = all or old['over']\n",
      "    if under is None:\n",
      "        under = all or old['under']\n",
      "    if invalid is None:\n",
      "        invalid = all or old['invalid']\n",
      "    maskvalue = ((_errdict[divide] << SHIFT_DIVIDEBYZERO) +\n",
      "                 (_errdict[over] << SHIFT_OVERFLOW) +\n",
      "                 (_errdict[under] << SHIFT_UNDERFLOW) +\n",
      "                 (_errdict[invalid] << SHIFT_INVALID))\n",
      "    pyvals[1] = maskvalue\n",
      "    umath.seterrobj(pyvals)\n",
      "    return old\n",
      "docstring: seterr\n",
      "\n",
      "    Set how floating-point errors are handled.\n",
      "\n",
      "    Note that operations on integer scalar types (such as `int16`) are\n",
      "    handled like floating point, and are affected by these settings.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    all : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n",
      "        Set treatment for all types of floating-point errors at once:\n",
      "\n",
      "        - ignore: Take no action when the exception occurs.\n",
      "        - warn: Print a `RuntimeWarning` (via the Python `warnings` module).\n",
      "        - raise: Raise a `FloatingPointError`.\n",
      "        - call: Call a function specified using the `seterrcall` function.\n",
      "        - print: Print a warning directly to ``stdout``.\n",
      "        - log: Record error in a Log object specified by `seterrcall`.\n",
      "\n",
      "        The default is not to change the current behavior.\n",
      "    divide : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n",
      "        Treatment for division by zero.\n",
      "    over : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n",
      "        Treatment for floating-point overflow.\n",
      "    under : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n",
      "        Treatment for floating-point underflow.\n",
      "    invalid : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n",
      "        Treatment for invalid floating-point operation.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    old_settings : dict\n",
      "        Dictionary containing the old settings.\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    seterrcall : Set a callback function for the 'call' mode.\n",
      "    geterr, geterrcall, errstate\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The floating-point exceptions are defined in the IEEE 754 standard [1]_:\n",
      "\n",
      "    - Division by zero: infinite result obtained from finite numbers.\n",
      "    - Overflow: result too large to be expressed.\n",
      "    - Underflow: result so close to zero that some precision\n",
      "      was lost.\n",
      "    - Invalid operation: result is not an expressible number, typically\n",
      "      indicates that a NaN was produced.\n",
      "\n",
      "    .. [1] https://en.wikipedia.org/wiki/IEEE_754\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> old_settings = np.seterr(all='ignore')  #seterr to known value\n",
      "    >>> np.seterr(over='raise')\n",
      "    {'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}\n",
      "    >>> np.seterr(**old_settings)  # reset to default\n",
      "    {'divide': 'ignore', 'over': 'raise', 'under': 'ignore', 'invalid': 'ignore'}\n",
      "\n",
      "    >>> np.int16(32000) * np.int16(3)\n",
      "    30464\n",
      "    >>> old_settings = np.seterr(all='warn', over='raise')\n",
      "    >>> np.int16(32000) * np.int16(3)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<stdin>\", line 1, in <module>\n",
      "    FloatingPointError: overflow encountered in scalar multiply\n",
      "\n",
      "    >>> old_settings = np.seterr(all='print')\n",
      "    >>> np.geterr()\n",
      "    {'divide': 'print', 'over': 'print', 'under': 'print', 'invalid': 'print'}\n",
      "    >>> np.int16(32000) * np.int16(3)\n",
      "    30464\n",
      "\n",
      "    \n",
      "code: geterr\n",
      "@set_module('numpy')\n",
      "def geterr():\n",
      "    maskvalue = umath.geterrobj()[1]\n",
      "    mask = 7\n",
      "    res = {}\n",
      "    val = (maskvalue >> SHIFT_DIVIDEBYZERO) & mask\n",
      "    res['divide'] = _errdict_rev[val]\n",
      "    val = (maskvalue >> SHIFT_OVERFLOW) & mask\n",
      "    res['over'] = _errdict_rev[val]\n",
      "    val = (maskvalue >> SHIFT_UNDERFLOW) & mask\n",
      "    res['under'] = _errdict_rev[val]\n",
      "    val = (maskvalue >> SHIFT_INVALID) & mask\n",
      "    res['invalid'] = _errdict_rev[val]\n",
      "    return res\n",
      "docstring: geterr\n",
      "\n",
      "    Get the current way of handling floating-point errors.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    res : dict\n",
      "        A dictionary with keys \"divide\", \"over\", \"under\", and \"invalid\",\n",
      "        whose values are from the strings \"ignore\", \"print\", \"log\", \"warn\",\n",
      "        \"raise\", and \"call\". The keys represent possible floating-point\n",
      "        exceptions, and the values define how these exceptions are handled.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    geterrcall, seterr, seterrcall\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    For complete documentation of the types of floating-point exceptions and\n",
      "    treatment options, see `seterr`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.geterr()\n",
      "    {'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}\n",
      "    >>> np.arange(3.) / np.arange(3.)\n",
      "    array([nan,  1.,  1.])\n",
      "\n",
      "    >>> oldsettings = np.seterr(all='warn', over='raise')\n",
      "    >>> np.geterr()\n",
      "    {'divide': 'warn', 'over': 'raise', 'under': 'warn', 'invalid': 'warn'}\n",
      "    >>> np.arange(3.) / np.arange(3.)\n",
      "    array([nan,  1.,  1.])\n",
      "\n",
      "    \n",
      "code: setbufsize\n",
      "@set_module('numpy')\n",
      "def setbufsize(size):\n",
      "    if size > 10e6:\n",
      "        raise ValueError(\"Buffer size, %s, is too big.\" % size)\n",
      "    if size < 5:\n",
      "        raise ValueError(\"Buffer size, %s, is too small.\" % size)\n",
      "    if size % 16 != 0:\n",
      "        raise ValueError(\"Buffer size, %s, is not a multiple of 16.\" % size)\n",
      "    pyvals = umath.geterrobj()\n",
      "    old = getbufsize()\n",
      "    pyvals[0] = size\n",
      "    umath.seterrobj(pyvals)\n",
      "    return old\n",
      "docstring: setbufsize\n",
      "\n",
      "    Set the size of the buffer used in ufuncs.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    size : int\n",
      "        Size of buffer.\n",
      "\n",
      "    \n",
      "code: getbufsize\n",
      "@set_module('numpy')\n",
      "def getbufsize():\n",
      "    return umath.geterrobj()[0]\n",
      "docstring: getbufsize\n",
      "\n",
      "    Return the size of the buffer used in ufuncs.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    getbufsize : int\n",
      "        Size of ufunc buffer in bytes.\n",
      "\n",
      "    \n",
      "code: seterrcall\n",
      "@set_module('numpy')\n",
      "def seterrcall(func):\n",
      "    if func is not None and not isinstance(func, collections.abc.Callable):\n",
      "        if (not hasattr(func, 'write') or\n",
      "                not isinstance(func.write, collections.abc.Callable)):\n",
      "            raise ValueError(\"Only callable can be used as callback\")\n",
      "    pyvals = umath.geterrobj()\n",
      "    old = geterrcall()\n",
      "    pyvals[2] = func\n",
      "    umath.seterrobj(pyvals)\n",
      "    return old\n",
      "docstring: seterrcall\n",
      "\n",
      "    Set the floating-point error callback function or log object.\n",
      "\n",
      "    There are two ways to capture floating-point error messages.  The first\n",
      "    is to set the error-handler to 'call', using `seterr`.  Then, set\n",
      "    the function to call using this function.\n",
      "\n",
      "    The second is to set the error-handler to 'log', using `seterr`.\n",
      "    Floating-point errors then trigger a call to the 'write' method of\n",
      "    the provided object.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    func : callable f(err, flag) or object with write method\n",
      "        Function to call upon floating-point errors ('call'-mode) or\n",
      "        object whose 'write' method is used to log such message ('log'-mode).\n",
      "\n",
      "        The call function takes two arguments. The first is a string describing\n",
      "        the type of error (such as \"divide by zero\", \"overflow\", \"underflow\",\n",
      "        or \"invalid value\"), and the second is the status flag.  The flag is a\n",
      "        byte, whose four least-significant bits indicate the type of error, one\n",
      "        of \"divide\", \"over\", \"under\", \"invalid\"::\n",
      "\n",
      "          [0 0 0 0 divide over under invalid]\n",
      "\n",
      "        In other words, ``flags = divide + 2*over + 4*under + 8*invalid``.\n",
      "\n",
      "        If an object is provided, its write method should take one argument,\n",
      "        a string.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    h : callable, log instance or None\n",
      "        The old error handler.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    seterr, geterr, geterrcall\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Callback upon error:\n",
      "\n",
      "    >>> def err_handler(type, flag):\n",
      "    ...     print(\"Floating point error (%s), with flag %s\" % (type, flag))\n",
      "    ...\n",
      "\n",
      "    >>> saved_handler = np.seterrcall(err_handler)\n",
      "    >>> save_err = np.seterr(all='call')\n",
      "\n",
      "    >>> np.array([1, 2, 3]) / 0.0\n",
      "    Floating point error (divide by zero), with flag 1\n",
      "    array([inf, inf, inf])\n",
      "\n",
      "    >>> np.seterrcall(saved_handler)\n",
      "    <function err_handler at 0x...>\n",
      "    >>> np.seterr(**save_err)\n",
      "    {'divide': 'call', 'over': 'call', 'under': 'call', 'invalid': 'call'}\n",
      "\n",
      "    Log error message:\n",
      "\n",
      "    >>> class Log:\n",
      "    ...     def write(self, msg):\n",
      "    ...         print(\"LOG: %s\" % msg)\n",
      "    ...\n",
      "\n",
      "    >>> log = Log()\n",
      "    >>> saved_handler = np.seterrcall(log)\n",
      "    >>> save_err = np.seterr(all='log')\n",
      "\n",
      "    >>> np.array([1, 2, 3]) / 0.0\n",
      "    LOG: Warning: divide by zero encountered in divide\n",
      "    array([inf, inf, inf])\n",
      "\n",
      "    >>> np.seterrcall(saved_handler)\n",
      "    <numpy.core.numeric.Log object at 0x...>\n",
      "    >>> np.seterr(**save_err)\n",
      "    {'divide': 'log', 'over': 'log', 'under': 'log', 'invalid': 'log'}\n",
      "\n",
      "    \n",
      "code: geterrcall\n",
      "@set_module('numpy')\n",
      "def geterrcall():\n",
      "    return umath.geterrobj()[2]\n",
      "docstring: geterrcall\n",
      "\n",
      "    Return the current callback function used on floating-point errors.\n",
      "\n",
      "    When the error handling for a floating-point error (one of \"divide\",\n",
      "    \"over\", \"under\", or \"invalid\") is set to 'call' or 'log', the function\n",
      "    that is called or the log instance that is written to is returned by\n",
      "    `geterrcall`. This function or log instance has been set with\n",
      "    `seterrcall`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    errobj : callable, log instance or None\n",
      "        The current error handler. If no handler was set through `seterrcall`,\n",
      "        ``None`` is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    seterrcall, seterr, geterr\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    For complete documentation of the types of floating-point exceptions and\n",
      "    treatment options, see `seterr`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.geterrcall()  # we did not yet set a handler, returns None\n",
      "\n",
      "    >>> oldsettings = np.seterr(all='call')\n",
      "    >>> def err_handler(type, flag):\n",
      "    ...     print(\"Floating point error (%s), with flag %s\" % (type, flag))\n",
      "    >>> oldhandler = np.seterrcall(err_handler)\n",
      "    >>> np.array([1, 2, 3]) / 0.0\n",
      "    Floating point error (divide by zero), with flag 1\n",
      "    array([inf, inf, inf])\n",
      "\n",
      "    >>> cur_handler = np.geterrcall()\n",
      "    >>> cur_handler is err_handler\n",
      "    True\n",
      "\n",
      "    \n",
      "code: errstate._recreate_cm\n",
      "    def _recreate_cm(self):\n",
      "        return self\n",
      "docstring: errstate._recreate_cm\n",
      "Return a recreated instance of self.\n",
      "\n",
      "        Allows an otherwise one-shot context manager like\n",
      "        _GeneratorContextManager to support use as\n",
      "        a decorator via implicit recreation.\n",
      "\n",
      "        This is a private interface just for _GeneratorContextManager.\n",
      "        See issue #11647 for details.\n",
      "        \n",
      "code: _no_nep50_warning\n",
      "@set_module('numpy')\n",
      "@contextlib.contextmanager\n",
      "def _no_nep50_warning():\n",
      "    token = NO_NEP50_WARNING.set(True)\n",
      "    try:\n",
      "        yield\n",
      "    finally:\n",
      "        NO_NEP50_WARNING.reset(token)\n",
      "docstring: _no_nep50_warning\n",
      "\n",
      "    Context manager to disable NEP 50 warnings.  This context manager is\n",
      "    only relevant if the NEP 50 warnings are enabled globally (which is not\n",
      "    thread/context safe).\n",
      "\n",
      "    This warning context manager itself is fully safe, however.\n",
      "    \n",
      "code: record.pprint\n",
      "    def pprint(self):\n",
      "        # pretty-print all fields\n",
      "        names = self.dtype.names\n",
      "        maxlen = max(len(name) for name in names)\n",
      "        fmt = '%% %ds: %%s' % maxlen\n",
      "        rows = [fmt % (name, getattr(self, name)) for name in names]\n",
      "        return \"\\n\".join(rows)\n",
      "docstring: record.pprint\n",
      "Pretty-print all fields.\n",
      "code: format_parser._parseFormats\n",
      "    def _parseFormats(self, formats, aligned=False):\n",
      "        if formats is None:\n",
      "            raise ValueError(\"Need formats argument\")\n",
      "        if isinstance(formats, list):\n",
      "            dtype = sb.dtype(\n",
      "                [('f{}'.format(i), format_) for i, format_ in enumerate(formats)],\n",
      "                aligned,\n",
      "            )\n",
      "        else:\n",
      "            dtype = sb.dtype(formats, aligned)\n",
      "        fields = dtype.fields\n",
      "        if fields is None:\n",
      "            dtype = sb.dtype([('f1', dtype)], aligned)\n",
      "            fields = dtype.fields\n",
      "        keys = dtype.names\n",
      "        self._f_formats = [fields[key][0] for key in keys]\n",
      "        self._offsets = [fields[key][1] for key in keys]\n",
      "        self._nfields = len(keys)\n",
      "docstring: format_parser._parseFormats\n",
      " Parse the field formats \n",
      "code: format_parser._setfieldnames\n",
      "    def _setfieldnames(self, names, titles):\n",
      "        if names:\n",
      "            if type(names) in [list, tuple]:\n",
      "                pass\n",
      "            elif isinstance(names, str):\n",
      "                names = names.split(',')\n",
      "            else:\n",
      "                raise NameError(\"illegal input names %s\" % repr(names))\n",
      "            self._names = [n.strip() for n in names[:self._nfields]]\n",
      "        else:\n",
      "            self._names = []\n",
      "  \"f0, f1, f2,...\"\n",
      " f[n+1],...\" etc. where n is the number of specified names...\"\n",
      "        self._names += ['f%d' % i for i in range(len(self._names),\n",
      "                                                 self._nfields)]\n",
      "        # check for redundant names\n",
      "        _dup = find_duplicate(self._names)\n",
      "        if _dup:\n",
      "            raise ValueError(\"Duplicate field names: %s\" % _dup)\n",
      "        if titles:\n",
      "            self._titles = [n.strip() for n in titles[:self._nfields]]\n",
      "        else:\n",
      "            self._titles = []\n",
      "            titles = []\n",
      "        if self._nfields > len(titles):\n",
      "            self._titles += [None] * (self._nfields - len(titles))\n",
      "docstring: format_parser._setfieldnames\n",
      "convert input field names into a list and assign to the _names\n",
      "        attribute \n",
      "code: chararray.__add__\n",
      "    def __add__(self, other):\n",
      "        return asarray(add(self, other))\n",
      "docstring: chararray.__add__\n",
      "\n",
      "        Return (self + other), that is string concatenation,\n",
      "        element-wise for a pair of array_likes of str or unicode.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        add\n",
      "        \n",
      "code: chararray.__eq__\n",
      "    def __eq__(self, other):\n",
      "        return equal(self, other)\n",
      "docstring: chararray.__eq__\n",
      "\n",
      "        Return (self == other) element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        equal\n",
      "        \n",
      "code: chararray.__ge__\n",
      "    def __ge__(self, other):\n",
      "        return greater_equal(self, other)\n",
      "docstring: chararray.__ge__\n",
      "\n",
      "        Return (self >= other) element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        greater_equal\n",
      "        \n",
      "code: chararray.__gt__\n",
      "    def __gt__(self, other):\n",
      "        return greater(self, other)\n",
      "docstring: chararray.__gt__\n",
      "\n",
      "        Return (self > other) element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        greater\n",
      "        \n",
      "code: chararray.__le__\n",
      "    def __le__(self, other):\n",
      "        return less_equal(self, other)\n",
      "docstring: chararray.__le__\n",
      "\n",
      "        Return (self <= other) element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        less_equal\n",
      "        \n",
      "code: chararray.__lt__\n",
      "    def __lt__(self, other):\n",
      "        return less(self, other)\n",
      "docstring: chararray.__lt__\n",
      "\n",
      "        Return (self < other) element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        less\n",
      "        \n",
      "code: chararray.__mod__\n",
      "    def __mod__(self, i):\n",
      "        return asarray(mod(self, i))\n",
      "docstring: chararray.__mod__\n",
      "\n",
      "        Return (self % i), that is pre-Python 2.6 string formatting\n",
      "        (interpolation), element-wise for a pair of array_likes of `string_`\n",
      "        or `unicode_`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        mod\n",
      "        \n",
      "code: chararray.__mul__\n",
      "    def __mul__(self, i):\n",
      "        return asarray(multiply(self, i))\n",
      "docstring: chararray.__mul__\n",
      "\n",
      "        Return (self * i), that is string multiple concatenation,\n",
      "        element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        multiply\n",
      "        \n",
      "code: chararray.__ne__\n",
      "    def __ne__(self, other):\n",
      "        return not_equal(self, other)\n",
      "docstring: chararray.__ne__\n",
      "\n",
      "        Return (self != other) element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        not_equal\n",
      "        \n",
      "code: chararray.__radd__\n",
      "    def __radd__(self, other):\n",
      "        return asarray(add(numpy.asarray(other), self))\n",
      "docstring: chararray.__radd__\n",
      "\n",
      "        Return (other + self), that is string concatenation,\n",
      "        element-wise for a pair of array_likes of `string_` or `unicode_`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        add\n",
      "        \n",
      "code: chararray.__rmul__\n",
      "    def __rmul__(self, i):\n",
      "        return asarray(multiply(self, i))\n",
      "docstring: chararray.__rmul__\n",
      "\n",
      "        Return (self * i), that is string multiple concatenation,\n",
      "        element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        multiply\n",
      "        \n",
      "code: chararray.capitalize\n",
      "    def capitalize(self):\n",
      "        return asarray(capitalize(self))\n",
      "docstring: chararray.capitalize\n",
      "\n",
      "        Return a copy of `self` with only the first character of each element\n",
      "        capitalized.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.capitalize\n",
      "\n",
      "        \n",
      "code: chararray.center\n",
      "    def center(self, width, fillchar=' '):\n",
      "        return asarray(center(self, width, fillchar))\n",
      "docstring: chararray.center\n",
      "\n",
      "        Return a copy of `self` with its elements centered in a\n",
      "        string of length `width`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        center\n",
      "        \n",
      "code: chararray.count\n",
      "    def count(self, sub, start=0, end=None):\n",
      "        return count(self, sub, start, end)\n",
      "docstring: chararray.count\n",
      "\n",
      "        Returns an array with the number of non-overlapping occurrences of\n",
      "        substring `sub` in the range [`start`, `end`].\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.count\n",
      "\n",
      "        \n",
      "code: chararray.decode\n",
      "    def decode(self, encoding=None, errors=None):\n",
      "        return decode(self, encoding, errors)\n",
      "docstring: chararray.decode\n",
      "\n",
      "        Calls ``bytes.decode`` element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.decode\n",
      "\n",
      "        \n",
      "code: chararray.encode\n",
      "    def encode(self, encoding=None, errors=None):\n",
      "        return encode(self, encoding, errors)\n",
      "docstring: chararray.encode\n",
      "\n",
      "        Calls `str.encode` element-wise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.encode\n",
      "\n",
      "        \n",
      "code: chararray.endswith\n",
      "    def endswith(self, suffix, start=0, end=None):\n",
      "        return endswith(self, suffix, start, end)\n",
      "docstring: chararray.endswith\n",
      "\n",
      "        Returns a boolean array which is `True` where the string element\n",
      "        in `self` ends with `suffix`, otherwise `False`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.endswith\n",
      "\n",
      "        \n",
      "code: chararray.expandtabs\n",
      "    def expandtabs(self, tabsize=8):\n",
      "        return asarray(expandtabs(self, tabsize))\n",
      "docstring: chararray.expandtabs\n",
      "\n",
      "        Return a copy of each string element where all tab characters are\n",
      "        replaced by one or more spaces.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.expandtabs\n",
      "\n",
      "        \n",
      "code: chararray.find\n",
      "    def find(self, sub, start=0, end=None):\n",
      "        return find(self, sub, start, end)\n",
      "docstring: chararray.find\n",
      "\n",
      "        For each element, return the lowest index in the string where\n",
      "        substring `sub` is found.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.find\n",
      "\n",
      "        \n",
      "code: chararray.index\n",
      "    def index(self, sub, start=0, end=None):\n",
      "        return index(self, sub, start, end)\n",
      "docstring: chararray.index\n",
      "\n",
      "        Like `find`, but raises `ValueError` when the substring is not found.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.index\n",
      "\n",
      "        \n",
      "code: chararray.isalnum\n",
      "    def isalnum(self):\n",
      "        return isalnum(self)\n",
      "docstring: chararray.isalnum\n",
      "\n",
      "        Returns true for each element if all characters in the string\n",
      "        are alphanumeric and there is at least one character, false\n",
      "        otherwise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.isalnum\n",
      "\n",
      "        \n",
      "code: chararray.isalpha\n",
      "    def isalpha(self):\n",
      "        return isalpha(self)\n",
      "docstring: chararray.isalpha\n",
      "\n",
      "        Returns true for each element if all characters in the string\n",
      "        are alphabetic and there is at least one character, false\n",
      "        otherwise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.isalpha\n",
      "\n",
      "        \n",
      "code: chararray.isdecimal\n",
      "    def isdecimal(self):\n",
      "        return isdecimal(self)\n",
      "docstring: chararray.isdecimal\n",
      "\n",
      "        For each element in `self`, return True if there are only\n",
      "        decimal characters in the element.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.isdecimal\n",
      "\n",
      "        \n",
      "code: chararray.isdigit\n",
      "    def isdigit(self):\n",
      "        return isdigit(self)\n",
      "docstring: chararray.isdigit\n",
      "\n",
      "        Returns true for each element if all characters in the string are\n",
      "        digits and there is at least one character, false otherwise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.isdigit\n",
      "\n",
      "        \n",
      "code: chararray.islower\n",
      "    def islower(self):\n",
      "        return islower(self)\n",
      "docstring: chararray.islower\n",
      "\n",
      "        Returns true for each element if all cased characters in the\n",
      "        string are lowercase and there is at least one cased character,\n",
      "        false otherwise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.islower\n",
      "\n",
      "        \n",
      "code: chararray.isnumeric\n",
      "    def isnumeric(self):\n",
      "        return isnumeric(self)\n",
      "docstring: chararray.isnumeric\n",
      "\n",
      "        For each element in `self`, return True if there are only\n",
      "        numeric characters in the element.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.isnumeric\n",
      "\n",
      "        \n",
      "code: chararray.isspace\n",
      "    def isspace(self):\n",
      "        return isspace(self)\n",
      "docstring: chararray.isspace\n",
      "\n",
      "        Returns true for each element if there are only whitespace\n",
      "        characters in the string and there is at least one character,\n",
      "        false otherwise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.isspace\n",
      "\n",
      "        \n",
      "code: chararray.istitle\n",
      "    def istitle(self):\n",
      "        return istitle(self)\n",
      "docstring: chararray.istitle\n",
      "\n",
      "        Returns true for each element if the element is a titlecased\n",
      "        string and there is at least one character, false otherwise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.istitle\n",
      "\n",
      "        \n",
      "code: chararray.isupper\n",
      "    def isupper(self):\n",
      "        return isupper(self)\n",
      "docstring: chararray.isupper\n",
      "\n",
      "        Returns true for each element if all cased characters in the\n",
      "        string are uppercase and there is at least one character, false\n",
      "        otherwise.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.isupper\n",
      "\n",
      "        \n",
      "code: chararray.join\n",
      "    def join(self, seq):\n",
      "        return join(self, seq)\n",
      "docstring: chararray.join\n",
      "\n",
      "        Return a string which is the concatenation of the strings in the\n",
      "        sequence `seq`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.join\n",
      "\n",
      "        \n",
      "code: chararray.ljust\n",
      "    def ljust(self, width, fillchar=' '):\n",
      "        return asarray(ljust(self, width, fillchar))\n",
      "docstring: chararray.ljust\n",
      "\n",
      "        Return an array with the elements of `self` left-justified in a\n",
      "        string of length `width`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.ljust\n",
      "\n",
      "        \n",
      "code: chararray.lower\n",
      "    def lower(self):\n",
      "        return asarray(lower(self))\n",
      "docstring: chararray.lower\n",
      "\n",
      "        Return an array with the elements of `self` converted to\n",
      "        lowercase.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.lower\n",
      "\n",
      "        \n",
      "code: chararray.lstrip\n",
      "    def lstrip(self, chars=None):\n",
      "        return asarray(lstrip(self, chars))\n",
      "docstring: chararray.lstrip\n",
      "\n",
      "        For each element in `self`, return a copy with the leading characters\n",
      "        removed.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.lstrip\n",
      "\n",
      "        \n",
      "code: chararray.partition\n",
      "    def partition(self, sep):\n",
      "        return asarray(partition(self, sep))\n",
      "docstring: chararray.partition\n",
      "\n",
      "        Partition each element in `self` around `sep`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        partition\n",
      "        \n",
      "code: chararray.replace\n",
      "    def replace(self, old, new, count=None):\n",
      "        return asarray(replace(self, old, new, count))\n",
      "docstring: chararray.replace\n",
      "\n",
      "        For each element in `self`, return a copy of the string with all\n",
      "        occurrences of substring `old` replaced by `new`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.replace\n",
      "\n",
      "        \n",
      "code: chararray.rfind\n",
      "    def rfind(self, sub, start=0, end=None):\n",
      "        return rfind(self, sub, start, end)\n",
      "docstring: chararray.rfind\n",
      "\n",
      "        For each element in `self`, return the highest index in the string\n",
      "        where substring `sub` is found, such that `sub` is contained\n",
      "        within [`start`, `end`].\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.rfind\n",
      "\n",
      "        \n",
      "code: chararray.rindex\n",
      "    def rindex(self, sub, start=0, end=None):\n",
      "        return rindex(self, sub, start, end)\n",
      "docstring: chararray.rindex\n",
      "\n",
      "        Like `rfind`, but raises `ValueError` when the substring `sub` is\n",
      "        not found.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.rindex\n",
      "\n",
      "        \n",
      "code: chararray.rjust\n",
      "    def rjust(self, width, fillchar=' '):\n",
      "        return asarray(rjust(self, width, fillchar))\n",
      "docstring: chararray.rjust\n",
      "\n",
      "        Return an array with the elements of `self`\n",
      "        right-justified in a string of length `width`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.rjust\n",
      "\n",
      "        \n",
      "code: chararray.rpartition\n",
      "    def rpartition(self, sep):\n",
      "        return asarray(rpartition(self, sep))\n",
      "docstring: chararray.rpartition\n",
      "\n",
      "        Partition each element in `self` around `sep`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        rpartition\n",
      "        \n",
      "code: chararray.rsplit\n",
      "    def rsplit(self, sep=None, maxsplit=None):\n",
      "        return rsplit(self, sep, maxsplit)\n",
      "docstring: chararray.rsplit\n",
      "\n",
      "        For each element in `self`, return a list of the words in\n",
      "        the string, using `sep` as the delimiter string.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.rsplit\n",
      "\n",
      "        \n",
      "code: chararray.rstrip\n",
      "    def rstrip(self, chars=None):\n",
      "        return asarray(rstrip(self, chars))\n",
      "docstring: chararray.rstrip\n",
      "\n",
      "        For each element in `self`, return a copy with the trailing\n",
      "        characters removed.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.rstrip\n",
      "\n",
      "        \n",
      "code: chararray.split\n",
      "    def split(self, sep=None, maxsplit=None):\n",
      "        return split(self, sep, maxsplit)\n",
      "docstring: chararray.split\n",
      "\n",
      "        For each element in `self`, return a list of the words in the\n",
      "        string, using `sep` as the delimiter string.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.split\n",
      "\n",
      "        \n",
      "code: chararray.splitlines\n",
      "    def splitlines(self, keepends=None):\n",
      "        return splitlines(self, keepends)\n",
      "docstring: chararray.splitlines\n",
      "\n",
      "        For each element in `self`, return a list of the lines in the\n",
      "        element, breaking at line boundaries.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.splitlines\n",
      "\n",
      "        \n",
      "code: chararray.startswith\n",
      "    def startswith(self, prefix, start=0, end=None):\n",
      "        return startswith(self, prefix, start, end)\n",
      "docstring: chararray.startswith\n",
      "\n",
      "        Returns a boolean array which is `True` where the string element\n",
      "        in `self` starts with `prefix`, otherwise `False`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.startswith\n",
      "\n",
      "        \n",
      "code: chararray.strip\n",
      "    def strip(self, chars=None):\n",
      "        return asarray(strip(self, chars))\n",
      "docstring: chararray.strip\n",
      "\n",
      "        For each element in `self`, return a copy with the leading and\n",
      "        trailing characters removed.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.strip\n",
      "\n",
      "        \n",
      "code: chararray.swapcase\n",
      "    def swapcase(self):\n",
      "        return asarray(swapcase(self))\n",
      "docstring: chararray.swapcase\n",
      "\n",
      "        For each element in `self`, return a copy of the string with\n",
      "        uppercase characters converted to lowercase and vice versa.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.swapcase\n",
      "\n",
      "        \n",
      "code: chararray.title\n",
      "    def title(self):\n",
      "        return asarray(title(self))\n",
      "docstring: chararray.title\n",
      "\n",
      "        For each element in `self`, return a titlecased version of the\n",
      "        string: words start with uppercase characters, all remaining cased\n",
      "        characters are lowercase.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.title\n",
      "\n",
      "        \n",
      "code: chararray.translate\n",
      "    def translate(self, table, deletechars=None):\n",
      "        return asarray(translate(self, table, deletechars))\n",
      "docstring: chararray.translate\n",
      "\n",
      "        For each element in `self`, return a copy of the string where\n",
      "        all characters occurring in the optional argument\n",
      "        `deletechars` are removed, and the remaining characters have\n",
      "        been mapped through the given translation table.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.translate\n",
      "\n",
      "        \n",
      "code: chararray.upper\n",
      "    def upper(self):\n",
      "        return asarray(upper(self))\n",
      "docstring: chararray.upper\n",
      "\n",
      "        Return an array with the elements of `self` converted to\n",
      "        uppercase.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.upper\n",
      "\n",
      "        \n",
      "code: chararray.zfill\n",
      "    def zfill(self, width):\n",
      "        return asarray(zfill(self, width))\n",
      "docstring: chararray.zfill\n",
      "\n",
      "        Return the numeric string left-filled with zeros in a string of\n",
      "        length `width`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        char.zfill\n",
      "\n",
      "        \n",
      "code: logspace\n",
      "@array_function_dispatch(_logspace_dispatcher)\n",
      "def logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None,\n",
      "             axis=0):\n",
      "    y = linspace(start, stop, num=num, endpoint=endpoint, axis=axis)\n",
      "    if dtype is None:\n",
      "        return _nx.power(base, y)\n",
      "    return _nx.power(base, y).astype(dtype, copy=False)\n",
      "docstring: logspace\n",
      "\n",
      "    Return numbers spaced evenly on a log scale.\n",
      "\n",
      "    In linear space, the sequence starts at ``base ** start``\n",
      "    (`base` to the power of `start`) and ends with ``base ** stop``\n",
      "    (see `endpoint` below).\n",
      "\n",
      "    .. versionchanged:: 1.16.0\n",
      "        Non-scalar `start` and `stop` are now supported.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    start : array_like\n",
      "        ``base ** start`` is the starting value of the sequence.\n",
      "    stop : array_like\n",
      "        ``base ** stop`` is the final value of the sequence, unless `endpoint`\n",
      "        is False.  In that case, ``num + 1`` values are spaced over the\n",
      "        interval in log-space, of which all but the last (a sequence of\n",
      "        length `num`) are returned.\n",
      "    num : integer, optional\n",
      "        Number of samples to generate.  Default is 50.\n",
      "    endpoint : boolean, optional\n",
      "        If true, `stop` is the last sample. Otherwise, it is not included.\n",
      "        Default is True.\n",
      "    base : array_like, optional\n",
      "        The base of the log space. The step size between the elements in\n",
      "        ``ln(samples) / ln(base)`` (or ``log_base(samples)``) is uniform.\n",
      "        Default is 10.0.\n",
      "    dtype : dtype\n",
      "        The type of the output array.  If `dtype` is not given, the data type\n",
      "        is inferred from `start` and `stop`. The inferred type will never be\n",
      "        an integer; `float` is chosen even if the arguments would produce an\n",
      "        array of integers.\n",
      "    axis : int, optional\n",
      "        The axis in the result to store the samples.  Relevant only if start\n",
      "        or stop are array-like.  By default (0), the samples will be along a\n",
      "        new axis inserted at the beginning. Use -1 to get an axis at the end.\n",
      "\n",
      "        .. versionadded:: 1.16.0\n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    samples : ndarray\n",
      "        `num` samples, equally spaced on a log scale.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    arange : Similar to linspace, with the step size specified instead of the\n",
      "             number of samples. Note that, when used with a float endpoint, the\n",
      "             endpoint may or may not be included.\n",
      "    linspace : Similar to logspace, but with the samples uniformly distributed\n",
      "               in linear space, instead of log space.\n",
      "    geomspace : Similar to logspace, but with endpoints specified directly.\n",
      "    :ref:`how-to-partition`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Logspace is equivalent to the code\n",
      "\n",
      "    >>> y = np.linspace(start, stop, num=num, endpoint=endpoint)\n",
      "    ... # doctest: +SKIP\n",
      "    >>> power(base, y).astype(dtype)\n",
      "    ... # doctest: +SKIP\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.logspace(2.0, 3.0, num=4)\n",
      "    array([ 100.        ,  215.443469  ,  464.15888336, 1000.        ])\n",
      "    >>> np.logspace(2.0, 3.0, num=4, endpoint=False)\n",
      "    array([100.        ,  177.827941  ,  316.22776602,  562.34132519])\n",
      "    >>> np.logspace(2.0, 3.0, num=4, base=2.0)\n",
      "    array([4.        ,  5.0396842 ,  6.34960421,  8.        ])\n",
      "\n",
      "    Graphical illustration:\n",
      "\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> N = 10\n",
      "    >>> x1 = np.logspace(0.1, 1, N, endpoint=True)\n",
      "    >>> x2 = np.logspace(0.1, 1, N, endpoint=False)\n",
      "    >>> y = np.zeros(N)\n",
      "    >>> plt.plot(x1, y, 'o')\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.plot(x2, y + 0.5, 'o')\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.ylim([-0.5, 1])\n",
      "    (-0.5, 1)\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: linspace\n",
      "@array_function_dispatch(_linspace_dispatcher)\n",
      "def linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None,\n",
      "             axis=0):\n",
      "    num = operator.index(num)\n",
      "    if num < 0:\n",
      "        raise ValueError(\"Number of samples, %s, must be non-negative.\" % num)\n",
      "    div = (num - 1) if endpoint else num\n",
      " and make sure one can use variables that have an __array_interface__, gh-6634\n",
      "    start = asanyarray(start) * 1.0\n",
      "    stop  = asanyarray(stop)  * 1.0\n",
      "    dt = result_type(start, stop, float(num))\n",
      "    if dtype is None:\n",
      "        dtype = dt\n",
      "        integer_dtype = False\n",
      "    else:\n",
      "        integer_dtype = _nx.issubdtype(dtype, _nx.integer)\n",
      "    delta = stop - start\n",
      "    y = _nx.arange(0, num, dtype=dt).reshape((-1,) + (1,) * ndim(delta))\n",
      " from overriding what class is produced, and thus prevents, e.g. use of Quantities,\n",
      " Special handling for denormal numbers, gh-5437\n",
      "            y /= div\n",
      "            if _mult_inplace:\n",
      "                y *= delta\n",
      "            else:\n",
      "                y = y * delta\n",
      "        else:\n",
      "            if _mult_inplace:\n",
      "                y *= step\n",
      "            else:\n",
      "                y = y * step\n",
      "    else:\n",
      " have an undefined step\n",
      "        step = NaN\n",
      "        # Multiply with delta to allow possible override of output class.\n",
      "        y = y * delta\n",
      "    y += start\n",
      "    if endpoint and num > 1:\n",
      "        y[-1] = stop\n",
      "    if axis != 0:\n",
      "        y = _nx.moveaxis(y, 0, axis)\n",
      "    if integer_dtype:\n",
      "        _nx.floor(y, out=y)\n",
      "    if retstep:\n",
      "        return y.astype(dtype, copy=False), step\n",
      "    else:\n",
      "        return y.astype(dtype, copy=False)\n",
      "docstring: linspace\n",
      "\n",
      "    Return evenly spaced numbers over a specified interval.\n",
      "\n",
      "    Returns `num` evenly spaced samples, calculated over the\n",
      "    interval [`start`, `stop`].\n",
      "\n",
      "    The endpoint of the interval can optionally be excluded.\n",
      "\n",
      "    .. versionchanged:: 1.16.0\n",
      "        Non-scalar `start` and `stop` are now supported.\n",
      "\n",
      "    .. versionchanged:: 1.20.0\n",
      "        Values are rounded towards ``-inf`` instead of ``0`` when an\n",
      "        integer ``dtype`` is specified. The old behavior can\n",
      "        still be obtained with ``np.linspace(start, stop, num).astype(int)``\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    start : array_like\n",
      "        The starting value of the sequence.\n",
      "    stop : array_like\n",
      "        The end value of the sequence, unless `endpoint` is set to False.\n",
      "        In that case, the sequence consists of all but the last of ``num + 1``\n",
      "        evenly spaced samples, so that `stop` is excluded.  Note that the step\n",
      "        size changes when `endpoint` is False.\n",
      "    num : int, optional\n",
      "        Number of samples to generate. Default is 50. Must be non-negative.\n",
      "    endpoint : bool, optional\n",
      "        If True, `stop` is the last sample. Otherwise, it is not included.\n",
      "        Default is True.\n",
      "    retstep : bool, optional\n",
      "        If True, return (`samples`, `step`), where `step` is the spacing\n",
      "        between samples.\n",
      "    dtype : dtype, optional\n",
      "        The type of the output array.  If `dtype` is not given, the data type\n",
      "        is inferred from `start` and `stop`. The inferred dtype will never be\n",
      "        an integer; `float` is chosen even if the arguments would produce an\n",
      "        array of integers.\n",
      "\n",
      "        .. versionadded:: 1.9.0\n",
      "\n",
      "    axis : int, optional\n",
      "        The axis in the result to store the samples.  Relevant only if start\n",
      "        or stop are array-like.  By default (0), the samples will be along a\n",
      "        new axis inserted at the beginning. Use -1 to get an axis at the end.\n",
      "\n",
      "        .. versionadded:: 1.16.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    samples : ndarray\n",
      "        There are `num` equally spaced samples in the closed interval\n",
      "        ``[start, stop]`` or the half-open interval ``[start, stop)``\n",
      "        (depending on whether `endpoint` is True or False).\n",
      "    step : float, optional\n",
      "        Only returned if `retstep` is True\n",
      "\n",
      "        Size of spacing between samples.\n",
      "\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    arange : Similar to `linspace`, but uses a step size (instead of the\n",
      "             number of samples).\n",
      "    geomspace : Similar to `linspace`, but with numbers spaced evenly on a log\n",
      "                scale (a geometric progression).\n",
      "    logspace : Similar to `geomspace`, but with the end points specified as\n",
      "               logarithms.\n",
      "    :ref:`how-to-partition`\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.linspace(2.0, 3.0, num=5)\n",
      "    array([2.  , 2.25, 2.5 , 2.75, 3.  ])\n",
      "    >>> np.linspace(2.0, 3.0, num=5, endpoint=False)\n",
      "    array([2. ,  2.2,  2.4,  2.6,  2.8])\n",
      "    >>> np.linspace(2.0, 3.0, num=5, retstep=True)\n",
      "    (array([2.  ,  2.25,  2.5 ,  2.75,  3.  ]), 0.25)\n",
      "\n",
      "    Graphical illustration:\n",
      "\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> N = 8\n",
      "    >>> y = np.zeros(N)\n",
      "    >>> x1 = np.linspace(0, 10, N, endpoint=True)\n",
      "    >>> x2 = np.linspace(0, 10, N, endpoint=False)\n",
      "    >>> plt.plot(x1, y, 'o')\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.plot(x2, y + 0.5, 'o')\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.ylim([-0.5, 1])\n",
      "    (-0.5, 1)\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: geomspace\n",
      "@array_function_dispatch(_geomspace_dispatcher)\n",
      "def geomspace(start, stop, num=50, endpoint=True, dtype=None, axis=0):\n",
      "    start = asanyarray(start)\n",
      "    stop = asanyarray(stop)\n",
      "    if _nx.any(start == 0) or _nx.any(stop == 0):\n",
      "        raise ValueError('Geometric sequence cannot include zero')\n",
      "    dt = result_type(start, stop, float(num), _nx.zeros((), dtype))\n",
      "    if dtype is None:\n",
      "        dtype = dt\n",
      "    else:\n",
      " Promote both arguments to the same dtype in case, for instance, one is\n",
      " Copy since we may change things in-place further down.\n",
      "    start = start.astype(dt, copy=True)\n",
      "    stop = stop.astype(dt, copy=True)\n",
      "    out_sign = _nx.ones(_nx.broadcast(start, stop).shape, dt)\n",
      " positive real, calculating, then undoing rotation\n",
      "    if _nx.issubdtype(dt, _nx.complexfloating):\n",
      "        all_imag = (start.real == 0.) & (stop.real == 0.)\n",
      "        if _nx.any(all_imag):\n",
      "            start[all_imag] = start[all_imag].imag\n",
      "            stop[all_imag] = stop[all_imag].imag\n",
      "            out_sign[all_imag] = 1j\n",
      "    both_negative = (_nx.sign(start) == -1) & (_nx.sign(stop) == -1)\n",
      "    if _nx.any(both_negative):\n",
      "        _nx.negative(start, out=start, where=both_negative)\n",
      "        _nx.negative(stop, out=stop, where=both_negative)\n",
      "        _nx.negative(out_sign, out=out_sign, where=both_negative)\n",
      "    log_start = _nx.log10(start)\n",
      "    log_stop = _nx.log10(stop)\n",
      "    result = logspace(log_start, log_stop, num=num,\n",
      "                      endpoint=endpoint, base=10.0, dtype=dtype)\n",
      " necessary because np.exp(np.log(x)) is not necessarily equal to x.\n",
      "    if num > 0:\n",
      "        result[0] = start\n",
      "        if num > 1 and endpoint:\n",
      "            result[-1] = stop\n",
      "    result = out_sign * result\n",
      "    if axis != 0:\n",
      "        result = _nx.moveaxis(result, 0, axis)\n",
      "    return result.astype(dtype, copy=False)\n",
      "docstring: geomspace\n",
      "\n",
      "    Return numbers spaced evenly on a log scale (a geometric progression).\n",
      "\n",
      "    This is similar to `logspace`, but with endpoints specified directly.\n",
      "    Each output sample is a constant multiple of the previous.\n",
      "\n",
      "    .. versionchanged:: 1.16.0\n",
      "        Non-scalar `start` and `stop` are now supported.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    start : array_like\n",
      "        The starting value of the sequence.\n",
      "    stop : array_like\n",
      "        The final value of the sequence, unless `endpoint` is False.\n",
      "        In that case, ``num + 1`` values are spaced over the\n",
      "        interval in log-space, of which all but the last (a sequence of\n",
      "        length `num`) are returned.\n",
      "    num : integer, optional\n",
      "        Number of samples to generate.  Default is 50.\n",
      "    endpoint : boolean, optional\n",
      "        If true, `stop` is the last sample. Otherwise, it is not included.\n",
      "        Default is True.\n",
      "    dtype : dtype\n",
      "        The type of the output array.  If `dtype` is not given, the data type\n",
      "        is inferred from `start` and `stop`. The inferred dtype will never be\n",
      "        an integer; `float` is chosen even if the arguments would produce an\n",
      "        array of integers.\n",
      "    axis : int, optional\n",
      "        The axis in the result to store the samples.  Relevant only if start\n",
      "        or stop are array-like.  By default (0), the samples will be along a\n",
      "        new axis inserted at the beginning. Use -1 to get an axis at the end.\n",
      "\n",
      "        .. versionadded:: 1.16.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    samples : ndarray\n",
      "        `num` samples, equally spaced on a log scale.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    logspace : Similar to geomspace, but with endpoints specified using log\n",
      "               and base.\n",
      "    linspace : Similar to geomspace, but with arithmetic instead of geometric\n",
      "               progression.\n",
      "    arange : Similar to linspace, with the step size specified instead of the\n",
      "             number of samples.\n",
      "    :ref:`how-to-partition`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    If the inputs or dtype are complex, the output will follow a logarithmic\n",
      "    spiral in the complex plane.  (There are an infinite number of spirals\n",
      "    passing through two points; the output will follow the shortest such path.)\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.geomspace(1, 1000, num=4)\n",
      "    array([    1.,    10.,   100.,  1000.])\n",
      "    >>> np.geomspace(1, 1000, num=3, endpoint=False)\n",
      "    array([   1.,   10.,  100.])\n",
      "    >>> np.geomspace(1, 1000, num=4, endpoint=False)\n",
      "    array([   1.        ,    5.62341325,   31.6227766 ,  177.827941  ])\n",
      "    >>> np.geomspace(1, 256, num=9)\n",
      "    array([   1.,    2.,    4.,    8.,   16.,   32.,   64.,  128.,  256.])\n",
      "\n",
      "    Note that the above may not produce exact integers:\n",
      "\n",
      "    >>> np.geomspace(1, 256, num=9, dtype=int)\n",
      "    array([  1,   2,   4,   7,  16,  32,  63, 127, 256])\n",
      "    >>> np.around(np.geomspace(1, 256, num=9)).astype(int)\n",
      "    array([  1,   2,   4,   8,  16,  32,  64, 128, 256])\n",
      "\n",
      "    Negative, decreasing, and complex inputs are allowed:\n",
      "\n",
      "    >>> np.geomspace(1000, 1, num=4)\n",
      "    array([1000.,  100.,   10.,    1.])\n",
      "    >>> np.geomspace(-1000, -1, num=4)\n",
      "    array([-1000.,  -100.,   -10.,    -1.])\n",
      "    >>> np.geomspace(1j, 1000j, num=4)  # Straight line\n",
      "    array([0.   +1.j, 0.  +10.j, 0. +100.j, 0.+1000.j])\n",
      "    >>> np.geomspace(-1+0j, 1+0j, num=5)  # Circle\n",
      "    array([-1.00000000e+00+1.22464680e-16j, -7.07106781e-01+7.07106781e-01j,\n",
      "            6.12323400e-17+1.00000000e+00j,  7.07106781e-01+7.07106781e-01j,\n",
      "            1.00000000e+00+0.00000000e+00j])\n",
      "\n",
      "    Graphical illustration of `endpoint` parameter:\n",
      "\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> N = 10\n",
      "    >>> y = np.zeros(N)\n",
      "    >>> plt.semilogx(np.geomspace(1, 1000, N, endpoint=True), y + 1, 'o')\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.semilogx(np.geomspace(1, 1000, N, endpoint=False), y + 2, 'o')\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.axis([0.5, 2000, 0, 3])\n",
      "    [0.5, 2000, 0, 3]\n",
      "    >>> plt.grid(True, color='0.7', linestyle='-', which='both', axis='both')\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: iinfo.__str__\n",
      "    def __str__(self):\n",
      "        fmt = (\n",
      "            'Machine parameters for %(dtype)s\\n'\n",
      "            '---------------------------------------------------------------\\n'\n",
      "            'min = %(min)s\\n'\n",
      "            'max = %(max)s\\n'\n",
      "            '---------------------------------------------------------------\\n'\n",
      "            )\n",
      "        return fmt % {'dtype': self.dtype, 'min': self.min, 'max': self.max}\n",
      "docstring: iinfo.__str__\n",
      "String representation.\n",
      "code: atleast_1d\n",
      "@array_function_dispatch(_atleast_1d_dispatcher)\n",
      "def atleast_1d(*arys):\n",
      "    res = []\n",
      "    for ary in arys:\n",
      "        ary = asanyarray(ary)\n",
      "        if ary.ndim == 0:\n",
      "            result = ary.reshape(1)\n",
      "        else:\n",
      "            result = ary\n",
      "        res.append(result)\n",
      "    if len(res) == 1:\n",
      "        return res[0]\n",
      "    else:\n",
      "        return res\n",
      "docstring: atleast_1d\n",
      "\n",
      "    Convert inputs to arrays with at least one dimension.\n",
      "\n",
      "    Scalar inputs are converted to 1-dimensional arrays, whilst\n",
      "    higher-dimensional inputs are preserved.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arys1, arys2, ... : array_like\n",
      "        One or more input arrays.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    ret : ndarray\n",
      "        An array, or list of arrays, each with ``a.ndim >= 1``.\n",
      "        Copies are made only if necessary.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    atleast_2d, atleast_3d\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.atleast_1d(1.0)\n",
      "    array([1.])\n",
      "\n",
      "    >>> x = np.arange(9.0).reshape(3,3)\n",
      "    >>> np.atleast_1d(x)\n",
      "    array([[0., 1., 2.],\n",
      "           [3., 4., 5.],\n",
      "           [6., 7., 8.]])\n",
      "    >>> np.atleast_1d(x) is x\n",
      "    True\n",
      "\n",
      "    >>> np.atleast_1d(1, [3, 4])\n",
      "    [array([1]), array([3, 4])]\n",
      "\n",
      "    \n",
      "code: atleast_2d\n",
      "@array_function_dispatch(_atleast_2d_dispatcher)\n",
      "def atleast_2d(*arys):\n",
      "    res = []\n",
      "    for ary in arys:\n",
      "        ary = asanyarray(ary)\n",
      "        if ary.ndim == 0:\n",
      "            result = ary.reshape(1, 1)\n",
      "        elif ary.ndim == 1:\n",
      "            result = ary[_nx.newaxis, :]\n",
      "        else:\n",
      "            result = ary\n",
      "        res.append(result)\n",
      "    if len(res) == 1:\n",
      "        return res[0]\n",
      "    else:\n",
      "        return res\n",
      "docstring: atleast_2d\n",
      "\n",
      "    View inputs as arrays with at least two dimensions.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arys1, arys2, ... : array_like\n",
      "        One or more array-like sequences.  Non-array inputs are converted\n",
      "        to arrays.  Arrays that already have two or more dimensions are\n",
      "        preserved.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    res, res2, ... : ndarray\n",
      "        An array, or list of arrays, each with ``a.ndim >= 2``.\n",
      "        Copies are avoided where possible, and views with two or more\n",
      "        dimensions are returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    atleast_1d, atleast_3d\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.atleast_2d(3.0)\n",
      "    array([[3.]])\n",
      "\n",
      "    >>> x = np.arange(3.0)\n",
      "    >>> np.atleast_2d(x)\n",
      "    array([[0., 1., 2.]])\n",
      "    >>> np.atleast_2d(x).base is x\n",
      "    True\n",
      "\n",
      "    >>> np.atleast_2d(1, [1, 2], [[1, 2]])\n",
      "    [array([[1]]), array([[1, 2]]), array([[1, 2]])]\n",
      "\n",
      "    \n",
      "code: atleast_3d\n",
      "@array_function_dispatch(_atleast_3d_dispatcher)\n",
      "def atleast_3d(*arys):\n",
      "    res = []\n",
      "    for ary in arys:\n",
      "        ary = asanyarray(ary)\n",
      "        if ary.ndim == 0:\n",
      "            result = ary.reshape(1, 1, 1)\n",
      "        elif ary.ndim == 1:\n",
      "            result = ary[_nx.newaxis, :, _nx.newaxis]\n",
      "        elif ary.ndim == 2:\n",
      "            result = ary[:, :, _nx.newaxis]\n",
      "        else:\n",
      "            result = ary\n",
      "        res.append(result)\n",
      "    if len(res) == 1:\n",
      "        return res[0]\n",
      "    else:\n",
      "        return res\n",
      "docstring: atleast_3d\n",
      "\n",
      "    View inputs as arrays with at least three dimensions.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arys1, arys2, ... : array_like\n",
      "        One or more array-like sequences.  Non-array inputs are converted to\n",
      "        arrays.  Arrays that already have three or more dimensions are\n",
      "        preserved.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    res1, res2, ... : ndarray\n",
      "        An array, or list of arrays, each with ``a.ndim >= 3``.  Copies are\n",
      "        avoided where possible, and views with three or more dimensions are\n",
      "        returned.  For example, a 1-D array of shape ``(N,)`` becomes a view\n",
      "        of shape ``(1, N, 1)``, and a 2-D array of shape ``(M, N)`` becomes a\n",
      "        view of shape ``(M, N, 1)``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    atleast_1d, atleast_2d\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.atleast_3d(3.0)\n",
      "    array([[[3.]]])\n",
      "\n",
      "    >>> x = np.arange(3.0)\n",
      "    >>> np.atleast_3d(x).shape\n",
      "    (1, 3, 1)\n",
      "\n",
      "    >>> x = np.arange(12.0).reshape(4,3)\n",
      "    >>> np.atleast_3d(x).shape\n",
      "    (4, 3, 1)\n",
      "    >>> np.atleast_3d(x).base is x.base  # x is a reshape, so not base itself\n",
      "    True\n",
      "\n",
      "    >>> for arr in np.atleast_3d([1, 2], [[1, 2]], [[[1, 2]]]):\n",
      "    ...     print(arr, arr.shape) # doctest: +SKIP\n",
      "    ...\n",
      "    [[[1]\n",
      "      [2]]] (1, 2, 1)\n",
      "    [[[1]\n",
      "      [2]]] (1, 2, 1)\n",
      "    [[[1 2]]] (1, 1, 2)\n",
      "\n",
      "    \n",
      "code: block\n",
      "@array_function_dispatch(_block_dispatcher)\n",
      "def block(arrays):\n",
      "    arrays, list_ndim, result_ndim, final_size = _block_setup(arrays)\n",
      " around 256x256 was faster by straight concatenation on a\n",
      " It didn't seem to matter heavily on the dtype used.\n",
      " A 2D array using repeated concatenation requires 2 copies of the array.\n",
      " The fastest algorithm will depend on the ratio of CPU power to memory\n",
      " One can monitor the results of the benchmark\n",
      "bench_shape_base.Block2D.time_block2d\n",
      " algorithm is implemented which would likely be faster than the python\n",
      "    # version.\n",
      "    if list_ndim * final_size > (2 * 512 * 512):\n",
      "        return _block_slicing(arrays, list_ndim, result_ndim)\n",
      "    else:\n",
      "        return _block_concatenate(arrays, list_ndim, result_ndim)\n",
      "docstring: block\n",
      "\n",
      "    Assemble an nd-array from nested lists of blocks.\n",
      "\n",
      "    Blocks in the innermost lists are concatenated (see `concatenate`) along\n",
      "    the last dimension (-1), then these are concatenated along the\n",
      "    second-last dimension (-2), and so on until the outermost list is reached.\n",
      "\n",
      "    Blocks can be of any dimension, but will not be broadcasted using the normal\n",
      "    rules. Instead, leading axes of size 1 are inserted, to make ``block.ndim``\n",
      "    the same for all blocks. This is primarily useful for working with scalars,\n",
      "    and means that code like ``np.block([v, 1])`` is valid, where\n",
      "    ``v.ndim == 1``.\n",
      "\n",
      "    When the nested list is two levels deep, this allows block matrices to be\n",
      "    constructed from their components.\n",
      "\n",
      "    .. versionadded:: 1.13.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arrays : nested list of array_like or scalars (but not tuples)\n",
      "        If passed a single ndarray or scalar (a nested list of depth 0), this\n",
      "        is returned unmodified (and not copied).\n",
      "\n",
      "        Elements shapes must match along the appropriate axes (without\n",
      "        broadcasting), but leading 1s will be prepended to the shape as\n",
      "        necessary to make the dimensions match.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    block_array : ndarray\n",
      "        The array assembled from the given blocks.\n",
      "\n",
      "        The dimensionality of the output is equal to the greatest of:\n",
      "        * the dimensionality of all the inputs\n",
      "        * the depth to which the input list is nested\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        * If list depths are mismatched - for instance, ``[[a, b], c]`` is\n",
      "          illegal, and should be spelt ``[[a, b], [c]]``\n",
      "        * If lists are empty - for instance, ``[[a, b], []]``\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    vstack : Stack arrays in sequence vertically (row wise).\n",
      "    hstack : Stack arrays in sequence horizontally (column wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third axis).\n",
      "    column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      "    vsplit : Split an array into multiple sub-arrays vertically (row-wise).\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "\n",
      "    When called with only scalars, ``np.block`` is equivalent to an ndarray\n",
      "    call. So ``np.block([[1, 2], [3, 4]])`` is equivalent to\n",
      "    ``np.array([[1, 2], [3, 4]])``.\n",
      "\n",
      "    This function does not enforce that the blocks lie on a fixed grid.\n",
      "    ``np.block([[a, b], [c, d]])`` is not restricted to arrays of the form::\n",
      "\n",
      "        AAAbb\n",
      "        AAAbb\n",
      "        cccDD\n",
      "\n",
      "    But is also allowed to produce, for some ``a, b, c, d``::\n",
      "\n",
      "        AAAbb\n",
      "        AAAbb\n",
      "        cDDDD\n",
      "\n",
      "    Since concatenation happens along the last axis first, `block` is _not_\n",
      "    capable of producing the following directly::\n",
      "\n",
      "        AAAbb\n",
      "        cccbb\n",
      "        cccDD\n",
      "\n",
      "    Matlab's \"square bracket stacking\", ``[A, B, ...; p, q, ...]``, is\n",
      "    equivalent to ``np.block([[A, B, ...], [p, q, ...]])``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    The most common use of this function is to build a block matrix\n",
      "\n",
      "    >>> A = np.eye(2) * 2\n",
      "    >>> B = np.eye(3) * 3\n",
      "    >>> np.block([\n",
      "    ...     [A,               np.zeros((2, 3))],\n",
      "    ...     [np.ones((3, 2)), B               ]\n",
      "    ... ])\n",
      "    array([[2., 0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0., 0.],\n",
      "           [1., 1., 3., 0., 0.],\n",
      "           [1., 1., 0., 3., 0.],\n",
      "           [1., 1., 0., 0., 3.]])\n",
      "\n",
      "    With a list of depth 1, `block` can be used as `hstack`\n",
      "\n",
      "    >>> np.block([1, 2, 3])              # hstack([1, 2, 3])\n",
      "    array([1, 2, 3])\n",
      "\n",
      "    >>> a = np.array([1, 2, 3])\n",
      "    >>> b = np.array([4, 5, 6])\n",
      "    >>> np.block([a, b, 10])             # hstack([a, b, 10])\n",
      "    array([ 1,  2,  3,  4,  5,  6, 10])\n",
      "\n",
      "    >>> A = np.ones((2, 2), int)\n",
      "    >>> B = 2 * A\n",
      "    >>> np.block([A, B])                 # hstack([A, B])\n",
      "    array([[1, 1, 2, 2],\n",
      "           [1, 1, 2, 2]])\n",
      "\n",
      "    With a list of depth 2, `block` can be used in place of `vstack`:\n",
      "\n",
      "    >>> a = np.array([1, 2, 3])\n",
      "    >>> b = np.array([4, 5, 6])\n",
      "    >>> np.block([[a], [b]])             # vstack([a, b])\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "\n",
      "    >>> A = np.ones((2, 2), int)\n",
      "    >>> B = 2 * A\n",
      "    >>> np.block([[A], [B]])             # vstack([A, B])\n",
      "    array([[1, 1],\n",
      "           [1, 1],\n",
      "           [2, 2],\n",
      "           [2, 2]])\n",
      "\n",
      "    It can also be used in places of `atleast_1d` and `atleast_2d`\n",
      "\n",
      "    >>> a = np.array(0)\n",
      "    >>> b = np.array([1])\n",
      "    >>> np.block([a])                    # atleast_1d(a)\n",
      "    array([0])\n",
      "    >>> np.block([b])                    # atleast_1d(b)\n",
      "    array([1])\n",
      "\n",
      "    >>> np.block([[a]])                  # atleast_2d(a)\n",
      "    array([[0]])\n",
      "    >>> np.block([[b]])                  # atleast_2d(b)\n",
      "    array([[1]])\n",
      "\n",
      "\n",
      "    \n",
      "code: hstack\n",
      "@array_function_dispatch(_vhstack_dispatcher)\n",
      "def hstack(tup, *, dtype=None, casting=\"same_kind\"):\n",
      "    if not overrides.ARRAY_FUNCTION_ENABLED:\n",
      " As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\n",
      "    if arrs and arrs[0].ndim == 1:\n",
      "        return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)\n",
      "    else:\n",
      "        return _nx.concatenate(arrs, 1, dtype=dtype, casting=casting)\n",
      "docstring: hstack\n",
      "\n",
      "    Stack arrays in sequence horizontally (column wise).\n",
      "\n",
      "    This is equivalent to concatenation along the second axis, except for 1-D\n",
      "    arrays where it concatenates along the first axis. Rebuilds arrays divided\n",
      "    by `hsplit`.\n",
      "\n",
      "    This function makes most sense for arrays with up to 3 dimensions. For\n",
      "    instance, for pixel-data with a height (first axis), width (second axis),\n",
      "    and r/g/b channels (third axis). The functions `concatenate`, `stack` and\n",
      "    `block` provide more general stacking and concatenation operations.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of ndarrays\n",
      "        The arrays must have the same shape along all but the second axis,\n",
      "        except 1-D arrays which can be any length.\n",
      "\n",
      "    dtype : str or dtype\n",
      "        If provided, the destination array will have this dtype. Cannot be\n",
      "        provided together with `out`.\n",
      "\n",
      "    .. versionadded:: 1.24\n",
      "\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n",
      "\n",
      "    .. versionadded:: 1.24\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The array formed by stacking the given arrays.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    block : Assemble an nd-array from nested lists of blocks.\n",
      "    vstack : Stack arrays in sequence vertically (row wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third axis).\n",
      "    column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      "    hsplit : Split an array into multiple sub-arrays horizontally (column-wise).\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array((1,2,3))\n",
      "    >>> b = np.array((4,5,6))\n",
      "    >>> np.hstack((a,b))\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "    >>> a = np.array([[1],[2],[3]])\n",
      "    >>> b = np.array([[4],[5],[6]])\n",
      "    >>> np.hstack((a,b))\n",
      "    array([[1, 4],\n",
      "           [2, 5],\n",
      "           [3, 6]])\n",
      "\n",
      "    \n",
      "code: stack\n",
      "@array_function_dispatch(_stack_dispatcher)\n",
      "def stack(arrays, axis=0, out=None, *, dtype=None, casting=\"same_kind\"):\n",
      "    if not overrides.ARRAY_FUNCTION_ENABLED:\n",
      "        # raise warning if necessary\n",
      "        _arrays_for_stack_dispatcher(arrays, stacklevel=2)\n",
      "    arrays = [asanyarray(arr) for arr in arrays]\n",
      "    if not arrays:\n",
      "        raise ValueError('need at least one array to stack')\n",
      "    shapes = {arr.shape for arr in arrays}\n",
      "    if len(shapes) != 1:\n",
      "        raise ValueError('all input arrays must have the same shape')\n",
      "    result_ndim = arrays[0].ndim + 1\n",
      "    axis = normalize_axis_index(axis, result_ndim)\n",
      "    sl = (slice(None),) * axis + (_nx.newaxis,)\n",
      "    expanded_arrays = [arr[sl] for arr in arrays]\n",
      "    return _nx.concatenate(expanded_arrays, axis=axis, out=out,\n",
      "                           dtype=dtype, casting=casting)\n",
      "docstring: stack\n",
      "\n",
      "    Join a sequence of arrays along a new axis.\n",
      "\n",
      "    The ``axis`` parameter specifies the index of the new axis in the\n",
      "    dimensions of the result. For example, if ``axis=0`` it will be the first\n",
      "    dimension and if ``axis=-1`` it will be the last dimension.\n",
      "\n",
      "    .. versionadded:: 1.10.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arrays : sequence of array_like\n",
      "        Each array must have the same shape.\n",
      "\n",
      "    axis : int, optional\n",
      "        The axis in the result array along which the input arrays are stacked.\n",
      "\n",
      "    out : ndarray, optional\n",
      "        If provided, the destination to place the result. The shape must be\n",
      "        correct, matching that of what stack would have returned if no\n",
      "        out argument were specified.\n",
      "\n",
      "    dtype : str or dtype\n",
      "        If provided, the destination array will have this dtype. Cannot be\n",
      "        provided together with `out`.\n",
      "\n",
      "        .. versionadded:: 1.24\n",
      "\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n",
      "\n",
      "        .. versionadded:: 1.24\n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The stacked array has one more dimension than the input arrays.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    block : Assemble an nd-array from nested lists of blocks.\n",
      "    split : Split array into a list of multiple sub-arrays of equal size.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> arrays = [np.random.randn(3, 4) for _ in range(10)]\n",
      "    >>> np.stack(arrays, axis=0).shape\n",
      "    (10, 3, 4)\n",
      "\n",
      "    >>> np.stack(arrays, axis=1).shape\n",
      "    (3, 10, 4)\n",
      "\n",
      "    >>> np.stack(arrays, axis=2).shape\n",
      "    (3, 4, 10)\n",
      "\n",
      "    >>> a = np.array([1, 2, 3])\n",
      "    >>> b = np.array([4, 5, 6])\n",
      "    >>> np.stack((a, b))\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "\n",
      "    >>> np.stack((a, b), axis=-1)\n",
      "    array([[1, 4],\n",
      "           [2, 5],\n",
      "           [3, 6]])\n",
      "\n",
      "    \n",
      "code: vstack\n",
      "@array_function_dispatch(_vhstack_dispatcher)\n",
      "def vstack(tup, *, dtype=None, casting=\"same_kind\"):\n",
      "    if not overrides.ARRAY_FUNCTION_ENABLED:\n",
      "        # raise warning if necessary\n",
      "        _arrays_for_stack_dispatcher(tup, stacklevel=2)\n",
      "    arrs = atleast_2d(*tup)\n",
      "    if not isinstance(arrs, list):\n",
      "        arrs = [arrs]\n",
      "    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)\n",
      "docstring: vstack\n",
      "\n",
      "    Stack arrays in sequence vertically (row wise).\n",
      "\n",
      "    This is equivalent to concatenation along the first axis after 1-D arrays\n",
      "    of shape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n",
      "    `vsplit`.\n",
      "\n",
      "    This function makes most sense for arrays with up to 3 dimensions. For\n",
      "    instance, for pixel-data with a height (first axis), width (second axis),\n",
      "    and r/g/b channels (third axis). The functions `concatenate`, `stack` and\n",
      "    `block` provide more general stacking and concatenation operations.\n",
      "\n",
      "    ``np.row_stack`` is an alias for `vstack`. They are the same function.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of ndarrays\n",
      "        The arrays must have the same shape along all but the first axis.\n",
      "        1-D arrays must have the same length.\n",
      "\n",
      "    dtype : str or dtype\n",
      "        If provided, the destination array will have this dtype. Cannot be\n",
      "        provided together with `out`.\n",
      "\n",
      "    .. versionadded:: 1.24\n",
      "\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n",
      "\n",
      "    .. versionadded:: 1.24\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The array formed by stacking the given arrays, will be at least 2-D.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    block : Assemble an nd-array from nested lists of blocks.\n",
      "    hstack : Stack arrays in sequence horizontally (column wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third axis).\n",
      "    column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      "    vsplit : Split an array into multiple sub-arrays vertically (row-wise).\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1, 2, 3])\n",
      "    >>> b = np.array([4, 5, 6])\n",
      "    >>> np.vstack((a,b))\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "\n",
      "    >>> a = np.array([[1], [2], [3]])\n",
      "    >>> b = np.array([[4], [5], [6]])\n",
      "    >>> np.vstack((a,b))\n",
      "    array([[1],\n",
      "           [2],\n",
      "           [3],\n",
      "           [4],\n",
      "           [5],\n",
      "           [6]])\n",
      "\n",
      "    \n",
      "code: einsum\n",
      "@array_function_dispatch(_einsum_dispatcher, module='numpy')\n",
      "def einsum(*operands, out=None, optimize=False, **kwargs):\n",
      " If no optimization, run pure einsum\n",
      "    if optimize is False:\n",
      "        if specified_out:\n",
      "            kwargs['out'] = out\n",
      "        return c_einsum(*operands, **kwargs)\n",
      " repeat default values here\n",
      "    valid_einsum_kwargs = ['dtype', 'order', 'casting']\n",
      "    unknown_kwargs = [k for (k, v) in kwargs.items() if\n",
      "                      k not in valid_einsum_kwargs]\n",
      "    if len(unknown_kwargs):\n",
      "        raise TypeError(\"Did not understand the following kwargs: %s\"\n",
      "                        % unknown_kwargs)\n",
      " Handle order kwarg for output array, c_einsum allows mixed case\n",
      "    output_order = kwargs.pop('order', 'K')\n",
      "    if output_order.upper() == 'A':\n",
      "        if all(arr.flags.f_contiguous for arr in operands):\n",
      "            output_order = 'F'\n",
      "        else:\n",
      "            output_order = 'C'\n",
      " Do we need to deal with the output?\n",
      "        handle_out = specified_out and ((num + 1) == len(contraction_list))\n",
      " Checks have already been handled\n",
      "            input_str, results_index = einsum_str.split('->')\n",
      "            input_left, input_right = input_str.split(',')\n",
      "            tensor_result = input_left + input_right\n",
      "            for s in idx_rm:\n",
      "                tensor_result = tensor_result.replace(s, \"\")\n",
      " Contract!\n",
      "            new_view = tensordot(*tmp_operands, axes=(tuple(left_pos), tuple(right_pos)))\n",
      " Call einsum\n",
      "        else:\n",
      " Do the contraction\n",
      "            new_view = c_einsum(einsum_str, *tmp_operands, **kwargs)\n",
      "        # Append new items and dereference what we can\n",
      "        operands.append(new_view)\n",
      "        del tmp_operands, new_view\n",
      "    if specified_out:\n",
      "        return out\n",
      "    else:\n",
      "        return asanyarray(operands[0], order=output_order)\n",
      "docstring: einsum\n",
      "\n",
      "    einsum(subscripts, *operands, out=None, dtype=None, order='K',\n",
      "           casting='safe', optimize=False)\n",
      "\n",
      "    Evaluates the Einstein summation convention on the operands.\n",
      "\n",
      "    Using the Einstein summation convention, many common multi-dimensional,\n",
      "    linear algebraic array operations can be represented in a simple fashion.\n",
      "    In *implicit* mode `einsum` computes these values.\n",
      "\n",
      "    In *explicit* mode, `einsum` provides further flexibility to compute\n",
      "    other array operations that might not be considered classical Einstein\n",
      "    summation operations, by disabling, or forcing summation over specified\n",
      "    subscript labels.\n",
      "\n",
      "    See the notes and examples for clarification.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    subscripts : str\n",
      "        Specifies the subscripts for summation as comma separated list of\n",
      "        subscript labels. An implicit (classical Einstein summation)\n",
      "        calculation is performed unless the explicit indicator '->' is\n",
      "        included as well as subscript labels of the precise output form.\n",
      "    operands : list of array_like\n",
      "        These are the arrays for the operation.\n",
      "    out : ndarray, optional\n",
      "        If provided, the calculation is done into this array.\n",
      "    dtype : {data-type, None}, optional\n",
      "        If provided, forces the calculation to use the data type specified.\n",
      "        Note that you may have to also give a more liberal `casting`\n",
      "        parameter to allow the conversions. Default is None.\n",
      "    order : {'C', 'F', 'A', 'K'}, optional\n",
      "        Controls the memory layout of the output. 'C' means it should\n",
      "        be C contiguous. 'F' means it should be Fortran contiguous,\n",
      "        'A' means it should be 'F' if the inputs are all 'F', 'C' otherwise.\n",
      "        'K' means it should be as close to the layout as the inputs as\n",
      "        is possible, including arbitrarily permuted axes.\n",
      "        Default is 'K'.\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur.  Setting this to\n",
      "        'unsafe' is not recommended, as it can adversely affect accumulations.\n",
      "\n",
      "          * 'no' means the data types should not be cast at all.\n",
      "          * 'equiv' means only byte-order changes are allowed.\n",
      "          * 'safe' means only casts which can preserve values are allowed.\n",
      "          * 'same_kind' means only safe casts or casts within a kind,\n",
      "            like float64 to float32, are allowed.\n",
      "          * 'unsafe' means any data conversions may be done.\n",
      "\n",
      "        Default is 'safe'.\n",
      "    optimize : {False, True, 'greedy', 'optimal'}, optional\n",
      "        Controls if intermediate optimization should occur. No optimization\n",
      "        will occur if False and True will default to the 'greedy' algorithm.\n",
      "        Also accepts an explicit contraction list from the ``np.einsum_path``\n",
      "        function. See ``np.einsum_path`` for more details. Defaults to False.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        The calculation based on the Einstein summation convention.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    einsum_path, dot, inner, outer, tensordot, linalg.multi_dot\n",
      "    einops :\n",
      "        similar verbose interface is provided by\n",
      "        `einops <https://github.com/arogozhnikov/einops>`_ package to cover\n",
      "        additional operations: transpose, reshape/flatten, repeat/tile,\n",
      "        squeeze/unsqueeze and reductions.\n",
      "    opt_einsum :\n",
      "        `opt_einsum <https://optimized-einsum.readthedocs.io/en/stable/>`_\n",
      "        optimizes contraction order for einsum-like expressions\n",
      "        in backend-agnostic manner.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.6.0\n",
      "\n",
      "    The Einstein summation convention can be used to compute\n",
      "    many multi-dimensional, linear algebraic array operations. `einsum`\n",
      "    provides a succinct way of representing these.\n",
      "\n",
      "    A non-exhaustive list of these operations,\n",
      "    which can be computed by `einsum`, is shown below along with examples:\n",
      "\n",
      "    * Trace of an array, :py:func:`numpy.trace`.\n",
      "    * Return a diagonal, :py:func:`numpy.diag`.\n",
      "    * Array axis summations, :py:func:`numpy.sum`.\n",
      "    * Transpositions and permutations, :py:func:`numpy.transpose`.\n",
      "    * Matrix multiplication and dot product, :py:func:`numpy.matmul` :py:func:`numpy.dot`.\n",
      "    * Vector inner and outer products, :py:func:`numpy.inner` :py:func:`numpy.outer`.\n",
      "    * Broadcasting, element-wise and scalar multiplication, :py:func:`numpy.multiply`.\n",
      "    * Tensor contractions, :py:func:`numpy.tensordot`.\n",
      "    * Chained array operations, in efficient calculation order, :py:func:`numpy.einsum_path`.\n",
      "\n",
      "    The subscripts string is a comma-separated list of subscript labels,\n",
      "    where each label refers to a dimension of the corresponding operand.\n",
      "    Whenever a label is repeated it is summed, so ``np.einsum('i,i', a, b)``\n",
      "    is equivalent to :py:func:`np.inner(a,b) <numpy.inner>`. If a label\n",
      "    appears only once, it is not summed, so ``np.einsum('i', a)`` produces a\n",
      "    view of ``a`` with no changes. A further example ``np.einsum('ij,jk', a, b)``\n",
      "    describes traditional matrix multiplication and is equivalent to\n",
      "    :py:func:`np.matmul(a,b) <numpy.matmul>`. Repeated subscript labels in one\n",
      "    operand take the diagonal. For example, ``np.einsum('ii', a)`` is equivalent\n",
      "    to :py:func:`np.trace(a) <numpy.trace>`.\n",
      "\n",
      "    In *implicit mode*, the chosen subscripts are important\n",
      "    since the axes of the output are reordered alphabetically.  This\n",
      "    means that ``np.einsum('ij', a)`` doesn't affect a 2D array, while\n",
      "    ``np.einsum('ji', a)`` takes its transpose. Additionally,\n",
      "    ``np.einsum('ij,jk', a, b)`` returns a matrix multiplication, while,\n",
      "    ``np.einsum('ij,jh', a, b)`` returns the transpose of the\n",
      "    multiplication since subscript 'h' precedes subscript 'i'.\n",
      "\n",
      "    In *explicit mode* the output can be directly controlled by\n",
      "    specifying output subscript labels.  This requires the\n",
      "    identifier '->' as well as the list of output subscript labels.\n",
      "    This feature increases the flexibility of the function since\n",
      "    summing can be disabled or forced when required. The call\n",
      "    ``np.einsum('i->', a)`` is like :py:func:`np.sum(a, axis=-1) <numpy.sum>`,\n",
      "    and ``np.einsum('ii->i', a)`` is like :py:func:`np.diag(a) <numpy.diag>`.\n",
      "    The difference is that `einsum` does not allow broadcasting by default.\n",
      "    Additionally ``np.einsum('ij,jh->ih', a, b)`` directly specifies the\n",
      "    order of the output subscript labels and therefore returns matrix\n",
      "    multiplication, unlike the example above in implicit mode.\n",
      "\n",
      "    To enable and control broadcasting, use an ellipsis.  Default\n",
      "    NumPy-style broadcasting is done by adding an ellipsis\n",
      "    to the left of each term, like ``np.einsum('...ii->...i', a)``.\n",
      "    To take the trace along the first and last axes,\n",
      "    you can do ``np.einsum('i...i', a)``, or to do a matrix-matrix\n",
      "    product with the left-most indices instead of rightmost, one can do\n",
      "    ``np.einsum('ij...,jk...->ik...', a, b)``.\n",
      "\n",
      "    When there is only one operand, no axes are summed, and no output\n",
      "    parameter is provided, a view into the operand is returned instead\n",
      "    of a new array.  Thus, taking the diagonal as ``np.einsum('ii->i', a)``\n",
      "    produces a view (changed in version 1.10.0).\n",
      "\n",
      "    `einsum` also provides an alternative way to provide the subscripts\n",
      "    and operands as ``einsum(op0, sublist0, op1, sublist1, ..., [sublistout])``.\n",
      "    If the output shape is not provided in this format `einsum` will be\n",
      "    calculated in implicit mode, otherwise it will be performed explicitly.\n",
      "    The examples below have corresponding `einsum` calls with the two\n",
      "    parameter methods.\n",
      "\n",
      "    .. versionadded:: 1.10.0\n",
      "\n",
      "    Views returned from einsum are now writeable whenever the input array\n",
      "    is writeable. For example, ``np.einsum('ijk...->kji...', a)`` will now\n",
      "    have the same effect as :py:func:`np.swapaxes(a, 0, 2) <numpy.swapaxes>`\n",
      "    and ``np.einsum('ii->i', a)`` will return a writeable view of the diagonal\n",
      "    of a 2D array.\n",
      "\n",
      "    .. versionadded:: 1.12.0\n",
      "\n",
      "    Added the ``optimize`` argument which will optimize the contraction order\n",
      "    of an einsum expression. For a contraction with three or more operands this\n",
      "    can greatly increase the computational efficiency at the cost of a larger\n",
      "    memory footprint during computation.\n",
      "\n",
      "    Typically a 'greedy' algorithm is applied which empirical tests have shown\n",
      "    returns the optimal path in the majority of cases. In some cases 'optimal'\n",
      "    will return the superlative path through a more expensive, exhaustive search.\n",
      "    For iterative calculations it may be advisable to calculate the optimal path\n",
      "    once and reuse that path by supplying it as an argument. An example is given\n",
      "    below.\n",
      "\n",
      "    See :py:func:`numpy.einsum_path` for more details.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(25).reshape(5,5)\n",
      "    >>> b = np.arange(5)\n",
      "    >>> c = np.arange(6).reshape(2,3)\n",
      "\n",
      "    Trace of a matrix:\n",
      "\n",
      "    >>> np.einsum('ii', a)\n",
      "    60\n",
      "    >>> np.einsum(a, [0,0])\n",
      "    60\n",
      "    >>> np.trace(a)\n",
      "    60\n",
      "\n",
      "    Extract the diagonal (requires explicit form):\n",
      "\n",
      "    >>> np.einsum('ii->i', a)\n",
      "    array([ 0,  6, 12, 18, 24])\n",
      "    >>> np.einsum(a, [0,0], [0])\n",
      "    array([ 0,  6, 12, 18, 24])\n",
      "    >>> np.diag(a)\n",
      "    array([ 0,  6, 12, 18, 24])\n",
      "\n",
      "    Sum over an axis (requires explicit form):\n",
      "\n",
      "    >>> np.einsum('ij->i', a)\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    >>> np.einsum(a, [0,1], [0])\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    >>> np.sum(a, axis=1)\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "\n",
      "    For higher dimensional arrays summing a single axis can be done with ellipsis:\n",
      "\n",
      "    >>> np.einsum('...j->...', a)\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    >>> np.einsum(a, [Ellipsis,1], [Ellipsis])\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "\n",
      "    Compute a matrix transpose, or reorder any number of axes:\n",
      "\n",
      "    >>> np.einsum('ji', c)\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    >>> np.einsum('ij->ji', c)\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    >>> np.einsum(c, [1,0])\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    >>> np.transpose(c)\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "\n",
      "    Vector inner products:\n",
      "\n",
      "    >>> np.einsum('i,i', b, b)\n",
      "    30\n",
      "    >>> np.einsum(b, [0], b, [0])\n",
      "    30\n",
      "    >>> np.inner(b,b)\n",
      "    30\n",
      "\n",
      "    Matrix vector multiplication:\n",
      "\n",
      "    >>> np.einsum('ij,j', a, b)\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    >>> np.einsum(a, [0,1], b, [1])\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    >>> np.dot(a, b)\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    >>> np.einsum('...j,j', a, b)\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "\n",
      "    Broadcasting and scalar multiplication:\n",
      "\n",
      "    >>> np.einsum('..., ...', 3, c)\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    >>> np.einsum(',ij', 3, c)\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    >>> np.einsum(3, [Ellipsis], c, [Ellipsis])\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    >>> np.multiply(3, c)\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "\n",
      "    Vector outer product:\n",
      "\n",
      "    >>> np.einsum('i,j', np.arange(2)+1, b)\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [0, 2, 4, 6, 8]])\n",
      "    >>> np.einsum(np.arange(2)+1, [0], b, [1])\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [0, 2, 4, 6, 8]])\n",
      "    >>> np.outer(np.arange(2)+1, b)\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [0, 2, 4, 6, 8]])\n",
      "\n",
      "    Tensor contraction:\n",
      "\n",
      "    >>> a = np.arange(60.).reshape(3,4,5)\n",
      "    >>> b = np.arange(24.).reshape(4,3,2)\n",
      "    >>> np.einsum('ijk,jil->kl', a, b)\n",
      "    array([[4400., 4730.],\n",
      "           [4532., 4874.],\n",
      "           [4664., 5018.],\n",
      "           [4796., 5162.],\n",
      "           [4928., 5306.]])\n",
      "    >>> np.einsum(a, [0,1,2], b, [1,0,3], [2,3])\n",
      "    array([[4400., 4730.],\n",
      "           [4532., 4874.],\n",
      "           [4664., 5018.],\n",
      "           [4796., 5162.],\n",
      "           [4928., 5306.]])\n",
      "    >>> np.tensordot(a,b, axes=([1,0],[0,1]))\n",
      "    array([[4400., 4730.],\n",
      "           [4532., 4874.],\n",
      "           [4664., 5018.],\n",
      "           [4796., 5162.],\n",
      "           [4928., 5306.]])\n",
      "\n",
      "    Writeable returned arrays (since version 1.10.0):\n",
      "\n",
      "    >>> a = np.zeros((3, 3))\n",
      "    >>> np.einsum('ii->i', a)[:] = 1\n",
      "    >>> a\n",
      "    array([[1., 0., 0.],\n",
      "           [0., 1., 0.],\n",
      "           [0., 0., 1.]])\n",
      "\n",
      "    Example of ellipsis use:\n",
      "\n",
      "    >>> a = np.arange(6).reshape((3,2))\n",
      "    >>> b = np.arange(12).reshape((4,3))\n",
      "    >>> np.einsum('ki,jk->ij', a, b)\n",
      "    array([[10, 28, 46, 64],\n",
      "           [13, 40, 67, 94]])\n",
      "    >>> np.einsum('ki,...k->i...', a, b)\n",
      "    array([[10, 28, 46, 64],\n",
      "           [13, 40, 67, 94]])\n",
      "    >>> np.einsum('k...,jk', a, b)\n",
      "    array([[10, 28, 46, 64],\n",
      "           [13, 40, 67, 94]])\n",
      "\n",
      "    Chained array operations. For more complicated contractions, speed ups\n",
      "    might be achieved by repeatedly computing a 'greedy' path or pre-computing the\n",
      "    'optimal' path and repeatedly applying it, using an\n",
      "    `einsum_path` insertion (since version 1.12.0). Performance improvements can be\n",
      "    particularly significant with larger arrays:\n",
      "\n",
      "    >>> a = np.ones(64).reshape(2,4,8)\n",
      "\n",
      "    Basic `einsum`: ~1520ms  (benchmarked on 3.1GHz Intel i5.)\n",
      "\n",
      "    >>> for iteration in range(500):\n",
      "    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a)\n",
      "\n",
      "    Sub-optimal `einsum` (due to repeated path calculation time): ~330ms\n",
      "\n",
      "    >>> for iteration in range(500):\n",
      "    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal')\n",
      "\n",
      "    Greedy `einsum` (faster optimal path approximation): ~160ms\n",
      "\n",
      "    >>> for iteration in range(500):\n",
      "    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='greedy')\n",
      "\n",
      "    Optimal `einsum` (best usage pattern in some use cases): ~110ms\n",
      "\n",
      "    >>> path = np.einsum_path('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal')[0]\n",
      "    >>> for iteration in range(500):\n",
      "    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize=path)\n",
      "\n",
      "    \n",
      "code: einsum_path\n",
      "@array_function_dispatch(_einsum_path_dispatcher, module='numpy')\n",
      "def einsum_path(*operands, optimize='greedy', einsum_call=False):\n",
      " No optimization or a named path algorithm\n",
      "    if (path_type is False) or isinstance(path_type, str):\n",
      "        pass\n",
      " Path tuple with memory limit\n",
      "    elif ((len(path_type) == 2) and isinstance(path_type[0], str) and\n",
      "            isinstance(path_type[1], (int, float))):\n",
      "        memory_limit = int(path_type[1])\n",
      "        path_type = path_type[0]\n",
      "    else:\n",
      "        raise TypeError(\"Did not understand the path: %s\" % str(path_type))\n",
      " Python side parsing\n",
      "    input_subscripts, output_subscript, operands = _parse_einsum_input(operands)\n",
      " Get length of each unique dimension and ensure all dimensions are correct\n",
      "    dimension_dict = {}\n",
      "    broadcast_indices = [[] for x in range(len(input_list))]\n",
      "    for tnum, term in enumerate(input_list):\n",
      "        sh = operands[tnum].shape\n",
      "        if len(sh) != len(term):\n",
      "            raise ValueError(\"Einstein sum subscript %s does not contain the \"\n",
      "                             \"correct number of indices for operand %d.\"\n",
      "                             % (input_subscripts[tnum], tnum))\n",
      "        for cnum, char in enumerate(term):\n",
      "            dim = sh[cnum]\n",
      " For broadcasting cases we always want the largest dim size\n",
      "                if dimension_dict[char] == 1:\n",
      "                    dimension_dict[char] = dim\n",
      "                elif dim not in (1, dimension_dict[char]):\n",
      "                    raise ValueError(\"Size of label '%s' for operand %d (%d) \"\n",
      "                                     \"does not match previous terms (%d).\"\n",
      "                                     % (char, tnum, dimension_dict[char], dim))\n",
      "            else:\n",
      "                dimension_dict[char] = dim\n",
      " Compute size of each input array plus the output array\n",
      "    size_list = [_compute_size_by_dict(term, dimension_dict)\n",
      "                 for term in input_list + [output_subscript]]\n",
      "    max_size = max(size_list)\n",
      "    if memory_limit is None:\n",
      "        memory_arg = max_size\n",
      "    else:\n",
      "        memory_arg = memory_limit\n",
      " This isn't quite right, need to look into exactly how einsum does this\n",
      "    inner_product = (sum(len(x) for x in input_sets) - len(indices)) > 0\n",
      "    naive_cost = _flop_count(indices, inner_product, len(input_list), dimension_dict)\n",
      " Nothing to be optimized, leave it to einsum\n",
      "        path = [tuple(range(len(input_list)))]\n",
      "    elif path_type == \"greedy\":\n",
      "        path = _greedy_path(input_sets, output_set, dimension_dict, memory_arg)\n",
      "    elif path_type == \"optimal\":\n",
      "        path = _optimal_path(input_sets, output_set, dimension_dict, memory_arg)\n",
      "    else:\n",
      "        raise KeyError(\"Path name %s not found\", path_type)\n",
      "    cost_list, scale_list, size_list, contraction_list = [], [], [], []\n",
      " Make sure we remove inds from right to left\n",
      "        contract_inds = tuple(sorted(list(contract_inds), reverse=True))\n",
      "        contract = _find_contraction(contract_inds, input_sets, output_set)\n",
      "        out_inds, input_sets, idx_removed, idx_contract = contract\n",
      "        cost = _flop_count(idx_contract, idx_removed, len(contract_inds), dimension_dict)\n",
      "        cost_list.append(cost)\n",
      "        scale_list.append(len(idx_contract))\n",
      "        size_list.append(_compute_size_by_dict(out_inds, dimension_dict))\n",
      "        bcast = set()\n",
      "        tmp_inputs = []\n",
      "        for x in contract_inds:\n",
      "            tmp_inputs.append(input_list.pop(x))\n",
      "            bcast |= broadcast_indices.pop(x)\n",
      "        new_bcast_inds = bcast - idx_removed\n",
      " Last contraction\n",
      "        if (cnum - len(path)) == -1:\n",
      "            idx_result = output_subscript\n",
      "        else:\n",
      "            sort_result = [(dimension_dict[ind], ind) for ind in out_inds]\n",
      "            idx_result = \"\".join([x[1] for x in sorted(sort_result)])\n",
      "        input_list.append(idx_result)\n",
      "        broadcast_indices.append(new_bcast_inds)\n",
      "        einsum_str = \",\".join(tmp_inputs) + \"->\" + idx_result\n",
      "        contraction = (contract_inds, idx_removed, einsum_str, input_list[:], do_blas)\n",
      "        contraction_list.append(contraction)\n",
      "    opt_cost = sum(cost_list) + 1\n",
      "    if len(input_list) != 1:\n",
      " mistake in order to prevent from returning an intermediate value.\n",
      "        raise RuntimeError(\n",
      "            \"Invalid einsum_path is specified: {} more operands has to be \"\n",
      "            \"contracted.\".format(len(input_list) - 1))\n",
      "    if einsum_call_arg:\n",
      "        return (operands, contraction_list)\n",
      "    # Return the path along with a nice string representation\n",
      "    overall_contraction = input_subscripts + \"->\" + output_subscript\n",
      "    header = (\"scaling\", \"current\", \"remaining\")\n",
      "    speedup = naive_cost / opt_cost\n",
      "    max_i = max(size_list)\n",
      "    path_print  = \"  Complete contraction:  %s\\n\" % overall_contraction\n",
      "    path_print += \"         Naive scaling:  %d\\n\" % len(indices)\n",
      "    path_print += \"     Optimized scaling:  %d\\n\" % max(scale_list)\n",
      "    path_print += \"      Naive FLOP count:  %.3e\\n\" % naive_cost\n",
      "    path_print += \"  Optimized FLOP count:  %.3e\\n\" % opt_cost\n",
      "    path_print += \"   Theoretical speedup:  %3.3f\\n\" % speedup\n",
      "    path_print += \"  Largest intermediate:  %.3e elements\\n\" % max_i\n",
      "    path_print += \"-\" * 74 + \"\\n\"\n",
      "    path_print += \"%6s %24s %40s\\n\" % header\n",
      "    path_print += \"-\" * 74\n",
      "    for n, contraction in enumerate(contraction_list):\n",
      "        inds, idx_rm, einsum_str, remaining, blas = contraction\n",
      "        remaining_str = \",\".join(remaining) + \"->\" + output_subscript\n",
      "        path_run = (scale_list[n], einsum_str, remaining_str)\n",
      "        path_print += \"\\n%4d    %24s %40s\" % path_run\n",
      "    path = ['einsum_path'] + path\n",
      "    return (path, path_print)\n",
      "docstring: einsum_path\n",
      "\n",
      "    einsum_path(subscripts, *operands, optimize='greedy')\n",
      "\n",
      "    Evaluates the lowest cost contraction order for an einsum expression by\n",
      "    considering the creation of intermediate arrays.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    subscripts : str\n",
      "        Specifies the subscripts for summation.\n",
      "    *operands : list of array_like\n",
      "        These are the arrays for the operation.\n",
      "    optimize : {bool, list, tuple, 'greedy', 'optimal'}\n",
      "        Choose the type of path. If a tuple is provided, the second argument is\n",
      "        assumed to be the maximum intermediate size created. If only a single\n",
      "        argument is provided the largest input or output array size is used\n",
      "        as a maximum intermediate size.\n",
      "\n",
      "        * if a list is given that starts with ``einsum_path``, uses this as the\n",
      "          contraction path\n",
      "        * if False no optimization is taken\n",
      "        * if True defaults to the 'greedy' algorithm\n",
      "        * 'optimal' An algorithm that combinatorially explores all possible\n",
      "          ways of contracting the listed tensors and choosest the least costly\n",
      "          path. Scales exponentially with the number of terms in the\n",
      "          contraction.\n",
      "        * 'greedy' An algorithm that chooses the best pair contraction\n",
      "          at each step. Effectively, this algorithm searches the largest inner,\n",
      "          Hadamard, and then outer products at each step. Scales cubically with\n",
      "          the number of terms in the contraction. Equivalent to the 'optimal'\n",
      "          path for most contractions.\n",
      "\n",
      "        Default is 'greedy'.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    path : list of tuples\n",
      "        A list representation of the einsum path.\n",
      "    string_repr : str\n",
      "        A printable representation of the einsum path.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The resulting path indicates which terms of the input contraction should be\n",
      "    contracted first, the result of this contraction is then appended to the\n",
      "    end of the contraction list. This list can then be iterated over until all\n",
      "    intermediate contractions are complete.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    einsum, linalg.multi_dot\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    We can begin with a chain dot example. In this case, it is optimal to\n",
      "    contract the ``b`` and ``c`` tensors first as represented by the first\n",
      "    element of the path ``(1, 2)``. The resulting tensor is added to the end\n",
      "    of the contraction and the remaining contraction ``(0, 1)`` is then\n",
      "    completed.\n",
      "\n",
      "    >>> np.random.seed(123)\n",
      "    >>> a = np.random.rand(2, 2)\n",
      "    >>> b = np.random.rand(2, 5)\n",
      "    >>> c = np.random.rand(5, 2)\n",
      "    >>> path_info = np.einsum_path('ij,jk,kl->il', a, b, c, optimize='greedy')\n",
      "    >>> print(path_info[0])\n",
      "    ['einsum_path', (1, 2), (0, 1)]\n",
      "    >>> print(path_info[1])\n",
      "      Complete contraction:  ij,jk,kl->il # may vary\n",
      "             Naive scaling:  4\n",
      "         Optimized scaling:  3\n",
      "          Naive FLOP count:  1.600e+02\n",
      "      Optimized FLOP count:  5.600e+01\n",
      "       Theoretical speedup:  2.857\n",
      "      Largest intermediate:  4.000e+00 elements\n",
      "    -------------------------------------------------------------------------\n",
      "    scaling                  current                                remaining\n",
      "    -------------------------------------------------------------------------\n",
      "       3                   kl,jk->jl                                ij,jl->il\n",
      "       3                   jl,ij->il                                   il->il\n",
      "\n",
      "\n",
      "    A more complex index transformation example.\n",
      "\n",
      "    >>> I = np.random.rand(10, 10, 10, 10)\n",
      "    >>> C = np.random.rand(10, 10)\n",
      "    >>> path_info = np.einsum_path('ea,fb,abcd,gc,hd->efgh', C, C, I, C, C,\n",
      "    ...                            optimize='greedy')\n",
      "\n",
      "    >>> print(path_info[0])\n",
      "    ['einsum_path', (0, 2), (0, 3), (0, 2), (0, 1)]\n",
      "    >>> print(path_info[1]) \n",
      "      Complete contraction:  ea,fb,abcd,gc,hd->efgh # may vary\n",
      "             Naive scaling:  8\n",
      "         Optimized scaling:  5\n",
      "          Naive FLOP count:  8.000e+08\n",
      "      Optimized FLOP count:  8.000e+05\n",
      "       Theoretical speedup:  1000.000\n",
      "      Largest intermediate:  1.000e+04 elements\n",
      "    --------------------------------------------------------------------------\n",
      "    scaling                  current                                remaining\n",
      "    --------------------------------------------------------------------------\n",
      "       5               abcd,ea->bcde                      fb,gc,hd,bcde->efgh\n",
      "       5               bcde,fb->cdef                         gc,hd,cdef->efgh\n",
      "       5               cdef,gc->defg                            hd,defg->efgh\n",
      "       5               defg,hd->efgh                               efgh->efgh\n",
      "    \n",
      "code: iscomplexobj\n",
      "@array_function_dispatch(_is_type_dispatcher)\n",
      "def iscomplexobj(x):\n",
      "    try:\n",
      "        dtype = x.dtype\n",
      "        type_ = dtype.type\n",
      "    except AttributeError:\n",
      "        type_ = asarray(x).dtype.type\n",
      "    return issubclass(type_, _nx.complexfloating)\n",
      "docstring: iscomplexobj\n",
      "\n",
      "    Check for a complex type or an array of complex numbers.\n",
      "\n",
      "    The type of the input is checked, not the value. Even if the input\n",
      "    has an imaginary part equal to zero, `iscomplexobj` evaluates to True.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : any\n",
      "        The input can be of any type and shape.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    iscomplexobj : bool\n",
      "        The return value, True if `x` is of a complex type or has at least\n",
      "        one complex element.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    isrealobj, iscomplex\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.iscomplexobj(1)\n",
      "    False\n",
      "    >>> np.iscomplexobj(1+0j)\n",
      "    True\n",
      "    >>> np.iscomplexobj([3, 1+0j, True])\n",
      "    True\n",
      "\n",
      "    \n",
      "code: isrealobj\n",
      "@array_function_dispatch(_is_type_dispatcher)\n",
      "def isrealobj(x):\n",
      "    return not iscomplexobj(x)\n",
      "docstring: isrealobj\n",
      "\n",
      "    Return True if x is a not complex type or an array of complex numbers.\n",
      "\n",
      "    The type of the input is checked, not the value. So even if the input\n",
      "    has an imaginary part equal to zero, `isrealobj` evaluates to False\n",
      "    if the data type is complex.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : any\n",
      "        The input can be of any type and shape.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    y : bool\n",
      "        The return value, False if `x` is of a complex type.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    iscomplexobj, isreal\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The function is only meant for arrays with numerical values but it\n",
      "    accepts all other objects. Since it assumes array input, the return\n",
      "    value of other objects may be True.\n",
      "\n",
      "    >>> np.isrealobj('A string')\n",
      "    True\n",
      "    >>> np.isrealobj(False)\n",
      "    True\n",
      "    >>> np.isrealobj(None)\n",
      "    True\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.isrealobj(1)\n",
      "    True\n",
      "    >>> np.isrealobj(1+0j)\n",
      "    False\n",
      "    >>> np.isrealobj([3, 1+0j, True])\n",
      "    False\n",
      "\n",
      "    \n",
      "code: imag\n",
      "@array_function_dispatch(_imag_dispatcher)\n",
      "def imag(val):\n",
      "    try:\n",
      "        return val.imag\n",
      "    except AttributeError:\n",
      "        return asanyarray(val).imag\n",
      "docstring: imag\n",
      "\n",
      "    Return the imaginary part of the complex argument.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    val : array_like\n",
      "        Input array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray or scalar\n",
      "        The imaginary component of the complex argument. If `val` is real,\n",
      "        the type of `val` is used for the output.  If `val` has complex\n",
      "        elements, the returned type is float.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    real, angle, real_if_close\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1+2j, 3+4j, 5+6j])\n",
      "    >>> a.imag\n",
      "    array([2.,  4.,  6.])\n",
      "    >>> a.imag = np.array([8, 10, 12])\n",
      "    >>> a\n",
      "    array([1. +8.j,  3.+10.j,  5.+12.j])\n",
      "    >>> np.imag(1 + 1j)\n",
      "    1.0\n",
      "\n",
      "    \n",
      "code: iscomplex\n",
      "@array_function_dispatch(_is_type_dispatcher)\n",
      "def iscomplex(x):\n",
      "    ax = asanyarray(x)\n",
      "    if issubclass(ax.dtype.type, _nx.complexfloating):\n",
      "        return ax.imag != 0\n",
      "    res = zeros(ax.shape, bool)\n",
      "    return res[()]   # convert to scalar if needed\n",
      "docstring: iscomplex\n",
      "\n",
      "    Returns a bool array, where True if input element is complex.\n",
      "\n",
      "    What is tested is whether the input has a non-zero imaginary part, not if\n",
      "    the input type is complex.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        Input array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray of bools\n",
      "        Output array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    isreal\n",
      "    iscomplexobj : Return True if x is a complex type or an array of complex\n",
      "                   numbers.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.iscomplex([1+1j, 1+0j, 4.5, 3, 2, 2j])\n",
      "    array([ True, False, False, False, False,  True])\n",
      "\n",
      "    \n",
      "code: isreal\n",
      "@array_function_dispatch(_is_type_dispatcher)\n",
      "def isreal(x):\n",
      "    return imag(x) == 0\n",
      "docstring: isreal\n",
      "\n",
      "    Returns a bool array, where True if input element is real.\n",
      "\n",
      "    If element has complex type with zero complex part, the return value\n",
      "    for that element is True.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        Input array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray, bool\n",
      "        Boolean array of same shape as `x`.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    `isreal` may behave unexpectedly for string or object arrays (see examples)\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    iscomplex\n",
      "    isrealobj : Return True if x is not a complex type.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1+1j, 1+0j, 4.5, 3, 2, 2j], dtype=complex)\n",
      "    >>> np.isreal(a)\n",
      "    array([False,  True,  True,  True,  True, False])\n",
      "\n",
      "    The function does not work on string arrays.\n",
      "\n",
      "    >>> a = np.array([2j, \"a\"], dtype=\"U\")\n",
      "    >>> np.isreal(a)  # Warns about non-elementwise comparison\n",
      "    False\n",
      "\n",
      "    Returns True for all elements in input array of ``dtype=object`` even if\n",
      "    any of the elements is complex.\n",
      "\n",
      "    >>> a = np.array([1, \"2\", 3+4j], dtype=object)\n",
      "    >>> np.isreal(a)\n",
      "    array([ True,  True,  True])\n",
      "\n",
      "    isreal should not be used with object arrays\n",
      "\n",
      "    >>> a = np.array([1+2j, 2+1j], dtype=object)\n",
      "    >>> np.isreal(a)\n",
      "    array([ True,  True])\n",
      "\n",
      "    \n",
      "code: nan_to_num\n",
      "@array_function_dispatch(_nan_to_num_dispatcher)\n",
      "def nan_to_num(x, copy=True, nan=0.0, posinf=None, neginf=None):\n",
      "    x = _nx.array(x, subok=True, copy=copy)\n",
      "    xtype = x.dtype.type\n",
      "    isscalar = (x.ndim == 0)\n",
      "    if not issubclass(xtype, _nx.inexact):\n",
      "        return x[()] if isscalar else x\n",
      "    iscomplex = issubclass(xtype, _nx.complexfloating)\n",
      "    dest = (x.real, x.imag) if iscomplex else (x,)\n",
      "    maxf, minf = _getmaxmin(x.real.dtype)\n",
      "    if posinf is not None:\n",
      "        maxf = posinf\n",
      "    if neginf is not None:\n",
      "        minf = neginf\n",
      "    for d in dest:\n",
      "        idx_nan = isnan(d)\n",
      "        idx_posinf = isposinf(d)\n",
      "        idx_neginf = isneginf(d)\n",
      "        _nx.copyto(d, nan, where=idx_nan)\n",
      "        _nx.copyto(d, maxf, where=idx_posinf)\n",
      "        _nx.copyto(d, minf, where=idx_neginf)\n",
      "    return x[()] if isscalar else x\n",
      "docstring: nan_to_num\n",
      "\n",
      "    Replace NaN with zero and infinity with large finite numbers (default\n",
      "    behaviour) or with the numbers defined by the user using the `nan`,\n",
      "    `posinf` and/or `neginf` keywords.\n",
      "\n",
      "    If `x` is inexact, NaN is replaced by zero or by the user defined value in\n",
      "    `nan` keyword, infinity is replaced by the largest finite floating point\n",
      "    values representable by ``x.dtype`` or by the user defined value in\n",
      "    `posinf` keyword and -infinity is replaced by the most negative finite\n",
      "    floating point values representable by ``x.dtype`` or by the user defined\n",
      "    value in `neginf` keyword.\n",
      "\n",
      "    For complex dtypes, the above is applied to each of the real and\n",
      "    imaginary components of `x` separately.\n",
      "\n",
      "    If `x` is not inexact, then no replacements are made.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : scalar or array_like\n",
      "        Input data.\n",
      "    copy : bool, optional\n",
      "        Whether to create a copy of `x` (True) or to replace values\n",
      "        in-place (False). The in-place operation only occurs if\n",
      "        casting to an array does not require a copy.\n",
      "        Default is True.\n",
      "\n",
      "        .. versionadded:: 1.13\n",
      "    nan : int, float, optional\n",
      "        Value to be used to fill NaN values. If no value is passed\n",
      "        then NaN values will be replaced with 0.0.\n",
      "\n",
      "        .. versionadded:: 1.17\n",
      "    posinf : int, float, optional\n",
      "        Value to be used to fill positive infinity values. If no value is\n",
      "        passed then positive infinity values will be replaced with a very\n",
      "        large number.\n",
      "\n",
      "        .. versionadded:: 1.17\n",
      "    neginf : int, float, optional\n",
      "        Value to be used to fill negative infinity values. If no value is\n",
      "        passed then negative infinity values will be replaced with a very\n",
      "        small (or negative) number.\n",
      "\n",
      "        .. versionadded:: 1.17\n",
      "\n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        `x`, with the non-finite values replaced. If `copy` is False, this may\n",
      "        be `x` itself.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    isinf : Shows which elements are positive or negative infinity.\n",
      "    isneginf : Shows which elements are negative infinity.\n",
      "    isposinf : Shows which elements are positive infinity.\n",
      "    isnan : Shows which elements are Not a Number (NaN).\n",
      "    isfinite : Shows which elements are finite (not NaN, not infinity)\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n",
      "    (IEEE 754). This means that Not a Number is not equivalent to infinity.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.nan_to_num(np.inf)\n",
      "    1.7976931348623157e+308\n",
      "    >>> np.nan_to_num(-np.inf)\n",
      "    -1.7976931348623157e+308\n",
      "    >>> np.nan_to_num(np.nan)\n",
      "    0.0\n",
      "    >>> x = np.array([np.inf, -np.inf, np.nan, -128, 128])\n",
      "    >>> np.nan_to_num(x)\n",
      "    array([ 1.79769313e+308, -1.79769313e+308,  0.00000000e+000, # may vary\n",
      "           -1.28000000e+002,  1.28000000e+002])\n",
      "    >>> np.nan_to_num(x, nan=-9999, posinf=33333333, neginf=33333333)\n",
      "    array([ 3.3333333e+07,  3.3333333e+07, -9.9990000e+03,\n",
      "           -1.2800000e+02,  1.2800000e+02])\n",
      "    >>> y = np.array([complex(np.inf, np.nan), np.nan, complex(np.nan, np.inf)])\n",
      "    array([  1.79769313e+308,  -1.79769313e+308,   0.00000000e+000, # may vary\n",
      "         -1.28000000e+002,   1.28000000e+002])\n",
      "    >>> np.nan_to_num(y)\n",
      "    array([  1.79769313e+308 +0.00000000e+000j, # may vary\n",
      "             0.00000000e+000 +0.00000000e+000j,\n",
      "             0.00000000e+000 +1.79769313e+308j])\n",
      "    >>> np.nan_to_num(y, nan=111111, posinf=222222)\n",
      "    array([222222.+111111.j, 111111.     +0.j, 111111.+222222.j])\n",
      "    \n",
      "code: real\n",
      "@array_function_dispatch(_real_dispatcher)\n",
      "def real(val):\n",
      "    try:\n",
      "        return val.real\n",
      "    except AttributeError:\n",
      "        return asanyarray(val).real\n",
      "docstring: real\n",
      "\n",
      "    Return the real part of the complex argument.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    val : array_like\n",
      "        Input array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray or scalar\n",
      "        The real component of the complex argument. If `val` is real, the type\n",
      "        of `val` is used for the output.  If `val` has complex elements, the\n",
      "        returned type is float.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    real_if_close, imag, angle\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1+2j, 3+4j, 5+6j])\n",
      "    >>> a.real\n",
      "    array([1.,  3.,  5.])\n",
      "    >>> a.real = 9\n",
      "    >>> a\n",
      "    array([9.+2.j,  9.+4.j,  9.+6.j])\n",
      "    >>> a.real = np.array([9, 8, 7])\n",
      "    >>> a\n",
      "    array([9.+2.j,  8.+4.j,  7.+6.j])\n",
      "    >>> np.real(1 + 1j)\n",
      "    1.0\n",
      "\n",
      "    \n",
      "code: real_if_close\n",
      "@array_function_dispatch(_real_if_close_dispatcher)\n",
      "def real_if_close(a, tol=100):\n",
      "    a = asanyarray(a)\n",
      "    if not issubclass(a.dtype.type, _nx.complexfloating):\n",
      "        return a\n",
      "    if tol > 1:\n",
      "        from numpy.core import getlimits\n",
      "        f = getlimits.finfo(a.dtype.type)\n",
      "        tol = f.eps * tol\n",
      "    if _nx.all(_nx.absolute(a.imag) < tol):\n",
      "        a = a.real\n",
      "    return a\n",
      "docstring: real_if_close\n",
      "\n",
      "    If input is complex with all imaginary parts close to zero, return\n",
      "    real parts.\n",
      "\n",
      "    \"Close to zero\" is defined as `tol` * (machine epsilon of the type for\n",
      "    `a`).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    tol : float\n",
      "        Tolerance in machine epsilons for the complex part of the elements\n",
      "        in the array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        If `a` is real, the type of `a` is used for the output.  If `a`\n",
      "        has complex elements, the returned type is float.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    real, imag, angle\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Machine epsilon varies from machine to machine and between data types\n",
      "    but Python floats on most platforms have a machine epsilon equal to\n",
      "    2.2204460492503131e-16.  You can use 'np.finfo(float).eps' to print\n",
      "    out the machine epsilon for floats.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.finfo(float).eps\n",
      "    2.2204460492503131e-16 # may vary\n",
      "\n",
      "    >>> np.real_if_close([2.1 + 4e-14j, 5.2 + 3e-15j], tol=1000)\n",
      "    array([2.1, 5.2])\n",
      "    >>> np.real_if_close([2.1 + 4e-13j, 5.2 + 3e-15j], tol=1000)\n",
      "    array([2.1+4.e-13j, 5.2 + 3e-15j])\n",
      "\n",
      "    \n",
      "code: typename\n",
      "@set_module('numpy')\n",
      "def typename(char):\n",
      "    return _namefromtype[char]\n",
      "docstring: typename\n",
      "\n",
      "    Return a description for the given data type code.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    char : str\n",
      "        Data type code.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : str\n",
      "        Description of the input data type code.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    dtype, typecodes\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> typechars = ['S1', '?', 'B', 'D', 'G', 'F', 'I', 'H', 'L', 'O', 'Q',\n",
      "    ...              'S', 'U', 'V', 'b', 'd', 'g', 'f', 'i', 'h', 'l', 'q']\n",
      "    >>> for typechar in typechars:\n",
      "    ...     print(typechar, ' : ', np.typename(typechar))\n",
      "    ...\n",
      "    S1  :  character\n",
      "    ?  :  bool\n",
      "    B  :  unsigned char\n",
      "    D  :  complex double precision\n",
      "    G  :  complex long double precision\n",
      "    F  :  complex single precision\n",
      "    I  :  unsigned integer\n",
      "    H  :  unsigned short\n",
      "    L  :  unsigned long integer\n",
      "    O  :  object\n",
      "    Q  :  unsigned long long integer\n",
      "    S  :  string\n",
      "    U  :  unicode\n",
      "    V  :  void\n",
      "    b  :  signed char\n",
      "    d  :  double precision\n",
      "    g  :  long precision\n",
      "    f  :  single precision\n",
      "    i  :  integer\n",
      "    h  :  short\n",
      "    l  :  long integer\n",
      "    q  :  long long integer\n",
      "\n",
      "    \n",
      "code: asfarray\n",
      "@array_function_dispatch(_asfarray_dispatcher)\n",
      "def asfarray(a, dtype=_nx.float_):\n",
      "    if not _nx.issubdtype(dtype, _nx.inexact):\n",
      "        dtype = _nx.float_\n",
      "    return asarray(a, dtype=dtype)\n",
      "docstring: asfarray\n",
      "\n",
      "    Return an array converted to a float type.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        The input array.\n",
      "    dtype : str or dtype object, optional\n",
      "        Float type code to coerce input array `a`.  If `dtype` is one of the\n",
      "        'int' dtypes, it is replaced with float64.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The input `a` as a float ndarray.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.asfarray([2, 3])\n",
      "    array([2.,  3.])\n",
      "    >>> np.asfarray([2, 3], dtype='float')\n",
      "    array([2.,  3.])\n",
      "    >>> np.asfarray([2, 3], dtype='int8')\n",
      "    array([2.,  3.])\n",
      "\n",
      "    \n",
      "code: mintypecode\n",
      "@set_module('numpy')\n",
      "def mintypecode(typechars, typeset='GDFgdf', default='d'):\n",
      "    typecodes = ((isinstance(t, str) and t) or asarray(t).dtype.char\n",
      "                 for t in typechars)\n",
      "    intersection = set(t for t in typecodes if t in typeset)\n",
      "    if not intersection:\n",
      "        return default\n",
      "    if 'F' in intersection and 'd' in intersection:\n",
      "        return 'D'\n",
      "    return min(intersection, key=_typecodes_by_elsize.index)\n",
      "docstring: mintypecode\n",
      "\n",
      "    Return the character for the minimum-size type to which given types can\n",
      "    be safely cast.\n",
      "\n",
      "    The returned type character must represent the smallest size dtype such\n",
      "    that an array of the returned type can handle the data from an array of\n",
      "    all types in `typechars` (or if `typechars` is an array, then its\n",
      "    dtype.char).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    typechars : list of str or array_like\n",
      "        If a list of strings, each string should represent a dtype.\n",
      "        If array_like, the character representation of the array dtype is used.\n",
      "    typeset : str or list of str, optional\n",
      "        The set of characters that the returned character is chosen from.\n",
      "        The default set is 'GDFgdf'.\n",
      "    default : str, optional\n",
      "        The default character, this is returned if none of the characters in\n",
      "        `typechars` matches a character in `typeset`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    typechar : str\n",
      "        The character representing the minimum-size type that was found.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    dtype, sctype2char, maximum_sctype\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.mintypecode(['d', 'f', 'S'])\n",
      "    'd'\n",
      "    >>> x = np.array([1.1, 2-3.j])\n",
      "    >>> np.mintypecode(x)\n",
      "    'D'\n",
      "\n",
      "    >>> np.mintypecode('abceh', default='G')\n",
      "    'G'\n",
      "\n",
      "    \n",
      "code: common_type\n",
      "@array_function_dispatch(_common_type_dispatcher)\n",
      "def common_type(*arrays):\n",
      "    is_complex = False\n",
      "    precision = 0\n",
      "    for a in arrays:\n",
      "        t = a.dtype.type\n",
      "        if iscomplexobj(a):\n",
      "            is_complex = True\n",
      "        if issubclass(t, _nx.integer):\n",
      "            p = 2  # array_precision[_nx.double]\n",
      "        else:\n",
      "            p = array_precision.get(t, None)\n",
      "            if p is None:\n",
      "                raise TypeError(\"can't get common type for non-numeric array\")\n",
      "        precision = max(precision, p)\n",
      "    if is_complex:\n",
      "        return array_type[1][precision]\n",
      "    else:\n",
      "        return array_type[0][precision]\n",
      "docstring: common_type\n",
      "\n",
      "    Return a scalar type which is common to the input arrays.\n",
      "\n",
      "    The return type will always be an inexact (i.e. floating point) scalar\n",
      "    type, even if all the arrays are integer arrays. If one of the inputs is\n",
      "    an integer array, the minimum precision type that is returned is a\n",
      "    64-bit floating point dtype.\n",
      "\n",
      "    All input arrays except int64 and uint64 can be safely cast to the\n",
      "    returned dtype without loss of information.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    array1, array2, ... : ndarrays\n",
      "        Input arrays.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : data type code\n",
      "        Data type code.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    dtype, mintypecode\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.common_type(np.arange(2, dtype=np.float32))\n",
      "    <class 'numpy.float32'>\n",
      "    >>> np.common_type(np.arange(2, dtype=np.float32), np.arange(2))\n",
      "    <class 'numpy.float64'>\n",
      "    >>> np.common_type(np.arange(4), np.array([45, 6.j]), np.array([45.0]))\n",
      "    <class 'numpy.complex128'>\n",
      "\n",
      "    \n",
      "code: ravel_multi_index\n",
      "\n",
      "docstring: ravel_multi_index\n",
      "\n",
      "    ravel_multi_index(multi_index, dims, mode='raise', order='C')\n",
      "\n",
      "    Converts a tuple of index arrays into an array of flat\n",
      "    indices, applying boundary modes to the multi-index.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    multi_index : tuple of array_like\n",
      "        A tuple of integer arrays, one array for each dimension.\n",
      "    dims : tuple of ints\n",
      "        The shape of array into which the indices from ``multi_index`` apply.\n",
      "    mode : {'raise', 'wrap', 'clip'}, optional\n",
      "        Specifies how out-of-bounds indices are handled.  Can specify\n",
      "        either one mode or a tuple of modes, one mode per index.\n",
      "\n",
      "        * 'raise' -- raise an error (default)\n",
      "        * 'wrap' -- wrap around\n",
      "        * 'clip' -- clip to the range\n",
      "\n",
      "        In 'clip' mode, a negative index which would normally\n",
      "        wrap will clip to 0 instead.\n",
      "    order : {'C', 'F'}, optional\n",
      "        Determines whether the multi-index should be viewed as\n",
      "        indexing in row-major (C-style) or column-major\n",
      "        (Fortran-style) order.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    raveled_indices : ndarray\n",
      "        An array of indices into the flattened version of an array\n",
      "        of dimensions ``dims``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    unravel_index\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.6.0\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> arr = np.array([[3,6,6],[4,5,1]])\n",
      "    >>> np.ravel_multi_index(arr, (7,6))\n",
      "    array([22, 41, 37])\n",
      "    >>> np.ravel_multi_index(arr, (7,6), order='F')\n",
      "    array([31, 41, 13])\n",
      "    >>> np.ravel_multi_index(arr, (4,6), mode='clip')\n",
      "    array([22, 23, 19])\n",
      "    >>> np.ravel_multi_index(arr, (4,4), mode=('clip','wrap'))\n",
      "    array([12, 13, 13])\n",
      "\n",
      "    >>> np.ravel_multi_index((3,1,4,1), (6,7,8,9))\n",
      "    1621\n",
      "    \n",
      "code: unravel_index\n",
      "\n",
      "docstring: unravel_index\n",
      "\n",
      "    unravel_index(indices, shape, order='C')\n",
      "\n",
      "    Converts a flat index or array of flat indices into a tuple\n",
      "    of coordinate arrays.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    indices : array_like\n",
      "        An integer array whose elements are indices into the flattened\n",
      "        version of an array of dimensions ``shape``. Before version 1.6.0,\n",
      "        this function accepted just one index value.\n",
      "    shape : tuple of ints\n",
      "        The shape of the array to use for unraveling ``indices``.\n",
      "\n",
      "        .. versionchanged:: 1.16.0\n",
      "            Renamed from ``dims`` to ``shape``.\n",
      "\n",
      "    order : {'C', 'F'}, optional\n",
      "        Determines whether the indices should be viewed as indexing in\n",
      "        row-major (C-style) or column-major (Fortran-style) order.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    unraveled_coords : tuple of ndarray\n",
      "        Each array in the tuple has the same shape as the ``indices``\n",
      "        array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ravel_multi_index\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.unravel_index([22, 41, 37], (7,6))\n",
      "    (array([3, 6, 6]), array([4, 5, 1]))\n",
      "    >>> np.unravel_index([31, 41, 13], (7,6), order='F')\n",
      "    (array([3, 6, 6]), array([4, 5, 1]))\n",
      "\n",
      "    >>> np.unravel_index(1621, (6,7,8,9))\n",
      "    (3, 1, 4, 1)\n",
      "\n",
      "    \n",
      "code: ix_\n",
      "@array_function_dispatch(_ix__dispatcher)\n",
      "def ix_(*args):\n",
      "    out = []\n",
      "    nd = len(args)\n",
      "    for k, new in enumerate(args):\n",
      "        if not isinstance(new, _nx.ndarray):\n",
      "            new = asarray(new)\n",
      "            if new.size == 0:\n",
      "                # Explicitly type empty arrays to avoid float default\n",
      "                new = new.astype(_nx.intp)\n",
      "        if new.ndim != 1:\n",
      "            raise ValueError(\"Cross index must be 1 dimensional\")\n",
      "        if issubdtype(new.dtype, _nx.bool_):\n",
      "            new, = new.nonzero()\n",
      "        new = new.reshape((1,)*k + (new.size,) + (1,)*(nd-k-1))\n",
      "        out.append(new)\n",
      "    return tuple(out)\n",
      "docstring: ix_\n",
      "\n",
      "    Construct an open mesh from multiple sequences.\n",
      "\n",
      "    This function takes N 1-D sequences and returns N outputs with N\n",
      "    dimensions each, such that the shape is 1 in all but one dimension\n",
      "    and the dimension with the non-unit shape value cycles through all\n",
      "    N dimensions.\n",
      "\n",
      "    Using `ix_` one can quickly construct index arrays that will index\n",
      "    the cross product. ``a[np.ix_([1,3],[2,5])]`` returns the array\n",
      "    ``[[a[1,2] a[1,5]], [a[3,2] a[3,5]]]``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    args : 1-D sequences\n",
      "        Each sequence should be of integer or boolean type.\n",
      "        Boolean sequences will be interpreted as boolean masks for the\n",
      "        corresponding dimension (equivalent to passing in\n",
      "        ``np.nonzero(boolean_sequence)``).\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : tuple of ndarrays\n",
      "        N arrays with N dimensions each, with N the number of input\n",
      "        sequences. Together these arrays form an open mesh.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ogrid, mgrid, meshgrid\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(10).reshape(2, 5)\n",
      "    >>> a\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [5, 6, 7, 8, 9]])\n",
      "    >>> ixgrid = np.ix_([0, 1], [2, 4])\n",
      "    >>> ixgrid\n",
      "    (array([[0],\n",
      "           [1]]), array([[2, 4]]))\n",
      "    >>> ixgrid[0].shape, ixgrid[1].shape\n",
      "    ((2, 1), (1, 2))\n",
      "    >>> a[ixgrid]\n",
      "    array([[2, 4],\n",
      "           [7, 9]])\n",
      "\n",
      "    >>> ixgrid = np.ix_([True, True], [2, 4])\n",
      "    >>> a[ixgrid]\n",
      "    array([[2, 4],\n",
      "           [7, 9]])\n",
      "    >>> ixgrid = np.ix_([True, True], [False, False, True, False, True])\n",
      "    >>> a[ixgrid]\n",
      "    array([[2, 4],\n",
      "           [7, 9]])\n",
      "\n",
      "    \n",
      "code: ndenumerate.__next__\n",
      "    def __next__(self):\n",
      "        return self.iter.coords, next(self.iter)\n",
      "docstring: ndenumerate.__next__\n",
      "\n",
      "        Standard iterator method, returns the index tuple and array value.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        coords : tuple of ints\n",
      "            The indices of the current iteration.\n",
      "        val : scalar\n",
      "            The array element of the current iteration.\n",
      "\n",
      "        \n",
      "code: ndindex.__next__\n",
      "    def __next__(self):\n",
      "        next(self._it)\n",
      "        return self._it.multi_index\n",
      "docstring: ndindex.__next__\n",
      "\n",
      "        Standard iterator method, updates the index and returns the index\n",
      "        tuple.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        val : tuple of ints\n",
      "            Returns a tuple containing the indices of the current\n",
      "            iteration.\n",
      "\n",
      "        \n",
      "code: ndindex.ndincr\n",
      "    def ndincr(self):\n",
      "        # NumPy 1.20.0, 2020-09-08\n",
      "        warnings.warn(\n",
      "            \"`ndindex.ndincr()` is deprecated, use `next(ndindex)` instead\",\n",
      "            DeprecationWarning, stacklevel=2)\n",
      "        next(self)\n",
      "docstring: ndindex.ndincr\n",
      "\n",
      "        Increment the multi-dimensional index by one.\n",
      "\n",
      "        This method is for backward compatibility only: do not use.\n",
      "\n",
      "        .. deprecated:: 1.20.0\n",
      "            This method has been advised against since numpy 1.8.0, but only\n",
      "            started emitting DeprecationWarning as of this version.\n",
      "        \n",
      "code: fill_diagonal\n",
      "@array_function_dispatch(_fill_diagonal_dispatcher)\n",
      "def fill_diagonal(a, val, wrap=False):\n",
      "    if a.ndim < 2:\n",
      "        raise ValueError(\"array must be at least 2-d\")\n",
      "    end = None\n",
      "    if a.ndim == 2:\n",
      " accept rectangular ones.\n",
      "        step = a.shape[1] + 1\n",
      " For more than d=2, the strided formula is only valid for arrays with\n",
      " Write the value out into the diagonal.\n",
      "    a.flat[:end:step] = val\n",
      "docstring: fill_diagonal\n",
      "Fill the main diagonal of the given array of any dimensionality.\n",
      "\n",
      "    For an array `a` with ``a.ndim >= 2``, the diagonal is the list of\n",
      "    locations with indices ``a[i, ..., i]`` all identical. This function\n",
      "    modifies the input array in-place, it does not return a value.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array, at least 2-D.\n",
      "      Array whose diagonal is to be filled, it gets modified in-place.\n",
      "\n",
      "    val : scalar or array_like\n",
      "      Value(s) to write on the diagonal. If `val` is scalar, the value is\n",
      "      written along the diagonal. If array-like, the flattened `val` is\n",
      "      written along the diagonal, repeating if necessary to fill all\n",
      "      diagonal entries.\n",
      "\n",
      "    wrap : bool\n",
      "      For tall matrices in NumPy version up to 1.6.2, the\n",
      "      diagonal \"wrapped\" after N columns. You can have this behavior\n",
      "      with this option. This affects only tall matrices.\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    diag_indices, diag_indices_from\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "    This functionality can be obtained via `diag_indices`, but internally\n",
      "    this version uses a much faster implementation that never constructs the\n",
      "    indices and uses simple slicing.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.zeros((3, 3), int)\n",
      "    >>> np.fill_diagonal(a, 5)\n",
      "    >>> a\n",
      "    array([[5, 0, 0],\n",
      "           [0, 5, 0],\n",
      "           [0, 0, 5]])\n",
      "\n",
      "    The same function can operate on a 4-D array:\n",
      "\n",
      "    >>> a = np.zeros((3, 3, 3, 3), int)\n",
      "    >>> np.fill_diagonal(a, 4)\n",
      "\n",
      "    We only show a few blocks for clarity:\n",
      "\n",
      "    >>> a[0, 0]\n",
      "    array([[4, 0, 0],\n",
      "           [0, 0, 0],\n",
      "           [0, 0, 0]])\n",
      "    >>> a[1, 1]\n",
      "    array([[0, 0, 0],\n",
      "           [0, 4, 0],\n",
      "           [0, 0, 0]])\n",
      "    >>> a[2, 2]\n",
      "    array([[0, 0, 0],\n",
      "           [0, 0, 0],\n",
      "           [0, 0, 4]])\n",
      "\n",
      "    The wrap option affects only tall matrices:\n",
      "\n",
      "    >>> # tall matrices no wrap\n",
      "    >>> a = np.zeros((5, 3), int)\n",
      "    >>> np.fill_diagonal(a, 4)\n",
      "    >>> a\n",
      "    array([[4, 0, 0],\n",
      "           [0, 4, 0],\n",
      "           [0, 0, 4],\n",
      "           [0, 0, 0],\n",
      "           [0, 0, 0]])\n",
      "\n",
      "    >>> # tall matrices wrap\n",
      "    >>> a = np.zeros((5, 3), int)\n",
      "    >>> np.fill_diagonal(a, 4, wrap=True)\n",
      "    >>> a\n",
      "    array([[4, 0, 0],\n",
      "           [0, 4, 0],\n",
      "           [0, 0, 4],\n",
      "           [0, 0, 0],\n",
      "           [4, 0, 0]])\n",
      "\n",
      "    >>> # wide matrices\n",
      "    >>> a = np.zeros((3, 5), int)\n",
      "    >>> np.fill_diagonal(a, 4, wrap=True)\n",
      "    >>> a\n",
      "    array([[4, 0, 0, 0, 0],\n",
      "           [0, 4, 0, 0, 0],\n",
      "           [0, 0, 4, 0, 0]])\n",
      "\n",
      "    The anti-diagonal can be filled by reversing the order of elements\n",
      "    using either `numpy.flipud` or `numpy.fliplr`.\n",
      "\n",
      "    >>> a = np.zeros((3, 3), int);\n",
      "    >>> np.fill_diagonal(np.fliplr(a), [1,2,3])  # Horizontal flip\n",
      "    >>> a\n",
      "    array([[0, 0, 1],\n",
      "           [0, 2, 0],\n",
      "           [3, 0, 0]])\n",
      "    >>> np.fill_diagonal(np.flipud(a), [1,2,3])  # Vertical flip\n",
      "    >>> a\n",
      "    array([[0, 0, 3],\n",
      "           [0, 2, 0],\n",
      "           [1, 0, 0]])\n",
      "\n",
      "    Note that the order in which the diagonal is filled varies depending\n",
      "    on the flip function.\n",
      "    \n",
      "code: diag_indices\n",
      "@set_module('numpy')\n",
      "def diag_indices(n, ndim=2):\n",
      "    idx = arange(n)\n",
      "    return (idx,) * ndim\n",
      "docstring: diag_indices\n",
      "\n",
      "    Return the indices to access the main diagonal of an array.\n",
      "\n",
      "    This returns a tuple of indices that can be used to access the main\n",
      "    diagonal of an array `a` with ``a.ndim >= 2`` dimensions and shape\n",
      "    (n, n, ..., n). For ``a.ndim = 2`` this is the usual diagonal, for\n",
      "    ``a.ndim > 2`` this is the set of indices to access ``a[i, i, ..., i]``\n",
      "    for ``i = [0..n-1]``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n : int\n",
      "      The size, along each dimension, of the arrays for which the returned\n",
      "      indices can be used.\n",
      "\n",
      "    ndim : int, optional\n",
      "      The number of dimensions.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    diag_indices_from\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Create a set of indices to access the diagonal of a (4, 4) array:\n",
      "\n",
      "    >>> di = np.diag_indices(4)\n",
      "    >>> di\n",
      "    (array([0, 1, 2, 3]), array([0, 1, 2, 3]))\n",
      "    >>> a = np.arange(16).reshape(4, 4)\n",
      "    >>> a\n",
      "    array([[ 0,  1,  2,  3],\n",
      "           [ 4,  5,  6,  7],\n",
      "           [ 8,  9, 10, 11],\n",
      "           [12, 13, 14, 15]])\n",
      "    >>> a[di] = 100\n",
      "    >>> a\n",
      "    array([[100,   1,   2,   3],\n",
      "           [  4, 100,   6,   7],\n",
      "           [  8,   9, 100,  11],\n",
      "           [ 12,  13,  14, 100]])\n",
      "\n",
      "    Now, we create indices to manipulate a 3-D array:\n",
      "\n",
      "    >>> d3 = np.diag_indices(2, 3)\n",
      "    >>> d3\n",
      "    (array([0, 1]), array([0, 1]), array([0, 1]))\n",
      "\n",
      "    And use it to set the diagonal of an array of zeros to 1:\n",
      "\n",
      "    >>> a = np.zeros((2, 2, 2), dtype=int)\n",
      "    >>> a[d3] = 1\n",
      "    >>> a\n",
      "    array([[[1, 0],\n",
      "            [0, 0]],\n",
      "           [[0, 0],\n",
      "            [0, 1]]])\n",
      "\n",
      "    \n",
      "code: diag_indices_from\n",
      "@array_function_dispatch(_diag_indices_from)\n",
      "def diag_indices_from(arr):\n",
      "    if not arr.ndim >= 2:\n",
      "        raise ValueError(\"input array must be at least 2-d\")\n",
      " all dimensions equal, so we check first.\n",
      "    if not alltrue(diff(arr.shape) == 0):\n",
      "        raise ValueError(\"All dimensions of input must be of equal length\")\n",
      "    return diag_indices(arr.shape[0], arr.ndim)\n",
      "docstring: diag_indices_from\n",
      "\n",
      "    Return the indices to access the main diagonal of an n-dimensional array.\n",
      "\n",
      "    See `diag_indices` for full details.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : array, at least 2-D\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    diag_indices\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "    \n",
      "code: select\n",
      "@array_function_dispatch(_select_dispatcher)\n",
      "def select(condlist, choicelist, default=0):\n",
      " Now that the dtype is known, handle the deprecated select([], []) case\n",
      "    if len(condlist) == 0:\n",
      "        raise ValueError(\"select with an empty condition list is not possible\")\n",
      "    choicelist = [np.asarray(choice) for choice in choicelist]\n",
      "    try:\n",
      "        intermediate_dtype = np.result_type(*choicelist)\n",
      "    except TypeError as e:\n",
      "        msg = f'Choicelist elements do not have a common dtype: {e}'\n",
      "        raise TypeError(msg) from None\n",
      "    default_array = np.asarray(default)\n",
      "    choicelist.append(default_array)\n",
      " behaviour\n",
      "    try:\n",
      "        dtype = np.result_type(intermediate_dtype, default_array)\n",
      "    except TypeError as e:\n",
      "        msg = f'Choicelists and default value do not have a common dtype: {e}'\n",
      "        raise TypeError(msg) from None\n",
      " as the shape is needed for the result. Doing it separately optimizes\n",
      " If cond array is not an ndarray in boolean format or scalar bool, abort.\n",
      "    for i, cond in enumerate(condlist):\n",
      "        if cond.dtype.type is not np.bool_:\n",
      "            raise TypeError(\n",
      "                'invalid entry {} in condlist: should be boolean ndarray'.format(i))\n",
      "    if choicelist[0].ndim == 0:\n",
      " Use np.copyto to burn each choicelist array onto result, using the\n",
      " order since the first choice should take precedence.\n",
      "    choicelist = choicelist[-2::-1]\n",
      "    condlist = condlist[::-1]\n",
      "    for choice, cond in zip(choicelist, condlist):\n",
      "        np.copyto(result, choice, where=cond)\n",
      "    return result\n",
      "docstring: select\n",
      "\n",
      "    Return an array drawn from elements in choicelist, depending on conditions.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    condlist : list of bool ndarrays\n",
      "        The list of conditions which determine from which array in `choicelist`\n",
      "        the output elements are taken. When multiple conditions are satisfied,\n",
      "        the first one encountered in `condlist` is used.\n",
      "    choicelist : list of ndarrays\n",
      "        The list of arrays from which the output elements are taken. It has\n",
      "        to be of the same length as `condlist`.\n",
      "    default : scalar, optional\n",
      "        The element inserted in `output` when all conditions evaluate to False.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        The output at position m is the m-th element of the array in\n",
      "        `choicelist` where the m-th element of the corresponding array in\n",
      "        `condlist` is True.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    where : Return elements from one of two arrays depending on condition.\n",
      "    take, choose, compress, diag, diagonal\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(6)\n",
      "    >>> condlist = [x<3, x>3]\n",
      "    >>> choicelist = [x, x**2]\n",
      "    >>> np.select(condlist, choicelist, 42)\n",
      "    array([ 0,  1,  2, 42, 16, 25])\n",
      "\n",
      "    >>> condlist = [x<=4, x>3]\n",
      "    >>> choicelist = [x, x**2]\n",
      "    >>> np.select(condlist, choicelist, 55)\n",
      "    array([ 0,  1,  2,  3,  4, 25])\n",
      "\n",
      "    \n",
      "code: piecewise\n",
      "@array_function_dispatch(_piecewise_dispatcher)\n",
      "def piecewise(x, condlist, funclist, *args, **kw):\n",
      "    x = asanyarray(x)\n",
      "    n2 = len(funclist)\n",
      " compute the \"otherwise\" condition.\n",
      "        condelse = ~np.any(condlist, axis=0, keepdims=True)\n",
      "        condlist = np.concatenate([condlist, condelse], axis=0)\n",
      "        n += 1\n",
      "    elif n != n2:\n",
      "        raise ValueError(\n",
      "            \"with {} condition(s), either {} or {} functions are expected\"\n",
      "            .format(n, n, n+1)\n",
      "        )\n",
      "    y = zeros_like(x)\n",
      "    for cond, func in zip(condlist, funclist):\n",
      "        if not isinstance(func, collections.abc.Callable):\n",
      "            y[cond] = func\n",
      "        else:\n",
      "            vals = x[cond]\n",
      "            if vals.size > 0:\n",
      "                y[cond] = func(vals, *args, **kw)\n",
      "    return y\n",
      "docstring: piecewise\n",
      "\n",
      "    Evaluate a piecewise-defined function.\n",
      "\n",
      "    Given a set of conditions and corresponding functions, evaluate each\n",
      "    function on the input data wherever its condition is true.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : ndarray or scalar\n",
      "        The input domain.\n",
      "    condlist : list of bool arrays or bool scalars\n",
      "        Each boolean array corresponds to a function in `funclist`.  Wherever\n",
      "        `condlist[i]` is True, `funclist[i](x)` is used as the output value.\n",
      "\n",
      "        Each boolean array in `condlist` selects a piece of `x`,\n",
      "        and should therefore be of the same shape as `x`.\n",
      "\n",
      "        The length of `condlist` must correspond to that of `funclist`.\n",
      "        If one extra function is given, i.e. if\n",
      "        ``len(funclist) == len(condlist) + 1``, then that extra function\n",
      "        is the default value, used wherever all conditions are false.\n",
      "    funclist : list of callables, f(x,*args,**kw), or scalars\n",
      "        Each function is evaluated over `x` wherever its corresponding\n",
      "        condition is True.  It should take a 1d array as input and give an 1d\n",
      "        array or a scalar value as output.  If, instead of a callable,\n",
      "        a scalar is provided then a constant function (``lambda x: scalar``) is\n",
      "        assumed.\n",
      "    args : tuple, optional\n",
      "        Any further arguments given to `piecewise` are passed to the functions\n",
      "        upon execution, i.e., if called ``piecewise(..., ..., 1, 'a')``, then\n",
      "        each function is called as ``f(x, 1, 'a')``.\n",
      "    kw : dict, optional\n",
      "        Keyword arguments used in calling `piecewise` are passed to the\n",
      "        functions upon execution, i.e., if called\n",
      "        ``piecewise(..., ..., alpha=1)``, then each function is called as\n",
      "        ``f(x, alpha=1)``.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The output is the same shape and type as x and is found by\n",
      "        calling the functions in `funclist` on the appropriate portions of `x`,\n",
      "        as defined by the boolean arrays in `condlist`.  Portions not covered\n",
      "        by any condition have a default value of 0.\n",
      "\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    choose, select, where\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This is similar to choose or select, except that functions are\n",
      "    evaluated on elements of `x` that satisfy the corresponding condition from\n",
      "    `condlist`.\n",
      "\n",
      "    The result is::\n",
      "\n",
      "            |--\n",
      "            |funclist[0](x[condlist[0]])\n",
      "      out = |funclist[1](x[condlist[1]])\n",
      "            |...\n",
      "            |funclist[n2](x[condlist[n2]])\n",
      "            |--\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Define the sigma function, which is -1 for ``x < 0`` and +1 for ``x >= 0``.\n",
      "\n",
      "    >>> x = np.linspace(-2.5, 2.5, 6)\n",
      "    >>> np.piecewise(x, [x < 0, x >= 0], [-1, 1])\n",
      "    array([-1., -1., -1.,  1.,  1.,  1.])\n",
      "\n",
      "    Define the absolute value, which is ``-x`` for ``x <0`` and ``x`` for\n",
      "    ``x >= 0``.\n",
      "\n",
      "    >>> np.piecewise(x, [x < 0, x >= 0], [lambda x: -x, lambda x: x])\n",
      "    array([2.5,  1.5,  0.5,  0.5,  1.5,  2.5])\n",
      "\n",
      "    Apply the same function to a scalar value.\n",
      "\n",
      "    >>> y = -2\n",
      "    >>> np.piecewise(y, [y < 0, y >= 0], [lambda x: -x, lambda x: x])\n",
      "    array(2)\n",
      "\n",
      "    \n",
      "code: trim_zeros\n",
      "@array_function_dispatch(_trim_zeros)\n",
      "def trim_zeros(filt, trim='fb'):\n",
      "    first = 0\n",
      "    trim = trim.upper()\n",
      "    if 'F' in trim:\n",
      "        for i in filt:\n",
      "            if i != 0.:\n",
      "                break\n",
      "            else:\n",
      "                first = first + 1\n",
      "    last = len(filt)\n",
      "    if 'B' in trim:\n",
      "        for i in filt[::-1]:\n",
      "            if i != 0.:\n",
      "                break\n",
      "            else:\n",
      "                last = last - 1\n",
      "    return filt[first:last]\n",
      "docstring: trim_zeros\n",
      "\n",
      "    Trim the leading and/or trailing zeros from a 1-D array or sequence.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    filt : 1-D array or sequence\n",
      "        Input array.\n",
      "    trim : str, optional\n",
      "        A string with 'f' representing trim from front and 'b' to trim from\n",
      "        back. Default is 'fb', trim zeros from both front and back of the\n",
      "        array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    trimmed : 1-D array or sequence\n",
      "        The result of trimming the input. The input data type is preserved.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array((0, 0, 0, 1, 2, 3, 0, 2, 1, 0))\n",
      "    >>> np.trim_zeros(a)\n",
      "    array([1, 2, 3, 0, 2, 1])\n",
      "\n",
      "    >>> np.trim_zeros(a, 'b')\n",
      "    array([0, 0, 0, ..., 0, 2, 1])\n",
      "\n",
      "    The input data type is preserved, list/tuple in means list/tuple out.\n",
      "\n",
      "    >>> np.trim_zeros([0, 1, 2, 0])\n",
      "    [1, 2]\n",
      "\n",
      "    \n",
      "code: copy\n",
      "@array_function_dispatch(_copy_dispatcher)\n",
      "def copy(a, order='K', subok=False):\n",
      "    return array(a, order=order, subok=subok, copy=True)\n",
      "docstring: copy\n",
      "\n",
      "    Return an array copy of the given object.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    order : {'C', 'F', 'A', 'K'}, optional\n",
      "        Controls the memory layout of the copy. 'C' means C-order,\n",
      "        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n",
      "        'C' otherwise. 'K' means match the layout of `a` as closely\n",
      "        as possible. (Note that this function and :meth:`ndarray.copy` are very\n",
      "        similar, but have different default values for their order=\n",
      "        arguments.)\n",
      "    subok : bool, optional\n",
      "        If True, then sub-classes will be passed-through, otherwise the\n",
      "        returned array will be forced to be a base-class array (defaults to False).\n",
      "\n",
      "        .. versionadded:: 1.19.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    arr : ndarray\n",
      "        Array interpretation of `a`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.copy : Preferred method for creating an array copy\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This is equivalent to:\n",
      "\n",
      "    >>> np.array(a, copy=True)  #doctest: +SKIP\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Create an array x, with a reference y and a copy z:\n",
      "\n",
      "    >>> x = np.array([1, 2, 3])\n",
      "    >>> y = x\n",
      "    >>> z = np.copy(x)\n",
      "\n",
      "    Note that, when we modify x, y changes, but not z:\n",
      "\n",
      "    >>> x[0] = 10\n",
      "    >>> x[0] == y[0]\n",
      "    True\n",
      "    >>> x[0] == z[0]\n",
      "    False\n",
      "\n",
      "    Note that, np.copy clears previously set WRITEABLE=False flag.\n",
      "\n",
      "    >>> a = np.array([1, 2, 3])\n",
      "    >>> a.flags[\"WRITEABLE\"] = False\n",
      "    >>> b = np.copy(a)\n",
      "    >>> b.flags[\"WRITEABLE\"]\n",
      "    True\n",
      "    >>> b[0] = 3\n",
      "    >>> b\n",
      "    array([3, 2, 3])\n",
      "\n",
      "    Note that np.copy is a shallow copy and will not copy object\n",
      "    elements within arrays. This is mainly important for arrays\n",
      "    containing Python objects. The new array will contain the\n",
      "    same object which may lead to surprises if that object can\n",
      "    be modified (is mutable):\n",
      "\n",
      "    >>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n",
      "    >>> b = np.copy(a)\n",
      "    >>> b[2][0] = 10\n",
      "    >>> a\n",
      "    array([1, 'm', list([10, 3, 4])], dtype=object)\n",
      "\n",
      "    To ensure all elements within an ``object`` array are copied,\n",
      "    use `copy.deepcopy`:\n",
      "\n",
      "    >>> import copy\n",
      "    >>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n",
      "    >>> c = copy.deepcopy(a)\n",
      "    >>> c[2][0] = 10\n",
      "    >>> c\n",
      "    array([1, 'm', list([10, 3, 4])], dtype=object)\n",
      "    >>> a\n",
      "    array([1, 'm', list([2, 3, 4])], dtype=object)\n",
      "\n",
      "    \n",
      "code: iterable\n",
      "@set_module('numpy')\n",
      "def iterable(y):\n",
      "    try:\n",
      "        iter(y)\n",
      "    except TypeError:\n",
      "        return False\n",
      "    return True\n",
      "docstring: iterable\n",
      "\n",
      "    Check whether or not an object can be iterated over.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : object\n",
      "      Input object.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    b : bool\n",
      "      Return ``True`` if the object has an iterator method or is a\n",
      "      sequence and ``False`` otherwise.\n",
      "\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.iterable([1, 2, 3])\n",
      "    True\n",
      "    >>> np.iterable(2)\n",
      "    False\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    In most cases, the results of ``np.iterable(obj)`` are consistent with\n",
      "    ``isinstance(obj, collections.abc.Iterable)``. One notable exception is\n",
      "    the treatment of 0-dimensional arrays::\n",
      "\n",
      "        >>> from collections.abc import Iterable\n",
      "        >>> a = np.array(1.0)  # 0-dimensional numpy array\n",
      "        >>> isinstance(a, Iterable)\n",
      "        True\n",
      "        >>> np.iterable(a)\n",
      "        False\n",
      "\n",
      "    \n",
      "code: percentile\n",
      "@array_function_dispatch(_percentile_dispatcher)\n",
      "def percentile(a,\n",
      "               q,\n",
      "               axis=None,\n",
      "               out=None,\n",
      "               overwrite_input=False,\n",
      "               method=\"linear\",\n",
      "               keepdims=False,\n",
      "               *,\n",
      "               interpolation=None):\n",
      "    if interpolation is not None:\n",
      "        method = _check_interpolation_as_method(\n",
      "            method, interpolation, \"percentile\")\n",
      "    q = np.true_divide(q, 100)\n",
      "    q = asanyarray(q)  # undo any decay that the ufunc performed (see gh-13105)\n",
      "    if not _quantile_is_valid(q):\n",
      "        raise ValueError(\"Percentiles must be in the range [0, 100]\")\n",
      "    return _quantile_unchecked(\n",
      "        a, q, axis, out, overwrite_input, method, keepdims)\n",
      "docstring: percentile\n",
      "\n",
      "    Compute the q-th percentile of the data along the specified axis.\n",
      "\n",
      "    Returns the q-th percentile(s) of the array elements.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array or object that can be converted to an array.\n",
      "    q : array_like of float\n",
      "        Percentile or sequence of percentiles to compute, which must be between\n",
      "        0 and 100 inclusive.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the percentiles are computed. The\n",
      "        default is to compute the percentile(s) along a flattened\n",
      "        version of the array.\n",
      "\n",
      "        .. versionchanged:: 1.9.0\n",
      "            A tuple of axes is supported\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must\n",
      "        have the same shape and buffer length as the expected output,\n",
      "        but the type (of the output) will be cast if necessary.\n",
      "    overwrite_input : bool, optional\n",
      "        If True, then allow the input array `a` to be modified by intermediate\n",
      "        calculations, to save memory. In this case, the contents of the input\n",
      "        `a` after this function completes is undefined.\n",
      "    method : str, optional\n",
      "        This parameter specifies the method to use for estimating the\n",
      "        percentile.  There are many different methods, some unique to NumPy.\n",
      "        See the notes for explanation.  The options sorted by their R type\n",
      "        as summarized in the H&F paper [1]_ are:\n",
      "\n",
      "        1. 'inverted_cdf'\n",
      "        2. 'averaged_inverted_cdf'\n",
      "        3. 'closest_observation'\n",
      "        4. 'interpolated_inverted_cdf'\n",
      "        5. 'hazen'\n",
      "        6. 'weibull'\n",
      "        7. 'linear'  (default)\n",
      "        8. 'median_unbiased'\n",
      "        9. 'normal_unbiased'\n",
      "\n",
      "        The first three methods are discontinuous.  NumPy further defines the\n",
      "        following discontinuous variations of the default 'linear' (7.) option:\n",
      "\n",
      "        * 'lower'\n",
      "        * 'higher',\n",
      "        * 'midpoint'\n",
      "        * 'nearest'\n",
      "\n",
      "        .. versionchanged:: 1.22.0\n",
      "            This argument was previously called \"interpolation\" and only\n",
      "            offered the \"linear\" default and last four options.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left in\n",
      "        the result as dimensions with size one. With this option, the\n",
      "        result will broadcast correctly against the original array `a`.\n",
      "\n",
      "        .. versionadded:: 1.9.0\n",
      "\n",
      "    interpolation : str, optional\n",
      "        Deprecated name for the method keyword argument.\n",
      "\n",
      "        .. deprecated:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    percentile : scalar or ndarray\n",
      "        If `q` is a single percentile and `axis=None`, then the result\n",
      "        is a scalar. If multiple percentiles are given, first axis of\n",
      "        the result corresponds to the percentiles. The other axes are\n",
      "        the axes that remain after the reduction of `a`. If the input\n",
      "        contains integers or floats smaller than ``float64``, the output\n",
      "        data-type is ``float64``. Otherwise, the output data-type is the\n",
      "        same as that of the input. If `out` is specified, that array is\n",
      "        returned instead.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    mean\n",
      "    median : equivalent to ``percentile(..., 50)``\n",
      "    nanpercentile\n",
      "    quantile : equivalent to percentile, except q in the range [0, 1].\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Given a vector ``V`` of length ``n``, the q-th percentile of ``V`` is\n",
      "    the value ``q/100`` of the way from the minimum to the maximum in a\n",
      "    sorted copy of ``V``. The values and distances of the two nearest\n",
      "    neighbors as well as the `method` parameter will determine the\n",
      "    percentile if the normalized ranking does not match the location of\n",
      "    ``q`` exactly. This function is the same as the median if ``q=50``, the\n",
      "    same as the minimum if ``q=0`` and the same as the maximum if\n",
      "    ``q=100``.\n",
      "\n",
      "    The optional `method` parameter specifies the method to use when the\n",
      "    desired percentile lies between two indexes ``i`` and ``j = i + 1``.\n",
      "    In that case, we first determine ``i + g``, a virtual index that lies\n",
      "    between ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\n",
      "    fractional part of the index. The final result is, then, an interpolation\n",
      "    of ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n",
      "    ``i`` and ``j`` are modified using correction constants ``alpha`` and\n",
      "    ``beta`` whose choices depend on the ``method`` used. Finally, note that\n",
      "    since Python uses 0-based indexing, the code subtracts another 1 from the\n",
      "    index internally.\n",
      "\n",
      "    The following formula determines the virtual index ``i + g``, the location \n",
      "    of the percentile in the sorted sample:\n",
      "\n",
      "    .. math::\n",
      "        i + g = (q / 100) * ( n - alpha - beta + 1 ) + alpha\n",
      "\n",
      "    The different methods then work as follows\n",
      "\n",
      "    inverted_cdf:\n",
      "        method 1 of H&F [1]_.\n",
      "        This method gives discontinuous results:\n",
      "\n",
      "        * if g > 0 ; then take j\n",
      "        * if g = 0 ; then take i\n",
      "\n",
      "    averaged_inverted_cdf:\n",
      "        method 2 of H&F [1]_.\n",
      "        This method give discontinuous results:\n",
      "\n",
      "        * if g > 0 ; then take j\n",
      "        * if g = 0 ; then average between bounds\n",
      "\n",
      "    closest_observation:\n",
      "        method 3 of H&F [1]_.\n",
      "        This method give discontinuous results:\n",
      "\n",
      "        * if g > 0 ; then take j\n",
      "        * if g = 0 and index is odd ; then take j\n",
      "        * if g = 0 and index is even ; then take i\n",
      "\n",
      "    interpolated_inverted_cdf:\n",
      "        method 4 of H&F [1]_.\n",
      "        This method give continuous results using:\n",
      "\n",
      "        * alpha = 0\n",
      "        * beta = 1\n",
      "\n",
      "    hazen:\n",
      "        method 5 of H&F [1]_.\n",
      "        This method give continuous results using:\n",
      "\n",
      "        * alpha = 1/2\n",
      "        * beta = 1/2\n",
      "\n",
      "    weibull:\n",
      "        method 6 of H&F [1]_.\n",
      "        This method give continuous results using:\n",
      "\n",
      "        * alpha = 0\n",
      "        * beta = 0\n",
      "\n",
      "    linear:\n",
      "        method 7 of H&F [1]_.\n",
      "        This method give continuous results using:\n",
      "\n",
      "        * alpha = 1\n",
      "        * beta = 1\n",
      "\n",
      "    median_unbiased:\n",
      "        method 8 of H&F [1]_.\n",
      "        This method is probably the best method if the sample\n",
      "        distribution function is unknown (see reference).\n",
      "        This method give continuous results using:\n",
      "\n",
      "        * alpha = 1/3\n",
      "        * beta = 1/3\n",
      "\n",
      "    normal_unbiased:\n",
      "        method 9 of H&F [1]_.\n",
      "        This method is probably the best method if the sample\n",
      "        distribution function is known to be normal.\n",
      "        This method give continuous results using:\n",
      "\n",
      "        * alpha = 3/8\n",
      "        * beta = 3/8\n",
      "\n",
      "    lower:\n",
      "        NumPy method kept for backwards compatibility.\n",
      "        Takes ``i`` as the interpolation point.\n",
      "\n",
      "    higher:\n",
      "        NumPy method kept for backwards compatibility.\n",
      "        Takes ``j`` as the interpolation point.\n",
      "\n",
      "    nearest:\n",
      "        NumPy method kept for backwards compatibility.\n",
      "        Takes ``i`` or ``j``, whichever is nearest.\n",
      "\n",
      "    midpoint:\n",
      "        NumPy method kept for backwards compatibility.\n",
      "        Uses ``(i + j) / 2``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n",
      "    >>> a\n",
      "    array([[10,  7,  4],\n",
      "           [ 3,  2,  1]])\n",
      "    >>> np.percentile(a, 50)\n",
      "    3.5\n",
      "    >>> np.percentile(a, 50, axis=0)\n",
      "    array([6.5, 4.5, 2.5])\n",
      "    >>> np.percentile(a, 50, axis=1)\n",
      "    array([7.,  2.])\n",
      "    >>> np.percentile(a, 50, axis=1, keepdims=True)\n",
      "    array([[7.],\n",
      "           [2.]])\n",
      "\n",
      "    >>> m = np.percentile(a, 50, axis=0)\n",
      "    >>> out = np.zeros_like(m)\n",
      "    >>> np.percentile(a, 50, axis=0, out=out)\n",
      "    array([6.5, 4.5, 2.5])\n",
      "    >>> m\n",
      "    array([6.5, 4.5, 2.5])\n",
      "\n",
      "    >>> b = a.copy()\n",
      "    >>> np.percentile(b, 50, axis=1, overwrite_input=True)\n",
      "    array([7.,  2.])\n",
      "    >>> assert not np.all(a == b)\n",
      "\n",
      "    The different methods can be visualized graphically:\n",
      "\n",
      "    .. plot::\n",
      "\n",
      "        import matplotlib.pyplot as plt\n",
      "\n",
      "        a = np.arange(4)\n",
      "        p = np.linspace(0, 100, 6001)\n",
      "        ax = plt.gca()\n",
      "        lines = [\n",
      "            ('linear', '-', 'C0'),\n",
      "            ('inverted_cdf', ':', 'C1'),\n",
      "            # Almost the same as `inverted_cdf`:\n",
      "            ('averaged_inverted_cdf', '-.', 'C1'),\n",
      "            ('closest_observation', ':', 'C2'),\n",
      "            ('interpolated_inverted_cdf', '--', 'C1'),\n",
      "            ('hazen', '--', 'C3'),\n",
      "            ('weibull', '-.', 'C4'),\n",
      "            ('median_unbiased', '--', 'C5'),\n",
      "            ('normal_unbiased', '-.', 'C6'),\n",
      "            ]\n",
      "        for method, style, color in lines:\n",
      "            ax.plot(\n",
      "                p, np.percentile(a, p, method=method),\n",
      "                label=method, linestyle=style, color=color)\n",
      "        ax.set(\n",
      "            title='Percentiles for different methods and data: ' + str(a),\n",
      "            xlabel='Percentile',\n",
      "            ylabel='Estimated percentile value',\n",
      "            yticks=a)\n",
      "        ax.legend()\n",
      "        plt.show()\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] R. J. Hyndman and Y. Fan,\n",
      "       \"Sample quantiles in statistical packages,\"\n",
      "       The American Statistician, 50(4), pp. 361-365, 1996\n",
      "\n",
      "    \n",
      "code: diff\n",
      "@array_function_dispatch(_diff_dispatcher)\n",
      "def diff(a, n=1, axis=-1, prepend=np._NoValue, append=np._NoValue):\n",
      "    if n == 0:\n",
      "        return a\n",
      "    if n < 0:\n",
      "        raise ValueError(\n",
      "            \"order must be non-negative but got \" + repr(n))\n",
      "    a = asanyarray(a)\n",
      "    nd = a.ndim\n",
      "    if nd == 0:\n",
      "        raise ValueError(\"diff requires input that is at least one dimensional\")\n",
      "    axis = normalize_axis_index(axis, nd)\n",
      "    combined = []\n",
      "    if prepend is not np._NoValue:\n",
      "        prepend = np.asanyarray(prepend)\n",
      "        if prepend.ndim == 0:\n",
      "            shape = list(a.shape)\n",
      "            shape[axis] = 1\n",
      "            prepend = np.broadcast_to(prepend, tuple(shape))\n",
      "        combined.append(prepend)\n",
      "    combined.append(a)\n",
      "    if append is not np._NoValue:\n",
      "        append = np.asanyarray(append)\n",
      "        if append.ndim == 0:\n",
      "            shape = list(a.shape)\n",
      "            shape[axis] = 1\n",
      "            append = np.broadcast_to(append, tuple(shape))\n",
      "        combined.append(append)\n",
      "    if len(combined) > 1:\n",
      "        a = np.concatenate(combined, axis)\n",
      "    slice1 = [slice(None)] * nd\n",
      "    slice2 = [slice(None)] * nd\n",
      "    slice1[axis] = slice(1, None)\n",
      "    slice2[axis] = slice(None, -1)\n",
      "    slice1 = tuple(slice1)\n",
      "    slice2 = tuple(slice2)\n",
      "    op = not_equal if a.dtype == np.bool_ else subtract\n",
      "    for _ in range(n):\n",
      "        a = op(a[slice1], a[slice2])\n",
      "    return a\n",
      "docstring: diff\n",
      "\n",
      "    Calculate the n-th discrete difference along the given axis.\n",
      "\n",
      "    The first difference is given by ``out[i] = a[i+1] - a[i]`` along\n",
      "    the given axis, higher differences are calculated by using `diff`\n",
      "    recursively.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array\n",
      "    n : int, optional\n",
      "        The number of times values are differenced. If zero, the input\n",
      "        is returned as-is.\n",
      "    axis : int, optional\n",
      "        The axis along which the difference is taken, default is the\n",
      "        last axis.\n",
      "    prepend, append : array_like, optional\n",
      "        Values to prepend or append to `a` along axis prior to\n",
      "        performing the difference.  Scalar values are expanded to\n",
      "        arrays with length 1 in the direction of axis and the shape\n",
      "        of the input array in along all other axes.  Otherwise the\n",
      "        dimension and shape must match `a` except along axis.\n",
      "\n",
      "        .. versionadded:: 1.16.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    diff : ndarray\n",
      "        The n-th differences. The shape of the output is the same as `a`\n",
      "        except along `axis` where the dimension is smaller by `n`. The\n",
      "        type of the output is the same as the type of the difference\n",
      "        between any two elements of `a`. This is the same as the type of\n",
      "        `a` in most cases. A notable exception is `datetime64`, which\n",
      "        results in a `timedelta64` output array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    gradient, ediff1d, cumsum\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Type is preserved for boolean arrays, so the result will contain\n",
      "    `False` when consecutive elements are the same and `True` when they\n",
      "    differ.\n",
      "\n",
      "    For unsigned integer arrays, the results will also be unsigned. This\n",
      "    should not be surprising, as the result is consistent with\n",
      "    calculating the difference directly:\n",
      "\n",
      "    >>> u8_arr = np.array([1, 0], dtype=np.uint8)\n",
      "    >>> np.diff(u8_arr)\n",
      "    array([255], dtype=uint8)\n",
      "    >>> u8_arr[1,...] - u8_arr[0,...]\n",
      "    255\n",
      "\n",
      "    If this is not desirable, then the array should be cast to a larger\n",
      "    integer type first:\n",
      "\n",
      "    >>> i16_arr = u8_arr.astype(np.int16)\n",
      "    >>> np.diff(i16_arr)\n",
      "    array([-1], dtype=int16)\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([1, 2, 4, 7, 0])\n",
      "    >>> np.diff(x)\n",
      "    array([ 1,  2,  3, -7])\n",
      "    >>> np.diff(x, n=2)\n",
      "    array([  1,   1, -10])\n",
      "\n",
      "    >>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]])\n",
      "    >>> np.diff(x)\n",
      "    array([[2, 3, 4],\n",
      "           [5, 1, 2]])\n",
      "    >>> np.diff(x, axis=0)\n",
      "    array([[-1,  2,  0, -2]])\n",
      "\n",
      "    >>> x = np.arange('1066-10-13', '1066-10-16', dtype=np.datetime64)\n",
      "    >>> np.diff(x)\n",
      "    array([1, 1], dtype='timedelta64[D]')\n",
      "\n",
      "    \n",
      "code: gradient\n",
      "@array_function_dispatch(_gradient_dispatcher)\n",
      "def gradient(f, *varargs, axis=None, edge_order=1):\n",
      "    f = np.asanyarray(f)\n",
      "    N = f.ndim  # number of dimensions\n",
      "    if axis is None:\n",
      "        axes = tuple(range(N))\n",
      "    else:\n",
      "        axes = _nx.normalize_axis_tuple(axis, N)\n",
      "    len_axes = len(axes)\n",
      "    n = len(varargs)\n",
      "    if n == 0:\n",
      " single scalar for all axes\n",
      "        dx = varargs * len_axes\n",
      "    elif n == len_axes:\n",
      " Convert numpy integer types to float64 to avoid modular\n",
      " if distances are constant reduce to the scalar case\n",
      " use central differences on interior and one-sided differences on the\n",
      " create slice objects --- initially all are [:, :, ..., :]\n",
      "    slice1 = [slice(None)]*N\n",
      "    slice2 = [slice(None)]*N\n",
      "    slice3 = [slice(None)]*N\n",
      "    slice4 = [slice(None)]*N\n",
      "    otype = f.dtype\n",
      "    if otype.type is np.datetime64:\n",
      " view as timedelta to allow addition\n",
      "        f = f.view(otype)\n",
      "    elif otype.type is np.timedelta64:\n",
      "        pass\n",
      "    elif np.issubdtype(otype, np.inexact):\n",
      "        pass\n",
      "    else:\n",
      " First check if f is a numpy integer type; if so, convert f to float64\n",
      " result allocation\n",
      "        out = np.empty_like(f, dtype=otype)\n",
      " Numerical differentiation: 2nd order interior\n",
      "        slice1[axis] = slice(1, -1)\n",
      "        slice2[axis] = slice(None, -2)\n",
      "        slice3[axis] = slice(1, -1)\n",
      "        slice4[axis] = slice(2, None)\n",
      "        if uniform_spacing:\n",
      "            out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "        else:\n",
      "            dx1 = ax_dx[0:-1]\n",
      "            dx2 = ax_dx[1:]\n",
      "            a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "            b = (dx2 - dx1) / (dx1 * dx2)\n",
      "            c = dx1 / (dx2 * (dx1 + dx2))\n",
      " 1D equivalent -- out[1:-1] = a * f[:-2] + b * f[1:-1] + c * f[2:]\n",
      "            out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
      " 1D equivalent -- out[0] = (f[1] - f[0]) / (x[1] - x[0])\n",
      "            out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "            slice1[axis] = -1\n",
      "            slice2[axis] = -1\n",
      "            slice3[axis] = -2\n",
      "            dx_n = ax_dx if uniform_spacing else ax_dx[-1]\n",
      " Numerical differentiation: 2nd order edges\n",
      "        else:\n",
      "            slice1[axis] = 0\n",
      "            slice2[axis] = 0\n",
      "            slice3[axis] = 1\n",
      "            slice4[axis] = 2\n",
      "            if uniform_spacing:\n",
      "                a = -1.5 / ax_dx\n",
      "                b = 2. / ax_dx\n",
      "                c = -0.5 / ax_dx\n",
      "            else:\n",
      "                dx1 = ax_dx[0]\n",
      "                dx2 = ax_dx[1]\n",
      "                a = -(2. * dx1 + dx2)/(dx1 * (dx1 + dx2))\n",
      "                b = (dx1 + dx2) / (dx1 * dx2)\n",
      "                c = - dx1 / (dx2 * (dx1 + dx2))\n",
      " 1D equivalent -- out[-1] = a * f[-3] + b * f[-2] + c * f[-1]\n",
      "            out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
      "        outvals.append(out)\n",
      "        # reset the slice object in this dimension to \":\"\n",
      "        slice1[axis] = slice(None)\n",
      "        slice2[axis] = slice(None)\n",
      "        slice3[axis] = slice(None)\n",
      "        slice4[axis] = slice(None)\n",
      "    if len_axes == 1:\n",
      "        return outvals[0]\n",
      "    else:\n",
      "        return outvals\n",
      "docstring: gradient\n",
      "\n",
      "    Return the gradient of an N-dimensional array.\n",
      "\n",
      "    The gradient is computed using second order accurate central differences\n",
      "    in the interior points and either first or second order accurate one-sides\n",
      "    (forward or backwards) differences at the boundaries.\n",
      "    The returned gradient hence has the same shape as the input array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    f : array_like\n",
      "        An N-dimensional array containing samples of a scalar function.\n",
      "    varargs : list of scalar or array, optional\n",
      "        Spacing between f values. Default unitary spacing for all dimensions.\n",
      "        Spacing can be specified using:\n",
      "\n",
      "        1. single scalar to specify a sample distance for all dimensions.\n",
      "        2. N scalars to specify a constant sample distance for each dimension.\n",
      "           i.e. `dx`, `dy`, `dz`, ...\n",
      "        3. N arrays to specify the coordinates of the values along each\n",
      "           dimension of F. The length of the array must match the size of\n",
      "           the corresponding dimension\n",
      "        4. Any combination of N scalars/arrays with the meaning of 2. and 3.\n",
      "\n",
      "        If `axis` is given, the number of varargs must equal the number of axes.\n",
      "        Default: 1.\n",
      "\n",
      "    edge_order : {1, 2}, optional\n",
      "        Gradient is calculated using N-th order accurate differences\n",
      "        at the boundaries. Default: 1.\n",
      "\n",
      "        .. versionadded:: 1.9.1\n",
      "\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Gradient is calculated only along the given axis or axes\n",
      "        The default (axis = None) is to calculate the gradient for all the axes\n",
      "        of the input array. axis may be negative, in which case it counts from\n",
      "        the last to the first axis.\n",
      "\n",
      "        .. versionadded:: 1.11.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    gradient : ndarray or list of ndarray\n",
      "        A list of ndarrays (or a single ndarray if there is only one dimension)\n",
      "        corresponding to the derivatives of f with respect to each dimension.\n",
      "        Each derivative has the same shape as f.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> f = np.array([1, 2, 4, 7, 11, 16], dtype=float)\n",
      "    >>> np.gradient(f)\n",
      "    array([1. , 1.5, 2.5, 3.5, 4.5, 5. ])\n",
      "    >>> np.gradient(f, 2)\n",
      "    array([0.5 ,  0.75,  1.25,  1.75,  2.25,  2.5 ])\n",
      "\n",
      "    Spacing can be also specified with an array that represents the coordinates\n",
      "    of the values F along the dimensions.\n",
      "    For instance a uniform spacing:\n",
      "\n",
      "    >>> x = np.arange(f.size)\n",
      "    >>> np.gradient(f, x)\n",
      "    array([1. ,  1.5,  2.5,  3.5,  4.5,  5. ])\n",
      "\n",
      "    Or a non uniform one:\n",
      "\n",
      "    >>> x = np.array([0., 1., 1.5, 3.5, 4., 6.], dtype=float)\n",
      "    >>> np.gradient(f, x)\n",
      "    array([1. ,  3. ,  3.5,  6.7,  6.9,  2.5])\n",
      "\n",
      "    For two dimensional arrays, the return will be two arrays ordered by\n",
      "    axis. In this example the first array stands for the gradient in\n",
      "    rows and the second one in columns direction:\n",
      "\n",
      "    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float))\n",
      "    [array([[ 2.,  2., -1.],\n",
      "           [ 2.,  2., -1.]]), array([[1. , 2.5, 4. ],\n",
      "           [1. , 1. , 1. ]])]\n",
      "\n",
      "    In this example the spacing is also specified:\n",
      "    uniform for axis=0 and non uniform for axis=1\n",
      "\n",
      "    >>> dx = 2.\n",
      "    >>> y = [1., 1.5, 3.5]\n",
      "    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), dx, y)\n",
      "    [array([[ 1. ,  1. , -0.5],\n",
      "           [ 1. ,  1. , -0.5]]), array([[2. , 2. , 2. ],\n",
      "           [2. , 1.7, 0.5]])]\n",
      "\n",
      "    It is possible to specify how boundaries are treated using `edge_order`\n",
      "\n",
      "    >>> x = np.array([0, 1, 2, 3, 4])\n",
      "    >>> f = x**2\n",
      "    >>> np.gradient(f, edge_order=1)\n",
      "    array([1.,  2.,  4.,  6.,  7.])\n",
      "    >>> np.gradient(f, edge_order=2)\n",
      "    array([0., 2., 4., 6., 8.])\n",
      "\n",
      "    The `axis` keyword can be used to specify a subset of axes of which the\n",
      "    gradient is calculated\n",
      "\n",
      "    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), axis=0)\n",
      "    array([[ 2.,  2., -1.],\n",
      "           [ 2.,  2., -1.]])\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Assuming that :math:`f\\in C^{3}` (i.e., :math:`f` has at least 3 continuous\n",
      "    derivatives) and let :math:`h_{*}` be a non-homogeneous stepsize, we\n",
      "    minimize the \"consistency error\" :math:`\\eta_{i}` between the true gradient\n",
      "    and its estimate from a linear combination of the neighboring grid-points:\n",
      "\n",
      "    .. math::\n",
      "\n",
      "        \\eta_{i} = f_{i}^{\\left(1\\right)} -\n",
      "                    \\left[ \\alpha f\\left(x_{i}\\right) +\n",
      "                            \\beta f\\left(x_{i} + h_{d}\\right) +\n",
      "                            \\gamma f\\left(x_{i}-h_{s}\\right)\n",
      "                    \\right]\n",
      "\n",
      "    By substituting :math:`f(x_{i} + h_{d})` and :math:`f(x_{i} - h_{s})`\n",
      "    with their Taylor series expansion, this translates into solving\n",
      "    the following the linear system:\n",
      "\n",
      "    .. math::\n",
      "\n",
      "        \\left\\{\n",
      "            \\begin{array}{r}\n",
      "                \\alpha+\\beta+\\gamma=0 \\\\\n",
      "                \\beta h_{d}-\\gamma h_{s}=1 \\\\\n",
      "                \\beta h_{d}^{2}+\\gamma h_{s}^{2}=0\n",
      "            \\end{array}\n",
      "        \\right.\n",
      "\n",
      "    The resulting approximation of :math:`f_{i}^{(1)}` is the following:\n",
      "\n",
      "    .. math::\n",
      "\n",
      "        \\hat f_{i}^{(1)} =\n",
      "            \\frac{\n",
      "                h_{s}^{2}f\\left(x_{i} + h_{d}\\right)\n",
      "                + \\left(h_{d}^{2} - h_{s}^{2}\\right)f\\left(x_{i}\\right)\n",
      "                - h_{d}^{2}f\\left(x_{i}-h_{s}\\right)}\n",
      "                { h_{s}h_{d}\\left(h_{d} + h_{s}\\right)}\n",
      "            + \\mathcal{O}\\left(\\frac{h_{d}h_{s}^{2}\n",
      "                                + h_{s}h_{d}^{2}}{h_{d}\n",
      "                                + h_{s}}\\right)\n",
      "\n",
      "    It is worth noting that if :math:`h_{s}=h_{d}`\n",
      "    (i.e., data are evenly spaced)\n",
      "    we find the standard second order approximation:\n",
      "\n",
      "    .. math::\n",
      "\n",
      "        \\hat f_{i}^{(1)}=\n",
      "            \\frac{f\\left(x_{i+1}\\right) - f\\left(x_{i-1}\\right)}{2h}\n",
      "            + \\mathcal{O}\\left(h^{2}\\right)\n",
      "\n",
      "    With a similar procedure the forward/backward approximations used for\n",
      "    boundaries can be derived.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1]  Quarteroni A., Sacco R., Saleri F. (2007) Numerical Mathematics\n",
      "            (Texts in Applied Mathematics). New York: Springer.\n",
      "    .. [2]  Durran D. R. (1999) Numerical Methods for Wave Equations\n",
      "            in Geophysical Fluid Dynamics. New York: Springer.\n",
      "    .. [3]  Fornberg B. (1988) Generation of Finite Difference Formulas on\n",
      "            Arbitrarily Spaced Grids,\n",
      "            Mathematics of Computation 51, no. 184 : 699-706.\n",
      "            `PDF <http://www.ams.org/journals/mcom/1988-51-184/\n",
      "            S0025-5718-1988-0935077-0/S0025-5718-1988-0935077-0.pdf>`_.\n",
      "    \n",
      "code: angle\n",
      "@array_function_dispatch(_angle_dispatcher)\n",
      "def angle(z, deg=False):\n",
      "    z = asanyarray(z)\n",
      "    if issubclass(z.dtype.type, _nx.complexfloating):\n",
      "        zimag = z.imag\n",
      "        zreal = z.real\n",
      "    else:\n",
      "        zimag = 0\n",
      "        zreal = z\n",
      "    a = arctan2(zimag, zreal)\n",
      "    if deg:\n",
      "        a *= 180/pi\n",
      "    return a\n",
      "docstring: angle\n",
      "\n",
      "    Return the angle of the complex argument.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    z : array_like\n",
      "        A complex number or sequence of complex numbers.\n",
      "    deg : bool, optional\n",
      "        Return angle in degrees if True, radians if False (default).\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    angle : ndarray or scalar\n",
      "        The counterclockwise angle from the positive real axis on the complex\n",
      "        plane in the range ``(-pi, pi]``, with dtype as numpy.float64.\n",
      "\n",
      "        .. versionchanged:: 1.16.0\n",
      "            This function works on subclasses of ndarray like `ma.array`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    arctan2\n",
      "    absolute\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Although the angle of the complex number 0 is undefined, ``numpy.angle(0)``\n",
      "    returns the value 0.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.angle([1.0, 1.0j, 1+1j])               # in radians\n",
      "    array([ 0.        ,  1.57079633,  0.78539816]) # may vary\n",
      "    >>> np.angle(1+1j, deg=True)                  # in degrees\n",
      "    45.0\n",
      "\n",
      "    \n",
      "code: unwrap\n",
      "@array_function_dispatch(_unwrap_dispatcher)\n",
      "def unwrap(p, discont=None, axis=-1, *, period=2*pi):\n",
      "    r\"\"\"\n",
      "    Unwrap by taking the complement of large deltas with respect to the period.\n",
      "    This unwraps a signal `p` by changing elements which have an absolute\n",
      "    difference from their predecessor of more than ``max(discont, period/2)``\n",
      "    to their `period`-complementary values.\n",
      "    For the default case where `period` is :math:`2\\pi` and `discont` is\n",
      "    :math:`\\pi`, this unwraps a radian phase `p` such that adjacent differences\n",
      "    are never greater than :math:`\\pi` by adding :math:`2k\\pi` for some\n",
      "    integer :math:`k`.\n",
      "    Parameters\n",
      "    ----------\n",
      "    p : array_like\n",
      "        Input array.\n",
      "    discont : float, optional\n",
      "        Maximum discontinuity between values, default is ``period/2``.\n",
      "        Values below ``period/2`` are treated as if they were ``period/2``.\n",
      "        To have an effect different from the default, `discont` should be\n",
      "        larger than ``period/2``.\n",
      "    axis : int, optional\n",
      "        Axis along which unwrap will operate, default is the last axis.\n",
      "    period : float, optional\n",
      "        Size of the range over which the input wraps. By default, it is\n",
      "        ``2 pi``.\n",
      "        .. versionadded:: 1.21.0\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Output array.\n",
      "    See Also\n",
      "    --------\n",
      "    rad2deg, deg2rad\n",
      "    Notes\n",
      "    -----\n",
      "    If the discontinuity in `p` is smaller than ``period/2``,\n",
      "    but larger than `discont`, no unwrapping is done because taking\n",
      "    the complement would only make the discontinuity larger.\n",
      "    Examples\n",
      "    --------\n",
      "    >>> phase = np.linspace(0, np.pi, num=5)\n",
      "    >>> phase[3:] += np.pi\n",
      "    >>> phase\n",
      "    array([ 0.        ,  0.78539816,  1.57079633,  5.49778714,  6.28318531]) # may vary\n",
      "    >>> np.unwrap(phase)\n",
      "    array([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ]) # may vary\n",
      "    >>> np.unwrap([0, 1, 2, -1, 0], period=4)\n",
      "    array([0, 1, 2, 3, 4])\n",
      "    >>> np.unwrap([ 1, 2, 3, 4, 5, 6, 1, 2, 3], period=6)\n",
      "    array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "    >>> np.unwrap([2, 3, 4, 5, 2, 3, 4, 5], period=4)\n",
      "    array([2, 3, 4, 5, 6, 7, 8, 9])\n",
      "    >>> phase_deg = np.mod(np.linspace(0 ,720, 19), 360) - 180\n",
      "    >>> np.unwrap(phase_deg, period=360)\n",
      "    array([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n",
      "            180.,  220.,  260.,  300.,  340.,  380.,  420.,  460.,  500.,\n",
      "            540.])\n",
      "    \"\"\"\n",
      "    p = asarray(p)\n",
      "    nd = p.ndim\n",
      "    dd = diff(p, axis=axis)\n",
      "    if discont is None:\n",
      "        discont = period/2\n",
      "    slice1 = [slice(None, None)]*nd     # full slices\n",
      "    slice1[axis] = slice(1, None)\n",
      "    slice1 = tuple(slice1)\n",
      "    dtype = np.result_type(dd, period)\n",
      "    if _nx.issubdtype(dtype, _nx.integer):\n",
      "        interval_high, rem = divmod(period, 2)\n",
      "        boundary_ambiguous = rem == 0\n",
      "    else:\n",
      "        interval_high = period / 2\n",
      "        boundary_ambiguous = True\n",
      "    interval_low = -interval_high\n",
      "    ddmod = mod(dd - interval_low, period) + interval_low\n",
      "    if boundary_ambiguous:\n",
      " `ddmod[mask] == -period/2`. correct these such that\n",
      "        # `ddmod[mask] == sign(dd[mask])*period/2`.\n",
      "        _nx.copyto(ddmod, interval_high,\n",
      "                   where=(ddmod == interval_low) & (dd > 0))\n",
      "    ph_correct = ddmod - dd\n",
      "    _nx.copyto(ph_correct, 0, where=abs(dd) < discont)\n",
      "    up = array(p, copy=True, dtype=dtype)\n",
      "    up[slice1] = p[slice1] + ph_correct.cumsum(axis)\n",
      "    return up\n",
      "docstring: unwrap\n",
      "\n",
      "    Unwrap by taking the complement of large deltas with respect to the period.\n",
      "\n",
      "    This unwraps a signal `p` by changing elements which have an absolute\n",
      "    difference from their predecessor of more than ``max(discont, period/2)``\n",
      "    to their `period`-complementary values.\n",
      "\n",
      "    For the default case where `period` is :math:`2\\pi` and `discont` is\n",
      "    :math:`\\pi`, this unwraps a radian phase `p` such that adjacent differences\n",
      "    are never greater than :math:`\\pi` by adding :math:`2k\\pi` for some\n",
      "    integer :math:`k`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    p : array_like\n",
      "        Input array.\n",
      "    discont : float, optional\n",
      "        Maximum discontinuity between values, default is ``period/2``.\n",
      "        Values below ``period/2`` are treated as if they were ``period/2``.\n",
      "        To have an effect different from the default, `discont` should be\n",
      "        larger than ``period/2``.\n",
      "    axis : int, optional\n",
      "        Axis along which unwrap will operate, default is the last axis.\n",
      "    period : float, optional\n",
      "        Size of the range over which the input wraps. By default, it is\n",
      "        ``2 pi``.\n",
      "\n",
      "        .. versionadded:: 1.21.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Output array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    rad2deg, deg2rad\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    If the discontinuity in `p` is smaller than ``period/2``,\n",
      "    but larger than `discont`, no unwrapping is done because taking\n",
      "    the complement would only make the discontinuity larger.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> phase = np.linspace(0, np.pi, num=5)\n",
      "    >>> phase[3:] += np.pi\n",
      "    >>> phase\n",
      "    array([ 0.        ,  0.78539816,  1.57079633,  5.49778714,  6.28318531]) # may vary\n",
      "    >>> np.unwrap(phase)\n",
      "    array([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ]) # may vary\n",
      "    >>> np.unwrap([0, 1, 2, -1, 0], period=4)\n",
      "    array([0, 1, 2, 3, 4])\n",
      "    >>> np.unwrap([ 1, 2, 3, 4, 5, 6, 1, 2, 3], period=6)\n",
      "    array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "    >>> np.unwrap([2, 3, 4, 5, 2, 3, 4, 5], period=4)\n",
      "    array([2, 3, 4, 5, 6, 7, 8, 9])\n",
      "    >>> phase_deg = np.mod(np.linspace(0 ,720, 19), 360) - 180\n",
      "    >>> np.unwrap(phase_deg, period=360)\n",
      "    array([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n",
      "            180.,  220.,  260.,  300.,  340.,  380.,  420.,  460.,  500.,\n",
      "            540.])\n",
      "    \n",
      "code: sort_complex\n",
      "@array_function_dispatch(_sort_complex)\n",
      "def sort_complex(a):\n",
      "    b = array(a, copy=True)\n",
      "    b.sort()\n",
      "    if not issubclass(b.dtype.type, _nx.complexfloating):\n",
      "        if b.dtype.char in 'bhBH':\n",
      "            return b.astype('F')\n",
      "        elif b.dtype.char == 'g':\n",
      "            return b.astype('G')\n",
      "        else:\n",
      "            return b.astype('D')\n",
      "    else:\n",
      "        return b\n",
      "docstring: sort_complex\n",
      "\n",
      "    Sort a complex array using the real part first, then the imaginary part.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : complex ndarray\n",
      "        Always returns a sorted complex array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.sort_complex([5, 3, 6, 2, 1])\n",
      "    array([1.+0.j, 2.+0.j, 3.+0.j, 5.+0.j, 6.+0.j])\n",
      "\n",
      "    >>> np.sort_complex([1 + 2j, 2 - 1j, 3 - 2j, 3 - 3j, 3 + 5j])\n",
      "    array([1.+2.j,  2.-1.j,  3.-3.j,  3.-2.j,  3.+5.j])\n",
      "\n",
      "    \n",
      "code: disp\n",
      "def disp(mesg, device=None, linefeed=True):\n",
      "    if device is None:\n",
      "        device = sys.stdout\n",
      "    if linefeed:\n",
      "        device.write('%s\\n' % mesg)\n",
      "    else:\n",
      "        device.write('%s' % mesg)\n",
      "    device.flush()\n",
      "    return\n",
      "docstring: disp\n",
      "\n",
      "    Display a message on a device.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    mesg : str\n",
      "        Message to display.\n",
      "    device : object\n",
      "        Device to write message. If None, defaults to ``sys.stdout`` which is\n",
      "        very similar to ``print``. `device` needs to have ``write()`` and\n",
      "        ``flush()`` methods.\n",
      "    linefeed : bool, optional\n",
      "        Option whether to print a line feed or not. Defaults to True.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    AttributeError\n",
      "        If `device` does not have a ``write()`` or ``flush()`` method.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Besides ``sys.stdout``, a file-like object can also be used as it has\n",
      "    both required methods:\n",
      "\n",
      "    >>> from io import StringIO\n",
      "    >>> buf = StringIO()\n",
      "    >>> np.disp(u'\"Display\" in a file', device=buf)\n",
      "    >>> buf.getvalue()\n",
      "    '\"Display\" in a file\\n'\n",
      "\n",
      "    \n",
      "code: flip\n",
      "@array_function_dispatch(_flip_dispatcher)\n",
      "def flip(m, axis=None):\n",
      "    if not hasattr(m, 'ndim'):\n",
      "        m = asarray(m)\n",
      "    if axis is None:\n",
      "        indexer = (np.s_[::-1],) * m.ndim\n",
      "    else:\n",
      "        axis = _nx.normalize_axis_tuple(axis, m.ndim)\n",
      "        indexer = [np.s_[:]] * m.ndim\n",
      "        for ax in axis:\n",
      "            indexer[ax] = np.s_[::-1]\n",
      "        indexer = tuple(indexer)\n",
      "    return m[indexer]\n",
      "docstring: flip\n",
      "\n",
      "    Reverse the order of elements in an array along the given axis.\n",
      "\n",
      "    The shape of the array is preserved, but the elements are reordered.\n",
      "\n",
      "    .. versionadded:: 1.12.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    m : array_like\n",
      "        Input array.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "         Axis or axes along which to flip over. The default,\n",
      "         axis=None, will flip over all of the axes of the input array.\n",
      "         If axis is negative it counts from the last to the first axis.\n",
      "\n",
      "         If axis is a tuple of ints, flipping is performed on all of the axes\n",
      "         specified in the tuple.\n",
      "\n",
      "         .. versionchanged:: 1.15.0\n",
      "            None and tuples of axes are supported\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : array_like\n",
      "        A view of `m` with the entries of axis reversed.  Since a view is\n",
      "        returned, this operation is done in constant time.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    flipud : Flip an array vertically (axis=0).\n",
      "    fliplr : Flip an array horizontally (axis=1).\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    flip(m, 0) is equivalent to flipud(m).\n",
      "\n",
      "    flip(m, 1) is equivalent to fliplr(m).\n",
      "\n",
      "    flip(m, n) corresponds to ``m[...,::-1,...]`` with ``::-1`` at position n.\n",
      "\n",
      "    flip(m) corresponds to ``m[::-1,::-1,...,::-1]`` with ``::-1`` at all\n",
      "    positions.\n",
      "\n",
      "    flip(m, (0, 1)) corresponds to ``m[::-1,::-1,...]`` with ``::-1`` at\n",
      "    position 0 and position 1.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> A = np.arange(8).reshape((2,2,2))\n",
      "    >>> A\n",
      "    array([[[0, 1],\n",
      "            [2, 3]],\n",
      "           [[4, 5],\n",
      "            [6, 7]]])\n",
      "    >>> np.flip(A, 0)\n",
      "    array([[[4, 5],\n",
      "            [6, 7]],\n",
      "           [[0, 1],\n",
      "            [2, 3]]])\n",
      "    >>> np.flip(A, 1)\n",
      "    array([[[2, 3],\n",
      "            [0, 1]],\n",
      "           [[6, 7],\n",
      "            [4, 5]]])\n",
      "    >>> np.flip(A)\n",
      "    array([[[7, 6],\n",
      "            [5, 4]],\n",
      "           [[3, 2],\n",
      "            [1, 0]]])\n",
      "    >>> np.flip(A, (0, 2))\n",
      "    array([[[5, 4],\n",
      "            [7, 6]],\n",
      "           [[1, 0],\n",
      "            [3, 2]]])\n",
      "    >>> A = np.random.randn(3,4,5)\n",
      "    >>> np.all(np.flip(A,2) == A[:,:,::-1,...])\n",
      "    True\n",
      "    \n",
      "code: rot90\n",
      "@array_function_dispatch(_rot90_dispatcher)\n",
      "def rot90(m, k=1, axes=(0, 1)):\n",
      "    axes = tuple(axes)\n",
      "    if len(axes) != 2:\n",
      "        raise ValueError(\"len(axes) must be 2.\")\n",
      "    m = asanyarray(m)\n",
      "    if axes[0] == axes[1] or absolute(axes[0] - axes[1]) == m.ndim:\n",
      "        raise ValueError(\"Axes must be different.\")\n",
      "    if (axes[0] >= m.ndim or axes[0] < -m.ndim\n",
      "        or axes[1] >= m.ndim or axes[1] < -m.ndim):\n",
      "        raise ValueError(\"Axes={} out of range for array of ndim={}.\"\n",
      "            .format(axes, m.ndim))\n",
      "    k %= 4\n",
      "    if k == 0:\n",
      "        return m[:]\n",
      "    if k == 2:\n",
      "        return flip(flip(m, axes[0]), axes[1])\n",
      "    axes_list = arange(0, m.ndim)\n",
      "    (axes_list[axes[0]], axes_list[axes[1]]) = (axes_list[axes[1]],\n",
      "                                                axes_list[axes[0]])\n",
      "    if k == 1:\n",
      "        return transpose(flip(m, axes[1]), axes_list)\n",
      "    else:\n",
      "        # k == 3\n",
      "        return flip(transpose(m, axes_list), axes[1])\n",
      "docstring: rot90\n",
      "\n",
      "    Rotate an array by 90 degrees in the plane specified by axes.\n",
      "\n",
      "    Rotation direction is from the first towards the second axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    m : array_like\n",
      "        Array of two or more dimensions.\n",
      "    k : integer\n",
      "        Number of times the array is rotated by 90 degrees.\n",
      "    axes : (2,) array_like\n",
      "        The array is rotated in the plane defined by the axes.\n",
      "        Axes must be different.\n",
      "\n",
      "        .. versionadded:: 1.12.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    y : ndarray\n",
      "        A rotated view of `m`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    flip : Reverse the order of elements in an array along the given axis.\n",
      "    fliplr : Flip an array horizontally.\n",
      "    flipud : Flip an array vertically.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    ``rot90(m, k=1, axes=(1,0))``  is the reverse of\n",
      "    ``rot90(m, k=1, axes=(0,1))``\n",
      "\n",
      "    ``rot90(m, k=1, axes=(1,0))`` is equivalent to\n",
      "    ``rot90(m, k=-1, axes=(0,1))``\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> m = np.array([[1,2],[3,4]], int)\n",
      "    >>> m\n",
      "    array([[1, 2],\n",
      "           [3, 4]])\n",
      "    >>> np.rot90(m)\n",
      "    array([[2, 4],\n",
      "           [1, 3]])\n",
      "    >>> np.rot90(m, 2)\n",
      "    array([[4, 3],\n",
      "           [2, 1]])\n",
      "    >>> m = np.arange(8).reshape((2,2,2))\n",
      "    >>> np.rot90(m, 1, (1,2))\n",
      "    array([[[1, 3],\n",
      "            [0, 2]],\n",
      "           [[5, 7],\n",
      "            [4, 6]]])\n",
      "\n",
      "    \n",
      "code: extract\n",
      "@array_function_dispatch(_extract_dispatcher)\n",
      "def extract(condition, arr):\n",
      "    return _nx.take(ravel(arr), nonzero(ravel(condition))[0])\n",
      "docstring: extract\n",
      "\n",
      "    Return the elements of an array that satisfy some condition.\n",
      "\n",
      "    This is equivalent to ``np.compress(ravel(condition), ravel(arr))``.  If\n",
      "    `condition` is boolean ``np.extract`` is equivalent to ``arr[condition]``.\n",
      "\n",
      "    Note that `place` does the exact opposite of `extract`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    condition : array_like\n",
      "        An array whose nonzero or True entries indicate the elements of `arr`\n",
      "        to extract.\n",
      "    arr : array_like\n",
      "        Input array of the same size as `condition`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    extract : ndarray\n",
      "        Rank 1 array of values from `arr` where `condition` is True.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    take, put, copyto, compress, place\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> arr = np.arange(12).reshape((3, 4))\n",
      "    >>> arr\n",
      "    array([[ 0,  1,  2,  3],\n",
      "           [ 4,  5,  6,  7],\n",
      "           [ 8,  9, 10, 11]])\n",
      "    >>> condition = np.mod(arr, 3)==0\n",
      "    >>> condition\n",
      "    array([[ True, False, False,  True],\n",
      "           [False, False,  True, False],\n",
      "           [False,  True, False, False]])\n",
      "    >>> np.extract(condition, arr)\n",
      "    array([0, 3, 6, 9])\n",
      "\n",
      "\n",
      "    If `condition` is boolean:\n",
      "\n",
      "    >>> arr[condition]\n",
      "    array([0, 3, 6, 9])\n",
      "\n",
      "    \n",
      "code: place\n",
      "@array_function_dispatch(_place_dispatcher)\n",
      "def place(arr, mask, vals):\n",
      "    if not isinstance(arr, np.ndarray):\n",
      "        raise TypeError(\"argument 1 must be numpy.ndarray, \"\n",
      "                        \"not {name}\".format(name=type(arr).__name__))\n",
      "    return _insert(arr, mask, vals)\n",
      "docstring: place\n",
      "\n",
      "    Change elements of an array based on conditional and input values.\n",
      "\n",
      "    Similar to ``np.copyto(arr, vals, where=mask)``, the difference is that\n",
      "    `place` uses the first N elements of `vals`, where N is the number of\n",
      "    True values in `mask`, while `copyto` uses the elements where `mask`\n",
      "    is True.\n",
      "\n",
      "    Note that `extract` does the exact opposite of `place`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : ndarray\n",
      "        Array to put data into.\n",
      "    mask : array_like\n",
      "        Boolean mask array. Must have the same size as `a`.\n",
      "    vals : 1-D sequence\n",
      "        Values to put into `a`. Only the first N elements are used, where\n",
      "        N is the number of True values in `mask`. If `vals` is smaller\n",
      "        than N, it will be repeated, and if elements of `a` are to be masked,\n",
      "        this sequence must be non-empty.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    copyto, put, take, extract\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> arr = np.arange(6).reshape(2, 3)\n",
      "    >>> np.place(arr, arr>2, [44, 55])\n",
      "    >>> arr\n",
      "    array([[ 0,  1,  2],\n",
      "           [44, 55, 44]])\n",
      "\n",
      "    \n",
      "code: vectorize.__call__\n",
      "    def __call__(self, *args, **kwargs):\n",
      "        excluded = self.excluded\n",
      "        if not kwargs and not excluded:\n",
      "            func = self.pyfunc\n",
      "            vargs = args\n",
      "        else:\n",
      " `inds` to mutate `the_args` and `kwargs` to pass to the original\n",
      "            # function.\n",
      "            nargs = len(args)\n",
      "            names = [_n for _n in kwargs if _n not in excluded]\n",
      "            inds = [_i for _i in range(nargs) if _i not in excluded]\n",
      "            the_args = list(args)\n",
      "            def func(*vargs):\n",
      "                for _n, _i in enumerate(inds):\n",
      "                    the_args[_i] = vargs[_n]\n",
      "                kwargs.update(zip(names, vargs[len(inds):]))\n",
      "                return self.pyfunc(*the_args, **kwargs)\n",
      "            vargs = [args[_i] for _i in inds]\n",
      "            vargs.extend([kwargs[_n] for _n in names])\n",
      "        return self._vectorize_call(func=func, args=vargs)\n",
      "docstring: vectorize.__call__\n",
      "\n",
      "        Return arrays with the results of `pyfunc` broadcast (vectorized) over\n",
      "        `args` and `kwargs` not in `excluded`.\n",
      "        \n",
      "code: vectorize._get_ufunc_and_otypes\n",
      "    def _get_ufunc_and_otypes(self, func, args):\n",
      " self._ufunc is a dictionary whose keys are the number of\n",
      " by frompyfunc. len(args) can be different for different calls if\n",
      " cache when func is self.pyfunc, which occurs when the call uses\n",
      " We'll get it from self._ufunc\n",
      "            if func is self.pyfunc:\n",
      "                ufunc = self._ufunc.setdefault(nin, ufunc)\n",
      "        else:\n",
      " the first entries of args.  We also cache the result to prevent\n",
      " Assumes that ufunc first evaluates the 0th elements in the input\n",
      " Performance note: profiling indicates that -- for simple\n",
      " execution time.\n",
      " Performance note: profiling indicates that creating the ufunc is\n",
      " worth trying to cache this.\n",
      "            ufunc = frompyfunc(_func, len(args), nout)\n",
      "        return ufunc, otypes\n",
      "docstring: vectorize._get_ufunc_and_otypes\n",
      "Return (ufunc, otypes).\n",
      "code: vectorize._vectorize_call\n",
      "    def _vectorize_call(self, func, args):\n",
      "        if self.signature is not None:\n",
      "            res = self._vectorize_call_with_signature(func, args)\n",
      "        elif not args:\n",
      "            res = func()\n",
      "        else:\n",
      "            ufunc, otypes = self._get_ufunc_and_otypes(func=func, args=args)\n",
      "            # Convert args to object arrays first\n",
      "            inputs = [asanyarray(a, dtype=object) for a in args]\n",
      "            outputs = ufunc(*inputs)\n",
      "            if ufunc.nout == 1:\n",
      "                res = asanyarray(outputs, dtype=otypes[0])\n",
      "            else:\n",
      "                res = tuple([asanyarray(x, dtype=t)\n",
      "                             for x, t in zip(outputs, otypes)])\n",
      "        return res\n",
      "docstring: vectorize._vectorize_call\n",
      "Vectorized call to `func` over positional `args`.\n",
      "code: vectorize._vectorize_call_with_signature\n",
      "    def _vectorize_call_with_signature(self, func, args):\n",
      "        input_core_dims, output_core_dims = self._in_and_out_core_dims\n",
      "        if len(args) != len(input_core_dims):\n",
      "            raise TypeError('wrong number of positional arguments: '\n",
      "                            'expected %r, got %r'\n",
      "                            % (len(input_core_dims), len(args)))\n",
      "        args = tuple(asanyarray(arg) for arg in args)\n",
      "        broadcast_shape, dim_sizes = _parse_input_dimensions(\n",
      "            args, input_core_dims)\n",
      "        input_shapes = _calculate_shapes(broadcast_shape, dim_sizes,\n",
      "                                         input_core_dims)\n",
      "        args = [np.broadcast_to(arg, shape, subok=True)\n",
      "                for arg, shape in zip(args, input_shapes)]\n",
      "        outputs = None\n",
      "        otypes = self.otypes\n",
      "        nout = len(output_core_dims)\n",
      "        for index in np.ndindex(*broadcast_shape):\n",
      "            results = func(*(arg[index] for arg in args))\n",
      "            n_results = len(results) if isinstance(results, tuple) else 1\n",
      "            if nout != n_results:\n",
      "                raise ValueError(\n",
      "                    'wrong number of outputs from pyfunc: expected %r, got %r'\n",
      "                    % (nout, n_results))\n",
      "            if nout == 1:\n",
      "                results = (results,)\n",
      "            if outputs is None:\n",
      "                for result, core_dims in zip(results, output_core_dims):\n",
      "                    _update_dim_sizes(dim_sizes, result, core_dims)\n",
      "                outputs = _create_arrays(broadcast_shape, dim_sizes,\n",
      "                                         output_core_dims, otypes, results)\n",
      "            for output, result in zip(outputs, results):\n",
      "                output[index] = result\n",
      "        if outputs is None:\n",
      "            # did not call the function even once\n",
      "            if otypes is None:\n",
      "                raise ValueError('cannot call `vectorize` on size 0 inputs '\n",
      "                                 'unless `otypes` is set')\n",
      "            if builtins.any(dim not in dim_sizes\n",
      "                            for dims in output_core_dims\n",
      "                            for dim in dims):\n",
      "                raise ValueError('cannot call `vectorize` with a signature '\n",
      "                                 'including new output dimensions on size 0 '\n",
      "                                 'inputs')\n",
      "            outputs = _create_arrays(broadcast_shape, dim_sizes,\n",
      "                                     output_core_dims, otypes)\n",
      "        return outputs[0] if nout == 1 else outputs\n",
      "docstring: vectorize._vectorize_call_with_signature\n",
      "Vectorized call over positional arguments with a signature.\n",
      "code: asarray_chkfinite\n",
      "@set_module('numpy')\n",
      "def asarray_chkfinite(a, dtype=None, order=None):\n",
      "    a = asarray(a, dtype=dtype, order=order)\n",
      "    if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():\n",
      "        raise ValueError(\n",
      "            \"array must not contain infs or NaNs\")\n",
      "    return a\n",
      "docstring: asarray_chkfinite\n",
      "Convert the input to an array, checking for NaNs or Infs.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data, in any form that can be converted to an array.  This\n",
      "        includes lists, lists of tuples, tuples, tuples of tuples, tuples\n",
      "        of lists and ndarrays.  Success requires no NaNs or Infs.\n",
      "    dtype : data-type, optional\n",
      "        By default, the data-type is inferred from the input data.\n",
      "    order : {'C', 'F', 'A', 'K'}, optional\n",
      "        Memory layout.  'A' and 'K' depend on the order of input array a.\n",
      "        'C' row-major (C-style),\n",
      "        'F' column-major (Fortran-style) memory representation.\n",
      "        'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n",
      "        'K' (keep) preserve input order\n",
      "        Defaults to 'C'.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array interpretation of `a`.  No copy is performed if the input\n",
      "        is already an ndarray.  If `a` is a subclass of ndarray, a base\n",
      "        class ndarray is returned.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        Raises ValueError if `a` contains NaN (Not a Number) or Inf (Infinity).\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    asarray : Create and array.\n",
      "    asanyarray : Similar function which passes through subclasses.\n",
      "    ascontiguousarray : Convert input to a contiguous array.\n",
      "    asfarray : Convert input to a floating point ndarray.\n",
      "    asfortranarray : Convert input to an ndarray with column-major\n",
      "                     memory order.\n",
      "    fromiter : Create an array from an iterator.\n",
      "    fromfunction : Construct an array by executing a function on grid\n",
      "                   positions.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Convert a list into an array.  If all elements are finite\n",
      "    ``asarray_chkfinite`` is identical to ``asarray``.\n",
      "\n",
      "    >>> a = [1, 2]\n",
      "    >>> np.asarray_chkfinite(a, dtype=float)\n",
      "    array([1., 2.])\n",
      "\n",
      "    Raises ValueError if array_like contains Nans or Infs.\n",
      "\n",
      "    >>> a = [1, 2, np.inf]\n",
      "    >>> try:\n",
      "    ...     np.asarray_chkfinite(a)\n",
      "    ... except ValueError:\n",
      "    ...     print('ValueError')\n",
      "    ...\n",
      "    ValueError\n",
      "\n",
      "    \n",
      "code: average\n",
      "@array_function_dispatch(_average_dispatcher)\n",
      "def average(a, axis=None, weights=None, returned=False, *,\n",
      "            keepdims=np._NoValue):\n",
      "    a = np.asanyarray(a)\n",
      "    if keepdims is np._NoValue:\n",
      " Sanity checks\n",
      "        if a.shape != wgt.shape:\n",
      "            if axis is None:\n",
      "                raise TypeError(\n",
      "                    \"Axis must be specified when shapes of a and weights \"\n",
      "                    \"differ.\")\n",
      "            if wgt.ndim != 1:\n",
      "                raise TypeError(\n",
      "                    \"1D weights expected when shapes of a and weights differ.\")\n",
      "            if wgt.shape[0] != a.shape[axis]:\n",
      "                raise ValueError(\n",
      "                    \"Length of weights not compatible with specified axis.\")\n",
      "            # setup wgt to broadcast along axis\n",
      "            wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)\n",
      "            wgt = wgt.swapaxes(-1, axis)\n",
      "        scl = wgt.sum(axis=axis, dtype=result_dtype, **keepdims_kw)\n",
      "        if np.any(scl == 0.0):\n",
      "            raise ZeroDivisionError(\n",
      "                \"Weights sum to zero, can't be normalized\")\n",
      "        avg = avg_as_array = np.multiply(a, wgt,\n",
      "                          dtype=result_dtype).sum(axis, **keepdims_kw) / scl\n",
      "    if returned:\n",
      "        if scl.shape != avg_as_array.shape:\n",
      "            scl = np.broadcast_to(scl, avg_as_array.shape).copy()\n",
      "        return avg, scl\n",
      "    else:\n",
      "        return avg\n",
      "docstring: average\n",
      "\n",
      "    Compute the weighted average along the specified axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing data to be averaged. If `a` is not an array, a\n",
      "        conversion is attempted.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which to average `a`.  The default,\n",
      "        axis=None, will average over all of the elements of the input array.\n",
      "        If axis is negative it counts from the last to the first axis.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If axis is a tuple of ints, averaging is performed on all of the axes\n",
      "        specified in the tuple instead of a single axis or all the axes as\n",
      "        before.\n",
      "    weights : array_like, optional\n",
      "        An array of weights associated with the values in `a`. Each value in\n",
      "        `a` contributes to the average according to its associated weight.\n",
      "        The weights array can either be 1-D (in which case its length must be\n",
      "        the size of `a` along the given axis) or of the same shape as `a`.\n",
      "        If `weights=None`, then all data in `a` are assumed to have a\n",
      "        weight equal to one.  The 1-D calculation is::\n",
      "\n",
      "            avg = sum(a * weights) / sum(weights)\n",
      "\n",
      "        The only constraint on `weights` is that `sum(weights)` must not be 0.\n",
      "    returned : bool, optional\n",
      "        Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)\n",
      "        is returned, otherwise only the average is returned.\n",
      "        If `weights=None`, `sum_of_weights` is equivalent to the number of\n",
      "        elements over which the average is taken.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `a`.\n",
      "        *Note:* `keepdims` will not work with instances of `numpy.matrix`\n",
      "        or other classes whose methods do not support `keepdims`.\n",
      "\n",
      "        .. versionadded:: 1.23.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    retval, [sum_of_weights] : array_type or double\n",
      "        Return the average along the specified axis. When `returned` is `True`,\n",
      "        return a tuple with the average as the first element and the sum\n",
      "        of the weights as the second element. `sum_of_weights` is of the\n",
      "        same type as `retval`. The result dtype follows a genereal pattern.\n",
      "        If `weights` is None, the result dtype will be that of `a` , or ``float64``\n",
      "        if `a` is integral. Otherwise, if `weights` is not None and `a` is non-\n",
      "        integral, the result type will be the type of lowest precision capable of\n",
      "        representing values of both `a` and `weights`. If `a` happens to be\n",
      "        integral, the previous rules still applies but the result dtype will\n",
      "        at least be ``float64``.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ZeroDivisionError\n",
      "        When all weights along axis are zero. See `numpy.ma.average` for a\n",
      "        version robust to this type of error.\n",
      "    TypeError\n",
      "        When the length of 1D `weights` is not the same as the shape of `a`\n",
      "        along axis.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    mean\n",
      "\n",
      "    ma.average : average for masked arrays -- useful if your data contains\n",
      "                 \"missing\" values\n",
      "    numpy.result_type : Returns the type that results from applying the\n",
      "                        numpy type promotion rules to the arguments.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> data = np.arange(1, 5)\n",
      "    >>> data\n",
      "    array([1, 2, 3, 4])\n",
      "    >>> np.average(data)\n",
      "    2.5\n",
      "    >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))\n",
      "    4.0\n",
      "\n",
      "    >>> data = np.arange(6).reshape((3, 2))\n",
      "    >>> data\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5]])\n",
      "    >>> np.average(data, axis=1, weights=[1./4, 3./4])\n",
      "    array([0.75, 2.75, 4.75])\n",
      "    >>> np.average(data, weights=[1./4, 3./4])\n",
      "    Traceback (most recent call last):\n",
      "        ...\n",
      "    TypeError: Axis must be specified when shapes of a and weights differ.\n",
      "\n",
      "    >>> a = np.ones(5, dtype=np.float128)\n",
      "    >>> w = np.ones(5, dtype=np.complex64)\n",
      "    >>> avg = np.average(a, weights=w)\n",
      "    >>> print(avg.dtype)\n",
      "    complex256\n",
      "\n",
      "    With ``keepdims=True``, the following result has shape (3, 1).\n",
      "\n",
      "    >>> np.average(data, axis=1, keepdims=True)\n",
      "    array([[0.5],\n",
      "           [2.5],\n",
      "           [4.5]])\n",
      "    \n",
      "code: bincount\n",
      "\n",
      "docstring: bincount\n",
      "\n",
      "    bincount(x, /, weights=None, minlength=0)\n",
      "\n",
      "    Count number of occurrences of each value in array of non-negative ints.\n",
      "\n",
      "    The number of bins (of size 1) is one larger than the largest value in\n",
      "    `x`. If `minlength` is specified, there will be at least this number\n",
      "    of bins in the output array (though it will be longer if necessary,\n",
      "    depending on the contents of `x`).\n",
      "    Each bin gives the number of occurrences of its index value in `x`.\n",
      "    If `weights` is specified the input array is weighted by it, i.e. if a\n",
      "    value ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead\n",
      "    of ``out[n] += 1``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like, 1 dimension, nonnegative ints\n",
      "        Input array.\n",
      "    weights : array_like, optional\n",
      "        Weights, array of the same shape as `x`.\n",
      "    minlength : int, optional\n",
      "        A minimum number of bins for the output array.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray of ints\n",
      "        The result of binning the input array.\n",
      "        The length of `out` is equal to ``np.amax(x)+1``.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If the input is not 1-dimensional, or contains elements with negative\n",
      "        values, or if `minlength` is negative.\n",
      "    TypeError\n",
      "        If the type of the input is float or complex.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    histogram, digitize, unique\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.bincount(np.arange(5))\n",
      "    array([1, 1, 1, 1, 1])\n",
      "    >>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))\n",
      "    array([1, 3, 1, 1, 0, 0, 0, 1])\n",
      "\n",
      "    >>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])\n",
      "    >>> np.bincount(x).size == np.amax(x)+1\n",
      "    True\n",
      "\n",
      "    The input array needs to be of integer dtype, otherwise a\n",
      "    TypeError is raised:\n",
      "\n",
      "    >>> np.bincount(np.arange(5, dtype=float))\n",
      "    Traceback (most recent call last):\n",
      "      ...\n",
      "    TypeError: Cannot cast array data from dtype('float64') to dtype('int64')\n",
      "    according to the rule 'safe'\n",
      "\n",
      "    A possible use of ``bincount`` is to perform sums over\n",
      "    variable-size chunks of an array, using the ``weights`` keyword.\n",
      "\n",
      "    >>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights\n",
      "    >>> x = np.array([0, 1, 1, 2, 2, 2])\n",
      "    >>> np.bincount(x,  weights=w)\n",
      "    array([ 0.3,  0.7,  1.1])\n",
      "\n",
      "    \n",
      "code: digitize\n",
      "@array_function_dispatch(_digitize_dispatcher)\n",
      "def digitize(x, bins, right=False):\n",
      "    x = _nx.asarray(x)\n",
      "    bins = _nx.asarray(bins)\n",
      " this is backwards because the arguments below are swapped\n",
      "    side = 'left' if right else 'right'\n",
      "    if mono == -1:\n",
      "        # reverse the bins, and invert the results\n",
      "        return len(bins) - _nx.searchsorted(bins[::-1], x, side=side)\n",
      "    else:\n",
      "        return _nx.searchsorted(bins, x, side=side)\n",
      "docstring: digitize\n",
      "\n",
      "    Return the indices of the bins to which each value in input array belongs.\n",
      "\n",
      "    =========  =============  ============================\n",
      "    `right`    order of bins  returned index `i` satisfies\n",
      "    =========  =============  ============================\n",
      "    ``False``  increasing     ``bins[i-1] <= x < bins[i]``\n",
      "    ``True``   increasing     ``bins[i-1] < x <= bins[i]``\n",
      "    ``False``  decreasing     ``bins[i-1] > x >= bins[i]``\n",
      "    ``True``   decreasing     ``bins[i-1] >= x > bins[i]``\n",
      "    =========  =============  ============================\n",
      "\n",
      "    If values in `x` are beyond the bounds of `bins`, 0 or ``len(bins)`` is\n",
      "    returned as appropriate.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        Input array to be binned. Prior to NumPy 1.10.0, this array had to\n",
      "        be 1-dimensional, but can now have any shape.\n",
      "    bins : array_like\n",
      "        Array of bins. It has to be 1-dimensional and monotonic.\n",
      "    right : bool, optional\n",
      "        Indicating whether the intervals include the right or the left bin\n",
      "        edge. Default behavior is (right==False) indicating that the interval\n",
      "        does not include the right edge. The left bin end is open in this\n",
      "        case, i.e., bins[i-1] <= x < bins[i] is the default behavior for\n",
      "        monotonically increasing bins.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    indices : ndarray of ints\n",
      "        Output array of indices, of same shape as `x`.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If `bins` is not monotonic.\n",
      "    TypeError\n",
      "        If the type of the input is complex.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    bincount, histogram, unique, searchsorted\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    If values in `x` are such that they fall outside the bin range,\n",
      "    attempting to index `bins` with the indices that `digitize` returns\n",
      "    will result in an IndexError.\n",
      "\n",
      "    .. versionadded:: 1.10.0\n",
      "\n",
      "    `np.digitize` is  implemented in terms of `np.searchsorted`. This means\n",
      "    that a binary search is used to bin the values, which scales much better\n",
      "    for larger number of bins than the previous linear search. It also removes\n",
      "    the requirement for the input array to be 1-dimensional.\n",
      "\n",
      "    For monotonically _increasing_ `bins`, the following are equivalent::\n",
      "\n",
      "        np.digitize(x, bins, right=True)\n",
      "        np.searchsorted(bins, x, side='left')\n",
      "\n",
      "    Note that as the order of the arguments are reversed, the side must be too.\n",
      "    The `searchsorted` call is marginally faster, as it does not do any\n",
      "    monotonicity checks. Perhaps more importantly, it supports all dtypes.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([0.2, 6.4, 3.0, 1.6])\n",
      "    >>> bins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])\n",
      "    >>> inds = np.digitize(x, bins)\n",
      "    >>> inds\n",
      "    array([1, 4, 3, 2])\n",
      "    >>> for n in range(x.size):\n",
      "    ...   print(bins[inds[n]-1], \"<=\", x[n], \"<\", bins[inds[n]])\n",
      "    ...\n",
      "    0.0 <= 0.2 < 1.0\n",
      "    4.0 <= 6.4 < 10.0\n",
      "    2.5 <= 3.0 < 4.0\n",
      "    1.0 <= 1.6 < 2.5\n",
      "\n",
      "    >>> x = np.array([1.2, 10.0, 12.4, 15.5, 20.])\n",
      "    >>> bins = np.array([0, 5, 10, 15, 20])\n",
      "    >>> np.digitize(x,bins,right=True)\n",
      "    array([1, 2, 3, 4, 4])\n",
      "    >>> np.digitize(x,bins,right=False)\n",
      "    array([1, 3, 3, 4, 5])\n",
      "    \n",
      "code: cov\n",
      "@array_function_dispatch(_cov_dispatcher)\n",
      "def cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None,\n",
      "        aweights=None, *, dtype=None):\n",
      " Handles complex arrays too\n",
      "    m = np.asarray(m)\n",
      "    if m.ndim > 2:\n",
      "        raise ValueError(\"m has more than 2 dimensions\")\n",
      "    if y is not None:\n",
      "        y = np.asarray(y)\n",
      "        if y.ndim > 2:\n",
      "            raise ValueError(\"y has more than 2 dimensions\")\n",
      "    if dtype is None:\n",
      "        if y is None:\n",
      "            dtype = np.result_type(m, np.float64)\n",
      "        else:\n",
      "            dtype = np.result_type(m, y, np.float64)\n",
      "    X = array(m, ndmin=2, dtype=dtype)\n",
      "    if not rowvar and X.shape[0] != 1:\n",
      "        X = X.T\n",
      "    if X.shape[0] == 0:\n",
      "        return np.array([]).reshape(0, 0)\n",
      "    if y is not None:\n",
      "        y = array(y, copy=False, ndmin=2, dtype=dtype)\n",
      "        if not rowvar and y.shape[0] != 1:\n",
      "            y = y.T\n",
      "        X = np.concatenate((X, y), axis=0)\n",
      "    if ddof is None:\n",
      "        if bias == 0:\n",
      "            ddof = 1\n",
      "        else:\n",
      "            ddof = 0\n",
      " Determine the normalization\n",
      "    if w is None:\n",
      "        fact = X.shape[1] - ddof\n",
      "    elif ddof == 0:\n",
      "        fact = w_sum\n",
      "    elif aweights is None:\n",
      "        fact = w_sum - ddof\n",
      "    else:\n",
      "        fact = w_sum - ddof*sum(w*aweights)/w_sum\n",
      "    if fact <= 0:\n",
      "        warnings.warn(\"Degrees of freedom <= 0 for slice\",\n",
      "                      RuntimeWarning, stacklevel=3)\n",
      "        fact = 0.0\n",
      "    X -= avg[:, None]\n",
      "    if w is None:\n",
      "        X_T = X.T\n",
      "    else:\n",
      "        X_T = (X*w).T\n",
      "    c = dot(X, X_T.conj())\n",
      "    c *= np.true_divide(1, fact)\n",
      "    return c.squeeze()\n",
      "docstring: cov\n",
      "\n",
      "    Estimate a covariance matrix, given data and weights.\n",
      "\n",
      "    Covariance indicates the level to which two variables vary together.\n",
      "    If we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,\n",
      "    then the covariance matrix element :math:`C_{ij}` is the covariance of\n",
      "    :math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance\n",
      "    of :math:`x_i`.\n",
      "\n",
      "    See the notes for an outline of the algorithm.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    m : array_like\n",
      "        A 1-D or 2-D array containing multiple variables and observations.\n",
      "        Each row of `m` represents a variable, and each column a single\n",
      "        observation of all those variables. Also see `rowvar` below.\n",
      "    y : array_like, optional\n",
      "        An additional set of variables and observations. `y` has the same form\n",
      "        as that of `m`.\n",
      "    rowvar : bool, optional\n",
      "        If `rowvar` is True (default), then each row represents a\n",
      "        variable, with observations in the columns. Otherwise, the relationship\n",
      "        is transposed: each column represents a variable, while the rows\n",
      "        contain observations.\n",
      "    bias : bool, optional\n",
      "        Default normalization (False) is by ``(N - 1)``, where ``N`` is the\n",
      "        number of observations given (unbiased estimate). If `bias` is True,\n",
      "        then normalization is by ``N``. These values can be overridden by using\n",
      "        the keyword ``ddof`` in numpy versions >= 1.5.\n",
      "    ddof : int, optional\n",
      "        If not ``None`` the default value implied by `bias` is overridden.\n",
      "        Note that ``ddof=1`` will return the unbiased estimate, even if both\n",
      "        `fweights` and `aweights` are specified, and ``ddof=0`` will return\n",
      "        the simple average. See the notes for the details. The default value\n",
      "        is ``None``.\n",
      "\n",
      "        .. versionadded:: 1.5\n",
      "    fweights : array_like, int, optional\n",
      "        1-D array of integer frequency weights; the number of times each\n",
      "        observation vector should be repeated.\n",
      "\n",
      "        .. versionadded:: 1.10\n",
      "    aweights : array_like, optional\n",
      "        1-D array of observation vector weights. These relative weights are\n",
      "        typically large for observations considered \"important\" and smaller for\n",
      "        observations considered less \"important\". If ``ddof=0`` the array of\n",
      "        weights can be used to assign probabilities to observation vectors.\n",
      "\n",
      "        .. versionadded:: 1.10\n",
      "    dtype : data-type, optional\n",
      "        Data-type of the result. By default, the return data-type will have\n",
      "        at least `numpy.float64` precision.\n",
      "\n",
      "        .. versionadded:: 1.20\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The covariance matrix of the variables.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    corrcoef : Normalized covariance matrix\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Assume that the observations are in the columns of the observation\n",
      "    array `m` and let ``f = fweights`` and ``a = aweights`` for brevity. The\n",
      "    steps to compute the weighted covariance are as follows::\n",
      "\n",
      "        >>> m = np.arange(10, dtype=np.float64)\n",
      "        >>> f = np.arange(10) * 2\n",
      "        >>> a = np.arange(10) ** 2.\n",
      "        >>> ddof = 1\n",
      "        >>> w = f * a\n",
      "        >>> v1 = np.sum(w)\n",
      "        >>> v2 = np.sum(w * a)\n",
      "        >>> m -= np.sum(m * w, axis=None, keepdims=True) / v1\n",
      "        >>> cov = np.dot(m * w, m.T) * v1 / (v1**2 - ddof * v2)\n",
      "\n",
      "    Note that when ``a == 1``, the normalization factor\n",
      "    ``v1 / (v1**2 - ddof * v2)`` goes over to ``1 / (np.sum(f) - ddof)``\n",
      "    as it should.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Consider two variables, :math:`x_0` and :math:`x_1`, which\n",
      "    correlate perfectly, but in opposite directions:\n",
      "\n",
      "    >>> x = np.array([[0, 2], [1, 1], [2, 0]]).T\n",
      "    >>> x\n",
      "    array([[0, 1, 2],\n",
      "           [2, 1, 0]])\n",
      "\n",
      "    Note how :math:`x_0` increases while :math:`x_1` decreases. The covariance\n",
      "    matrix shows this clearly:\n",
      "\n",
      "    >>> np.cov(x)\n",
      "    array([[ 1., -1.],\n",
      "           [-1.,  1.]])\n",
      "\n",
      "    Note that element :math:`C_{0,1}`, which shows the correlation between\n",
      "    :math:`x_0` and :math:`x_1`, is negative.\n",
      "\n",
      "    Further, note how `x` and `y` are combined:\n",
      "\n",
      "    >>> x = [-2.1, -1,  4.3]\n",
      "    >>> y = [3,  1.1,  0.12]\n",
      "    >>> X = np.stack((x, y), axis=0)\n",
      "    >>> np.cov(X)\n",
      "    array([[11.71      , -4.286     ], # may vary\n",
      "           [-4.286     ,  2.144133]])\n",
      "    >>> np.cov(x, y)\n",
      "    array([[11.71      , -4.286     ], # may vary\n",
      "           [-4.286     ,  2.144133]])\n",
      "    >>> np.cov(x)\n",
      "    array(11.71)\n",
      "\n",
      "    \n",
      "code: corrcoef\n",
      "@array_function_dispatch(_corrcoef_dispatcher)\n",
      "def corrcoef(x, y=None, rowvar=True, bias=np._NoValue, ddof=np._NoValue, *,\n",
      "             dtype=None):\n",
      "    if bias is not np._NoValue or ddof is not np._NoValue:\n",
      " scalar covariance\n",
      " Clip real and imaginary parts to [-1, 1].  This does not guarantee\n",
      " excessive work.\n",
      "    np.clip(c.real, -1, 1, out=c.real)\n",
      "    if np.iscomplexobj(c):\n",
      "        np.clip(c.imag, -1, 1, out=c.imag)\n",
      "    return c\n",
      "docstring: corrcoef\n",
      "\n",
      "    Return Pearson product-moment correlation coefficients.\n",
      "\n",
      "    Please refer to the documentation for `cov` for more detail.  The\n",
      "    relationship between the correlation coefficient matrix, `R`, and the\n",
      "    covariance matrix, `C`, is\n",
      "\n",
      "    .. math:: R_{ij} = \\frac{ C_{ij} } { \\sqrt{ C_{ii} C_{jj} } }\n",
      "\n",
      "    The values of `R` are between -1 and 1, inclusive.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        A 1-D or 2-D array containing multiple variables and observations.\n",
      "        Each row of `x` represents a variable, and each column a single\n",
      "        observation of all those variables. Also see `rowvar` below.\n",
      "    y : array_like, optional\n",
      "        An additional set of variables and observations. `y` has the same\n",
      "        shape as `x`.\n",
      "    rowvar : bool, optional\n",
      "        If `rowvar` is True (default), then each row represents a\n",
      "        variable, with observations in the columns. Otherwise, the relationship\n",
      "        is transposed: each column represents a variable, while the rows\n",
      "        contain observations.\n",
      "    bias : _NoValue, optional\n",
      "        Has no effect, do not use.\n",
      "\n",
      "        .. deprecated:: 1.10.0\n",
      "    ddof : _NoValue, optional\n",
      "        Has no effect, do not use.\n",
      "\n",
      "        .. deprecated:: 1.10.0\n",
      "    dtype : data-type, optional\n",
      "        Data-type of the result. By default, the return data-type will have\n",
      "        at least `numpy.float64` precision.\n",
      "\n",
      "        .. versionadded:: 1.20\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    R : ndarray\n",
      "        The correlation coefficient matrix of the variables.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    cov : Covariance matrix\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Due to floating point rounding the resulting array may not be Hermitian,\n",
      "    the diagonal elements may not be 1, and the elements may not satisfy the\n",
      "    inequality abs(a) <= 1. The real and imaginary parts are clipped to the\n",
      "    interval [-1,  1] in an attempt to improve on that situation but is not\n",
      "    much help in the complex case.\n",
      "\n",
      "    This function accepts but discards arguments `bias` and `ddof`.  This is\n",
      "    for backwards compatibility with previous versions of this function.  These\n",
      "    arguments had no effect on the return values of the function and can be\n",
      "    safely ignored in this and previous versions of numpy.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    In this example we generate two random arrays, ``xarr`` and ``yarr``, and\n",
      "    compute the row-wise and column-wise Pearson correlation coefficients,\n",
      "    ``R``. Since ``rowvar`` is  true by  default, we first find the row-wise\n",
      "    Pearson correlation coefficients between the variables of ``xarr``.\n",
      "\n",
      "    >>> import numpy as np\n",
      "    >>> rng = np.random.default_rng(seed=42)\n",
      "    >>> xarr = rng.random((3, 3))\n",
      "    >>> xarr\n",
      "    array([[0.77395605, 0.43887844, 0.85859792],\n",
      "           [0.69736803, 0.09417735, 0.97562235],\n",
      "           [0.7611397 , 0.78606431, 0.12811363]])\n",
      "    >>> R1 = np.corrcoef(xarr)\n",
      "    >>> R1\n",
      "    array([[ 1.        ,  0.99256089, -0.68080986],\n",
      "           [ 0.99256089,  1.        , -0.76492172],\n",
      "           [-0.68080986, -0.76492172,  1.        ]])\n",
      "\n",
      "    If we add another set of variables and observations ``yarr``, we can\n",
      "    compute the row-wise Pearson correlation coefficients between the\n",
      "    variables in ``xarr`` and ``yarr``.\n",
      "\n",
      "    >>> yarr = rng.random((3, 3))\n",
      "    >>> yarr\n",
      "    array([[0.45038594, 0.37079802, 0.92676499],\n",
      "           [0.64386512, 0.82276161, 0.4434142 ],\n",
      "           [0.22723872, 0.55458479, 0.06381726]])\n",
      "    >>> R2 = np.corrcoef(xarr, yarr)\n",
      "    >>> R2\n",
      "    array([[ 1.        ,  0.99256089, -0.68080986,  0.75008178, -0.934284  ,\n",
      "            -0.99004057],\n",
      "           [ 0.99256089,  1.        , -0.76492172,  0.82502011, -0.97074098,\n",
      "            -0.99981569],\n",
      "           [-0.68080986, -0.76492172,  1.        , -0.99507202,  0.89721355,\n",
      "             0.77714685],\n",
      "           [ 0.75008178,  0.82502011, -0.99507202,  1.        , -0.93657855,\n",
      "            -0.83571711],\n",
      "           [-0.934284  , -0.97074098,  0.89721355, -0.93657855,  1.        ,\n",
      "             0.97517215],\n",
      "           [-0.99004057, -0.99981569,  0.77714685, -0.83571711,  0.97517215,\n",
      "             1.        ]])\n",
      "\n",
      "    Finally if we use the option ``rowvar=False``, the columns are now\n",
      "    being treated as the variables and we will find the column-wise Pearson\n",
      "    correlation coefficients between variables in ``xarr`` and ``yarr``.\n",
      "\n",
      "    >>> R3 = np.corrcoef(xarr, yarr, rowvar=False)\n",
      "    >>> R3\n",
      "    array([[ 1.        ,  0.77598074, -0.47458546, -0.75078643, -0.9665554 ,\n",
      "             0.22423734],\n",
      "           [ 0.77598074,  1.        , -0.92346708, -0.99923895, -0.58826587,\n",
      "            -0.44069024],\n",
      "           [-0.47458546, -0.92346708,  1.        ,  0.93773029,  0.23297648,\n",
      "             0.75137473],\n",
      "           [-0.75078643, -0.99923895,  0.93773029,  1.        ,  0.55627469,\n",
      "             0.47536961],\n",
      "           [-0.9665554 , -0.58826587,  0.23297648,  0.55627469,  1.        ,\n",
      "            -0.46666491],\n",
      "           [ 0.22423734, -0.44069024,  0.75137473,  0.47536961, -0.46666491,\n",
      "             1.        ]])\n",
      "\n",
      "    \n",
      "code: msort\n",
      "@array_function_dispatch(_msort_dispatcher)\n",
      "def msort(a):\n",
      "    # 2022-10-20 1.24\n",
      "    warnings.warn(\n",
      "        \"msort is deprecated, use np.sort(a, axis=0) instead\",\n",
      "        DeprecationWarning,\n",
      "        stacklevel=3,\n",
      "    )\n",
      "    b = array(a, subok=True, copy=True)\n",
      "    b.sort(0)\n",
      "    return b\n",
      "docstring: msort\n",
      "\n",
      "    Return a copy of an array sorted along the first axis.\n",
      "\n",
      "    .. deprecated:: 1.24\n",
      "\n",
      "       msort is deprecated, use ``np.sort(a, axis=0)`` instead.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to be sorted.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    sorted_array : ndarray\n",
      "        Array of the same type and shape as `a`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    sort\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    ``np.msort(a)`` is equivalent to  ``np.sort(a, axis=0)``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 4], [3, 1]])\n",
      "    >>> np.msort(a)  # sort along the first axis\n",
      "    array([[1, 1],\n",
      "           [3, 4]])\n",
      "\n",
      "    \n",
      "code: median\n",
      "@array_function_dispatch(_median_dispatcher)\n",
      "def median(a, axis=None, out=None, overwrite_input=False, keepdims=False):\n",
      "    return _ureduce(a, func=_median, keepdims=keepdims, axis=axis, out=out,\n",
      "                    overwrite_input=overwrite_input)\n",
      "docstring: median\n",
      "\n",
      "    Compute the median along the specified axis.\n",
      "\n",
      "    Returns the median of the array elements.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array or object that can be converted to an array.\n",
      "    axis : {int, sequence of int, None}, optional\n",
      "        Axis or axes along which the medians are computed. The default\n",
      "        is to compute the median along a flattened version of the array.\n",
      "        A sequence of axes is supported since version 1.9.0.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must\n",
      "        have the same shape and buffer length as the expected output,\n",
      "        but the type (of the output) will be cast if necessary.\n",
      "    overwrite_input : bool, optional\n",
      "       If True, then allow use of memory of input array `a` for\n",
      "       calculations. The input array will be modified by the call to\n",
      "       `median`. This will save memory when you do not need to preserve\n",
      "       the contents of the input array. Treat the input as undefined,\n",
      "       but it will probably be fully or partially sorted. Default is\n",
      "       False. If `overwrite_input` is ``True`` and `a` is not already an\n",
      "       `ndarray`, an error will be raised.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `arr`.\n",
      "\n",
      "        .. versionadded:: 1.9.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    median : ndarray\n",
      "        A new array holding the result. If the input contains integers\n",
      "        or floats smaller than ``float64``, then the output data-type is\n",
      "        ``np.float64``.  Otherwise, the data-type of the output is the\n",
      "        same as that of the input. If `out` is specified, that array is\n",
      "        returned instead.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    mean, percentile\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Given a vector ``V`` of length ``N``, the median of ``V`` is the\n",
      "    middle value of a sorted copy of ``V``, ``V_sorted`` - i\n",
      "    e., ``V_sorted[(N-1)/2]``, when ``N`` is odd, and the average of the\n",
      "    two middle values of ``V_sorted`` when ``N`` is even.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n",
      "    >>> a\n",
      "    array([[10,  7,  4],\n",
      "           [ 3,  2,  1]])\n",
      "    >>> np.median(a)\n",
      "    3.5\n",
      "    >>> np.median(a, axis=0)\n",
      "    array([6.5, 4.5, 2.5])\n",
      "    >>> np.median(a, axis=1)\n",
      "    array([7.,  2.])\n",
      "    >>> m = np.median(a, axis=0)\n",
      "    >>> out = np.zeros_like(m)\n",
      "    >>> np.median(a, axis=0, out=m)\n",
      "    array([6.5,  4.5,  2.5])\n",
      "    >>> m\n",
      "    array([6.5,  4.5,  2.5])\n",
      "    >>> b = a.copy()\n",
      "    >>> np.median(b, axis=1, overwrite_input=True)\n",
      "    array([7.,  2.])\n",
      "    >>> assert not np.all(a==b)\n",
      "    >>> b = a.copy()\n",
      "    >>> np.median(b, axis=None, overwrite_input=True)\n",
      "    3.5\n",
      "    >>> assert not np.all(a==b)\n",
      "\n",
      "    \n",
      "code: sinc\n",
      "@array_function_dispatch(_sinc_dispatcher)\n",
      "def sinc(x):\n",
      "    r\"\"\"\n",
      "    Return the normalized sinc function.\n",
      "    The sinc function is equal to :math:`\\sin(\\pi x)/(\\pi x)` for any argument\n",
      "    :math:`x\\ne 0`. ``sinc(0)`` takes the limit value 1, making ``sinc`` not\n",
      "    only everywhere continuous but also infinitely differentiable.\n",
      "    .. note::\n",
      "        Note the normalization factor of ``pi`` used in the definition.\n",
      "        This is the most commonly used definition in signal processing.\n",
      "        Use ``sinc(x / np.pi)`` to obtain the unnormalized sinc function\n",
      "        :math:`\\sin(x)/x` that is more common in mathematics.\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : ndarray\n",
      "        Array (possibly multi-dimensional) of values for which to calculate\n",
      "        ``sinc(x)``.\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        ``sinc(x)``, which has the same shape as the input.\n",
      "    Notes\n",
      "    -----\n",
      "    The name sinc is short for \"sine cardinal\" or \"sinus cardinalis\".\n",
      "    The sinc function is used in various signal processing applications,\n",
      "    including in anti-aliasing, in the construction of a Lanczos resampling\n",
      "    filter, and in interpolation.\n",
      "    For bandlimited interpolation of discrete-time signals, the ideal\n",
      "    interpolation kernel is proportional to the sinc function.\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Weisstein, Eric W. \"Sinc Function.\" From MathWorld--A Wolfram Web\n",
      "           Resource. http://mathworld.wolfram.com/SincFunction.html\n",
      "    .. [2] Wikipedia, \"Sinc function\",\n",
      "           https://en.wikipedia.org/wiki/Sinc_function\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> x = np.linspace(-4, 4, 41)\n",
      "    >>> np.sinc(x)\n",
      "     array([-3.89804309e-17,  -4.92362781e-02,  -8.40918587e-02, # may vary\n",
      "            -8.90384387e-02,  -5.84680802e-02,   3.89804309e-17,\n",
      "            6.68206631e-02,   1.16434881e-01,   1.26137788e-01,\n",
      "            8.50444803e-02,  -3.89804309e-17,  -1.03943254e-01,\n",
      "            -1.89206682e-01,  -2.16236208e-01,  -1.55914881e-01,\n",
      "            3.89804309e-17,   2.33872321e-01,   5.04551152e-01,\n",
      "            7.56826729e-01,   9.35489284e-01,   1.00000000e+00,\n",
      "            9.35489284e-01,   7.56826729e-01,   5.04551152e-01,\n",
      "            2.33872321e-01,   3.89804309e-17,  -1.55914881e-01,\n",
      "           -2.16236208e-01,  -1.89206682e-01,  -1.03943254e-01,\n",
      "           -3.89804309e-17,   8.50444803e-02,   1.26137788e-01,\n",
      "            1.16434881e-01,   6.68206631e-02,   3.89804309e-17,\n",
      "            -5.84680802e-02,  -8.90384387e-02,  -8.40918587e-02,\n",
      "            -4.92362781e-02,  -3.89804309e-17])\n",
      "    >>> plt.plot(x, np.sinc(x))\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Sinc Function\")\n",
      "    Text(0.5, 1.0, 'Sinc Function')\n",
      "    >>> plt.ylabel(\"Amplitude\")\n",
      "    Text(0, 0.5, 'Amplitude')\n",
      "    >>> plt.xlabel(\"X\")\n",
      "    Text(0.5, 0, 'X')\n",
      "    >>> plt.show()\n",
      "    \"\"\"\n",
      "    x = np.asanyarray(x)\n",
      "    y = pi * where(x == 0, 1.0e-20, x)\n",
      "    return sin(y)/y\n",
      "docstring: sinc\n",
      "\n",
      "    Return the normalized sinc function.\n",
      "\n",
      "    The sinc function is equal to :math:`\\sin(\\pi x)/(\\pi x)` for any argument\n",
      "    :math:`x\\ne 0`. ``sinc(0)`` takes the limit value 1, making ``sinc`` not\n",
      "    only everywhere continuous but also infinitely differentiable.\n",
      "\n",
      "    .. note::\n",
      "\n",
      "        Note the normalization factor of ``pi`` used in the definition.\n",
      "        This is the most commonly used definition in signal processing.\n",
      "        Use ``sinc(x / np.pi)`` to obtain the unnormalized sinc function\n",
      "        :math:`\\sin(x)/x` that is more common in mathematics.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : ndarray\n",
      "        Array (possibly multi-dimensional) of values for which to calculate\n",
      "        ``sinc(x)``.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        ``sinc(x)``, which has the same shape as the input.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The name sinc is short for \"sine cardinal\" or \"sinus cardinalis\".\n",
      "\n",
      "    The sinc function is used in various signal processing applications,\n",
      "    including in anti-aliasing, in the construction of a Lanczos resampling\n",
      "    filter, and in interpolation.\n",
      "\n",
      "    For bandlimited interpolation of discrete-time signals, the ideal\n",
      "    interpolation kernel is proportional to the sinc function.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Weisstein, Eric W. \"Sinc Function.\" From MathWorld--A Wolfram Web\n",
      "           Resource. http://mathworld.wolfram.com/SincFunction.html\n",
      "    .. [2] Wikipedia, \"Sinc function\",\n",
      "           https://en.wikipedia.org/wiki/Sinc_function\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> x = np.linspace(-4, 4, 41)\n",
      "    >>> np.sinc(x)\n",
      "     array([-3.89804309e-17,  -4.92362781e-02,  -8.40918587e-02, # may vary\n",
      "            -8.90384387e-02,  -5.84680802e-02,   3.89804309e-17,\n",
      "            6.68206631e-02,   1.16434881e-01,   1.26137788e-01,\n",
      "            8.50444803e-02,  -3.89804309e-17,  -1.03943254e-01,\n",
      "            -1.89206682e-01,  -2.16236208e-01,  -1.55914881e-01,\n",
      "            3.89804309e-17,   2.33872321e-01,   5.04551152e-01,\n",
      "            7.56826729e-01,   9.35489284e-01,   1.00000000e+00,\n",
      "            9.35489284e-01,   7.56826729e-01,   5.04551152e-01,\n",
      "            2.33872321e-01,   3.89804309e-17,  -1.55914881e-01,\n",
      "           -2.16236208e-01,  -1.89206682e-01,  -1.03943254e-01,\n",
      "           -3.89804309e-17,   8.50444803e-02,   1.26137788e-01,\n",
      "            1.16434881e-01,   6.68206631e-02,   3.89804309e-17,\n",
      "            -5.84680802e-02,  -8.90384387e-02,  -8.40918587e-02,\n",
      "            -4.92362781e-02,  -3.89804309e-17])\n",
      "\n",
      "    >>> plt.plot(x, np.sinc(x))\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Sinc Function\")\n",
      "    Text(0.5, 1.0, 'Sinc Function')\n",
      "    >>> plt.ylabel(\"Amplitude\")\n",
      "    Text(0, 0.5, 'Amplitude')\n",
      "    >>> plt.xlabel(\"X\")\n",
      "    Text(0.5, 0, 'X')\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: hamming\n",
      "@set_module('numpy')\n",
      "def hamming(M):\n",
      "    if M < 1:\n",
      "        return array([], dtype=np.result_type(M, 0.0))\n",
      "    if M == 1:\n",
      "        return ones(1, dtype=np.result_type(M, 0.0))\n",
      "    n = arange(1-M, M, 2)\n",
      "    return 0.54 + 0.46*cos(pi*n/(M-1))\n",
      "docstring: hamming\n",
      "\n",
      "    Return the Hamming window.\n",
      "\n",
      "    The Hamming window is a taper formed by using a weighted cosine.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    M : int\n",
      "        Number of points in the output window. If zero or less, an\n",
      "        empty array is returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The window, with the maximum value normalized to one (the value\n",
      "        one appears only if the number of samples is odd).\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    bartlett, blackman, hanning, kaiser\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The Hamming window is defined as\n",
      "\n",
      "    .. math::  w(n) = 0.54 - 0.46\\cos\\left(\\frac{2\\pi{n}}{M-1}\\right)\n",
      "               \\qquad 0 \\leq n \\leq M-1\n",
      "\n",
      "    The Hamming was named for R. W. Hamming, an associate of J. W. Tukey\n",
      "    and is described in Blackman and Tukey. It was recommended for\n",
      "    smoothing the truncated autocovariance function in the time domain.\n",
      "    Most references to the Hamming window come from the signal processing\n",
      "    literature, where it is used as one of many windowing functions for\n",
      "    smoothing values.  It is also known as an apodization (which means\n",
      "    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n",
      "    and end of the sampled signal) or tapering function.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\n",
      "           spectra, Dover Publications, New York.\n",
      "    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\n",
      "           University of Alberta Press, 1975, pp. 109-110.\n",
      "    .. [3] Wikipedia, \"Window function\",\n",
      "           https://en.wikipedia.org/wiki/Window_function\n",
      "    .. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n",
      "           \"Numerical Recipes\", Cambridge University Press, 1986, page 425.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.hamming(12)\n",
      "    array([ 0.08      ,  0.15302337,  0.34890909,  0.60546483,  0.84123594, # may vary\n",
      "            0.98136677,  0.98136677,  0.84123594,  0.60546483,  0.34890909,\n",
      "            0.15302337,  0.08      ])\n",
      "\n",
      "    Plot the window and the frequency response:\n",
      "\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> from numpy.fft import fft, fftshift\n",
      "    >>> window = np.hamming(51)\n",
      "    >>> plt.plot(window)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Hamming window\")\n",
      "    Text(0.5, 1.0, 'Hamming window')\n",
      "    >>> plt.ylabel(\"Amplitude\")\n",
      "    Text(0, 0.5, 'Amplitude')\n",
      "    >>> plt.xlabel(\"Sample\")\n",
      "    Text(0.5, 0, 'Sample')\n",
      "    >>> plt.show()\n",
      "\n",
      "    >>> plt.figure()\n",
      "    <Figure size 640x480 with 0 Axes>\n",
      "    >>> A = fft(window, 2048) / 25.5\n",
      "    >>> mag = np.abs(fftshift(A))\n",
      "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
      "    >>> response = 20 * np.log10(mag)\n",
      "    >>> response = np.clip(response, -100, 100)\n",
      "    >>> plt.plot(freq, response)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Frequency response of Hamming window\")\n",
      "    Text(0.5, 1.0, 'Frequency response of Hamming window')\n",
      "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
      "    Text(0, 0.5, 'Magnitude [dB]')\n",
      "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
      "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
      "    >>> plt.axis('tight')\n",
      "    ...\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: hanning\n",
      "@set_module('numpy')\n",
      "def hanning(M):\n",
      "    if M < 1:\n",
      "        return array([], dtype=np.result_type(M, 0.0))\n",
      "    if M == 1:\n",
      "        return ones(1, dtype=np.result_type(M, 0.0))\n",
      "    n = arange(1-M, M, 2)\n",
      "    return 0.5 + 0.5*cos(pi*n/(M-1))\n",
      "docstring: hanning\n",
      "\n",
      "    Return the Hanning window.\n",
      "\n",
      "    The Hanning window is a taper formed by using a weighted cosine.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    M : int\n",
      "        Number of points in the output window. If zero or less, an\n",
      "        empty array is returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray, shape(M,)\n",
      "        The window, with the maximum value normalized to one (the value\n",
      "        one appears only if `M` is odd).\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    bartlett, blackman, hamming, kaiser\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The Hanning window is defined as\n",
      "\n",
      "    .. math::  w(n) = 0.5 - 0.5\\cos\\left(\\frac{2\\pi{n}}{M-1}\\right)\n",
      "               \\qquad 0 \\leq n \\leq M-1\n",
      "\n",
      "    The Hanning was named for Julius von Hann, an Austrian meteorologist.\n",
      "    It is also known as the Cosine Bell. Some authors prefer that it be\n",
      "    called a Hann window, to help avoid confusion with the very similar\n",
      "    Hamming window.\n",
      "\n",
      "    Most references to the Hanning window come from the signal processing\n",
      "    literature, where it is used as one of many windowing functions for\n",
      "    smoothing values.  It is also known as an apodization (which means\n",
      "    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n",
      "    and end of the sampled signal) or tapering function.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\n",
      "           spectra, Dover Publications, New York.\n",
      "    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\n",
      "           The University of Alberta Press, 1975, pp. 106-108.\n",
      "    .. [3] Wikipedia, \"Window function\",\n",
      "           https://en.wikipedia.org/wiki/Window_function\n",
      "    .. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n",
      "           \"Numerical Recipes\", Cambridge University Press, 1986, page 425.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.hanning(12)\n",
      "    array([0.        , 0.07937323, 0.29229249, 0.57115742, 0.82743037,\n",
      "           0.97974649, 0.97974649, 0.82743037, 0.57115742, 0.29229249,\n",
      "           0.07937323, 0.        ])\n",
      "\n",
      "    Plot the window and its frequency response:\n",
      "\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> from numpy.fft import fft, fftshift\n",
      "    >>> window = np.hanning(51)\n",
      "    >>> plt.plot(window)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Hann window\")\n",
      "    Text(0.5, 1.0, 'Hann window')\n",
      "    >>> plt.ylabel(\"Amplitude\")\n",
      "    Text(0, 0.5, 'Amplitude')\n",
      "    >>> plt.xlabel(\"Sample\")\n",
      "    Text(0.5, 0, 'Sample')\n",
      "    >>> plt.show()\n",
      "\n",
      "    >>> plt.figure()\n",
      "    <Figure size 640x480 with 0 Axes>\n",
      "    >>> A = fft(window, 2048) / 25.5\n",
      "    >>> mag = np.abs(fftshift(A))\n",
      "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
      "    >>> with np.errstate(divide='ignore', invalid='ignore'):\n",
      "    ...     response = 20 * np.log10(mag)\n",
      "    ...\n",
      "    >>> response = np.clip(response, -100, 100)\n",
      "    >>> plt.plot(freq, response)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Frequency response of the Hann window\")\n",
      "    Text(0.5, 1.0, 'Frequency response of the Hann window')\n",
      "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
      "    Text(0, 0.5, 'Magnitude [dB]')\n",
      "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
      "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
      "    >>> plt.axis('tight')\n",
      "    ...\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: bartlett\n",
      "@set_module('numpy')\n",
      "def bartlett(M):\n",
      "    if M < 1:\n",
      "        return array([], dtype=np.result_type(M, 0.0))\n",
      "    if M == 1:\n",
      "        return ones(1, dtype=np.result_type(M, 0.0))\n",
      "    n = arange(1-M, M, 2)\n",
      "    return where(less_equal(n, 0), 1 + n/(M-1), 1 - n/(M-1))\n",
      "docstring: bartlett\n",
      "\n",
      "    Return the Bartlett window.\n",
      "\n",
      "    The Bartlett window is very similar to a triangular window, except\n",
      "    that the end points are at zero.  It is often used in signal\n",
      "    processing for tapering a signal, without generating too much\n",
      "    ripple in the frequency domain.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    M : int\n",
      "        Number of points in the output window. If zero or less, an\n",
      "        empty array is returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : array\n",
      "        The triangular window, with the maximum value normalized to one\n",
      "        (the value one appears only if the number of samples is odd), with\n",
      "        the first and last samples equal to zero.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    blackman, hamming, hanning, kaiser\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The Bartlett window is defined as\n",
      "\n",
      "    .. math:: w(n) = \\frac{2}{M-1} \\left(\n",
      "              \\frac{M-1}{2} - \\left|n - \\frac{M-1}{2}\\right|\n",
      "              \\right)\n",
      "\n",
      "    Most references to the Bartlett window come from the signal processing\n",
      "    literature, where it is used as one of many windowing functions for\n",
      "    smoothing values.  Note that convolution with this window produces linear\n",
      "    interpolation.  It is also known as an apodization (which means \"removing\n",
      "    the foot\", i.e. smoothing discontinuities at the beginning and end of the\n",
      "    sampled signal) or tapering function. The Fourier transform of the\n",
      "    Bartlett window is the product of two sinc functions. Note the excellent\n",
      "    discussion in Kanasewich [2]_.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] M.S. Bartlett, \"Periodogram Analysis and Continuous Spectra\",\n",
      "           Biometrika 37, 1-16, 1950.\n",
      "    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\n",
      "           The University of Alberta Press, 1975, pp. 109-110.\n",
      "    .. [3] A.V. Oppenheim and R.W. Schafer, \"Discrete-Time Signal\n",
      "           Processing\", Prentice-Hall, 1999, pp. 468-471.\n",
      "    .. [4] Wikipedia, \"Window function\",\n",
      "           https://en.wikipedia.org/wiki/Window_function\n",
      "    .. [5] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n",
      "           \"Numerical Recipes\", Cambridge University Press, 1986, page 429.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> np.bartlett(12)\n",
      "    array([ 0.        ,  0.18181818,  0.36363636,  0.54545455,  0.72727273, # may vary\n",
      "            0.90909091,  0.90909091,  0.72727273,  0.54545455,  0.36363636,\n",
      "            0.18181818,  0.        ])\n",
      "\n",
      "    Plot the window and its frequency response (requires SciPy and matplotlib):\n",
      "\n",
      "    >>> from numpy.fft import fft, fftshift\n",
      "    >>> window = np.bartlett(51)\n",
      "    >>> plt.plot(window)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Bartlett window\")\n",
      "    Text(0.5, 1.0, 'Bartlett window')\n",
      "    >>> plt.ylabel(\"Amplitude\")\n",
      "    Text(0, 0.5, 'Amplitude')\n",
      "    >>> plt.xlabel(\"Sample\")\n",
      "    Text(0.5, 0, 'Sample')\n",
      "    >>> plt.show()\n",
      "\n",
      "    >>> plt.figure()\n",
      "    <Figure size 640x480 with 0 Axes>\n",
      "    >>> A = fft(window, 2048) / 25.5\n",
      "    >>> mag = np.abs(fftshift(A))\n",
      "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
      "    >>> with np.errstate(divide='ignore', invalid='ignore'):\n",
      "    ...     response = 20 * np.log10(mag)\n",
      "    ...\n",
      "    >>> response = np.clip(response, -100, 100)\n",
      "    >>> plt.plot(freq, response)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Frequency response of Bartlett window\")\n",
      "    Text(0.5, 1.0, 'Frequency response of Bartlett window')\n",
      "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
      "    Text(0, 0.5, 'Magnitude [dB]')\n",
      "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
      "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
      "    >>> _ = plt.axis('tight')\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: blackman\n",
      "@set_module('numpy')\n",
      "def blackman(M):\n",
      "    if M < 1:\n",
      "        return array([], dtype=np.result_type(M, 0.0))\n",
      "    if M == 1:\n",
      "        return ones(1, dtype=np.result_type(M, 0.0))\n",
      "    n = arange(1-M, M, 2)\n",
      "    return 0.42 + 0.5*cos(pi*n/(M-1)) + 0.08*cos(2.0*pi*n/(M-1))\n",
      "docstring: blackman\n",
      "\n",
      "    Return the Blackman window.\n",
      "\n",
      "    The Blackman window is a taper formed by using the first three\n",
      "    terms of a summation of cosines. It was designed to have close to the\n",
      "    minimal leakage possible.  It is close to optimal, only slightly worse\n",
      "    than a Kaiser window.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    M : int\n",
      "        Number of points in the output window. If zero or less, an empty\n",
      "        array is returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The window, with the maximum value normalized to one (the value one\n",
      "        appears only if the number of samples is odd).\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    bartlett, hamming, hanning, kaiser\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The Blackman window is defined as\n",
      "\n",
      "    .. math::  w(n) = 0.42 - 0.5 \\cos(2\\pi n/M) + 0.08 \\cos(4\\pi n/M)\n",
      "\n",
      "    Most references to the Blackman window come from the signal processing\n",
      "    literature, where it is used as one of many windowing functions for\n",
      "    smoothing values.  It is also known as an apodization (which means\n",
      "    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n",
      "    and end of the sampled signal) or tapering function. It is known as a\n",
      "    \"near optimal\" tapering function, almost as good (by some measures)\n",
      "    as the kaiser window.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    Blackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra,\n",
      "    Dover Publications, New York.\n",
      "\n",
      "    Oppenheim, A.V., and R.W. Schafer. Discrete-Time Signal Processing.\n",
      "    Upper Saddle River, NJ: Prentice-Hall, 1999, pp. 468-471.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> np.blackman(12)\n",
      "    array([-1.38777878e-17,   3.26064346e-02,   1.59903635e-01, # may vary\n",
      "            4.14397981e-01,   7.36045180e-01,   9.67046769e-01,\n",
      "            9.67046769e-01,   7.36045180e-01,   4.14397981e-01,\n",
      "            1.59903635e-01,   3.26064346e-02,  -1.38777878e-17])\n",
      "\n",
      "    Plot the window and the frequency response:\n",
      "\n",
      "    >>> from numpy.fft import fft, fftshift\n",
      "    >>> window = np.blackman(51)\n",
      "    >>> plt.plot(window)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Blackman window\")\n",
      "    Text(0.5, 1.0, 'Blackman window')\n",
      "    >>> plt.ylabel(\"Amplitude\")\n",
      "    Text(0, 0.5, 'Amplitude')\n",
      "    >>> plt.xlabel(\"Sample\")\n",
      "    Text(0.5, 0, 'Sample')\n",
      "    >>> plt.show()\n",
      "\n",
      "    >>> plt.figure()\n",
      "    <Figure size 640x480 with 0 Axes>\n",
      "    >>> A = fft(window, 2048) / 25.5\n",
      "    >>> mag = np.abs(fftshift(A))\n",
      "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
      "    >>> with np.errstate(divide='ignore', invalid='ignore'):\n",
      "    ...     response = 20 * np.log10(mag)\n",
      "    ...\n",
      "    >>> response = np.clip(response, -100, 100)\n",
      "    >>> plt.plot(freq, response)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Frequency response of Blackman window\")\n",
      "    Text(0.5, 1.0, 'Frequency response of Blackman window')\n",
      "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
      "    Text(0, 0.5, 'Magnitude [dB]')\n",
      "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
      "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
      "    >>> _ = plt.axis('tight')\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: kaiser\n",
      "@set_module('numpy')\n",
      "def kaiser(M, beta):\n",
      "    if M == 1:\n",
      "        return np.ones(1, dtype=np.result_type(M, 0.0))\n",
      "    n = arange(0, M)\n",
      "    alpha = (M-1)/2.0\n",
      "    return i0(beta * sqrt(1-((n-alpha)/alpha)**2.0))/i0(float(beta))\n",
      "docstring: kaiser\n",
      "\n",
      "    Return the Kaiser window.\n",
      "\n",
      "    The Kaiser window is a taper formed by using a Bessel function.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    M : int\n",
      "        Number of points in the output window. If zero or less, an\n",
      "        empty array is returned.\n",
      "    beta : float\n",
      "        Shape parameter for window.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : array\n",
      "        The window, with the maximum value normalized to one (the value\n",
      "        one appears only if the number of samples is odd).\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    bartlett, blackman, hamming, hanning\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The Kaiser window is defined as\n",
      "\n",
      "    .. math::  w(n) = I_0\\left( \\beta \\sqrt{1-\\frac{4n^2}{(M-1)^2}}\n",
      "               \\right)/I_0(\\beta)\n",
      "\n",
      "    with\n",
      "\n",
      "    .. math:: \\quad -\\frac{M-1}{2} \\leq n \\leq \\frac{M-1}{2},\n",
      "\n",
      "    where :math:`I_0` is the modified zeroth-order Bessel function.\n",
      "\n",
      "    The Kaiser was named for Jim Kaiser, who discovered a simple\n",
      "    approximation to the DPSS window based on Bessel functions.  The Kaiser\n",
      "    window is a very good approximation to the Digital Prolate Spheroidal\n",
      "    Sequence, or Slepian window, which is the transform which maximizes the\n",
      "    energy in the main lobe of the window relative to total energy.\n",
      "\n",
      "    The Kaiser can approximate many other windows by varying the beta\n",
      "    parameter.\n",
      "\n",
      "    ====  =======================\n",
      "    beta  Window shape\n",
      "    ====  =======================\n",
      "    0     Rectangular\n",
      "    5     Similar to a Hamming\n",
      "    6     Similar to a Hanning\n",
      "    8.6   Similar to a Blackman\n",
      "    ====  =======================\n",
      "\n",
      "    A beta value of 14 is probably a good starting point. Note that as beta\n",
      "    gets large, the window narrows, and so the number of samples needs to be\n",
      "    large enough to sample the increasingly narrow spike, otherwise NaNs will\n",
      "    get returned.\n",
      "\n",
      "    Most references to the Kaiser window come from the signal processing\n",
      "    literature, where it is used as one of many windowing functions for\n",
      "    smoothing values.  It is also known as an apodization (which means\n",
      "    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n",
      "    and end of the sampled signal) or tapering function.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] J. F. Kaiser, \"Digital Filters\" - Ch 7 in \"Systems analysis by\n",
      "           digital computer\", Editors: F.F. Kuo and J.F. Kaiser, p 218-285.\n",
      "           John Wiley and Sons, New York, (1966).\n",
      "    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\n",
      "           University of Alberta Press, 1975, pp. 177-178.\n",
      "    .. [3] Wikipedia, \"Window function\",\n",
      "           https://en.wikipedia.org/wiki/Window_function\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> np.kaiser(12, 14)\n",
      "     array([7.72686684e-06, 3.46009194e-03, 4.65200189e-02, # may vary\n",
      "            2.29737120e-01, 5.99885316e-01, 9.45674898e-01,\n",
      "            9.45674898e-01, 5.99885316e-01, 2.29737120e-01,\n",
      "            4.65200189e-02, 3.46009194e-03, 7.72686684e-06])\n",
      "\n",
      "\n",
      "    Plot the window and the frequency response:\n",
      "\n",
      "    >>> from numpy.fft import fft, fftshift\n",
      "    >>> window = np.kaiser(51, 14)\n",
      "    >>> plt.plot(window)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Kaiser window\")\n",
      "    Text(0.5, 1.0, 'Kaiser window')\n",
      "    >>> plt.ylabel(\"Amplitude\")\n",
      "    Text(0, 0.5, 'Amplitude')\n",
      "    >>> plt.xlabel(\"Sample\")\n",
      "    Text(0.5, 0, 'Sample')\n",
      "    >>> plt.show()\n",
      "\n",
      "    >>> plt.figure()\n",
      "    <Figure size 640x480 with 0 Axes>\n",
      "    >>> A = fft(window, 2048) / 25.5\n",
      "    >>> mag = np.abs(fftshift(A))\n",
      "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
      "    >>> response = 20 * np.log10(mag)\n",
      "    >>> response = np.clip(response, -100, 100)\n",
      "    >>> plt.plot(freq, response)\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.title(\"Frequency response of Kaiser window\")\n",
      "    Text(0.5, 1.0, 'Frequency response of Kaiser window')\n",
      "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
      "    Text(0, 0.5, 'Magnitude [dB]')\n",
      "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
      "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
      "    >>> plt.axis('tight')\n",
      "    (-0.5, 0.5, -100.0, ...) # may vary\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: trapz\n",
      "@array_function_dispatch(_trapz_dispatcher)\n",
      "def trapz(y, x=None, dx=1.0, axis=-1):\n",
      "    r\"\"\"\n",
      "    Integrate along the given axis using the composite trapezoidal rule.\n",
      "    If `x` is provided, the integration happens in sequence along its\n",
      "    elements - they are not sorted.\n",
      "    Integrate `y` (`x`) along each 1d slice on the given axis, compute\n",
      "    :math:`\\int y(x) dx`.\n",
      "    When `x` is specified, this integrates along the parametric curve,\n",
      "    computing :math:`\\int_t y(t) dt =\n",
      "    \\int_t y(t) \\left.\\frac{dx}{dt}\\right|_{x=x(t)} dt`.\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like\n",
      "        Input array to integrate.\n",
      "    x : array_like, optional\n",
      "        The sample points corresponding to the `y` values. If `x` is None,\n",
      "        the sample points are assumed to be evenly spaced `dx` apart. The\n",
      "        default is None.\n",
      "    dx : scalar, optional\n",
      "        The spacing between sample points when `x` is None. The default is 1.\n",
      "    axis : int, optional\n",
      "        The axis along which to integrate.\n",
      "    Returns\n",
      "    -------\n",
      "    trapz : float or ndarray\n",
      "        Definite integral of `y` = n-dimensional array as approximated along\n",
      "        a single axis by the trapezoidal rule. If `y` is a 1-dimensional array,\n",
      "        then the result is a float. If `n` is greater than 1, then the result\n",
      "        is an `n`-1 dimensional array.\n",
      "    See Also\n",
      "    --------\n",
      "    sum, cumsum\n",
      "    Notes\n",
      "    -----\n",
      "    Image [2]_ illustrates trapezoidal rule -- y-axis locations of points\n",
      "    will be taken from `y` array, by default x-axis distances between\n",
      "    points will be 1.0, alternatively they can be provided with `x` array\n",
      "    or with `dx` scalar.  Return value will be equal to combined area under\n",
      "    the red lines.\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Wikipedia page: https://en.wikipedia.org/wiki/Trapezoidal_rule\n",
      "    .. [2] Illustration image:\n",
      "           https://en.wikipedia.org/wiki/File:Composite_trapezoidal_rule_illustration.png\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.trapz([1,2,3])\n",
      "    4.0\n",
      "    >>> np.trapz([1,2,3], x=[4,6,8])\n",
      "    8.0\n",
      "    >>> np.trapz([1,2,3], dx=2)\n",
      "    8.0\n",
      "    Using a decreasing `x` corresponds to integrating in reverse:\n",
      "    >>> np.trapz([1,2,3], x=[8,6,4])\n",
      "    -8.0\n",
      "    More generally `x` is used to integrate along a parametric curve.\n",
      "    This finds the area of a circle, noting we repeat the sample which closes\n",
      "    the curve:\n",
      "    >>> theta = np.linspace(0, 2 * np.pi, num=1000, endpoint=True)\n",
      "    >>> np.trapz(np.cos(theta), x=np.sin(theta))\n",
      "    3.141571941375841\n",
      "    >>> a = np.arange(6).reshape(2, 3)\n",
      "    >>> a\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.trapz(a, axis=0)\n",
      "    array([1.5, 2.5, 3.5])\n",
      "    >>> np.trapz(a, axis=1)\n",
      "    array([2.,  8.])\n",
      "    \"\"\"\n",
      "    y = asanyarray(y)\n",
      "    if x is None:\n",
      "        d = dx\n",
      "    else:\n",
      "        x = asanyarray(x)\n",
      "        if x.ndim == 1:\n",
      "            d = diff(x)\n",
      " Operations didn't work, cast to ndarray\n",
      "        d = np.asarray(d)\n",
      "        y = np.asarray(y)\n",
      "        ret = add.reduce(d * (y[tuple(slice1)]+y[tuple(slice2)])/2.0, axis)\n",
      "    return ret\n",
      "docstring: trapz\n",
      "\n",
      "    Integrate along the given axis using the composite trapezoidal rule.\n",
      "\n",
      "    If `x` is provided, the integration happens in sequence along its\n",
      "    elements - they are not sorted.\n",
      "\n",
      "    Integrate `y` (`x`) along each 1d slice on the given axis, compute\n",
      "    :math:`\\int y(x) dx`.\n",
      "    When `x` is specified, this integrates along the parametric curve,\n",
      "    computing :math:`\\int_t y(t) dt =\n",
      "    \\int_t y(t) \\left.\\frac{dx}{dt}\\right|_{x=x(t)} dt`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    y : array_like\n",
      "        Input array to integrate.\n",
      "    x : array_like, optional\n",
      "        The sample points corresponding to the `y` values. If `x` is None,\n",
      "        the sample points are assumed to be evenly spaced `dx` apart. The\n",
      "        default is None.\n",
      "    dx : scalar, optional\n",
      "        The spacing between sample points when `x` is None. The default is 1.\n",
      "    axis : int, optional\n",
      "        The axis along which to integrate.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    trapz : float or ndarray\n",
      "        Definite integral of `y` = n-dimensional array as approximated along\n",
      "        a single axis by the trapezoidal rule. If `y` is a 1-dimensional array,\n",
      "        then the result is a float. If `n` is greater than 1, then the result\n",
      "        is an `n`-1 dimensional array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    sum, cumsum\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Image [2]_ illustrates trapezoidal rule -- y-axis locations of points\n",
      "    will be taken from `y` array, by default x-axis distances between\n",
      "    points will be 1.0, alternatively they can be provided with `x` array\n",
      "    or with `dx` scalar.  Return value will be equal to combined area under\n",
      "    the red lines.\n",
      "\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Wikipedia page: https://en.wikipedia.org/wiki/Trapezoidal_rule\n",
      "\n",
      "    .. [2] Illustration image:\n",
      "           https://en.wikipedia.org/wiki/File:Composite_trapezoidal_rule_illustration.png\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.trapz([1,2,3])\n",
      "    4.0\n",
      "    >>> np.trapz([1,2,3], x=[4,6,8])\n",
      "    8.0\n",
      "    >>> np.trapz([1,2,3], dx=2)\n",
      "    8.0\n",
      "\n",
      "    Using a decreasing `x` corresponds to integrating in reverse:\n",
      "\n",
      "    >>> np.trapz([1,2,3], x=[8,6,4])\n",
      "    -8.0\n",
      "\n",
      "    More generally `x` is used to integrate along a parametric curve.\n",
      "    This finds the area of a circle, noting we repeat the sample which closes\n",
      "    the curve:\n",
      "\n",
      "    >>> theta = np.linspace(0, 2 * np.pi, num=1000, endpoint=True)\n",
      "    >>> np.trapz(np.cos(theta), x=np.sin(theta))\n",
      "    3.141571941375841\n",
      "\n",
      "    >>> a = np.arange(6).reshape(2, 3)\n",
      "    >>> a\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.trapz(a, axis=0)\n",
      "    array([1.5, 2.5, 3.5])\n",
      "    >>> np.trapz(a, axis=1)\n",
      "    array([2.,  8.])\n",
      "    \n",
      "code: i0\n",
      "@array_function_dispatch(_i0_dispatcher)\n",
      "def i0(x):\n",
      "    x = np.asanyarray(x)\n",
      "    if x.dtype.kind == 'c':\n",
      "        raise TypeError(\"i0 not supported for complex values\")\n",
      "    if x.dtype.kind != 'f':\n",
      "        x = x.astype(float)\n",
      "    x = np.abs(x)\n",
      "    return piecewise(x, [x <= 8.0], [_i0_1, _i0_2])\n",
      "docstring: i0\n",
      "\n",
      "    Modified Bessel function of the first kind, order 0.\n",
      "\n",
      "    Usually denoted :math:`I_0`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like of float\n",
      "        Argument of the Bessel function.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray, shape = x.shape, dtype = float\n",
      "        The modified Bessel function evaluated at each of the elements of `x`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    scipy.special.i0, scipy.special.iv, scipy.special.ive\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The scipy implementation is recommended over this function: it is a\n",
      "    proper ufunc written in C, and more than an order of magnitude faster.\n",
      "\n",
      "    We use the algorithm published by Clenshaw [1]_ and referenced by\n",
      "    Abramowitz and Stegun [2]_, for which the function domain is\n",
      "    partitioned into the two intervals [0,8] and (8,inf), and Chebyshev\n",
      "    polynomial expansions are employed in each interval. Relative error on\n",
      "    the domain [0,30] using IEEE arithmetic is documented [3]_ as having a\n",
      "    peak of 5.8e-16 with an rms of 1.4e-16 (n = 30000).\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] C. W. Clenshaw, \"Chebyshev series for mathematical functions\", in\n",
      "           *National Physical Laboratory Mathematical Tables*, vol. 5, London:\n",
      "           Her Majesty's Stationery Office, 1962.\n",
      "    .. [2] M. Abramowitz and I. A. Stegun, *Handbook of Mathematical\n",
      "           Functions*, 10th printing, New York: Dover, 1964, pp. 379.\n",
      "           https://personal.math.ubc.ca/~cbm/aands/page_379.htm\n",
      "    .. [3] https://metacpan.org/pod/distribution/Math-Cephes/lib/Math/Cephes.pod#i0:-Modified-Bessel-function-of-order-zero\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.i0(0.)\n",
      "    array(1.0)\n",
      "    >>> np.i0([0, 1, 2, 3])\n",
      "    array([1.        , 1.26606588, 2.2795853 , 4.88079259])\n",
      "\n",
      "    \n",
      "code: add_newdoc\n",
      "def add_newdoc(place, obj, doc, warn_on_python=True):\n",
      "    new = getattr(__import__(place, globals(), {}, [obj]), obj)\n",
      "    if isinstance(doc, str):\n",
      "        _add_docstring(new, doc.strip(), warn_on_python)\n",
      "    elif isinstance(doc, tuple):\n",
      "        attr, docstring = doc\n",
      "        _add_docstring(getattr(new, attr), docstring.strip(), warn_on_python)\n",
      "    elif isinstance(doc, list):\n",
      "        for attr, docstring in doc:\n",
      "            _add_docstring(getattr(new, attr), docstring.strip(), warn_on_python)\n",
      "docstring: add_newdoc\n",
      "\n",
      "    Add documentation to an existing object, typically one defined in C\n",
      "\n",
      "    The purpose is to allow easier editing of the docstrings without requiring\n",
      "    a re-compile. This exists primarily for internal use within numpy itself.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    place : str\n",
      "        The absolute name of the module to import from\n",
      "    obj : str\n",
      "        The name of the object to add documentation to, typically a class or\n",
      "        function name\n",
      "    doc : {str, Tuple[str, str], List[Tuple[str, str]]}\n",
      "        If a string, the documentation to apply to `obj`\n",
      "\n",
      "        If a tuple, then the first element is interpreted as an attribute of\n",
      "        `obj` and the second as the docstring to apply - ``(method, docstring)``\n",
      "\n",
      "        If a list, then each element of the list should be a tuple of length\n",
      "        two - ``[(method1, docstring1), (method2, docstring2), ...]``\n",
      "    warn_on_python : bool\n",
      "        If True, the default, emit `UserWarning` if this is used to attach\n",
      "        documentation to a pure-python object.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This routine never raises an error if the docstring can't be written, but\n",
      "    will raise an error if the object being documented does not exist.\n",
      "\n",
      "    This routine cannot modify read-only docstrings, as appear\n",
      "    in new-style classes or built-in functions. Because this\n",
      "    routine never raises an error the caller must check manually\n",
      "    that the docstrings were changed.\n",
      "\n",
      "    Since this function grabs the ``char *`` from a c-level str object and puts\n",
      "    it into the ``tp_doc`` slot of the type of `obj`, it violates a number of\n",
      "    C-API best-practices, by:\n",
      "\n",
      "    - modifying a `PyTypeObject` after calling `PyType_Ready`\n",
      "    - calling `Py_INCREF` on the str and losing the reference, so the str\n",
      "      will never be released\n",
      "\n",
      "    If possible it should be avoided.\n",
      "    \n",
      "code: add_docstring\n",
      "\n",
      "docstring: add_docstring\n",
      "add_docstring(obj, docstring)\n",
      "\n",
      "    Add a docstring to a built-in obj if possible.\n",
      "    If the obj already has a docstring raise a RuntimeError\n",
      "    If this routine does not know how to add a docstring to the object\n",
      "    raise a TypeError\n",
      "code: meshgrid\n",
      "@array_function_dispatch(_meshgrid_dispatcher)\n",
      "def meshgrid(*xi, copy=True, sparse=False, indexing='xy'):\n",
      "    ndim = len(xi)\n",
      "    if indexing not in ['xy', 'ij']:\n",
      "        raise ValueError(\n",
      "            \"Valid values for `indexing` are 'xy' and 'ij'.\")\n",
      "    s0 = (1,) * ndim\n",
      "    output = [np.asanyarray(x).reshape(s0[:i] + (-1,) + s0[i + 1:])\n",
      "              for i, x in enumerate(xi)]\n",
      "    if indexing == 'xy' and ndim > 1:\n",
      " Return the full N-D matrix (not only the 1-D vector)\n",
      "        output = np.broadcast_arrays(*output, subok=True)\n",
      "    if copy:\n",
      "        output = [x.copy() for x in output]\n",
      "    return output\n",
      "docstring: meshgrid\n",
      "\n",
      "    Return coordinate matrices from coordinate vectors.\n",
      "\n",
      "    Make N-D coordinate arrays for vectorized evaluations of\n",
      "    N-D scalar/vector fields over N-D grids, given\n",
      "    one-dimensional coordinate arrays x1, x2,..., xn.\n",
      "\n",
      "    .. versionchanged:: 1.9\n",
      "       1-D and 0-D cases are allowed.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x1, x2,..., xn : array_like\n",
      "        1-D arrays representing the coordinates of a grid.\n",
      "    indexing : {'xy', 'ij'}, optional\n",
      "        Cartesian ('xy', default) or matrix ('ij') indexing of output.\n",
      "        See Notes for more details.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "    sparse : bool, optional\n",
      "        If True the shape of the returned coordinate array for dimension *i*\n",
      "        is reduced from ``(N1, ..., Ni, ... Nn)`` to\n",
      "        ``(1, ..., 1, Ni, 1, ..., 1)``.  These sparse coordinate grids are\n",
      "        intended to be use with :ref:`basics.broadcasting`.  When all\n",
      "        coordinates are used in an expression, broadcasting still leads to a\n",
      "        fully-dimensonal result array.\n",
      "\n",
      "        Default is False.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "    copy : bool, optional\n",
      "        If False, a view into the original arrays are returned in order to\n",
      "        conserve memory.  Default is True.  Please note that\n",
      "        ``sparse=False, copy=False`` will likely return non-contiguous\n",
      "        arrays.  Furthermore, more than one element of a broadcast array\n",
      "        may refer to a single memory location.  If you need to write to the\n",
      "        arrays, make copies first.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    X1, X2,..., XN : ndarray\n",
      "        For vectors `x1`, `x2`,..., `xn` with lengths ``Ni=len(xi)``,\n",
      "        returns ``(N1, N2, N3,..., Nn)`` shaped arrays if indexing='ij'\n",
      "        or ``(N2, N1, N3,..., Nn)`` shaped arrays if indexing='xy'\n",
      "        with the elements of `xi` repeated to fill the matrix along\n",
      "        the first dimension for `x1`, the second for `x2` and so on.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This function supports both indexing conventions through the indexing\n",
      "    keyword argument.  Giving the string 'ij' returns a meshgrid with\n",
      "    matrix indexing, while 'xy' returns a meshgrid with Cartesian indexing.\n",
      "    In the 2-D case with inputs of length M and N, the outputs are of shape\n",
      "    (N, M) for 'xy' indexing and (M, N) for 'ij' indexing.  In the 3-D case\n",
      "    with inputs of length M, N and P, outputs are of shape (N, M, P) for\n",
      "    'xy' indexing and (M, N, P) for 'ij' indexing.  The difference is\n",
      "    illustrated by the following code snippet::\n",
      "\n",
      "        xv, yv = np.meshgrid(x, y, indexing='ij')\n",
      "        for i in range(nx):\n",
      "            for j in range(ny):\n",
      "                # treat xv[i,j], yv[i,j]\n",
      "\n",
      "        xv, yv = np.meshgrid(x, y, indexing='xy')\n",
      "        for i in range(nx):\n",
      "            for j in range(ny):\n",
      "                # treat xv[j,i], yv[j,i]\n",
      "\n",
      "    In the 1-D and 0-D case, the indexing and sparse keywords have no effect.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    mgrid : Construct a multi-dimensional \"meshgrid\" using indexing notation.\n",
      "    ogrid : Construct an open multi-dimensional \"meshgrid\" using indexing\n",
      "            notation.\n",
      "    how-to-index\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> nx, ny = (3, 2)\n",
      "    >>> x = np.linspace(0, 1, nx)\n",
      "    >>> y = np.linspace(0, 1, ny)\n",
      "    >>> xv, yv = np.meshgrid(x, y)\n",
      "    >>> xv\n",
      "    array([[0. , 0.5, 1. ],\n",
      "           [0. , 0.5, 1. ]])\n",
      "    >>> yv\n",
      "    array([[0.,  0.,  0.],\n",
      "           [1.,  1.,  1.]])\n",
      "\n",
      "    The result of `meshgrid` is a coordinate grid:\n",
      "\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> plt.plot(xv, yv, marker='o', color='k', linestyle='none')\n",
      "    >>> plt.show()\n",
      "\n",
      "    You can create sparse output arrays to save memory and computation time.\n",
      "\n",
      "    >>> xv, yv = np.meshgrid(x, y, sparse=True)\n",
      "    >>> xv\n",
      "    array([[0. ,  0.5,  1. ]])\n",
      "    >>> yv\n",
      "    array([[0.],\n",
      "           [1.]])\n",
      "\n",
      "    `meshgrid` is very useful to evaluate functions on a grid. If the\n",
      "    function depends on all coordinates, both dense and sparse outputs can be\n",
      "    used.\n",
      "\n",
      "    >>> x = np.linspace(-5, 5, 101)\n",
      "    >>> y = np.linspace(-5, 5, 101)\n",
      "    >>> # full coordinate arrays\n",
      "    >>> xx, yy = np.meshgrid(x, y)\n",
      "    >>> zz = np.sqrt(xx**2 + yy**2)\n",
      "    >>> xx.shape, yy.shape, zz.shape\n",
      "    ((101, 101), (101, 101), (101, 101))\n",
      "    >>> # sparse coordinate arrays\n",
      "    >>> xs, ys = np.meshgrid(x, y, sparse=True)\n",
      "    >>> zs = np.sqrt(xs**2 + ys**2)\n",
      "    >>> xs.shape, ys.shape, zs.shape\n",
      "    ((1, 101), (101, 1), (101, 101))\n",
      "    >>> np.array_equal(zz, zs)\n",
      "    True\n",
      "\n",
      "    >>> h = plt.contourf(x, y, zs)\n",
      "    >>> plt.axis('scaled')\n",
      "    >>> plt.colorbar()\n",
      "    >>> plt.show()\n",
      "    \n",
      "code: delete\n",
      "@array_function_dispatch(_delete_dispatcher)\n",
      "def delete(arr, obj, axis=None):\n",
      "    wrap = None\n",
      "    if type(arr) is not ndarray:\n",
      "        try:\n",
      "            wrap = arr.__array_wrap__\n",
      "        except AttributeError:\n",
      "            pass\n",
      "    arr = asarray(arr)\n",
      "    ndim = arr.ndim\n",
      "    arrorder = 'F' if arr.flags.fnc else 'C'\n",
      "    if axis is None:\n",
      "        if ndim != 1:\n",
      "            arr = arr.ravel()\n",
      " Invert if step is negative:\n",
      "        if step < 0:\n",
      "            step = -step\n",
      "            start = xr[-1]\n",
      "            stop = xr[0] + 1\n",
      "        newshape[axis] -= numtodel\n",
      "        new = empty(newshape, arr.dtype, arrorder)\n",
      " copy end chunk\n",
      "        if stop == N:\n",
      "            pass\n",
      "        else:\n",
      "            slobj[axis] = slice(stop-numtodel, None)\n",
      "            slobj2 = [slice(None)]*ndim\n",
      "            slobj2[axis] = slice(stop, None)\n",
      "            new[tuple(slobj)] = arr[tuple(slobj2)]\n",
      " use array indexing.\n",
      "            keep = ones(stop-start, dtype=bool)\n",
      "            keep[:stop-start:step] = False\n",
      "            slobj[axis] = slice(start, stop-numtodel)\n",
      "            slobj2 = [slice(None)]*ndim\n",
      "            slobj2[axis] = slice(start, stop)\n",
      "            arr = arr[tuple(slobj2)]\n",
      "            slobj2[axis] = keep\n",
      "            new[tuple(slobj)] = arr[tuple(slobj2)]\n",
      "        if wrap:\n",
      "            return wrap(new)\n",
      "        else:\n",
      "            return new\n",
      "    if isinstance(obj, (int, integer)) and not isinstance(obj, bool):\n",
      "        single_value = True\n",
      "    else:\n",
      "        single_value = False\n",
      "        _obj = obj\n",
      "        obj = np.asarray(obj)\n",
      " is really too generic:\n",
      "        if obj.size == 0 and not isinstance(_obj, np.ndarray):\n",
      "            obj = obj.astype(intp)\n",
      "        elif obj.size == 1 and obj.dtype.kind in \"ui\":\n",
      " (most dtypes, except boolean, should just fail later).\n",
      "            obj = obj.item()\n",
      "            single_value = True\n",
      "    if single_value:\n",
      " optimization, the other branch is slower\n",
      "            keep = ~obj\n",
      "        else:\n",
      "            keep = ones(N, dtype=bool)\n",
      "            keep[obj,] = False\n",
      "        slobj[axis] = keep\n",
      "        new = arr[tuple(slobj)]\n",
      "    if wrap:\n",
      "        return wrap(new)\n",
      "    else:\n",
      "        return new\n",
      "docstring: delete\n",
      "\n",
      "    Return a new array with sub-arrays along an axis deleted. For a one\n",
      "    dimensional array, this returns those entries not returned by\n",
      "    `arr[obj]`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : array_like\n",
      "        Input array.\n",
      "    obj : slice, int or array of ints\n",
      "        Indicate indices of sub-arrays to remove along the specified axis.\n",
      "\n",
      "        .. versionchanged:: 1.19.0\n",
      "            Boolean indices are now treated as a mask of elements to remove,\n",
      "            rather than being cast to the integers 0 and 1.\n",
      "\n",
      "    axis : int, optional\n",
      "        The axis along which to delete the subarray defined by `obj`.\n",
      "        If `axis` is None, `obj` is applied to the flattened array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        A copy of `arr` with the elements specified by `obj` removed. Note\n",
      "        that `delete` does not occur in-place. If `axis` is None, `out` is\n",
      "        a flattened array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    insert : Insert elements into an array.\n",
      "    append : Append elements at the end of an array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Often it is preferable to use a boolean mask. For example:\n",
      "\n",
      "    >>> arr = np.arange(12) + 1\n",
      "    >>> mask = np.ones(len(arr), dtype=bool)\n",
      "    >>> mask[[0,2,4]] = False\n",
      "    >>> result = arr[mask,...]\n",
      "\n",
      "    Is equivalent to ``np.delete(arr, [0,2,4], axis=0)``, but allows further\n",
      "    use of `mask`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
      "    >>> arr\n",
      "    array([[ 1,  2,  3,  4],\n",
      "           [ 5,  6,  7,  8],\n",
      "           [ 9, 10, 11, 12]])\n",
      "    >>> np.delete(arr, 1, 0)\n",
      "    array([[ 1,  2,  3,  4],\n",
      "           [ 9, 10, 11, 12]])\n",
      "\n",
      "    >>> np.delete(arr, np.s_[::2], 1)\n",
      "    array([[ 2,  4],\n",
      "           [ 6,  8],\n",
      "           [10, 12]])\n",
      "    >>> np.delete(arr, [1,3,5], None)\n",
      "    array([ 1,  3,  5,  7,  8,  9, 10, 11, 12])\n",
      "\n",
      "    \n",
      "code: insert\n",
      "@array_function_dispatch(_insert_dispatcher)\n",
      "def insert(arr, obj, values, axis=None):\n",
      "    wrap = None\n",
      "    if type(arr) is not ndarray:\n",
      "        try:\n",
      "            wrap = arr.__array_wrap__\n",
      "        except AttributeError:\n",
      "            pass\n",
      "    arr = asarray(arr)\n",
      "    ndim = arr.ndim\n",
      "    arrorder = 'F' if arr.flags.fnc else 'C'\n",
      "    if axis is None:\n",
      "        if ndim != 1:\n",
      "            arr = arr.ravel()\n",
      " turn it into a range object\n",
      "        indices = arange(*obj.indices(N), dtype=intp)\n",
      "    else:\n",
      " See also delete\n",
      " Code after warning period:\n",
      "    raise ValueError('boolean array argument obj to insert '\n",
      "indices = np.flatnonzero(obj)\n",
      "        elif indices.ndim > 1:\n",
      "            raise ValueError(\n",
      "                \"index array argument obj to insert must be one dimensional \"\n",
      "                \"or scalar\")\n",
      "    if indices.size == 1:\n",
      "        index = indices.item()\n",
      "        if index < -N or index > N:\n",
      "            raise IndexError(f\"index {obj} is out of bounds for axis {axis} \"\n",
      "                             f\"with size {N}\")\n",
      "        if (index < 0):\n",
      "            index += N\n",
      " that:\n",
      "        values = array(values, copy=False, ndmin=arr.ndim, dtype=arr.dtype)\n",
      "        if indices.ndim == 0:\n",
      " very different from a[:,[0],:] = ...! This changes values so that\n",
      " Can safely cast the empty list to intp\n",
      "        indices = indices.astype(intp)\n",
      "    indices[indices < 0] += N\n",
      "    numnew = len(indices)\n",
      "    order = indices.argsort(kind='mergesort')   # stable sort\n",
      "    indices[order] += np.arange(numnew)\n",
      "    newshape[axis] += numnew\n",
      "    old_mask = ones(newshape[axis], dtype=bool)\n",
      "    old_mask[indices] = False\n",
      "    new = empty(newshape, arr.dtype, arrorder)\n",
      "    slobj2 = [slice(None)]*ndim\n",
      "    slobj[axis] = indices\n",
      "    slobj2[axis] = old_mask\n",
      "    new[tuple(slobj)] = values\n",
      "    new[tuple(slobj2)] = arr\n",
      "    if wrap:\n",
      "        return wrap(new)\n",
      "    return new\n",
      "docstring: insert\n",
      "\n",
      "    Insert values along the given axis before the given indices.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : array_like\n",
      "        Input array.\n",
      "    obj : int, slice or sequence of ints\n",
      "        Object that defines the index or indices before which `values` is\n",
      "        inserted.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "\n",
      "        Support for multiple insertions when `obj` is a single scalar or a\n",
      "        sequence with one element (similar to calling insert multiple\n",
      "        times).\n",
      "    values : array_like\n",
      "        Values to insert into `arr`. If the type of `values` is different\n",
      "        from that of `arr`, `values` is converted to the type of `arr`.\n",
      "        `values` should be shaped so that ``arr[...,obj,...] = values``\n",
      "        is legal.\n",
      "    axis : int, optional\n",
      "        Axis along which to insert `values`.  If `axis` is None then `arr`\n",
      "        is flattened first.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        A copy of `arr` with `values` inserted.  Note that `insert`\n",
      "        does not occur in-place: a new array is returned. If\n",
      "        `axis` is None, `out` is a flattened array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    append : Append elements at the end of an array.\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    delete : Delete elements from an array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Note that for higher dimensional inserts ``obj=0`` behaves very different\n",
      "    from ``obj=[0]`` just like ``arr[:,0,:] = values`` is different from\n",
      "    ``arr[:,[0],:] = values``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 1], [2, 2], [3, 3]])\n",
      "    >>> a\n",
      "    array([[1, 1],\n",
      "           [2, 2],\n",
      "           [3, 3]])\n",
      "    >>> np.insert(a, 1, 5)\n",
      "    array([1, 5, 1, ..., 2, 3, 3])\n",
      "    >>> np.insert(a, 1, 5, axis=1)\n",
      "    array([[1, 5, 1],\n",
      "           [2, 5, 2],\n",
      "           [3, 5, 3]])\n",
      "\n",
      "    Difference between sequence and scalars:\n",
      "\n",
      "    >>> np.insert(a, [1], [[1],[2],[3]], axis=1)\n",
      "    array([[1, 1, 1],\n",
      "           [2, 2, 2],\n",
      "           [3, 3, 3]])\n",
      "    >>> np.array_equal(np.insert(a, 1, [1, 2, 3], axis=1),\n",
      "    ...                np.insert(a, [1], [[1],[2],[3]], axis=1))\n",
      "    True\n",
      "\n",
      "    >>> b = a.flatten()\n",
      "    >>> b\n",
      "    array([1, 1, 2, 2, 3, 3])\n",
      "    >>> np.insert(b, [2, 2], [5, 6])\n",
      "    array([1, 1, 5, ..., 2, 3, 3])\n",
      "\n",
      "    >>> np.insert(b, slice(2, 4), [5, 6])\n",
      "    array([1, 1, 5, ..., 2, 3, 3])\n",
      "\n",
      "    >>> np.insert(b, [2, 2], [7.13, False]) # type casting\n",
      "    array([1, 1, 7, ..., 2, 3, 3])\n",
      "\n",
      "    >>> x = np.arange(8).reshape(2, 4)\n",
      "    >>> idx = (1, 3)\n",
      "    >>> np.insert(x, idx, 999, axis=1)\n",
      "    array([[  0, 999,   1,   2, 999,   3],\n",
      "           [  4, 999,   5,   6, 999,   7]])\n",
      "\n",
      "    \n",
      "code: append\n",
      "@array_function_dispatch(_append_dispatcher)\n",
      "def append(arr, values, axis=None):\n",
      "    arr = asanyarray(arr)\n",
      "    if axis is None:\n",
      "        if arr.ndim != 1:\n",
      "            arr = arr.ravel()\n",
      "        values = ravel(values)\n",
      "        axis = arr.ndim-1\n",
      "    return concatenate((arr, values), axis=axis)\n",
      "docstring: append\n",
      "\n",
      "    Append values to the end of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : array_like\n",
      "        Values are appended to a copy of this array.\n",
      "    values : array_like\n",
      "        These values are appended to a copy of `arr`.  It must be of the\n",
      "        correct shape (the same shape as `arr`, excluding `axis`).  If\n",
      "        `axis` is not specified, `values` can be any shape and will be\n",
      "        flattened before use.\n",
      "    axis : int, optional\n",
      "        The axis along which `values` are appended.  If `axis` is not\n",
      "        given, both `arr` and `values` are flattened before use.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    append : ndarray\n",
      "        A copy of `arr` with `values` appended to `axis`.  Note that\n",
      "        `append` does not occur in-place: a new array is allocated and\n",
      "        filled.  If `axis` is None, `out` is a flattened array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    insert : Insert elements into an array.\n",
      "    delete : Delete elements from an array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]])\n",
      "    array([1, 2, 3, ..., 7, 8, 9])\n",
      "\n",
      "    When `axis` is specified, `values` must have the correct shape.\n",
      "\n",
      "    >>> np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6],\n",
      "           [7, 8, 9]])\n",
      "    >>> np.append([[1, 2, 3], [4, 5, 6]], [7, 8, 9], axis=0)\n",
      "    Traceback (most recent call last):\n",
      "        ...\n",
      "    ValueError: all the input arrays must have same number of dimensions, but\n",
      "    the array at index 0 has 2 dimension(s) and the array at index 1 has 1\n",
      "    dimension(s)\n",
      "\n",
      "    \n",
      "code: interp\n",
      "@array_function_dispatch(_interp_dispatcher)\n",
      "def interp(x, xp, fp, left=None, right=None, period=None):\n",
      "    fp = np.asarray(fp)\n",
      "    if np.iscomplexobj(fp):\n",
      "        interp_func = compiled_interp_complex\n",
      "        input_dtype = np.complex128\n",
      "    else:\n",
      "        interp_func = compiled_interp\n",
      "        input_dtype = np.float64\n",
      "    if period is not None:\n",
      "        if period == 0:\n",
      "            raise ValueError(\"period must be a non-zero value\")\n",
      "        period = abs(period)\n",
      "        left = None\n",
      "        right = None\n",
      "        x = np.asarray(x, dtype=np.float64)\n",
      "        xp = np.asarray(xp, dtype=np.float64)\n",
      "        fp = np.asarray(fp, dtype=input_dtype)\n",
      "        if xp.ndim != 1 or fp.ndim != 1:\n",
      "            raise ValueError(\"Data points must be 1-D sequences\")\n",
      "        if xp.shape[0] != fp.shape[0]:\n",
      "            raise ValueError(\"fp and xp are not of the same length\")\n",
      "        # normalizing periodic boundaries\n",
      "        x = x % period\n",
      "        xp = xp % period\n",
      "        asort_xp = np.argsort(xp)\n",
      "        xp = xp[asort_xp]\n",
      "        fp = fp[asort_xp]\n",
      "        xp = np.concatenate((xp[-1:]-period, xp, xp[0:1]+period))\n",
      "        fp = np.concatenate((fp[-1:], fp, fp[0:1]))\n",
      "    return interp_func(x, xp, fp, left, right)\n",
      "docstring: interp\n",
      "\n",
      "    One-dimensional linear interpolation for monotonically increasing sample points.\n",
      "\n",
      "    Returns the one-dimensional piecewise linear interpolant to a function\n",
      "    with given discrete data points (`xp`, `fp`), evaluated at `x`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        The x-coordinates at which to evaluate the interpolated values.\n",
      "\n",
      "    xp : 1-D sequence of floats\n",
      "        The x-coordinates of the data points, must be increasing if argument\n",
      "        `period` is not specified. Otherwise, `xp` is internally sorted after\n",
      "        normalizing the periodic boundaries with ``xp = xp % period``.\n",
      "\n",
      "    fp : 1-D sequence of float or complex\n",
      "        The y-coordinates of the data points, same length as `xp`.\n",
      "\n",
      "    left : optional float or complex corresponding to fp\n",
      "        Value to return for `x < xp[0]`, default is `fp[0]`.\n",
      "\n",
      "    right : optional float or complex corresponding to fp\n",
      "        Value to return for `x > xp[-1]`, default is `fp[-1]`.\n",
      "\n",
      "    period : None or float, optional\n",
      "        A period for the x-coordinates. This parameter allows the proper\n",
      "        interpolation of angular x-coordinates. Parameters `left` and `right`\n",
      "        are ignored if `period` is specified.\n",
      "\n",
      "        .. versionadded:: 1.10.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    y : float or complex (corresponding to fp) or ndarray\n",
      "        The interpolated values, same shape as `x`.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If `xp` and `fp` have different length\n",
      "        If `xp` or `fp` are not 1-D sequences\n",
      "        If `period == 0`\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    scipy.interpolate\n",
      "\n",
      "    Warnings\n",
      "    --------\n",
      "    The x-coordinate sequence is expected to be increasing, but this is not\n",
      "    explicitly enforced.  However, if the sequence `xp` is non-increasing,\n",
      "    interpolation results are meaningless.\n",
      "\n",
      "    Note that, since NaN is unsortable, `xp` also cannot contain NaNs.\n",
      "\n",
      "    A simple check for `xp` being strictly increasing is::\n",
      "\n",
      "        np.all(np.diff(xp) > 0)\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> xp = [1, 2, 3]\n",
      "    >>> fp = [3, 2, 0]\n",
      "    >>> np.interp(2.5, xp, fp)\n",
      "    1.0\n",
      "    >>> np.interp([0, 1, 1.5, 2.72, 3.14], xp, fp)\n",
      "    array([3.  , 3.  , 2.5 , 0.56, 0.  ])\n",
      "    >>> UNDEF = -99.0\n",
      "    >>> np.interp(3.14, xp, fp, right=UNDEF)\n",
      "    -99.0\n",
      "\n",
      "    Plot an interpolant to the sine function:\n",
      "\n",
      "    >>> x = np.linspace(0, 2*np.pi, 10)\n",
      "    >>> y = np.sin(x)\n",
      "    >>> xvals = np.linspace(0, 2*np.pi, 50)\n",
      "    >>> yinterp = np.interp(xvals, x, y)\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> plt.plot(x, y, 'o')\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.plot(xvals, yinterp, '-x')\n",
      "    [<matplotlib.lines.Line2D object at 0x...>]\n",
      "    >>> plt.show()\n",
      "\n",
      "    Interpolation with periodic x-coordinates:\n",
      "\n",
      "    >>> x = [-180, -170, -185, 185, -10, -5, 0, 365]\n",
      "    >>> xp = [190, -190, 350, -350]\n",
      "    >>> fp = [5, 10, 3, 4]\n",
      "    >>> np.interp(x, xp, fp, period=360)\n",
      "    array([7.5 , 5.  , 8.75, 6.25, 3.  , 3.25, 3.5 , 3.75])\n",
      "\n",
      "    Complex interpolation:\n",
      "\n",
      "    >>> x = [1.5, 4.0]\n",
      "    >>> xp = [2,3,5]\n",
      "    >>> fp = [1.0j, 0, 2+3j]\n",
      "    >>> np.interp(x, xp, fp)\n",
      "    array([0.+1.j , 1.+1.5j])\n",
      "\n",
      "    \n",
      "code: add_newdoc_ufunc\n",
      "\n",
      "docstring: add_newdoc_ufunc\n",
      "add_ufunc_docstring(ufunc, new_docstring)\n",
      "\n",
      "    Replace the docstring for a ufunc with new_docstring.\n",
      "    This method will only work if the current docstring for\n",
      "    the ufunc is NULL. (At the C level, i.e. when ufunc->doc is NULL.)\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ufunc : numpy.ufunc\n",
      "        A ufunc whose current doc is NULL.\n",
      "    new_docstring : string\n",
      "        The new docstring for the ufunc.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This method allocates memory for new_docstring on\n",
      "    the heap. Technically this creates a mempory leak, since this\n",
      "    memory will not be reclaimed until the end of the program\n",
      "    even if the ufunc itself is removed. However this will only\n",
      "    be a problem if the user is repeatedly creating ufuncs with\n",
      "    no documentation, adding documentation via add_newdoc_ufunc,\n",
      "    and then throwing away the ufunc.\n",
      "code: quantile\n",
      "@array_function_dispatch(_quantile_dispatcher)\n",
      "def quantile(a,\n",
      "             q,\n",
      "             axis=None,\n",
      "             out=None,\n",
      "             overwrite_input=False,\n",
      "             method=\"linear\",\n",
      "             keepdims=False,\n",
      "             *,\n",
      "             interpolation=None):\n",
      "    if interpolation is not None:\n",
      "        method = _check_interpolation_as_method(\n",
      "            method, interpolation, \"quantile\")\n",
      "    q = np.asanyarray(q)\n",
      "    if not _quantile_is_valid(q):\n",
      "        raise ValueError(\"Quantiles must be in the range [0, 1]\")\n",
      "    return _quantile_unchecked(\n",
      "        a, q, axis, out, overwrite_input, method, keepdims)\n",
      "docstring: quantile\n",
      "\n",
      "    Compute the q-th quantile of the data along the specified axis.\n",
      "\n",
      "    .. versionadded:: 1.15.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array or object that can be converted to an array.\n",
      "    q : array_like of float\n",
      "        Quantile or sequence of quantiles to compute, which must be between\n",
      "        0 and 1 inclusive.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the quantiles are computed. The default is\n",
      "        to compute the quantile(s) along a flattened version of the array.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape and buffer length as the expected output, but the\n",
      "        type (of the output) will be cast if necessary.\n",
      "    overwrite_input : bool, optional\n",
      "        If True, then allow the input array `a` to be modified by\n",
      "        intermediate calculations, to save memory. In this case, the\n",
      "        contents of the input `a` after this function completes is\n",
      "        undefined.\n",
      "    method : str, optional\n",
      "        This parameter specifies the method to use for estimating the\n",
      "        quantile.  There are many different methods, some unique to NumPy.\n",
      "        See the notes for explanation.  The options sorted by their R type\n",
      "        as summarized in the H&F paper [1]_ are:\n",
      "\n",
      "        1. 'inverted_cdf'\n",
      "        2. 'averaged_inverted_cdf'\n",
      "        3. 'closest_observation'\n",
      "        4. 'interpolated_inverted_cdf'\n",
      "        5. 'hazen'\n",
      "        6. 'weibull'\n",
      "        7. 'linear'  (default)\n",
      "        8. 'median_unbiased'\n",
      "        9. 'normal_unbiased'\n",
      "\n",
      "        The first three methods are discontinuous.  NumPy further defines the\n",
      "        following discontinuous variations of the default 'linear' (7.) option:\n",
      "\n",
      "        * 'lower'\n",
      "        * 'higher',\n",
      "        * 'midpoint'\n",
      "        * 'nearest'\n",
      "\n",
      "        .. versionchanged:: 1.22.0\n",
      "            This argument was previously called \"interpolation\" and only\n",
      "            offered the \"linear\" default and last four options.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left in\n",
      "        the result as dimensions with size one. With this option, the\n",
      "        result will broadcast correctly against the original array `a`.\n",
      "\n",
      "    interpolation : str, optional\n",
      "        Deprecated name for the method keyword argument.\n",
      "\n",
      "        .. deprecated:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    quantile : scalar or ndarray\n",
      "        If `q` is a single quantile and `axis=None`, then the result\n",
      "        is a scalar. If multiple quantiles are given, first axis of\n",
      "        the result corresponds to the quantiles. The other axes are\n",
      "        the axes that remain after the reduction of `a`. If the input\n",
      "        contains integers or floats smaller than ``float64``, the output\n",
      "        data-type is ``float64``. Otherwise, the output data-type is the\n",
      "        same as that of the input. If `out` is specified, that array is\n",
      "        returned instead.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    mean\n",
      "    percentile : equivalent to quantile, but with q in the range [0, 100].\n",
      "    median : equivalent to ``quantile(..., 0.5)``\n",
      "    nanquantile\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Given a vector ``V`` of length ``n``, the q-th quantile of ``V`` is\n",
      "    the value ``q`` of the way from the minimum to the maximum in a\n",
      "    sorted copy of ``V``. The values and distances of the two nearest\n",
      "    neighbors as well as the `method` parameter will determine the\n",
      "    quantile if the normalized ranking does not match the location of\n",
      "    ``q`` exactly. This function is the same as the median if ``q=0.5``, the\n",
      "    same as the minimum if ``q=0.0`` and the same as the maximum if\n",
      "    ``q=1.0``.\n",
      "\n",
      "    The optional `method` parameter specifies the method to use when the\n",
      "    desired quantile lies between two indexes ``i`` and ``j = i + 1``.\n",
      "    In that case, we first determine ``i + g``, a virtual index that lies\n",
      "    between ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\n",
      "    fractional part of the index. The final result is, then, an interpolation\n",
      "    of ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n",
      "    ``i`` and ``j`` are modified using correction constants ``alpha`` and\n",
      "    ``beta`` whose choices depend on the ``method`` used. Finally, note that\n",
      "    since Python uses 0-based indexing, the code subtracts another 1 from the\n",
      "    index internally.\n",
      "\n",
      "    The following formula determines the virtual index ``i + g``, the location \n",
      "    of the quantile in the sorted sample:\n",
      "\n",
      "    .. math::\n",
      "        i + g = q * ( n - alpha - beta + 1 ) + alpha\n",
      "\n",
      "    The different methods then work as follows\n",
      "\n",
      "    inverted_cdf:\n",
      "        method 1 of H&F [1]_.\n",
      "        This method gives discontinuous results:\n",
      "\n",
      "        * if g > 0 ; then take j\n",
      "        * if g = 0 ; then take i\n",
      "\n",
      "    averaged_inverted_cdf:\n",
      "        method 2 of H&F [1]_.\n",
      "        This method gives discontinuous results:\n",
      "\n",
      "        * if g > 0 ; then take j\n",
      "        * if g = 0 ; then average between bounds\n",
      "\n",
      "    closest_observation:\n",
      "        method 3 of H&F [1]_.\n",
      "        This method gives discontinuous results:\n",
      "\n",
      "        * if g > 0 ; then take j\n",
      "        * if g = 0 and index is odd ; then take j\n",
      "        * if g = 0 and index is even ; then take i\n",
      "\n",
      "    interpolated_inverted_cdf:\n",
      "        method 4 of H&F [1]_.\n",
      "        This method gives continuous results using:\n",
      "\n",
      "        * alpha = 0\n",
      "        * beta = 1\n",
      "\n",
      "    hazen:\n",
      "        method 5 of H&F [1]_.\n",
      "        This method gives continuous results using:\n",
      "\n",
      "        * alpha = 1/2\n",
      "        * beta = 1/2\n",
      "\n",
      "    weibull:\n",
      "        method 6 of H&F [1]_.\n",
      "        This method gives continuous results using:\n",
      "\n",
      "        * alpha = 0\n",
      "        * beta = 0\n",
      "\n",
      "    linear:\n",
      "        method 7 of H&F [1]_.\n",
      "        This method gives continuous results using:\n",
      "\n",
      "        * alpha = 1\n",
      "        * beta = 1\n",
      "\n",
      "    median_unbiased:\n",
      "        method 8 of H&F [1]_.\n",
      "        This method is probably the best method if the sample\n",
      "        distribution function is unknown (see reference).\n",
      "        This method gives continuous results using:\n",
      "\n",
      "        * alpha = 1/3\n",
      "        * beta = 1/3\n",
      "\n",
      "    normal_unbiased:\n",
      "        method 9 of H&F [1]_.\n",
      "        This method is probably the best method if the sample\n",
      "        distribution function is known to be normal.\n",
      "        This method gives continuous results using:\n",
      "\n",
      "        * alpha = 3/8\n",
      "        * beta = 3/8\n",
      "\n",
      "    lower:\n",
      "        NumPy method kept for backwards compatibility.\n",
      "        Takes ``i`` as the interpolation point.\n",
      "\n",
      "    higher:\n",
      "        NumPy method kept for backwards compatibility.\n",
      "        Takes ``j`` as the interpolation point.\n",
      "\n",
      "    nearest:\n",
      "        NumPy method kept for backwards compatibility.\n",
      "        Takes ``i`` or ``j``, whichever is nearest.\n",
      "\n",
      "    midpoint:\n",
      "        NumPy method kept for backwards compatibility.\n",
      "        Uses ``(i + j) / 2``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n",
      "    >>> a\n",
      "    array([[10,  7,  4],\n",
      "           [ 3,  2,  1]])\n",
      "    >>> np.quantile(a, 0.5)\n",
      "    3.5\n",
      "    >>> np.quantile(a, 0.5, axis=0)\n",
      "    array([6.5, 4.5, 2.5])\n",
      "    >>> np.quantile(a, 0.5, axis=1)\n",
      "    array([7.,  2.])\n",
      "    >>> np.quantile(a, 0.5, axis=1, keepdims=True)\n",
      "    array([[7.],\n",
      "           [2.]])\n",
      "    >>> m = np.quantile(a, 0.5, axis=0)\n",
      "    >>> out = np.zeros_like(m)\n",
      "    >>> np.quantile(a, 0.5, axis=0, out=out)\n",
      "    array([6.5, 4.5, 2.5])\n",
      "    >>> m\n",
      "    array([6.5, 4.5, 2.5])\n",
      "    >>> b = a.copy()\n",
      "    >>> np.quantile(b, 0.5, axis=1, overwrite_input=True)\n",
      "    array([7.,  2.])\n",
      "    >>> assert not np.all(a == b)\n",
      "\n",
      "    See also `numpy.percentile` for a visualization of most methods.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] R. J. Hyndman and Y. Fan,\n",
      "       \"Sample quantiles in statistical packages,\"\n",
      "       The American Statistician, 50(4), pp. 361-365, 1996\n",
      "\n",
      "    \n",
      "code: column_stack\n",
      "@array_function_dispatch(_column_stack_dispatcher)\n",
      "def column_stack(tup):\n",
      "    if not overrides.ARRAY_FUNCTION_ENABLED:\n",
      "        # raise warning if necessary\n",
      "        _arrays_for_stack_dispatcher(tup, stacklevel=2)\n",
      "    arrays = []\n",
      "    for v in tup:\n",
      "        arr = asanyarray(v)\n",
      "        if arr.ndim < 2:\n",
      "            arr = array(arr, copy=False, subok=True, ndmin=2).T\n",
      "        arrays.append(arr)\n",
      "    return _nx.concatenate(arrays, 1)\n",
      "docstring: column_stack\n",
      "\n",
      "    Stack 1-D arrays as columns into a 2-D array.\n",
      "\n",
      "    Take a sequence of 1-D arrays and stack them as columns\n",
      "    to make a single 2-D array. 2-D arrays are stacked as-is,\n",
      "    just like with `hstack`.  1-D arrays are turned into 2-D columns\n",
      "    first.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of 1-D or 2-D arrays.\n",
      "        Arrays to stack. All of them must have the same first dimension.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    stacked : 2-D array\n",
      "        The array formed by stacking the given arrays.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    stack, hstack, vstack, concatenate\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array((1,2,3))\n",
      "    >>> b = np.array((2,3,4))\n",
      "    >>> np.column_stack((a,b))\n",
      "    array([[1, 2],\n",
      "           [2, 3],\n",
      "           [3, 4]])\n",
      "\n",
      "    \n",
      "code: row_stack\n",
      "@array_function_dispatch(_vhstack_dispatcher)\n",
      "def vstack(tup, *, dtype=None, casting=\"same_kind\"):\n",
      "    if not overrides.ARRAY_FUNCTION_ENABLED:\n",
      "        # raise warning if necessary\n",
      "        _arrays_for_stack_dispatcher(tup, stacklevel=2)\n",
      "    arrs = atleast_2d(*tup)\n",
      "    if not isinstance(arrs, list):\n",
      "        arrs = [arrs]\n",
      "    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)\n",
      "docstring: row_stack\n",
      "\n",
      "    Stack arrays in sequence vertically (row wise).\n",
      "\n",
      "    This is equivalent to concatenation along the first axis after 1-D arrays\n",
      "    of shape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n",
      "    `vsplit`.\n",
      "\n",
      "    This function makes most sense for arrays with up to 3 dimensions. For\n",
      "    instance, for pixel-data with a height (first axis), width (second axis),\n",
      "    and r/g/b channels (third axis). The functions `concatenate`, `stack` and\n",
      "    `block` provide more general stacking and concatenation operations.\n",
      "\n",
      "    ``np.row_stack`` is an alias for `vstack`. They are the same function.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of ndarrays\n",
      "        The arrays must have the same shape along all but the first axis.\n",
      "        1-D arrays must have the same length.\n",
      "\n",
      "    dtype : str or dtype\n",
      "        If provided, the destination array will have this dtype. Cannot be\n",
      "        provided together with `out`.\n",
      "\n",
      "    .. versionadded:: 1.24\n",
      "\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n",
      "\n",
      "    .. versionadded:: 1.24\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The array formed by stacking the given arrays, will be at least 2-D.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    block : Assemble an nd-array from nested lists of blocks.\n",
      "    hstack : Stack arrays in sequence horizontally (column wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third axis).\n",
      "    column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      "    vsplit : Split an array into multiple sub-arrays vertically (row-wise).\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1, 2, 3])\n",
      "    >>> b = np.array([4, 5, 6])\n",
      "    >>> np.vstack((a,b))\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "\n",
      "    >>> a = np.array([[1], [2], [3]])\n",
      "    >>> b = np.array([[4], [5], [6]])\n",
      "    >>> np.vstack((a,b))\n",
      "    array([[1],\n",
      "           [2],\n",
      "           [3],\n",
      "           [4],\n",
      "           [5],\n",
      "           [6]])\n",
      "\n",
      "    \n",
      "code: dstack\n",
      "@array_function_dispatch(_dstack_dispatcher)\n",
      "def dstack(tup):\n",
      "    if not overrides.ARRAY_FUNCTION_ENABLED:\n",
      "        # raise warning if necessary\n",
      "        _arrays_for_stack_dispatcher(tup, stacklevel=2)\n",
      "    arrs = atleast_3d(*tup)\n",
      "    if not isinstance(arrs, list):\n",
      "        arrs = [arrs]\n",
      "    return _nx.concatenate(arrs, 2)\n",
      "docstring: dstack\n",
      "\n",
      "    Stack arrays in sequence depth wise (along third axis).\n",
      "\n",
      "    This is equivalent to concatenation along the third axis after 2-D arrays\n",
      "    of shape `(M,N)` have been reshaped to `(M,N,1)` and 1-D arrays of shape\n",
      "    `(N,)` have been reshaped to `(1,N,1)`. Rebuilds arrays divided by\n",
      "    `dsplit`.\n",
      "\n",
      "    This function makes most sense for arrays with up to 3 dimensions. For\n",
      "    instance, for pixel-data with a height (first axis), width (second axis),\n",
      "    and r/g/b channels (third axis). The functions `concatenate`, `stack` and\n",
      "    `block` provide more general stacking and concatenation operations.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of arrays\n",
      "        The arrays must have the same shape along all but the third axis.\n",
      "        1-D or 2-D arrays must have the same shape.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The array formed by stacking the given arrays, will be at least 3-D.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    block : Assemble an nd-array from nested lists of blocks.\n",
      "    vstack : Stack arrays in sequence vertically (row wise).\n",
      "    hstack : Stack arrays in sequence horizontally (column wise).\n",
      "    column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      "    dsplit : Split array along third axis.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array((1,2,3))\n",
      "    >>> b = np.array((2,3,4))\n",
      "    >>> np.dstack((a,b))\n",
      "    array([[[1, 2],\n",
      "            [2, 3],\n",
      "            [3, 4]]])\n",
      "\n",
      "    >>> a = np.array([[1],[2],[3]])\n",
      "    >>> b = np.array([[2],[3],[4]])\n",
      "    >>> np.dstack((a,b))\n",
      "    array([[[1, 2]],\n",
      "           [[2, 3]],\n",
      "           [[3, 4]]])\n",
      "\n",
      "    \n",
      "code: array_split\n",
      "@array_function_dispatch(_array_split_dispatcher)\n",
      "def array_split(ary, indices_or_sections, axis=0):\n",
      "    try:\n",
      "        Ntotal = ary.shape[axis]\n",
      "    except AttributeError:\n",
      "        Ntotal = len(ary)\n",
      "    try:\n",
      " indices_or_sections is a scalar, not an array.\n",
      "        Nsections = int(indices_or_sections)\n",
      "        if Nsections <= 0:\n",
      "            raise ValueError('number sections must be larger than 0.') from None\n",
      "        Neach_section, extras = divmod(Ntotal, Nsections)\n",
      "        section_sizes = ([0] +\n",
      "                         extras * [Neach_section+1] +\n",
      "                         (Nsections-extras) * [Neach_section])\n",
      "        div_points = _nx.array(section_sizes, dtype=_nx.intp).cumsum()\n",
      "    sub_arys = []\n",
      "    sary = _nx.swapaxes(ary, axis, 0)\n",
      "    for i in range(Nsections):\n",
      "        st = div_points[i]\n",
      "        end = div_points[i + 1]\n",
      "        sub_arys.append(_nx.swapaxes(sary[st:end], axis, 0))\n",
      "    return sub_arys\n",
      "docstring: array_split\n",
      "\n",
      "    Split an array into multiple sub-arrays.\n",
      "\n",
      "    Please refer to the ``split`` documentation.  The only difference\n",
      "    between these functions is that ``array_split`` allows\n",
      "    `indices_or_sections` to be an integer that does *not* equally\n",
      "    divide the axis. For an array of length l that should be split\n",
      "    into n sections, it returns l % n sub-arrays of size l//n + 1\n",
      "    and the rest of size l//n.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    split : Split array into multiple sub-arrays of equal size.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(8.0)\n",
      "    >>> np.array_split(x, 3)\n",
      "    [array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.])]\n",
      "\n",
      "    >>> x = np.arange(9)\n",
      "    >>> np.array_split(x, 4)\n",
      "    [array([0, 1, 2]), array([3, 4]), array([5, 6]), array([7, 8])]\n",
      "\n",
      "    \n",
      "code: split\n",
      "@array_function_dispatch(_split_dispatcher)\n",
      "def split(ary, indices_or_sections, axis=0):\n",
      "    try:\n",
      "        len(indices_or_sections)\n",
      "    except TypeError:\n",
      "        sections = indices_or_sections\n",
      "        N = ary.shape[axis]\n",
      "        if N % sections:\n",
      "            raise ValueError(\n",
      "                'array split does not result in an equal division') from None\n",
      "    return array_split(ary, indices_or_sections, axis)\n",
      "docstring: split\n",
      "\n",
      "    Split an array into multiple sub-arrays as views into `ary`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ary : ndarray\n",
      "        Array to be divided into sub-arrays.\n",
      "    indices_or_sections : int or 1-D array\n",
      "        If `indices_or_sections` is an integer, N, the array will be divided\n",
      "        into N equal arrays along `axis`.  If such a split is not possible,\n",
      "        an error is raised.\n",
      "\n",
      "        If `indices_or_sections` is a 1-D array of sorted integers, the entries\n",
      "        indicate where along `axis` the array is split.  For example,\n",
      "        ``[2, 3]`` would, for ``axis=0``, result in\n",
      "\n",
      "          - ary[:2]\n",
      "          - ary[2:3]\n",
      "          - ary[3:]\n",
      "\n",
      "        If an index exceeds the dimension of the array along `axis`,\n",
      "        an empty sub-array is returned correspondingly.\n",
      "    axis : int, optional\n",
      "        The axis along which to split, default is 0.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    sub-arrays : list of ndarrays\n",
      "        A list of sub-arrays as views into `ary`.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If `indices_or_sections` is given as an integer, but\n",
      "        a split does not result in equal division.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    array_split : Split an array into multiple sub-arrays of equal or\n",
      "                  near-equal size.  Does not raise an exception if\n",
      "                  an equal division cannot be made.\n",
      "    hsplit : Split array into multiple sub-arrays horizontally (column-wise).\n",
      "    vsplit : Split array into multiple sub-arrays vertically (row wise).\n",
      "    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    hstack : Stack arrays in sequence horizontally (column wise).\n",
      "    vstack : Stack arrays in sequence vertically (row wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third dimension).\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(9.0)\n",
      "    >>> np.split(x, 3)\n",
      "    [array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.,  8.])]\n",
      "\n",
      "    >>> x = np.arange(8.0)\n",
      "    >>> np.split(x, [3, 5, 6, 10])\n",
      "    [array([0.,  1.,  2.]),\n",
      "     array([3.,  4.]),\n",
      "     array([5.]),\n",
      "     array([6.,  7.]),\n",
      "     array([], dtype=float64)]\n",
      "\n",
      "    \n",
      "code: hsplit\n",
      "@array_function_dispatch(_hvdsplit_dispatcher)\n",
      "def hsplit(ary, indices_or_sections):\n",
      "    if _nx.ndim(ary) == 0:\n",
      "        raise ValueError('hsplit only works on arrays of 1 or more dimensions')\n",
      "    if ary.ndim > 1:\n",
      "        return split(ary, indices_or_sections, 1)\n",
      "    else:\n",
      "        return split(ary, indices_or_sections, 0)\n",
      "docstring: hsplit\n",
      "\n",
      "    Split an array into multiple sub-arrays horizontally (column-wise).\n",
      "\n",
      "    Please refer to the `split` documentation.  `hsplit` is equivalent\n",
      "    to `split` with ``axis=1``, the array is always split along the second\n",
      "    axis except for 1-D arrays, where it is split at ``axis=0``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    split : Split an array into multiple sub-arrays of equal size.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(16.0).reshape(4, 4)\n",
      "    >>> x\n",
      "    array([[ 0.,   1.,   2.,   3.],\n",
      "           [ 4.,   5.,   6.,   7.],\n",
      "           [ 8.,   9.,  10.,  11.],\n",
      "           [12.,  13.,  14.,  15.]])\n",
      "    >>> np.hsplit(x, 2)\n",
      "    [array([[  0.,   1.],\n",
      "           [  4.,   5.],\n",
      "           [  8.,   9.],\n",
      "           [12.,  13.]]),\n",
      "     array([[  2.,   3.],\n",
      "           [  6.,   7.],\n",
      "           [10.,  11.],\n",
      "           [14.,  15.]])]\n",
      "    >>> np.hsplit(x, np.array([3, 6]))\n",
      "    [array([[ 0.,   1.,   2.],\n",
      "           [ 4.,   5.,   6.],\n",
      "           [ 8.,   9.,  10.],\n",
      "           [12.,  13.,  14.]]),\n",
      "     array([[ 3.],\n",
      "           [ 7.],\n",
      "           [11.],\n",
      "           [15.]]),\n",
      "     array([], shape=(4, 0), dtype=float64)]\n",
      "\n",
      "    With a higher dimensional array the split is still along the second axis.\n",
      "\n",
      "    >>> x = np.arange(8.0).reshape(2, 2, 2)\n",
      "    >>> x\n",
      "    array([[[0.,  1.],\n",
      "            [2.,  3.]],\n",
      "           [[4.,  5.],\n",
      "            [6.,  7.]]])\n",
      "    >>> np.hsplit(x, 2)\n",
      "    [array([[[0.,  1.]],\n",
      "           [[4.,  5.]]]),\n",
      "     array([[[2.,  3.]],\n",
      "           [[6.,  7.]]])]\n",
      "\n",
      "    With a 1-D array, the split is along axis 0.\n",
      "\n",
      "    >>> x = np.array([0, 1, 2, 3, 4, 5])\n",
      "    >>> np.hsplit(x, 2)\n",
      "    [array([0, 1, 2]), array([3, 4, 5])]\n",
      "\n",
      "    \n",
      "code: vsplit\n",
      "@array_function_dispatch(_hvdsplit_dispatcher)\n",
      "def vsplit(ary, indices_or_sections):\n",
      "    if _nx.ndim(ary) < 2:\n",
      "        raise ValueError('vsplit only works on arrays of 2 or more dimensions')\n",
      "    return split(ary, indices_or_sections, 0)\n",
      "docstring: vsplit\n",
      "\n",
      "    Split an array into multiple sub-arrays vertically (row-wise).\n",
      "\n",
      "    Please refer to the ``split`` documentation.  ``vsplit`` is equivalent\n",
      "    to ``split`` with `axis=0` (default), the array is always split along the\n",
      "    first axis regardless of the array dimension.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    split : Split an array into multiple sub-arrays of equal size.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(16.0).reshape(4, 4)\n",
      "    >>> x\n",
      "    array([[ 0.,   1.,   2.,   3.],\n",
      "           [ 4.,   5.,   6.,   7.],\n",
      "           [ 8.,   9.,  10.,  11.],\n",
      "           [12.,  13.,  14.,  15.]])\n",
      "    >>> np.vsplit(x, 2)\n",
      "    [array([[0., 1., 2., 3.],\n",
      "           [4., 5., 6., 7.]]), array([[ 8.,  9., 10., 11.],\n",
      "           [12., 13., 14., 15.]])]\n",
      "    >>> np.vsplit(x, np.array([3, 6]))\n",
      "    [array([[ 0.,  1.,  2.,  3.],\n",
      "           [ 4.,  5.,  6.,  7.],\n",
      "           [ 8.,  9., 10., 11.]]), array([[12., 13., 14., 15.]]), array([], shape=(0, 4), dtype=float64)]\n",
      "\n",
      "    With a higher dimensional array the split is still along the first axis.\n",
      "\n",
      "    >>> x = np.arange(8.0).reshape(2, 2, 2)\n",
      "    >>> x\n",
      "    array([[[0.,  1.],\n",
      "            [2.,  3.]],\n",
      "           [[4.,  5.],\n",
      "            [6.,  7.]]])\n",
      "    >>> np.vsplit(x, 2)\n",
      "    [array([[[0., 1.],\n",
      "            [2., 3.]]]), array([[[4., 5.],\n",
      "            [6., 7.]]])]\n",
      "\n",
      "    \n",
      "code: dsplit\n",
      "@array_function_dispatch(_hvdsplit_dispatcher)\n",
      "def dsplit(ary, indices_or_sections):\n",
      "    if _nx.ndim(ary) < 3:\n",
      "        raise ValueError('dsplit only works on arrays of 3 or more dimensions')\n",
      "    return split(ary, indices_or_sections, 2)\n",
      "docstring: dsplit\n",
      "\n",
      "    Split array into multiple sub-arrays along the 3rd axis (depth).\n",
      "\n",
      "    Please refer to the `split` documentation.  `dsplit` is equivalent\n",
      "    to `split` with ``axis=2``, the array is always split along the third\n",
      "    axis provided the array dimension is greater than or equal to 3.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    split : Split an array into multiple sub-arrays of equal size.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(16.0).reshape(2, 2, 4)\n",
      "    >>> x\n",
      "    array([[[ 0.,   1.,   2.,   3.],\n",
      "            [ 4.,   5.,   6.,   7.]],\n",
      "           [[ 8.,   9.,  10.,  11.],\n",
      "            [12.,  13.,  14.,  15.]]])\n",
      "    >>> np.dsplit(x, 2)\n",
      "    [array([[[ 0.,  1.],\n",
      "            [ 4.,  5.]],\n",
      "           [[ 8.,  9.],\n",
      "            [12., 13.]]]), array([[[ 2.,  3.],\n",
      "            [ 6.,  7.]],\n",
      "           [[10., 11.],\n",
      "            [14., 15.]]])]\n",
      "    >>> np.dsplit(x, np.array([3, 6]))\n",
      "    [array([[[ 0.,   1.,   2.],\n",
      "            [ 4.,   5.,   6.]],\n",
      "           [[ 8.,   9.,  10.],\n",
      "            [12.,  13.,  14.]]]),\n",
      "     array([[[ 3.],\n",
      "            [ 7.]],\n",
      "           [[11.],\n",
      "            [15.]]]),\n",
      "    array([], shape=(2, 2, 0), dtype=float64)]\n",
      "    \n",
      "code: apply_over_axes\n",
      "@array_function_dispatch(_apply_over_axes_dispatcher)\n",
      "def apply_over_axes(func, a, axes):\n",
      "    val = asarray(a)\n",
      "    N = a.ndim\n",
      "    if array(axes).ndim == 0:\n",
      "        axes = (axes,)\n",
      "    for axis in axes:\n",
      "        if axis < 0:\n",
      "            axis = N + axis\n",
      "        args = (val, axis)\n",
      "        res = func(*args)\n",
      "        if res.ndim == val.ndim:\n",
      "            val = res\n",
      "        else:\n",
      "            res = expand_dims(res, axis)\n",
      "            if res.ndim == val.ndim:\n",
      "                val = res\n",
      "            else:\n",
      "                raise ValueError(\"function is not returning \"\n",
      "                                 \"an array of the correct shape\")\n",
      "    return val\n",
      "docstring: apply_over_axes\n",
      "\n",
      "    Apply a function repeatedly over multiple axes.\n",
      "\n",
      "    `func` is called as `res = func(a, axis)`, where `axis` is the first\n",
      "    element of `axes`.  The result `res` of the function call must have\n",
      "    either the same dimensions as `a` or one less dimension.  If `res`\n",
      "    has one less dimension than `a`, a dimension is inserted before\n",
      "    `axis`.  The call to `func` is then repeated for each axis in `axes`,\n",
      "    with `res` as the first argument.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    func : function\n",
      "        This function must take two arguments, `func(a, axis)`.\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axes : array_like\n",
      "        Axes over which `func` is applied; the elements must be integers.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    apply_over_axis : ndarray\n",
      "        The output array.  The number of dimensions is the same as `a`,\n",
      "        but the shape can be different.  This depends on whether `func`\n",
      "        changes the shape of its output with respect to its input.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    apply_along_axis :\n",
      "        Apply a function to 1-D slices of an array along the given axis.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This function is equivalent to tuple axis arguments to reorderable ufuncs\n",
      "    with keepdims=True. Tuple axis arguments to ufuncs have been available since\n",
      "    version 1.7.0.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(24).reshape(2,3,4)\n",
      "    >>> a\n",
      "    array([[[ 0,  1,  2,  3],\n",
      "            [ 4,  5,  6,  7],\n",
      "            [ 8,  9, 10, 11]],\n",
      "           [[12, 13, 14, 15],\n",
      "            [16, 17, 18, 19],\n",
      "            [20, 21, 22, 23]]])\n",
      "\n",
      "    Sum over axes 0 and 2. The result has same number of dimensions\n",
      "    as the original array:\n",
      "\n",
      "    >>> np.apply_over_axes(np.sum, a, [0,2])\n",
      "    array([[[ 60],\n",
      "            [ 92],\n",
      "            [124]]])\n",
      "\n",
      "    Tuple axis arguments to ufuncs are equivalent:\n",
      "\n",
      "    >>> np.sum(a, axis=(0,2), keepdims=True)\n",
      "    array([[[ 60],\n",
      "            [ 92],\n",
      "            [124]]])\n",
      "\n",
      "    \n",
      "code: expand_dims\n",
      "@array_function_dispatch(_expand_dims_dispatcher)\n",
      "def expand_dims(a, axis):\n",
      "    if isinstance(a, matrix):\n",
      "        a = asarray(a)\n",
      "    else:\n",
      "        a = asanyarray(a)\n",
      "    if type(axis) not in (tuple, list):\n",
      "        axis = (axis,)\n",
      "    out_ndim = len(axis) + a.ndim\n",
      "    axis = normalize_axis_tuple(axis, out_ndim)\n",
      "    shape_it = iter(a.shape)\n",
      "    shape = [1 if ax in axis else next(shape_it) for ax in range(out_ndim)]\n",
      "    return a.reshape(shape)\n",
      "docstring: expand_dims\n",
      "\n",
      "    Expand the shape of an array.\n",
      "\n",
      "    Insert a new axis that will appear at the `axis` position in the expanded\n",
      "    array shape.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axis : int or tuple of ints\n",
      "        Position in the expanded axes where the new axis (or axes) is placed.\n",
      "\n",
      "        .. deprecated:: 1.13.0\n",
      "            Passing an axis where ``axis > a.ndim`` will be treated as\n",
      "            ``axis == a.ndim``, and passing ``axis < -a.ndim - 1`` will\n",
      "            be treated as ``axis == 0``. This behavior is deprecated.\n",
      "\n",
      "        .. versionchanged:: 1.18.0\n",
      "            A tuple of axes is now supported.  Out of range axes as\n",
      "            described above are now forbidden and raise an `AxisError`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    result : ndarray\n",
      "        View of `a` with the number of dimensions increased.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    squeeze : The inverse operation, removing singleton dimensions\n",
      "    reshape : Insert, remove, and combine dimensions, and resize existing ones\n",
      "    doc.indexing, atleast_1d, atleast_2d, atleast_3d\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([1, 2])\n",
      "    >>> x.shape\n",
      "    (2,)\n",
      "\n",
      "    The following is equivalent to ``x[np.newaxis, :]`` or ``x[np.newaxis]``:\n",
      "\n",
      "    >>> y = np.expand_dims(x, axis=0)\n",
      "    >>> y\n",
      "    array([[1, 2]])\n",
      "    >>> y.shape\n",
      "    (1, 2)\n",
      "\n",
      "    The following is equivalent to ``x[:, np.newaxis]``:\n",
      "\n",
      "    >>> y = np.expand_dims(x, axis=1)\n",
      "    >>> y\n",
      "    array([[1],\n",
      "           [2]])\n",
      "    >>> y.shape\n",
      "    (2, 1)\n",
      "\n",
      "    ``axis`` may also be a tuple:\n",
      "\n",
      "    >>> y = np.expand_dims(x, axis=(0, 1))\n",
      "    >>> y\n",
      "    array([[[1, 2]]])\n",
      "\n",
      "    >>> y = np.expand_dims(x, axis=(2, 0))\n",
      "    >>> y\n",
      "    array([[[1],\n",
      "            [2]]])\n",
      "\n",
      "    Note that some examples may use ``None`` instead of ``np.newaxis``.  These\n",
      "    are the same objects:\n",
      "\n",
      "    >>> np.newaxis is None\n",
      "    True\n",
      "\n",
      "    \n",
      "code: apply_along_axis\n",
      "@array_function_dispatch(_apply_along_axis_dispatcher)\n",
      "def apply_along_axis(func1d, axis, arr, *args, **kwargs):\n",
      " arr, with the iteration axis at the end\n",
      "    in_dims = list(range(nd))\n",
      "    inarr_view = transpose(arr, in_dims[:axis] + in_dims[axis+1:] + [axis])\n",
      " prevent 0d arrays decaying to scalars, which fixes gh-8642\n",
      "    inds = ndindex(inarr_view.shape[:-1])\n",
      "    inds = (ind + (Ellipsis,) for ind in inds)\n",
      " build a buffer for storing evaluations of func1d.\n",
      " laid out so that each write is contiguous.\n",
      " permutation of axes such that out = buff.transpose(buff_permute)\n",
      "    buff_dims = list(range(buff.ndim))\n",
      "    buff_permute = (\n",
      "        buff_dims[0 : axis] +\n",
      "        buff_dims[buff.ndim-res.ndim : buff.ndim] +\n",
      "        buff_dims[axis : buff.ndim-res.ndim]\n",
      "    )\n",
      " save the first result, then compute and save all remaining results\n",
      "    buff[ind0] = res\n",
      "    for ind in inds:\n",
      "        buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "    if not isinstance(res, matrix):\n",
      " finally, rotate the inserted axes back to where they belong\n",
      "        return transpose(buff, buff_permute)\n",
      "    else:\n",
      "        # matrices have to be transposed first, because they collapse dimensions!\n",
      "        out_arr = transpose(buff, buff_permute)\n",
      "        return res.__array_wrap__(out_arr)\n",
      "docstring: apply_along_axis\n",
      "\n",
      "    Apply a function to 1-D slices along the given axis.\n",
      "\n",
      "    Execute `func1d(a, *args, **kwargs)` where `func1d` operates on 1-D arrays\n",
      "    and `a` is a 1-D slice of `arr` along `axis`.\n",
      "\n",
      "    This is equivalent to (but faster than) the following use of `ndindex` and\n",
      "    `s_`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of indices::\n",
      "\n",
      "        Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n",
      "        for ii in ndindex(Ni):\n",
      "            for kk in ndindex(Nk):\n",
      "                f = func1d(arr[ii + s_[:,] + kk])\n",
      "                Nj = f.shape\n",
      "                for jj in ndindex(Nj):\n",
      "                    out[ii + jj + kk] = f[jj]\n",
      "\n",
      "    Equivalently, eliminating the inner loop, this can be expressed as::\n",
      "\n",
      "        Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n",
      "        for ii in ndindex(Ni):\n",
      "            for kk in ndindex(Nk):\n",
      "                out[ii + s_[...,] + kk] = func1d(arr[ii + s_[:,] + kk])\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    func1d : function (M,) -> (Nj...)\n",
      "        This function should accept 1-D arrays. It is applied to 1-D\n",
      "        slices of `arr` along the specified axis.\n",
      "    axis : integer\n",
      "        Axis along which `arr` is sliced.\n",
      "    arr : ndarray (Ni..., M, Nk...)\n",
      "        Input array.\n",
      "    args : any\n",
      "        Additional arguments to `func1d`.\n",
      "    kwargs : any\n",
      "        Additional named arguments to `func1d`.\n",
      "\n",
      "        .. versionadded:: 1.9.0\n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray  (Ni..., Nj..., Nk...)\n",
      "        The output array. The shape of `out` is identical to the shape of\n",
      "        `arr`, except along the `axis` dimension. This axis is removed, and\n",
      "        replaced with new dimensions equal to the shape of the return value\n",
      "        of `func1d`. So if `func1d` returns a scalar `out` will have one\n",
      "        fewer dimensions than `arr`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    apply_over_axes : Apply a function repeatedly over multiple axes.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> def my_func(a):\n",
      "    ...     \"\"\"Average first and last element of a 1-D array\"\"\"\n",
      "    ...     return (a[0] + a[-1]) * 0.5\n",
      "    >>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
      "    >>> np.apply_along_axis(my_func, 0, b)\n",
      "    array([4., 5., 6.])\n",
      "    >>> np.apply_along_axis(my_func, 1, b)\n",
      "    array([2.,  5.,  8.])\n",
      "\n",
      "    For a function that returns a 1D array, the number of dimensions in\n",
      "    `outarr` is the same as `arr`.\n",
      "\n",
      "    >>> b = np.array([[8,1,7], [4,3,9], [5,2,6]])\n",
      "    >>> np.apply_along_axis(sorted, 1, b)\n",
      "    array([[1, 7, 8],\n",
      "           [3, 4, 9],\n",
      "           [2, 5, 6]])\n",
      "\n",
      "    For a function that returns a higher dimensional array, those dimensions\n",
      "    are inserted in place of the `axis` dimension.\n",
      "\n",
      "    >>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
      "    >>> np.apply_along_axis(np.diag, -1, b)\n",
      "    array([[[1, 0, 0],\n",
      "            [0, 2, 0],\n",
      "            [0, 0, 3]],\n",
      "           [[4, 0, 0],\n",
      "            [0, 5, 0],\n",
      "            [0, 0, 6]],\n",
      "           [[7, 0, 0],\n",
      "            [0, 8, 0],\n",
      "            [0, 0, 9]]])\n",
      "    \n",
      "code: kron\n",
      "@array_function_dispatch(_kron_dispatcher)\n",
      "def kron(a, b):\n",
      " 1. Equalise the shapes by prepending smaller array with 1s\n",
      "    odd positions for 1st array and even positions for 2nd\n",
      " 4. The inner most array elements now contain the rows of\n",
      " 5. Reshape the result to kron's shape, which is same as\n",
      " Equalise the shapes by prepending smaller one with 1s\n",
      "    as_ = (1,)*max(0, ndb-nda) + as_\n",
      "    bs = (1,)*max(0, nda-ndb) + bs\n",
      " Compute the product\n",
      "    a_arr = expand_dims(a_arr, axis=tuple(range(1, nd*2, 2)))\n",
      "    b_arr = expand_dims(b_arr, axis=tuple(range(0, nd*2, 2)))\n",
      " Reshape back\n",
      "    result = result.reshape(_nx.multiply(as_, bs))\n",
      "    return result if not is_any_mat else matrix(result, copy=False)\n",
      "docstring: kron\n",
      "\n",
      "    Kronecker product of two arrays.\n",
      "\n",
      "    Computes the Kronecker product, a composite array made of blocks of the\n",
      "    second array scaled by the first.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a, b : array_like\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    outer : The outer product\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The function assumes that the number of dimensions of `a` and `b`\n",
      "    are the same, if necessary prepending the smallest with ones.\n",
      "    If ``a.shape = (r0,r1,..,rN)`` and ``b.shape = (s0,s1,...,sN)``,\n",
      "    the Kronecker product has shape ``(r0*s0, r1*s1, ..., rN*SN)``.\n",
      "    The elements are products of elements from `a` and `b`, organized\n",
      "    explicitly by::\n",
      "\n",
      "        kron(a,b)[k0,k1,...,kN] = a[i0,i1,...,iN] * b[j0,j1,...,jN]\n",
      "\n",
      "    where::\n",
      "\n",
      "        kt = it * st + jt,  t = 0,...,N\n",
      "\n",
      "    In the common 2-D case (N=1), the block structure can be visualized::\n",
      "\n",
      "        [[ a[0,0]*b,   a[0,1]*b,  ... , a[0,-1]*b  ],\n",
      "         [  ...                              ...   ],\n",
      "         [ a[-1,0]*b,  a[-1,1]*b, ... , a[-1,-1]*b ]]\n",
      "\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.kron([1,10,100], [5,6,7])\n",
      "    array([  5,   6,   7, ..., 500, 600, 700])\n",
      "    >>> np.kron([5,6,7], [1,10,100])\n",
      "    array([  5,  50, 500, ...,   7,  70, 700])\n",
      "\n",
      "    >>> np.kron(np.eye(2), np.ones((2,2)))\n",
      "    array([[1.,  1.,  0.,  0.],\n",
      "           [1.,  1.,  0.,  0.],\n",
      "           [0.,  0.,  1.,  1.],\n",
      "           [0.,  0.,  1.,  1.]])\n",
      "\n",
      "    >>> a = np.arange(100).reshape((2,5,2,5))\n",
      "    >>> b = np.arange(24).reshape((2,3,4))\n",
      "    >>> c = np.kron(a,b)\n",
      "    >>> c.shape\n",
      "    (2, 10, 6, 20)\n",
      "    >>> I = (1,3,0,2)\n",
      "    >>> J = (0,2,1)\n",
      "    >>> J1 = (0,) + J             # extend to ndim=4\n",
      "    >>> S1 = (1,) + b.shape\n",
      "    >>> K = tuple(np.array(I) * np.array(S1) + np.array(J1))\n",
      "    >>> c[K] == a[I]*b[J]\n",
      "    True\n",
      "\n",
      "    \n",
      "code: tile\n",
      "@array_function_dispatch(_tile_dispatcher)\n",
      "def tile(A, reps):\n",
      "    try:\n",
      "        tup = tuple(reps)\n",
      "    except TypeError:\n",
      "        tup = (reps,)\n",
      "    d = len(tup)\n",
      "    if all(x == 1 for x in tup) and isinstance(A, _nx.ndarray):\n",
      " numpy array and the repetitions are 1 in all dimensions\n",
      "        return _nx.array(A, copy=True, subok=True, ndmin=d)\n",
      "    else:\n",
      " have no data there is no risk of an inadvertent overwrite.\n",
      "        c = _nx.array(A, copy=False, subok=True, ndmin=d)\n",
      "    if (d < c.ndim):\n",
      "        tup = (1,)*(c.ndim-d) + tup\n",
      "    shape_out = tuple(s*t for s, t in zip(c.shape, tup))\n",
      "    n = c.size\n",
      "    if n > 0:\n",
      "        for dim_in, nrep in zip(c.shape, tup):\n",
      "            if nrep != 1:\n",
      "                c = c.reshape(-1, n).repeat(nrep, 0)\n",
      "            n //= dim_in\n",
      "    return c.reshape(shape_out)\n",
      "docstring: tile\n",
      "\n",
      "    Construct an array by repeating A the number of times given by reps.\n",
      "\n",
      "    If `reps` has length ``d``, the result will have dimension of\n",
      "    ``max(d, A.ndim)``.\n",
      "\n",
      "    If ``A.ndim < d``, `A` is promoted to be d-dimensional by prepending new\n",
      "    axes. So a shape (3,) array is promoted to (1, 3) for 2-D replication,\n",
      "    or shape (1, 1, 3) for 3-D replication. If this is not the desired\n",
      "    behavior, promote `A` to d-dimensions manually before calling this\n",
      "    function.\n",
      "\n",
      "    If ``A.ndim > d``, `reps` is promoted to `A`.ndim by pre-pending 1's to it.\n",
      "    Thus for an `A` of shape (2, 3, 4, 5), a `reps` of (2, 2) is treated as\n",
      "    (1, 1, 2, 2).\n",
      "\n",
      "    Note : Although tile may be used for broadcasting, it is strongly\n",
      "    recommended to use numpy's broadcasting operations and functions.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    A : array_like\n",
      "        The input array.\n",
      "    reps : array_like\n",
      "        The number of repetitions of `A` along each axis.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    c : ndarray\n",
      "        The tiled output array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    repeat : Repeat elements of an array.\n",
      "    broadcast_to : Broadcast an array to a new shape\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([0, 1, 2])\n",
      "    >>> np.tile(a, 2)\n",
      "    array([0, 1, 2, 0, 1, 2])\n",
      "    >>> np.tile(a, (2, 2))\n",
      "    array([[0, 1, 2, 0, 1, 2],\n",
      "           [0, 1, 2, 0, 1, 2]])\n",
      "    >>> np.tile(a, (2, 1, 2))\n",
      "    array([[[0, 1, 2, 0, 1, 2]],\n",
      "           [[0, 1, 2, 0, 1, 2]]])\n",
      "\n",
      "    >>> b = np.array([[1, 2], [3, 4]])\n",
      "    >>> np.tile(b, 2)\n",
      "    array([[1, 2, 1, 2],\n",
      "           [3, 4, 3, 4]])\n",
      "    >>> np.tile(b, (2, 1))\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [1, 2],\n",
      "           [3, 4]])\n",
      "\n",
      "    >>> c = np.array([1,2,3,4])\n",
      "    >>> np.tile(c,(4,1))\n",
      "    array([[1, 2, 3, 4],\n",
      "           [1, 2, 3, 4],\n",
      "           [1, 2, 3, 4],\n",
      "           [1, 2, 3, 4]])\n",
      "    \n",
      "code: get_array_wrap\n",
      "def get_array_wrap(*args):\n",
      "    wrappers = sorted((getattr(x, '__array_priority__', 0), -i,\n",
      "                 x.__array_wrap__) for i, x in enumerate(args)\n",
      "                                   if hasattr(x, '__array_wrap__'))\n",
      "    if wrappers:\n",
      "        return wrappers[-1][-1]\n",
      "    return None\n",
      "docstring: get_array_wrap\n",
      "Find the wrapper for the array with the highest priority.\n",
      "\n",
      "    In case of ties, leftmost wins. If no wrapper is found, return None\n",
      "    \n",
      "code: take_along_axis\n",
      "@array_function_dispatch(_take_along_axis_dispatcher)\n",
      "def take_along_axis(arr, indices, axis):\n",
      " flatiter has no .shape\n",
      "        axis = 0\n",
      "    else:\n",
      "        axis = normalize_axis_index(axis, arr.ndim)\n",
      "        arr_shape = arr.shape\n",
      "    # use the fancy index\n",
      "    return arr[_make_along_axis_idx(arr_shape, indices, axis)]\n",
      "docstring: take_along_axis\n",
      "\n",
      "    Take values from the input array by matching 1d index and data slices.\n",
      "\n",
      "    This iterates over matching 1d slices oriented along the specified axis in\n",
      "    the index and data arrays, and uses the former to look up values in the\n",
      "    latter. These slices can be different lengths.\n",
      "\n",
      "    Functions returning an index along an axis, like `argsort` and\n",
      "    `argpartition`, produce suitable indices for this function.\n",
      "\n",
      "    .. versionadded:: 1.15.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : ndarray (Ni..., M, Nk...)\n",
      "        Source array\n",
      "    indices : ndarray (Ni..., J, Nk...)\n",
      "        Indices to take along each 1d slice of `arr`. This must match the\n",
      "        dimension of arr, but dimensions Ni and Nj only need to broadcast\n",
      "        against `arr`.\n",
      "    axis : int\n",
      "        The axis to take 1d slices along. If axis is None, the input array is\n",
      "        treated as if it had first been flattened to 1d, for consistency with\n",
      "        `sort` and `argsort`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out: ndarray (Ni..., J, Nk...)\n",
      "        The indexed result.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This is equivalent to (but faster than) the following use of `ndindex` and\n",
      "    `s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::\n",
      "\n",
      "        Ni, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:]\n",
      "        J = indices.shape[axis]  # Need not equal M\n",
      "        out = np.empty(Ni + (J,) + Nk)\n",
      "\n",
      "        for ii in ndindex(Ni):\n",
      "            for kk in ndindex(Nk):\n",
      "                a_1d       = a      [ii + s_[:,] + kk]\n",
      "                indices_1d = indices[ii + s_[:,] + kk]\n",
      "                out_1d     = out    [ii + s_[:,] + kk]\n",
      "                for j in range(J):\n",
      "                    out_1d[j] = a_1d[indices_1d[j]]\n",
      "\n",
      "    Equivalently, eliminating the inner loop, the last two lines would be::\n",
      "\n",
      "                out_1d[:] = a_1d[indices_1d]\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    take : Take along an axis, using the same indices for every 1d slice\n",
      "    put_along_axis :\n",
      "        Put values into the destination array by matching 1d index and data slices\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    For this sample array\n",
      "\n",
      "    >>> a = np.array([[10, 30, 20], [60, 40, 50]])\n",
      "\n",
      "    We can sort either by using sort directly, or argsort and this function\n",
      "\n",
      "    >>> np.sort(a, axis=1)\n",
      "    array([[10, 20, 30],\n",
      "           [40, 50, 60]])\n",
      "    >>> ai = np.argsort(a, axis=1); ai\n",
      "    array([[0, 2, 1],\n",
      "           [1, 2, 0]])\n",
      "    >>> np.take_along_axis(a, ai, axis=1)\n",
      "    array([[10, 20, 30],\n",
      "           [40, 50, 60]])\n",
      "\n",
      "    The same works for max and min, if you expand the dimensions:\n",
      "\n",
      "    >>> np.expand_dims(np.max(a, axis=1), axis=1)\n",
      "    array([[30],\n",
      "           [60]])\n",
      "    >>> ai = np.expand_dims(np.argmax(a, axis=1), axis=1)\n",
      "    >>> ai\n",
      "    array([[1],\n",
      "           [0]])\n",
      "    >>> np.take_along_axis(a, ai, axis=1)\n",
      "    array([[30],\n",
      "           [60]])\n",
      "\n",
      "    If we want to get the max and min at the same time, we can stack the\n",
      "    indices first\n",
      "\n",
      "    >>> ai_min = np.expand_dims(np.argmin(a, axis=1), axis=1)\n",
      "    >>> ai_max = np.expand_dims(np.argmax(a, axis=1), axis=1)\n",
      "    >>> ai = np.concatenate([ai_min, ai_max], axis=1)\n",
      "    >>> ai\n",
      "    array([[0, 1],\n",
      "           [1, 0]])\n",
      "    >>> np.take_along_axis(a, ai, axis=1)\n",
      "    array([[10, 30],\n",
      "           [40, 60]])\n",
      "    \n",
      "code: put_along_axis\n",
      "@array_function_dispatch(_put_along_axis_dispatcher)\n",
      "def put_along_axis(arr, indices, values, axis):\n",
      " flatiter has no .shape\n",
      "    else:\n",
      "        axis = normalize_axis_index(axis, arr.ndim)\n",
      "        arr_shape = arr.shape\n",
      "    # use the fancy index\n",
      "    arr[_make_along_axis_idx(arr_shape, indices, axis)] = values\n",
      "docstring: put_along_axis\n",
      "\n",
      "    Put values into the destination array by matching 1d index and data slices.\n",
      "\n",
      "    This iterates over matching 1d slices oriented along the specified axis in\n",
      "    the index and data arrays, and uses the former to place values into the\n",
      "    latter. These slices can be different lengths.\n",
      "\n",
      "    Functions returning an index along an axis, like `argsort` and\n",
      "    `argpartition`, produce suitable indices for this function.\n",
      "\n",
      "    .. versionadded:: 1.15.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : ndarray (Ni..., M, Nk...)\n",
      "        Destination array.\n",
      "    indices : ndarray (Ni..., J, Nk...)\n",
      "        Indices to change along each 1d slice of `arr`. This must match the\n",
      "        dimension of arr, but dimensions in Ni and Nj may be 1 to broadcast\n",
      "        against `arr`.\n",
      "    values : array_like (Ni..., J, Nk...)\n",
      "        values to insert at those indices. Its shape and dimension are\n",
      "        broadcast to match that of `indices`.\n",
      "    axis : int\n",
      "        The axis to take 1d slices along. If axis is None, the destination\n",
      "        array is treated as if a flattened 1d view had been created of it.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This is equivalent to (but faster than) the following use of `ndindex` and\n",
      "    `s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::\n",
      "\n",
      "        Ni, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:]\n",
      "        J = indices.shape[axis]  # Need not equal M\n",
      "\n",
      "        for ii in ndindex(Ni):\n",
      "            for kk in ndindex(Nk):\n",
      "                a_1d       = a      [ii + s_[:,] + kk]\n",
      "                indices_1d = indices[ii + s_[:,] + kk]\n",
      "                values_1d  = values [ii + s_[:,] + kk]\n",
      "                for j in range(J):\n",
      "                    a_1d[indices_1d[j]] = values_1d[j]\n",
      "\n",
      "    Equivalently, eliminating the inner loop, the last two lines would be::\n",
      "\n",
      "                a_1d[indices_1d] = values_1d\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    take_along_axis :\n",
      "        Take values from the input array by matching 1d index and data slices\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    For this sample array\n",
      "\n",
      "    >>> a = np.array([[10, 30, 20], [60, 40, 50]])\n",
      "\n",
      "    We can replace the maximum values with:\n",
      "\n",
      "    >>> ai = np.expand_dims(np.argmax(a, axis=1), axis=1)\n",
      "    >>> ai\n",
      "    array([[1],\n",
      "           [0]])\n",
      "    >>> np.put_along_axis(a, ai, 99, axis=1)\n",
      "    >>> a\n",
      "    array([[10, 99, 20],\n",
      "           [99, 40, 50]])\n",
      "\n",
      "    \n",
      "code: broadcast_to\n",
      "@array_function_dispatch(_broadcast_to_dispatcher, module='numpy')\n",
      "def broadcast_to(array, shape, subok=False):\n",
      "    return _broadcast_to(array, shape, subok=subok, readonly=True)\n",
      "docstring: broadcast_to\n",
      "Broadcast an array to a new shape.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    array : array_like\n",
      "        The array to broadcast.\n",
      "    shape : tuple or int\n",
      "        The shape of the desired array. A single integer ``i`` is interpreted\n",
      "        as ``(i,)``.\n",
      "    subok : bool, optional\n",
      "        If True, then sub-classes will be passed-through, otherwise\n",
      "        the returned array will be forced to be a base-class array (default).\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    broadcast : array\n",
      "        A readonly view on the original array with the given shape. It is\n",
      "        typically not contiguous. Furthermore, more than one element of a\n",
      "        broadcasted array may refer to a single memory location.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If the array is not compatible with the new shape according to NumPy's\n",
      "        broadcasting rules.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    broadcast\n",
      "    broadcast_arrays\n",
      "    broadcast_shapes\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.10.0\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([1, 2, 3])\n",
      "    >>> np.broadcast_to(x, (3, 3))\n",
      "    array([[1, 2, 3],\n",
      "           [1, 2, 3],\n",
      "           [1, 2, 3]])\n",
      "    \n",
      "code: broadcast_arrays\n",
      "@array_function_dispatch(_broadcast_arrays_dispatcher, module='numpy')\n",
      "def broadcast_arrays(*args, subok=False):\n",
      " Otherwise, something like the following one-liner would suffice:\n",
      "                  order='C').itviews\n",
      "    args = [np.array(_m, copy=False, subok=subok) for _m in args]\n",
      "    shape = _broadcast_shape(*args)\n",
      "    if all(array.shape == shape for array in args):\n",
      "        # Common case where nothing needs to be broadcasted.\n",
      "        return args\n",
      "    return [_broadcast_to(array, shape, subok=subok, readonly=False)\n",
      "            for array in args]\n",
      "docstring: broadcast_arrays\n",
      "\n",
      "    Broadcast any number of arrays against each other.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    `*args` : array_likes\n",
      "        The arrays to broadcast.\n",
      "\n",
      "    subok : bool, optional\n",
      "        If True, then sub-classes will be passed-through, otherwise\n",
      "        the returned arrays will be forced to be a base-class array (default).\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    broadcasted : list of arrays\n",
      "        These arrays are views on the original arrays.  They are typically\n",
      "        not contiguous.  Furthermore, more than one element of a\n",
      "        broadcasted array may refer to a single memory location. If you need\n",
      "        to write to the arrays, make copies first. While you can set the\n",
      "        ``writable`` flag True, writing to a single output value may end up\n",
      "        changing more than one location in the output array.\n",
      "\n",
      "        .. deprecated:: 1.17\n",
      "            The output is currently marked so that if written to, a deprecation\n",
      "            warning will be emitted. A future version will set the\n",
      "            ``writable`` flag False so writing to it will raise an error.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    broadcast\n",
      "    broadcast_to\n",
      "    broadcast_shapes\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([[1,2,3]])\n",
      "    >>> y = np.array([[4],[5]])\n",
      "    >>> np.broadcast_arrays(x, y)\n",
      "    [array([[1, 2, 3],\n",
      "           [1, 2, 3]]), array([[4, 4, 4],\n",
      "           [5, 5, 5]])]\n",
      "\n",
      "    Here is a useful idiom for getting contiguous copies instead of\n",
      "    non-contiguous views.\n",
      "\n",
      "    >>> [np.array(a) for a in np.broadcast_arrays(x, y)]\n",
      "    [array([[1, 2, 3],\n",
      "           [1, 2, 3]]), array([[4, 4, 4],\n",
      "           [5, 5, 5]])]\n",
      "\n",
      "    \n",
      "code: broadcast_shapes\n",
      "@set_module('numpy')\n",
      "def broadcast_shapes(*args):\n",
      "    arrays = [np.empty(x, dtype=[]) for x in args]\n",
      "    return _broadcast_shape(*arrays)\n",
      "docstring: broadcast_shapes\n",
      "\n",
      "    Broadcast the input shapes into a single shape.\n",
      "\n",
      "    :ref:`Learn more about broadcasting here <basics.broadcasting>`.\n",
      "\n",
      "    .. versionadded:: 1.20.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    `*args` : tuples of ints, or ints\n",
      "        The shapes to be broadcast against each other.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    tuple\n",
      "        Broadcasted shape.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If the shapes are not compatible and cannot be broadcast according\n",
      "        to NumPy's broadcasting rules.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    broadcast\n",
      "    broadcast_arrays\n",
      "    broadcast_to\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.broadcast_shapes((1, 2), (3, 1), (3, 2))\n",
      "    (3, 2)\n",
      "\n",
      "    >>> np.broadcast_shapes((6, 7), (5, 6, 1), (7,), (5, 1, 7))\n",
      "    (5, 6, 7)\n",
      "    \n",
      "code: diag\n",
      "@array_function_dispatch(_diag_dispatcher)\n",
      "def diag(v, k=0):\n",
      "    v = asanyarray(v)\n",
      "    s = v.shape\n",
      "    if len(s) == 1:\n",
      "        n = s[0]+abs(k)\n",
      "        res = zeros((n, n), v.dtype)\n",
      "        if k >= 0:\n",
      "            i = k\n",
      "        else:\n",
      "            i = (-k) * n\n",
      "        res[:n-k].flat[i::n+1] = v\n",
      "        return res\n",
      "    elif len(s) == 2:\n",
      "        return diagonal(v, k)\n",
      "    else:\n",
      "        raise ValueError(\"Input must be 1- or 2-d.\")\n",
      "docstring: diag\n",
      "\n",
      "    Extract a diagonal or construct a diagonal array.\n",
      "\n",
      "    See the more detailed documentation for ``numpy.diagonal`` if you use this\n",
      "    function to extract a diagonal and wish to write to the resulting array;\n",
      "    whether it returns a copy or a view depends on what version of numpy you\n",
      "    are using.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    v : array_like\n",
      "        If `v` is a 2-D array, return a copy of its `k`-th diagonal.\n",
      "        If `v` is a 1-D array, return a 2-D array with `v` on the `k`-th\n",
      "        diagonal.\n",
      "    k : int, optional\n",
      "        Diagonal in question. The default is 0. Use `k>0` for diagonals\n",
      "        above the main diagonal, and `k<0` for diagonals below the main\n",
      "        diagonal.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The extracted diagonal or constructed diagonal array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    diagonal : Return specified diagonals.\n",
      "    diagflat : Create a 2-D array with the flattened input as a diagonal.\n",
      "    trace : Sum along diagonals.\n",
      "    triu : Upper triangle of an array.\n",
      "    tril : Lower triangle of an array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(9).reshape((3,3))\n",
      "    >>> x\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5],\n",
      "           [6, 7, 8]])\n",
      "\n",
      "    >>> np.diag(x)\n",
      "    array([0, 4, 8])\n",
      "    >>> np.diag(x, k=1)\n",
      "    array([1, 5])\n",
      "    >>> np.diag(x, k=-1)\n",
      "    array([3, 7])\n",
      "\n",
      "    >>> np.diag(np.diag(x))\n",
      "    array([[0, 0, 0],\n",
      "           [0, 4, 0],\n",
      "           [0, 0, 8]])\n",
      "\n",
      "    \n",
      "code: diagflat\n",
      "@array_function_dispatch(_diag_dispatcher)\n",
      "def diagflat(v, k=0):\n",
      "    try:\n",
      "        wrap = v.__array_wrap__\n",
      "    except AttributeError:\n",
      "        wrap = None\n",
      "    v = asarray(v).ravel()\n",
      "    s = len(v)\n",
      "    n = s + abs(k)\n",
      "    res = zeros((n, n), v.dtype)\n",
      "    if (k >= 0):\n",
      "        i = arange(0, n-k, dtype=intp)\n",
      "        fi = i+k+i*n\n",
      "    else:\n",
      "        i = arange(0, n+k, dtype=intp)\n",
      "        fi = i+(i-k)*n\n",
      "    res.flat[fi] = v\n",
      "    if not wrap:\n",
      "        return res\n",
      "    return wrap(res)\n",
      "docstring: diagflat\n",
      "\n",
      "    Create a two-dimensional array with the flattened input as a diagonal.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    v : array_like\n",
      "        Input data, which is flattened and set as the `k`-th\n",
      "        diagonal of the output.\n",
      "    k : int, optional\n",
      "        Diagonal to set; 0, the default, corresponds to the \"main\" diagonal,\n",
      "        a positive (negative) `k` giving the number of the diagonal above\n",
      "        (below) the main.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The 2-D output array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    diag : MATLAB work-alike for 1-D and 2-D arrays.\n",
      "    diagonal : Return specified diagonals.\n",
      "    trace : Sum along diagonals.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.diagflat([[1,2], [3,4]])\n",
      "    array([[1, 0, 0, 0],\n",
      "           [0, 2, 0, 0],\n",
      "           [0, 0, 3, 0],\n",
      "           [0, 0, 0, 4]])\n",
      "\n",
      "    >>> np.diagflat([1,2], 1)\n",
      "    array([[0, 1, 0],\n",
      "           [0, 0, 2],\n",
      "           [0, 0, 0]])\n",
      "\n",
      "    \n",
      "code: eye\n",
      "@set_array_function_like_doc\n",
      "@set_module('numpy')\n",
      "def eye(N, M=None, k=0, dtype=float, order='C', *, like=None):\n",
      "    if like is not None:\n",
      "        return _eye_with_like(N, M=M, k=k, dtype=dtype, order=order, like=like)\n",
      "    if M is None:\n",
      "        M = N\n",
      "    m = zeros((N, M), dtype=dtype, order=order)\n",
      "    if k >= M:\n",
      "        return m\n",
      " results in the expressions `M-k` and `M+1` used below.  This avoids\n",
      "    # a problem with inputs with type (for example) np.uint64.\n",
      "    M = operator.index(M)\n",
      "    k = operator.index(k)\n",
      "    if k >= 0:\n",
      "        i = k\n",
      "    else:\n",
      "        i = (-k) * M\n",
      "    m[:M-k].flat[i::M+1] = 1\n",
      "    return m\n",
      "docstring: eye\n",
      "\n",
      "    Return a 2-D array with ones on the diagonal and zeros elsewhere.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    N : int\n",
      "      Number of rows in the output.\n",
      "    M : int, optional\n",
      "      Number of columns in the output. If None, defaults to `N`.\n",
      "    k : int, optional\n",
      "      Index of the diagonal: 0 (the default) refers to the main diagonal,\n",
      "      a positive value refers to an upper diagonal, and a negative value\n",
      "      to a lower diagonal.\n",
      "    dtype : data-type, optional\n",
      "      Data-type of the returned array.\n",
      "    order : {'C', 'F'}, optional\n",
      "        Whether the output should be stored in row-major (C-style) or\n",
      "        column-major (Fortran-style) order in memory.\n",
      "\n",
      "        .. versionadded:: 1.14.0\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    I : ndarray of shape (N,M)\n",
      "      An array where all elements are equal to zero, except for the `k`-th\n",
      "      diagonal, whose values are equal to one.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    identity : (almost) equivalent function\n",
      "    diag : diagonal 2-D array from a 1-D array specified by the user.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.eye(2, dtype=int)\n",
      "    array([[1, 0],\n",
      "           [0, 1]])\n",
      "    >>> np.eye(3, k=1)\n",
      "    array([[0.,  1.,  0.],\n",
      "           [0.,  0.,  1.],\n",
      "           [0.,  0.,  0.]])\n",
      "\n",
      "    \n",
      "code: fliplr\n",
      "@array_function_dispatch(_flip_dispatcher)\n",
      "def fliplr(m):\n",
      "    m = asanyarray(m)\n",
      "    if m.ndim < 2:\n",
      "        raise ValueError(\"Input must be >= 2-d.\")\n",
      "    return m[:, ::-1]\n",
      "docstring: fliplr\n",
      "\n",
      "    Reverse the order of elements along axis 1 (left/right).\n",
      "\n",
      "    For a 2-D array, this flips the entries in each row in the left/right\n",
      "    direction. Columns are preserved, but appear in a different order than\n",
      "    before.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    m : array_like\n",
      "        Input array, must be at least 2-D.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    f : ndarray\n",
      "        A view of `m` with the columns reversed.  Since a view\n",
      "        is returned, this operation is :math:`\\mathcal O(1)`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    flipud : Flip array in the up/down direction.\n",
      "    flip : Flip array in one or more dimensions.\n",
      "    rot90 : Rotate array counterclockwise.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Equivalent to ``m[:,::-1]`` or ``np.flip(m, axis=1)``.\n",
      "    Requires the array to be at least 2-D.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> A = np.diag([1.,2.,3.])\n",
      "    >>> A\n",
      "    array([[1.,  0.,  0.],\n",
      "           [0.,  2.,  0.],\n",
      "           [0.,  0.,  3.]])\n",
      "    >>> np.fliplr(A)\n",
      "    array([[0.,  0.,  1.],\n",
      "           [0.,  2.,  0.],\n",
      "           [3.,  0.,  0.]])\n",
      "\n",
      "    >>> A = np.random.randn(2,3,5)\n",
      "    >>> np.all(np.fliplr(A) == A[:,::-1,...])\n",
      "    True\n",
      "\n",
      "    \n",
      "code: flipud\n",
      "@array_function_dispatch(_flip_dispatcher)\n",
      "def flipud(m):\n",
      "    m = asanyarray(m)\n",
      "    if m.ndim < 1:\n",
      "        raise ValueError(\"Input must be >= 1-d.\")\n",
      "    return m[::-1, ...]\n",
      "docstring: flipud\n",
      "\n",
      "    Reverse the order of elements along axis 0 (up/down).\n",
      "\n",
      "    For a 2-D array, this flips the entries in each column in the up/down\n",
      "    direction. Rows are preserved, but appear in a different order than before.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    m : array_like\n",
      "        Input array.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : array_like\n",
      "        A view of `m` with the rows reversed.  Since a view is\n",
      "        returned, this operation is :math:`\\mathcal O(1)`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    fliplr : Flip array in the left/right direction.\n",
      "    flip : Flip array in one or more dimensions.\n",
      "    rot90 : Rotate array counterclockwise.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Equivalent to ``m[::-1, ...]`` or ``np.flip(m, axis=0)``.\n",
      "    Requires the array to be at least 1-D.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> A = np.diag([1.0, 2, 3])\n",
      "    >>> A\n",
      "    array([[1.,  0.,  0.],\n",
      "           [0.,  2.,  0.],\n",
      "           [0.,  0.,  3.]])\n",
      "    >>> np.flipud(A)\n",
      "    array([[0.,  0.,  3.],\n",
      "           [0.,  2.,  0.],\n",
      "           [1.,  0.,  0.]])\n",
      "\n",
      "    >>> A = np.random.randn(2,3,5)\n",
      "    >>> np.all(np.flipud(A) == A[::-1,...])\n",
      "    True\n",
      "\n",
      "    >>> np.flipud([1,2])\n",
      "    array([2, 1])\n",
      "\n",
      "    \n",
      "code: tri\n",
      "@set_array_function_like_doc\n",
      "@set_module('numpy')\n",
      "def tri(N, M=None, k=0, dtype=float, *, like=None):\n",
      "    if like is not None:\n",
      "        return _tri_with_like(N, M=M, k=k, dtype=dtype, like=like)\n",
      "    if M is None:\n",
      "        M = N\n",
      "    m = greater_equal.outer(arange(N, dtype=_min_int(0, N)),\n",
      "                            arange(-k, M-k, dtype=_min_int(-k, M - k)))\n",
      "    # Avoid making a copy if the requested type is already bool\n",
      "    m = m.astype(dtype, copy=False)\n",
      "    return m\n",
      "docstring: tri\n",
      "\n",
      "    An array with ones at and below the given diagonal and zeros elsewhere.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    N : int\n",
      "        Number of rows in the array.\n",
      "    M : int, optional\n",
      "        Number of columns in the array.\n",
      "        By default, `M` is taken equal to `N`.\n",
      "    k : int, optional\n",
      "        The sub-diagonal at and below which the array is filled.\n",
      "        `k` = 0 is the main diagonal, while `k` < 0 is below it,\n",
      "        and `k` > 0 is above.  The default is 0.\n",
      "    dtype : dtype, optional\n",
      "        Data type of the returned array.  The default is float.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    tri : ndarray of shape (N, M)\n",
      "        Array with its lower triangle filled with ones and zero elsewhere;\n",
      "        in other words ``T[i,j] == 1`` for ``j <= i + k``, 0 otherwise.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.tri(3, 5, 2, dtype=int)\n",
      "    array([[1, 1, 1, 0, 0],\n",
      "           [1, 1, 1, 1, 0],\n",
      "           [1, 1, 1, 1, 1]])\n",
      "\n",
      "    >>> np.tri(3, 5, -1)\n",
      "    array([[0.,  0.,  0.,  0.,  0.],\n",
      "           [1.,  0.,  0.,  0.,  0.],\n",
      "           [1.,  1.,  0.,  0.,  0.]])\n",
      "\n",
      "    \n",
      "code: triu\n",
      "@array_function_dispatch(_trilu_dispatcher)\n",
      "def triu(m, k=0):\n",
      "    m = asanyarray(m)\n",
      "    mask = tri(*m.shape[-2:], k=k-1, dtype=bool)\n",
      "    return where(mask, zeros(1, m.dtype), m)\n",
      "docstring: triu\n",
      "\n",
      "    Upper triangle of an array.\n",
      "\n",
      "    Return a copy of an array with the elements below the `k`-th diagonal\n",
      "    zeroed. For arrays with ``ndim`` exceeding 2, `triu` will apply to the\n",
      "    final two axes.\n",
      "\n",
      "    Please refer to the documentation for `tril` for further details.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    tril : lower triangle of an array\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)\n",
      "    array([[ 1,  2,  3],\n",
      "           [ 4,  5,  6],\n",
      "           [ 0,  8,  9],\n",
      "           [ 0,  0, 12]])\n",
      "\n",
      "    >>> np.triu(np.arange(3*4*5).reshape(3, 4, 5))\n",
      "    array([[[ 0,  1,  2,  3,  4],\n",
      "            [ 0,  6,  7,  8,  9],\n",
      "            [ 0,  0, 12, 13, 14],\n",
      "            [ 0,  0,  0, 18, 19]],\n",
      "           [[20, 21, 22, 23, 24],\n",
      "            [ 0, 26, 27, 28, 29],\n",
      "            [ 0,  0, 32, 33, 34],\n",
      "            [ 0,  0,  0, 38, 39]],\n",
      "           [[40, 41, 42, 43, 44],\n",
      "            [ 0, 46, 47, 48, 49],\n",
      "            [ 0,  0, 52, 53, 54],\n",
      "            [ 0,  0,  0, 58, 59]]])\n",
      "\n",
      "    \n",
      "code: tril\n",
      "@array_function_dispatch(_trilu_dispatcher)\n",
      "def tril(m, k=0):\n",
      "    m = asanyarray(m)\n",
      "    mask = tri(*m.shape[-2:], k=k, dtype=bool)\n",
      "    return where(mask, m, zeros(1, m.dtype))\n",
      "docstring: tril\n",
      "\n",
      "    Lower triangle of an array.\n",
      "\n",
      "    Return a copy of an array with elements above the `k`-th diagonal zeroed.\n",
      "    For arrays with ``ndim`` exceeding 2, `tril` will apply to the final two\n",
      "    axes.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    m : array_like, shape (..., M, N)\n",
      "        Input array.\n",
      "    k : int, optional\n",
      "        Diagonal above which to zero elements.  `k = 0` (the default) is the\n",
      "        main diagonal, `k < 0` is below it and `k > 0` is above.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    tril : ndarray, shape (..., M, N)\n",
      "        Lower triangle of `m`, of same shape and data-type as `m`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    triu : same thing, only for the upper triangle\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.tril([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)\n",
      "    array([[ 0,  0,  0],\n",
      "           [ 4,  0,  0],\n",
      "           [ 7,  8,  0],\n",
      "           [10, 11, 12]])\n",
      "\n",
      "    >>> np.tril(np.arange(3*4*5).reshape(3, 4, 5))\n",
      "    array([[[ 0,  0,  0,  0,  0],\n",
      "            [ 5,  6,  0,  0,  0],\n",
      "            [10, 11, 12,  0,  0],\n",
      "            [15, 16, 17, 18,  0]],\n",
      "           [[20,  0,  0,  0,  0],\n",
      "            [25, 26,  0,  0,  0],\n",
      "            [30, 31, 32,  0,  0],\n",
      "            [35, 36, 37, 38,  0]],\n",
      "           [[40,  0,  0,  0,  0],\n",
      "            [45, 46,  0,  0,  0],\n",
      "            [50, 51, 52,  0,  0],\n",
      "            [55, 56, 57, 58,  0]]])\n",
      "\n",
      "    \n",
      "code: vander\n",
      "@array_function_dispatch(_vander_dispatcher)\n",
      "def vander(x, N=None, increasing=False):\n",
      "    x = asarray(x)\n",
      "    if x.ndim != 1:\n",
      "        raise ValueError(\"x must be a one-dimensional array or sequence.\")\n",
      "    if N is None:\n",
      "        N = len(x)\n",
      "    v = empty((len(x), N), dtype=promote_types(x.dtype, int))\n",
      "    tmp = v[:, ::-1] if not increasing else v\n",
      "    if N > 0:\n",
      "        tmp[:, 0] = 1\n",
      "    if N > 1:\n",
      "        tmp[:, 1:] = x[:, None]\n",
      "        multiply.accumulate(tmp[:, 1:], out=tmp[:, 1:], axis=1)\n",
      "    return v\n",
      "docstring: vander\n",
      "\n",
      "    Generate a Vandermonde matrix.\n",
      "\n",
      "    The columns of the output matrix are powers of the input vector. The\n",
      "    order of the powers is determined by the `increasing` boolean argument.\n",
      "    Specifically, when `increasing` is False, the `i`-th output column is\n",
      "    the input vector raised element-wise to the power of ``N - i - 1``. Such\n",
      "    a matrix with a geometric progression in each row is named for Alexandre-\n",
      "    Theophile Vandermonde.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        1-D input array.\n",
      "    N : int, optional\n",
      "        Number of columns in the output.  If `N` is not specified, a square\n",
      "        array is returned (``N = len(x)``).\n",
      "    increasing : bool, optional\n",
      "        Order of the powers of the columns.  If True, the powers increase\n",
      "        from left to right, if False (the default) they are reversed.\n",
      "\n",
      "        .. versionadded:: 1.9.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Vandermonde matrix.  If `increasing` is False, the first column is\n",
      "        ``x^(N-1)``, the second ``x^(N-2)`` and so forth. If `increasing` is\n",
      "        True, the columns are ``x^0, x^1, ..., x^(N-1)``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    polynomial.polynomial.polyvander\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([1, 2, 3, 5])\n",
      "    >>> N = 3\n",
      "    >>> np.vander(x, N)\n",
      "    array([[ 1,  1,  1],\n",
      "           [ 4,  2,  1],\n",
      "           [ 9,  3,  1],\n",
      "           [25,  5,  1]])\n",
      "\n",
      "    >>> np.column_stack([x**(N-1-i) for i in range(N)])\n",
      "    array([[ 1,  1,  1],\n",
      "           [ 4,  2,  1],\n",
      "           [ 9,  3,  1],\n",
      "           [25,  5,  1]])\n",
      "\n",
      "    >>> x = np.array([1, 2, 3, 5])\n",
      "    >>> np.vander(x)\n",
      "    array([[  1,   1,   1,   1],\n",
      "           [  8,   4,   2,   1],\n",
      "           [ 27,   9,   3,   1],\n",
      "           [125,  25,   5,   1]])\n",
      "    >>> np.vander(x, increasing=True)\n",
      "    array([[  1,   1,   1,   1],\n",
      "           [  1,   2,   4,   8],\n",
      "           [  1,   3,   9,  27],\n",
      "           [  1,   5,  25, 125]])\n",
      "\n",
      "    The determinant of a square Vandermonde matrix is the product\n",
      "    of the differences between the values of the input vector:\n",
      "\n",
      "    >>> np.linalg.det(np.vander(x))\n",
      "    48.000000000000043 # may vary\n",
      "    >>> (5-3)*(5-2)*(5-1)*(3-2)*(3-1)*(2-1)\n",
      "    48\n",
      "\n",
      "    \n",
      "code: histogram2d\n",
      "@array_function_dispatch(_histogram2d_dispatcher)\n",
      "def histogram2d(x, y, bins=10, range=None, density=None, weights=None):\n",
      "    from numpy import histogramdd\n",
      "    if len(x) != len(y):\n",
      "        raise ValueError('x and y must have the same length.')\n",
      "    try:\n",
      "        N = len(bins)\n",
      "    except TypeError:\n",
      "        N = 1\n",
      "    if N != 1 and N != 2:\n",
      "        xedges = yedges = asarray(bins)\n",
      "        bins = [xedges, yedges]\n",
      "    hist, edges = histogramdd([x, y], bins, range, density, weights)\n",
      "    return hist, edges[0], edges[1]\n",
      "docstring: histogram2d\n",
      "\n",
      "    Compute the bi-dimensional histogram of two data samples.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like, shape (N,)\n",
      "        An array containing the x coordinates of the points to be\n",
      "        histogrammed.\n",
      "    y : array_like, shape (N,)\n",
      "        An array containing the y coordinates of the points to be\n",
      "        histogrammed.\n",
      "    bins : int or array_like or [int, int] or [array, array], optional\n",
      "        The bin specification:\n",
      "\n",
      "          * If int, the number of bins for the two dimensions (nx=ny=bins).\n",
      "          * If array_like, the bin edges for the two dimensions\n",
      "            (x_edges=y_edges=bins).\n",
      "          * If [int, int], the number of bins in each dimension\n",
      "            (nx, ny = bins).\n",
      "          * If [array, array], the bin edges in each dimension\n",
      "            (x_edges, y_edges = bins).\n",
      "          * A combination [int, array] or [array, int], where int\n",
      "            is the number of bins and array is the bin edges.\n",
      "\n",
      "    range : array_like, shape(2,2), optional\n",
      "        The leftmost and rightmost edges of the bins along each dimension\n",
      "        (if not specified explicitly in the `bins` parameters):\n",
      "        ``[[xmin, xmax], [ymin, ymax]]``. All values outside of this range\n",
      "        will be considered outliers and not tallied in the histogram.\n",
      "    density : bool, optional\n",
      "        If False, the default, returns the number of samples in each bin.\n",
      "        If True, returns the probability *density* function at the bin,\n",
      "        ``bin_count / sample_count / bin_area``.\n",
      "    weights : array_like, shape(N,), optional\n",
      "        An array of values ``w_i`` weighing each sample ``(x_i, y_i)``.\n",
      "        Weights are normalized to 1 if `density` is True. If `density` is\n",
      "        False, the values of the returned histogram are equal to the sum of\n",
      "        the weights belonging to the samples falling into each bin.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    H : ndarray, shape(nx, ny)\n",
      "        The bi-dimensional histogram of samples `x` and `y`. Values in `x`\n",
      "        are histogrammed along the first dimension and values in `y` are\n",
      "        histogrammed along the second dimension.\n",
      "    xedges : ndarray, shape(nx+1,)\n",
      "        The bin edges along the first dimension.\n",
      "    yedges : ndarray, shape(ny+1,)\n",
      "        The bin edges along the second dimension.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    histogram : 1D histogram\n",
      "    histogramdd : Multidimensional histogram\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When `density` is True, then the returned histogram is the sample\n",
      "    density, defined such that the sum over bins of the product\n",
      "    ``bin_value * bin_area`` is 1.\n",
      "\n",
      "    Please note that the histogram does not follow the Cartesian convention\n",
      "    where `x` values are on the abscissa and `y` values on the ordinate\n",
      "    axis.  Rather, `x` is histogrammed along the first dimension of the\n",
      "    array (vertical), and `y` along the second dimension of the array\n",
      "    (horizontal).  This ensures compatibility with `histogramdd`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from matplotlib.image import NonUniformImage\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "\n",
      "    Construct a 2-D histogram with variable bin width. First define the bin\n",
      "    edges:\n",
      "\n",
      "    >>> xedges = [0, 1, 3, 5]\n",
      "    >>> yedges = [0, 2, 3, 4, 6]\n",
      "\n",
      "    Next we create a histogram H with random bin content:\n",
      "\n",
      "    >>> x = np.random.normal(2, 1, 100)\n",
      "    >>> y = np.random.normal(1, 1, 100)\n",
      "    >>> H, xedges, yedges = np.histogram2d(x, y, bins=(xedges, yedges))\n",
      "    >>> # Histogram does not follow Cartesian convention (see Notes),\n",
      "    >>> # therefore transpose H for visualization purposes.\n",
      "    >>> H = H.T\n",
      "\n",
      "    :func:`imshow <matplotlib.pyplot.imshow>` can only display square bins:\n",
      "\n",
      "    >>> fig = plt.figure(figsize=(7, 3))\n",
      "    >>> ax = fig.add_subplot(131, title='imshow: square bins')\n",
      "    >>> plt.imshow(H, interpolation='nearest', origin='lower',\n",
      "    ...         extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n",
      "    <matplotlib.image.AxesImage object at 0x...>\n",
      "\n",
      "    :func:`pcolormesh <matplotlib.pyplot.pcolormesh>` can display actual edges:\n",
      "\n",
      "    >>> ax = fig.add_subplot(132, title='pcolormesh: actual edges',\n",
      "    ...         aspect='equal')\n",
      "    >>> X, Y = np.meshgrid(xedges, yedges)\n",
      "    >>> ax.pcolormesh(X, Y, H)\n",
      "    <matplotlib.collections.QuadMesh object at 0x...>\n",
      "\n",
      "    :class:`NonUniformImage <matplotlib.image.NonUniformImage>` can be used to\n",
      "    display actual bin edges with interpolation:\n",
      "\n",
      "    >>> ax = fig.add_subplot(133, title='NonUniformImage: interpolated',\n",
      "    ...         aspect='equal', xlim=xedges[[0, -1]], ylim=yedges[[0, -1]])\n",
      "    >>> im = NonUniformImage(ax, interpolation='bilinear')\n",
      "    >>> xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
      "    >>> ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
      "    >>> im.set_data(xcenters, ycenters, H)\n",
      "    >>> ax.images.append(im)\n",
      "    >>> plt.show()\n",
      "\n",
      "    It is also possible to construct a 2-D histogram without specifying bin\n",
      "    edges:\n",
      "\n",
      "    >>> # Generate non-symmetric test data\n",
      "    >>> n = 10000\n",
      "    >>> x = np.linspace(1, 100, n)\n",
      "    >>> y = 2*np.log(x) + np.random.rand(n) - 0.5\n",
      "    >>> # Compute 2d histogram. Note the order of x/y and xedges/yedges\n",
      "    >>> H, yedges, xedges = np.histogram2d(y, x, bins=20)\n",
      "\n",
      "    Now we can plot the histogram using\n",
      "    :func:`pcolormesh <matplotlib.pyplot.pcolormesh>`, and a\n",
      "    :func:`hexbin <matplotlib.pyplot.hexbin>` for comparison.\n",
      "\n",
      "    >>> # Plot histogram using pcolormesh\n",
      "    >>> fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
      "    >>> ax1.pcolormesh(xedges, yedges, H, cmap='rainbow')\n",
      "    >>> ax1.plot(x, 2*np.log(x), 'k-')\n",
      "    >>> ax1.set_xlim(x.min(), x.max())\n",
      "    >>> ax1.set_ylim(y.min(), y.max())\n",
      "    >>> ax1.set_xlabel('x')\n",
      "    >>> ax1.set_ylabel('y')\n",
      "    >>> ax1.set_title('histogram2d')\n",
      "    >>> ax1.grid()\n",
      "\n",
      "    >>> # Create hexbin plot for comparison\n",
      "    >>> ax2.hexbin(x, y, gridsize=20, cmap='rainbow')\n",
      "    >>> ax2.plot(x, 2*np.log(x), 'k-')\n",
      "    >>> ax2.set_title('hexbin')\n",
      "    >>> ax2.set_xlim(x.min(), x.max())\n",
      "    >>> ax2.set_xlabel('x')\n",
      "    >>> ax2.grid()\n",
      "\n",
      "    >>> plt.show()\n",
      "    \n",
      "code: mask_indices\n",
      "@set_module('numpy')\n",
      "def mask_indices(n, mask_func, k=0):\n",
      "    m = ones((n, n), int)\n",
      "    a = mask_func(m, k)\n",
      "    return nonzero(a != 0)\n",
      "docstring: mask_indices\n",
      "\n",
      "    Return the indices to access (n, n) arrays, given a masking function.\n",
      "\n",
      "    Assume `mask_func` is a function that, for a square array a of size\n",
      "    ``(n, n)`` with a possible offset argument `k`, when called as\n",
      "    ``mask_func(a, k)`` returns a new array with zeros in certain locations\n",
      "    (functions like `triu` or `tril` do precisely this). Then this function\n",
      "    returns the indices where the non-zero values would be located.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n : int\n",
      "        The returned indices will be valid to access arrays of shape (n, n).\n",
      "    mask_func : callable\n",
      "        A function whose call signature is similar to that of `triu`, `tril`.\n",
      "        That is, ``mask_func(x, k)`` returns a boolean array, shaped like `x`.\n",
      "        `k` is an optional argument to the function.\n",
      "    k : scalar\n",
      "        An optional argument which is passed through to `mask_func`. Functions\n",
      "        like `triu`, `tril` take a second argument that is interpreted as an\n",
      "        offset.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    indices : tuple of arrays.\n",
      "        The `n` arrays of indices corresponding to the locations where\n",
      "        ``mask_func(np.ones((n, n)), k)`` is True.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    triu, tril, triu_indices, tril_indices\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    These are the indices that would allow you to access the upper triangular\n",
      "    part of any 3x3 array:\n",
      "\n",
      "    >>> iu = np.mask_indices(3, np.triu)\n",
      "\n",
      "    For example, if `a` is a 3x3 array:\n",
      "\n",
      "    >>> a = np.arange(9).reshape(3, 3)\n",
      "    >>> a\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5],\n",
      "           [6, 7, 8]])\n",
      "    >>> a[iu]\n",
      "    array([0, 1, 2, 4, 5, 8])\n",
      "\n",
      "    An offset can be passed also to the masking function.  This gets us the\n",
      "    indices starting on the first diagonal right of the main one:\n",
      "\n",
      "    >>> iu1 = np.mask_indices(3, np.triu, 1)\n",
      "\n",
      "    with which we now extract only three elements:\n",
      "\n",
      "    >>> a[iu1]\n",
      "    array([1, 2, 5])\n",
      "\n",
      "    \n",
      "code: tril_indices\n",
      "@set_module('numpy')\n",
      "def tril_indices(n, k=0, m=None):\n",
      "    tri_ = tri(n, m, k=k, dtype=bool)\n",
      "    return tuple(broadcast_to(inds, tri_.shape)[tri_]\n",
      "                 for inds in indices(tri_.shape, sparse=True))\n",
      "docstring: tril_indices\n",
      "\n",
      "    Return the indices for the lower-triangle of an (n, m) array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n : int\n",
      "        The row dimension of the arrays for which the returned\n",
      "        indices will be valid.\n",
      "    k : int, optional\n",
      "        Diagonal offset (see `tril` for details).\n",
      "    m : int, optional\n",
      "        .. versionadded:: 1.9.0\n",
      "\n",
      "        The column dimension of the arrays for which the returned\n",
      "        arrays will be valid.\n",
      "        By default `m` is taken equal to `n`.\n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    inds : tuple of arrays\n",
      "        The indices for the triangle. The returned tuple contains two arrays,\n",
      "        each with the indices along one dimension of the array.\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    triu_indices : similar function, for upper-triangular.\n",
      "    mask_indices : generic function accepting an arbitrary mask function.\n",
      "    tril, triu\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Compute two different sets of indices to access 4x4 arrays, one for the\n",
      "    lower triangular part starting at the main diagonal, and one starting two\n",
      "    diagonals further right:\n",
      "\n",
      "    >>> il1 = np.tril_indices(4)\n",
      "    >>> il2 = np.tril_indices(4, 2)\n",
      "\n",
      "    Here is how they can be used with a sample array:\n",
      "\n",
      "    >>> a = np.arange(16).reshape(4, 4)\n",
      "    >>> a\n",
      "    array([[ 0,  1,  2,  3],\n",
      "           [ 4,  5,  6,  7],\n",
      "           [ 8,  9, 10, 11],\n",
      "           [12, 13, 14, 15]])\n",
      "\n",
      "    Both for indexing:\n",
      "\n",
      "    >>> a[il1]\n",
      "    array([ 0,  4,  5, ..., 13, 14, 15])\n",
      "\n",
      "    And for assigning values:\n",
      "\n",
      "    >>> a[il1] = -1\n",
      "    >>> a\n",
      "    array([[-1,  1,  2,  3],\n",
      "           [-1, -1,  6,  7],\n",
      "           [-1, -1, -1, 11],\n",
      "           [-1, -1, -1, -1]])\n",
      "\n",
      "    These cover almost the whole array (two diagonals right of the main one):\n",
      "\n",
      "    >>> a[il2] = -10\n",
      "    >>> a\n",
      "    array([[-10, -10, -10,   3],\n",
      "           [-10, -10, -10, -10],\n",
      "           [-10, -10, -10, -10],\n",
      "           [-10, -10, -10, -10]])\n",
      "\n",
      "    \n",
      "code: tril_indices_from\n",
      "@array_function_dispatch(_trilu_indices_form_dispatcher)\n",
      "def tril_indices_from(arr, k=0):\n",
      "    if arr.ndim != 2:\n",
      "        raise ValueError(\"input array must be 2-d\")\n",
      "    return tril_indices(arr.shape[-2], k=k, m=arr.shape[-1])\n",
      "docstring: tril_indices_from\n",
      "\n",
      "    Return the indices for the lower-triangle of arr.\n",
      "\n",
      "    See `tril_indices` for full details.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : array_like\n",
      "        The indices will be valid for square arrays whose dimensions are\n",
      "        the same as arr.\n",
      "    k : int, optional\n",
      "        Diagonal offset (see `tril` for details).\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    tril_indices, tril\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "    \n",
      "code: triu_indices\n",
      "@set_module('numpy')\n",
      "def triu_indices(n, k=0, m=None):\n",
      "    tri_ = ~tri(n, m, k=k - 1, dtype=bool)\n",
      "    return tuple(broadcast_to(inds, tri_.shape)[tri_]\n",
      "                 for inds in indices(tri_.shape, sparse=True))\n",
      "docstring: triu_indices\n",
      "\n",
      "    Return the indices for the upper-triangle of an (n, m) array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n : int\n",
      "        The size of the arrays for which the returned indices will\n",
      "        be valid.\n",
      "    k : int, optional\n",
      "        Diagonal offset (see `triu` for details).\n",
      "    m : int, optional\n",
      "        .. versionadded:: 1.9.0\n",
      "\n",
      "        The column dimension of the arrays for which the returned\n",
      "        arrays will be valid.\n",
      "        By default `m` is taken equal to `n`.\n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    inds : tuple, shape(2) of ndarrays, shape(`n`)\n",
      "        The indices for the triangle. The returned tuple contains two arrays,\n",
      "        each with the indices along one dimension of the array.  Can be used\n",
      "        to slice a ndarray of shape(`n`, `n`).\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    tril_indices : similar function, for lower-triangular.\n",
      "    mask_indices : generic function accepting an arbitrary mask function.\n",
      "    triu, tril\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Compute two different sets of indices to access 4x4 arrays, one for the\n",
      "    upper triangular part starting at the main diagonal, and one starting two\n",
      "    diagonals further right:\n",
      "\n",
      "    >>> iu1 = np.triu_indices(4)\n",
      "    >>> iu2 = np.triu_indices(4, 2)\n",
      "\n",
      "    Here is how they can be used with a sample array:\n",
      "\n",
      "    >>> a = np.arange(16).reshape(4, 4)\n",
      "    >>> a\n",
      "    array([[ 0,  1,  2,  3],\n",
      "           [ 4,  5,  6,  7],\n",
      "           [ 8,  9, 10, 11],\n",
      "           [12, 13, 14, 15]])\n",
      "\n",
      "    Both for indexing:\n",
      "\n",
      "    >>> a[iu1]\n",
      "    array([ 0,  1,  2, ..., 10, 11, 15])\n",
      "\n",
      "    And for assigning values:\n",
      "\n",
      "    >>> a[iu1] = -1\n",
      "    >>> a\n",
      "    array([[-1, -1, -1, -1],\n",
      "           [ 4, -1, -1, -1],\n",
      "           [ 8,  9, -1, -1],\n",
      "           [12, 13, 14, -1]])\n",
      "\n",
      "    These cover only a small part of the whole array (two diagonals right\n",
      "    of the main one):\n",
      "\n",
      "    >>> a[iu2] = -10\n",
      "    >>> a\n",
      "    array([[ -1,  -1, -10, -10],\n",
      "           [  4,  -1,  -1, -10],\n",
      "           [  8,   9,  -1,  -1],\n",
      "           [ 12,  13,  14,  -1]])\n",
      "\n",
      "    \n",
      "code: triu_indices_from\n",
      "@array_function_dispatch(_trilu_indices_form_dispatcher)\n",
      "def triu_indices_from(arr, k=0):\n",
      "    if arr.ndim != 2:\n",
      "        raise ValueError(\"input array must be 2-d\")\n",
      "    return triu_indices(arr.shape[-2], k=k, m=arr.shape[-1])\n",
      "docstring: triu_indices_from\n",
      "\n",
      "    Return the indices for the upper-triangle of arr.\n",
      "\n",
      "    See `triu_indices` for full details.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arr : ndarray, shape(N, N)\n",
      "        The indices will be valid for square arrays.\n",
      "    k : int, optional\n",
      "        Diagonal offset (see `triu` for details).\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    triu_indices_from : tuple, shape(2) of ndarray, shape(N)\n",
      "        Indices for the upper-triangle of `arr`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    triu_indices, triu\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "    \n",
      "code: fix\n",
      "@array_function_dispatch(_dispatcher, verify=False, module='numpy')\n",
      "@_fix_and_maybe_deprecate_out_named_y\n",
      "def fix(x, out=None):\n",
      " when no out argument is passed and no subclasses are involved, flatten\n",
      "    # scalars\n",
      "    if out is None and type(res) is nx.ndarray:\n",
      "        res = res[()]\n",
      "    return res\n",
      "docstring: fix\n",
      "\n",
      "    Round to nearest integer towards zero.\n",
      "\n",
      "    Round an array of floats element-wise to nearest integer towards zero.\n",
      "    The rounded values are returned as floats.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        An array of floats to be rounded\n",
      "    out : ndarray, optional\n",
      "        A location into which the result is stored. If provided, it must have\n",
      "        a shape that the input broadcasts to. If not provided or None, a\n",
      "        freshly-allocated array is returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray of floats\n",
      "        A float array with the same dimensions as the input.\n",
      "        If second argument is not supplied then a float array is returned\n",
      "        with the rounded values.\n",
      "\n",
      "        If a second argument is supplied the result is stored there.\n",
      "        The return value `out` is then a reference to that array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    rint, trunc, floor, ceil\n",
      "    around : Round to given number of decimals\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.fix(3.14)\n",
      "    3.0\n",
      "    >>> np.fix(3)\n",
      "    3.0\n",
      "    >>> np.fix([2.1, 2.9, -2.1, -2.9])\n",
      "    array([ 2.,  2., -2., -2.])\n",
      "\n",
      "    \n",
      "code: isneginf\n",
      "@array_function_dispatch(_dispatcher, verify=False, module='numpy')\n",
      "@_fix_and_maybe_deprecate_out_named_y\n",
      "def isneginf(x, out=None):\n",
      "    is_inf = nx.isinf(x)\n",
      "    try:\n",
      "        signbit = nx.signbit(x)\n",
      "    except TypeError as e:\n",
      "        dtype = nx.asanyarray(x).dtype\n",
      "        raise TypeError(f'This operation is not supported for {dtype} values '\n",
      "                        'because it would be ambiguous.') from e\n",
      "    else:\n",
      "        return nx.logical_and(is_inf, signbit, out)\n",
      "docstring: isneginf\n",
      "\n",
      "    Test element-wise for negative infinity, return result as bool array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        The input array.\n",
      "    out : array_like, optional\n",
      "        A location into which the result is stored. If provided, it must have a\n",
      "        shape that the input broadcasts to. If not provided or None, a\n",
      "        freshly-allocated boolean array is returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        A boolean array with the same dimensions as the input.\n",
      "        If second argument is not supplied then a numpy boolean array is\n",
      "        returned with values True where the corresponding element of the\n",
      "        input is negative infinity and values False where the element of\n",
      "        the input is not negative infinity.\n",
      "\n",
      "        If a second argument is supplied the result is stored there. If the\n",
      "        type of that array is a numeric type the result is represented as\n",
      "        zeros and ones, if the type is boolean then as False and True. The\n",
      "        return value `out` is then a reference to that array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    isinf, isposinf, isnan, isfinite\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n",
      "    (IEEE 754).\n",
      "\n",
      "    Errors result if the second argument is also supplied when x is a scalar\n",
      "    input, if first and second arguments have different shapes, or if the\n",
      "    first argument has complex values.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.isneginf(np.NINF)\n",
      "    True\n",
      "    >>> np.isneginf(np.inf)\n",
      "    False\n",
      "    >>> np.isneginf(np.PINF)\n",
      "    False\n",
      "    >>> np.isneginf([-np.inf, 0., np.inf])\n",
      "    array([ True, False, False])\n",
      "\n",
      "    >>> x = np.array([-np.inf, 0., np.inf])\n",
      "    >>> y = np.array([2, 2, 2])\n",
      "    >>> np.isneginf(x, y)\n",
      "    array([1, 0, 0])\n",
      "    >>> y\n",
      "    array([1, 0, 0])\n",
      "\n",
      "    \n",
      "code: isposinf\n",
      "@array_function_dispatch(_dispatcher, verify=False, module='numpy')\n",
      "@_fix_and_maybe_deprecate_out_named_y\n",
      "def isposinf(x, out=None):\n",
      "    is_inf = nx.isinf(x)\n",
      "    try:\n",
      "        signbit = ~nx.signbit(x)\n",
      "    except TypeError as e:\n",
      "        dtype = nx.asanyarray(x).dtype\n",
      "        raise TypeError(f'This operation is not supported for {dtype} values '\n",
      "                        'because it would be ambiguous.') from e\n",
      "    else:\n",
      "        return nx.logical_and(is_inf, signbit, out)\n",
      "docstring: isposinf\n",
      "\n",
      "    Test element-wise for positive infinity, return result as bool array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        The input array.\n",
      "    out : array_like, optional\n",
      "        A location into which the result is stored. If provided, it must have a\n",
      "        shape that the input broadcasts to. If not provided or None, a\n",
      "        freshly-allocated boolean array is returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        A boolean array with the same dimensions as the input.\n",
      "        If second argument is not supplied then a boolean array is returned\n",
      "        with values True where the corresponding element of the input is\n",
      "        positive infinity and values False where the element of the input is\n",
      "        not positive infinity.\n",
      "\n",
      "        If a second argument is supplied the result is stored there. If the\n",
      "        type of that array is a numeric type the result is represented as zeros\n",
      "        and ones, if the type is boolean then as False and True.\n",
      "        The return value `out` is then a reference to that array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    isinf, isneginf, isfinite, isnan\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n",
      "    (IEEE 754).\n",
      "\n",
      "    Errors result if the second argument is also supplied when x is a scalar\n",
      "    input, if first and second arguments have different shapes, or if the\n",
      "    first argument has complex values\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.isposinf(np.PINF)\n",
      "    True\n",
      "    >>> np.isposinf(np.inf)\n",
      "    True\n",
      "    >>> np.isposinf(np.NINF)\n",
      "    False\n",
      "    >>> np.isposinf([-np.inf, 0., np.inf])\n",
      "    array([False, False,  True])\n",
      "\n",
      "    >>> x = np.array([-np.inf, 0., np.inf])\n",
      "    >>> y = np.array([2, 2, 2])\n",
      "    >>> np.isposinf(x, y)\n",
      "    array([0, 0, 1])\n",
      "    >>> y\n",
      "    array([0, 0, 1])\n",
      "\n",
      "    \n",
      "code: pad\n",
      "@array_function_dispatch(_pad_dispatcher, module='numpy')\n",
      "def pad(array, pad_width, mode='constant', **kwargs):\n",
      "    array = np.asarray(array)\n",
      "    pad_width = np.asarray(pad_width)\n",
      "    if not pad_width.dtype.kind == 'i':\n",
      "        raise TypeError('`pad_width` must be of integral type.')\n",
      " Old behavior: Use user-supplied function with np.apply_along_axis\n",
      "        function = mode\n",
      " And apply along each axis\n",
      "        for axis in range(padded.ndim):\n",
      " function operates inplace on the padded array.\n",
      " compute indices for the iteration axes, and append a trailing\n",
      " Make sure that no unsupported keywords were passed for the current mode\n",
      "    allowed_kwargs = {\n",
      "        'empty': [], 'edge': [], 'wrap': [],\n",
      "        'constant': ['constant_values'],\n",
      "        'linear_ramp': ['end_values'],\n",
      "        'maximum': ['stat_length'],\n",
      "        'mean': ['stat_length'],\n",
      "        'median': ['stat_length'],\n",
      "        'minimum': ['stat_length'],\n",
      "        'reflect': ['reflect_type'],\n",
      "        'symmetric': ['reflect_type'],\n",
      "    }\n",
      "    try:\n",
      "        unsupported_kwargs = set(kwargs) - set(allowed_kwargs[mode])\n",
      "    except KeyError:\n",
      "        raise ValueError(\"mode '{}' is not supported\".format(mode)) from None\n",
      "    if unsupported_kwargs:\n",
      "        raise ValueError(\"unsupported keyword arguments for mode '{}': {}\"\n",
      "                         .format(mode, unsupported_kwargs))\n",
      "    stat_functions = {\"maximum\": np.amax, \"minimum\": np.amin,\n",
      "                      \"mean\": np.mean, \"median\": np.median}\n",
      " (padded area is undefined)\n",
      "    padded, original_area_slice = _pad_simple(array, pad_width)\n",
      " (zipping may be more readable than using enumerate)\n",
      "    axes = range(padded.ndim)\n",
      "    if mode == \"constant\":\n",
      "        values = kwargs.get(\"constant_values\", 0)\n",
      "        values = _as_pairs(values, padded.ndim)\n",
      "        for axis, width_pair, value_pair in zip(axes, pad_width, values):\n",
      "            roi = _view_roi(padded, original_area_slice, axis)\n",
      "            _set_pad_area(roi, axis, width_pair, value_pair)\n",
      "    elif mode == \"empty\":\n",
      "        pass  # Do nothing as _pad_simple already returned the correct result\n",
      "    elif array.size == 0:\n",
      " modes depend on `array` not being empty\n",
      " passed, don't need to do anything more as _pad_simple already\n",
      " Extending singleton dimension for 'reflect' is legacy\n",
      " Iteratively pad until dimension is filled with reflected\n",
      " the length of the original values in the current dimension.\n",
      "                left_index, right_index = _set_reflect_both(\n",
      "                    roi, axis, (left_index, right_index),\n",
      "                    method, include_edge\n",
      "                )\n",
      "    elif mode == \"wrap\":\n",
      "        for axis, (left_index, right_index) in zip(axes, pad_width):\n",
      "            roi = _view_roi(padded, original_area_slice, axis)\n",
      "            while left_index > 0 or right_index > 0:\n",
      " values. This is necessary if the pad area is larger than\n",
      "                # the length of the original values in the current dimension.\n",
      "                left_index, right_index = _set_wrap_both(\n",
      "                    roi, axis, (left_index, right_index))\n",
      "    return padded\n",
      "docstring: pad\n",
      "\n",
      "    Pad an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    array : array_like of rank N\n",
      "        The array to pad.\n",
      "    pad_width : {sequence, array_like, int}\n",
      "        Number of values padded to the edges of each axis.\n",
      "        ``((before_1, after_1), ... (before_N, after_N))`` unique pad widths\n",
      "        for each axis.\n",
      "        ``(before, after)`` or ``((before, after),)`` yields same before\n",
      "        and after pad for each axis.\n",
      "        ``(pad,)`` or ``int`` is a shortcut for before = after = pad width\n",
      "        for all axes.\n",
      "    mode : str or function, optional\n",
      "        One of the following string values or a user supplied function.\n",
      "\n",
      "        'constant' (default)\n",
      "            Pads with a constant value.\n",
      "        'edge'\n",
      "            Pads with the edge values of array.\n",
      "        'linear_ramp'\n",
      "            Pads with the linear ramp between end_value and the\n",
      "            array edge value.\n",
      "        'maximum'\n",
      "            Pads with the maximum value of all or part of the\n",
      "            vector along each axis.\n",
      "        'mean'\n",
      "            Pads with the mean value of all or part of the\n",
      "            vector along each axis.\n",
      "        'median'\n",
      "            Pads with the median value of all or part of the\n",
      "            vector along each axis.\n",
      "        'minimum'\n",
      "            Pads with the minimum value of all or part of the\n",
      "            vector along each axis.\n",
      "        'reflect'\n",
      "            Pads with the reflection of the vector mirrored on\n",
      "            the first and last values of the vector along each\n",
      "            axis.\n",
      "        'symmetric'\n",
      "            Pads with the reflection of the vector mirrored\n",
      "            along the edge of the array.\n",
      "        'wrap'\n",
      "            Pads with the wrap of the vector along the axis.\n",
      "            The first values are used to pad the end and the\n",
      "            end values are used to pad the beginning.\n",
      "        'empty'\n",
      "            Pads with undefined values.\n",
      "\n",
      "            .. versionadded:: 1.17\n",
      "\n",
      "        <function>\n",
      "            Padding function, see Notes.\n",
      "    stat_length : sequence or int, optional\n",
      "        Used in 'maximum', 'mean', 'median', and 'minimum'.  Number of\n",
      "        values at edge of each axis used to calculate the statistic value.\n",
      "\n",
      "        ``((before_1, after_1), ... (before_N, after_N))`` unique statistic\n",
      "        lengths for each axis.\n",
      "\n",
      "        ``(before, after)`` or ``((before, after),)`` yields same before\n",
      "        and after statistic lengths for each axis.\n",
      "\n",
      "        ``(stat_length,)`` or ``int`` is a shortcut for\n",
      "        ``before = after = statistic`` length for all axes.\n",
      "\n",
      "        Default is ``None``, to use the entire axis.\n",
      "    constant_values : sequence or scalar, optional\n",
      "        Used in 'constant'.  The values to set the padded values for each\n",
      "        axis.\n",
      "\n",
      "        ``((before_1, after_1), ... (before_N, after_N))`` unique pad constants\n",
      "        for each axis.\n",
      "\n",
      "        ``(before, after)`` or ``((before, after),)`` yields same before\n",
      "        and after constants for each axis.\n",
      "\n",
      "        ``(constant,)`` or ``constant`` is a shortcut for\n",
      "        ``before = after = constant`` for all axes.\n",
      "\n",
      "        Default is 0.\n",
      "    end_values : sequence or scalar, optional\n",
      "        Used in 'linear_ramp'.  The values used for the ending value of the\n",
      "        linear_ramp and that will form the edge of the padded array.\n",
      "\n",
      "        ``((before_1, after_1), ... (before_N, after_N))`` unique end values\n",
      "        for each axis.\n",
      "\n",
      "        ``(before, after)`` or ``((before, after),)`` yields same before\n",
      "        and after end values for each axis.\n",
      "\n",
      "        ``(constant,)`` or ``constant`` is a shortcut for\n",
      "        ``before = after = constant`` for all axes.\n",
      "\n",
      "        Default is 0.\n",
      "    reflect_type : {'even', 'odd'}, optional\n",
      "        Used in 'reflect', and 'symmetric'.  The 'even' style is the\n",
      "        default with an unaltered reflection around the edge value.  For\n",
      "        the 'odd' style, the extended part of the array is created by\n",
      "        subtracting the reflected values from two times the edge value.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    pad : ndarray\n",
      "        Padded array of rank equal to `array` with shape increased\n",
      "        according to `pad_width`.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.7.0\n",
      "\n",
      "    For an array with rank greater than 1, some of the padding of later\n",
      "    axes is calculated from padding of previous axes.  This is easiest to\n",
      "    think about with a rank 2 array where the corners of the padded array\n",
      "    are calculated by using padded values from the first axis.\n",
      "\n",
      "    The padding function, if used, should modify a rank 1 array in-place. It\n",
      "    has the following signature::\n",
      "\n",
      "        padding_func(vector, iaxis_pad_width, iaxis, kwargs)\n",
      "\n",
      "    where\n",
      "\n",
      "        vector : ndarray\n",
      "            A rank 1 array already padded with zeros.  Padded values are\n",
      "            vector[:iaxis_pad_width[0]] and vector[-iaxis_pad_width[1]:].\n",
      "        iaxis_pad_width : tuple\n",
      "            A 2-tuple of ints, iaxis_pad_width[0] represents the number of\n",
      "            values padded at the beginning of vector where\n",
      "            iaxis_pad_width[1] represents the number of values padded at\n",
      "            the end of vector.\n",
      "        iaxis : int\n",
      "            The axis currently being calculated.\n",
      "        kwargs : dict\n",
      "            Any keyword arguments the function requires.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = [1, 2, 3, 4, 5]\n",
      "    >>> np.pad(a, (2, 3), 'constant', constant_values=(4, 6))\n",
      "    array([4, 4, 1, ..., 6, 6, 6])\n",
      "\n",
      "    >>> np.pad(a, (2, 3), 'edge')\n",
      "    array([1, 1, 1, ..., 5, 5, 5])\n",
      "\n",
      "    >>> np.pad(a, (2, 3), 'linear_ramp', end_values=(5, -4))\n",
      "    array([ 5,  3,  1,  2,  3,  4,  5,  2, -1, -4])\n",
      "\n",
      "    >>> np.pad(a, (2,), 'maximum')\n",
      "    array([5, 5, 1, 2, 3, 4, 5, 5, 5])\n",
      "\n",
      "    >>> np.pad(a, (2,), 'mean')\n",
      "    array([3, 3, 1, 2, 3, 4, 5, 3, 3])\n",
      "\n",
      "    >>> np.pad(a, (2,), 'median')\n",
      "    array([3, 3, 1, 2, 3, 4, 5, 3, 3])\n",
      "\n",
      "    >>> a = [[1, 2], [3, 4]]\n",
      "    >>> np.pad(a, ((3, 2), (2, 3)), 'minimum')\n",
      "    array([[1, 1, 1, 2, 1, 1, 1],\n",
      "           [1, 1, 1, 2, 1, 1, 1],\n",
      "           [1, 1, 1, 2, 1, 1, 1],\n",
      "           [1, 1, 1, 2, 1, 1, 1],\n",
      "           [3, 3, 3, 4, 3, 3, 3],\n",
      "           [1, 1, 1, 2, 1, 1, 1],\n",
      "           [1, 1, 1, 2, 1, 1, 1]])\n",
      "\n",
      "    >>> a = [1, 2, 3, 4, 5]\n",
      "    >>> np.pad(a, (2, 3), 'reflect')\n",
      "    array([3, 2, 1, 2, 3, 4, 5, 4, 3, 2])\n",
      "\n",
      "    >>> np.pad(a, (2, 3), 'reflect', reflect_type='odd')\n",
      "    array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8])\n",
      "\n",
      "    >>> np.pad(a, (2, 3), 'symmetric')\n",
      "    array([2, 1, 1, 2, 3, 4, 5, 5, 4, 3])\n",
      "\n",
      "    >>> np.pad(a, (2, 3), 'symmetric', reflect_type='odd')\n",
      "    array([0, 1, 1, 2, 3, 4, 5, 5, 6, 7])\n",
      "\n",
      "    >>> np.pad(a, (2, 3), 'wrap')\n",
      "    array([4, 5, 1, 2, 3, 4, 5, 1, 2, 3])\n",
      "\n",
      "    >>> def pad_with(vector, pad_width, iaxis, kwargs):\n",
      "    ...     pad_value = kwargs.get('padder', 10)\n",
      "    ...     vector[:pad_width[0]] = pad_value\n",
      "    ...     vector[-pad_width[1]:] = pad_value\n",
      "    >>> a = np.arange(6)\n",
      "    >>> a = a.reshape((2, 3))\n",
      "    >>> np.pad(a, 2, pad_with)\n",
      "    array([[10, 10, 10, 10, 10, 10, 10],\n",
      "           [10, 10, 10, 10, 10, 10, 10],\n",
      "           [10, 10,  0,  1,  2, 10, 10],\n",
      "           [10, 10,  3,  4,  5, 10, 10],\n",
      "           [10, 10, 10, 10, 10, 10, 10],\n",
      "           [10, 10, 10, 10, 10, 10, 10]])\n",
      "    >>> np.pad(a, 2, pad_with, padder=100)\n",
      "    array([[100, 100, 100, 100, 100, 100, 100],\n",
      "           [100, 100, 100, 100, 100, 100, 100],\n",
      "           [100, 100,   0,   1,   2, 100, 100],\n",
      "           [100, 100,   3,   4,   5, 100, 100],\n",
      "           [100, 100, 100, 100, 100, 100, 100],\n",
      "           [100, 100, 100, 100, 100, 100, 100]])\n",
      "    \n",
      "code: poly\n",
      "@array_function_dispatch(_poly_dispatcher)\n",
      "def poly(seq_of_zeros):\n",
      "    seq_of_zeros = atleast_1d(seq_of_zeros)\n",
      "    sh = seq_of_zeros.shape\n",
      "    if len(sh) == 2 and sh[0] == sh[1] and sh[0] != 0:\n",
      "        seq_of_zeros = eigvals(seq_of_zeros)\n",
      "    elif len(sh) == 1:\n",
      "        dt = seq_of_zeros.dtype\n",
      " if complex roots are all complex conjugates, the roots are real.\n",
      "        roots = NX.asarray(seq_of_zeros, complex)\n",
      "        if NX.all(NX.sort(roots) == NX.sort(roots.conjugate())):\n",
      "            a = a.real.copy()\n",
      "    return a\n",
      "docstring: poly\n",
      "\n",
      "    Find the coefficients of a polynomial with the given sequence of roots.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    Returns the coefficients of the polynomial whose leading coefficient\n",
      "    is one for the given sequence of zeros (multiple roots must be included\n",
      "    in the sequence as many times as their multiplicity; see Examples).\n",
      "    A square matrix (or array, which will be treated as a matrix) can also\n",
      "    be given, in which case the coefficients of the characteristic polynomial\n",
      "    of the matrix are returned.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    seq_of_zeros : array_like, shape (N,) or (N, N)\n",
      "        A sequence of polynomial roots, or a square array or matrix object.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    c : ndarray\n",
      "        1D array of polynomial coefficients from highest to lowest degree:\n",
      "\n",
      "        ``c[0] * x**(N) + c[1] * x**(N-1) + ... + c[N-1] * x + c[N]``\n",
      "        where c[0] always equals 1.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If input is the wrong shape (the input must be a 1-D or square\n",
      "        2-D array).\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    polyval : Compute polynomial values.\n",
      "    roots : Return the roots of a polynomial.\n",
      "    polyfit : Least squares polynomial fit.\n",
      "    poly1d : A one-dimensional polynomial class.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Specifying the roots of a polynomial still leaves one degree of\n",
      "    freedom, typically represented by an undetermined leading\n",
      "    coefficient. [1]_ In the case of this function, that coefficient -\n",
      "    the first one in the returned array - is always taken as one. (If\n",
      "    for some reason you have one other point, the only automatic way\n",
      "    presently to leverage that information is to use ``polyfit``.)\n",
      "\n",
      "    The characteristic polynomial, :math:`p_a(t)`, of an `n`-by-`n`\n",
      "    matrix **A** is given by\n",
      "\n",
      "        :math:`p_a(t) = \\mathrm{det}(t\\, \\mathbf{I} - \\mathbf{A})`,\n",
      "\n",
      "    where **I** is the `n`-by-`n` identity matrix. [2]_\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] M. Sullivan and M. Sullivan, III, \"Algebra and Trignometry,\n",
      "       Enhanced With Graphing Utilities,\" Prentice-Hall, pg. 318, 1996.\n",
      "\n",
      "    .. [2] G. Strang, \"Linear Algebra and Its Applications, 2nd Edition,\"\n",
      "       Academic Press, pg. 182, 1980.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Given a sequence of a polynomial's zeros:\n",
      "\n",
      "    >>> np.poly((0, 0, 0)) # Multiple root example\n",
      "    array([1., 0., 0., 0.])\n",
      "\n",
      "    The line above represents z**3 + 0*z**2 + 0*z + 0.\n",
      "\n",
      "    >>> np.poly((-1./2, 0, 1./2))\n",
      "    array([ 1.  ,  0.  , -0.25,  0.  ])\n",
      "\n",
      "    The line above represents z**3 - z/4\n",
      "\n",
      "    >>> np.poly((np.random.random(1)[0], 0, np.random.random(1)[0]))\n",
      "    array([ 1.        , -0.77086955,  0.08618131,  0.        ]) # random\n",
      "\n",
      "    Given a square array object:\n",
      "\n",
      "    >>> P = np.array([[0, 1./3], [-1./2, 0]])\n",
      "    >>> np.poly(P)\n",
      "    array([1.        , 0.        , 0.16666667])\n",
      "\n",
      "    Note how in all cases the leading coefficient is always 1.\n",
      "\n",
      "    \n",
      "code: roots\n",
      "@array_function_dispatch(_roots_dispatcher)\n",
      "def roots(p):\n",
      " find non-zero array entries\n",
      "    non_zero = NX.nonzero(NX.ravel(p))[0]\n",
      " find the number of trailing zeros -- this is the number of roots at 0.\n",
      "    trailing_zeros = len(p) - non_zero[-1] - 1\n",
      " casting: if incoming array isn't floating point, make it floating point.\n",
      "    if not issubclass(p.dtype.type, (NX.floating, NX.complexfloating)):\n",
      "        p = p.astype(float)\n",
      "    N = len(p)\n",
      "    if N > 1:\n",
      " tack any zeros onto the back of the array\n",
      "    roots = hstack((roots, NX.zeros(trailing_zeros, roots.dtype)))\n",
      "    return roots\n",
      "docstring: roots\n",
      "\n",
      "    Return the roots of a polynomial with coefficients given in p.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    The values in the rank-1 array `p` are coefficients of a polynomial.\n",
      "    If the length of `p` is n+1 then the polynomial is described by::\n",
      "\n",
      "      p[0] * x**n + p[1] * x**(n-1) + ... + p[n-1]*x + p[n]\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    p : array_like\n",
      "        Rank-1 array of polynomial coefficients.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        An array containing the roots of the polynomial.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        When `p` cannot be converted to a rank-1 array.\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    poly : Find the coefficients of a polynomial with a given sequence\n",
      "           of roots.\n",
      "    polyval : Compute polynomial values.\n",
      "    polyfit : Least squares polynomial fit.\n",
      "    poly1d : A one-dimensional polynomial class.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The algorithm relies on computing the eigenvalues of the\n",
      "    companion matrix [1]_.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] R. A. Horn & C. R. Johnson, *Matrix Analysis*.  Cambridge, UK:\n",
      "        Cambridge University Press, 1999, pp. 146-7.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> coeff = [3.2, 2, 1]\n",
      "    >>> np.roots(coeff)\n",
      "    array([-0.3125+0.46351241j, -0.3125-0.46351241j])\n",
      "\n",
      "    \n",
      "code: polyint\n",
      "@array_function_dispatch(_polyint_dispatcher)\n",
      "def polyint(p, m=1, k=None):\n",
      "    m = int(m)\n",
      "    if m < 0:\n",
      "        raise ValueError(\"Order of integral must be positive (see polyder)\")\n",
      "    if k is None:\n",
      "        k = NX.zeros(m, float)\n",
      "    k = atleast_1d(k)\n",
      "    if len(k) == 1 and m > 1:\n",
      "        k = k[0]*NX.ones(m, float)\n",
      "    if len(k) < m:\n",
      "        raise ValueError(\n",
      "              \"k must be a scalar or a rank-1 array of length 1 or >m.\")\n",
      "    truepoly = isinstance(p, poly1d)\n",
      "    p = NX.asarray(p)\n",
      "    if m == 0:\n",
      "        if truepoly:\n",
      "            return poly1d(p)\n",
      "        return p\n",
      "    else:\n",
      "        # Note: this must work also with object and integer arrays\n",
      "        y = NX.concatenate((p.__truediv__(NX.arange(len(p), 0, -1)), [k[0]]))\n",
      "        val = polyint(y, m - 1, k=k[1:])\n",
      "        if truepoly:\n",
      "            return poly1d(val)\n",
      "        return val\n",
      "docstring: polyint\n",
      "\n",
      "    Return an antiderivative (indefinite integral) of a polynomial.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    The returned order `m` antiderivative `P` of polynomial `p` satisfies\n",
      "    :math:`\\frac{d^m}{dx^m}P(x) = p(x)` and is defined up to `m - 1`\n",
      "    integration constants `k`. The constants determine the low-order\n",
      "    polynomial part\n",
      "\n",
      "    .. math:: \\frac{k_{m-1}}{0!} x^0 + \\ldots + \\frac{k_0}{(m-1)!}x^{m-1}\n",
      "\n",
      "    of `P` so that :math:`P^{(j)}(0) = k_{m-j-1}`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    p : array_like or poly1d\n",
      "        Polynomial to integrate.\n",
      "        A sequence is interpreted as polynomial coefficients, see `poly1d`.\n",
      "    m : int, optional\n",
      "        Order of the antiderivative. (Default: 1)\n",
      "    k : list of `m` scalars or scalar, optional\n",
      "        Integration constants. They are given in the order of integration:\n",
      "        those corresponding to highest-order terms come first.\n",
      "\n",
      "        If ``None`` (default), all constants are assumed to be zero.\n",
      "        If `m = 1`, a single scalar can be given instead of a list.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    polyder : derivative of a polynomial\n",
      "    poly1d.integ : equivalent method\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    The defining property of the antiderivative:\n",
      "\n",
      "    >>> p = np.poly1d([1,1,1])\n",
      "    >>> P = np.polyint(p)\n",
      "    >>> P\n",
      "     poly1d([ 0.33333333,  0.5       ,  1.        ,  0.        ]) # may vary\n",
      "    >>> np.polyder(P) == p\n",
      "    True\n",
      "\n",
      "    The integration constants default to zero, but can be specified:\n",
      "\n",
      "    >>> P = np.polyint(p, 3)\n",
      "    >>> P(0)\n",
      "    0.0\n",
      "    >>> np.polyder(P)(0)\n",
      "    0.0\n",
      "    >>> np.polyder(P, 2)(0)\n",
      "    0.0\n",
      "    >>> P = np.polyint(p, 3, k=[6,5,3])\n",
      "    >>> P\n",
      "    poly1d([ 0.01666667,  0.04166667,  0.16666667,  3. ,  5. ,  3. ]) # may vary\n",
      "\n",
      "    Note that 3 = 6 / 2!, and that the constants are given in the order of\n",
      "    integrations. Constant of the highest-order polynomial term comes first:\n",
      "\n",
      "    >>> np.polyder(P, 2)(0)\n",
      "    6.0\n",
      "    >>> np.polyder(P, 1)(0)\n",
      "    5.0\n",
      "    >>> P(0)\n",
      "    3.0\n",
      "\n",
      "    \n",
      "code: polyder\n",
      "@array_function_dispatch(_polyder_dispatcher)\n",
      "def polyder(p, m=1):\n",
      "    m = int(m)\n",
      "    if m < 0:\n",
      "        raise ValueError(\"Order of derivative must be positive (see polyint)\")\n",
      "    truepoly = isinstance(p, poly1d)\n",
      "    p = NX.asarray(p)\n",
      "    n = len(p) - 1\n",
      "    y = p[:-1] * NX.arange(n, 0, -1)\n",
      "    if m == 0:\n",
      "        val = p\n",
      "    else:\n",
      "        val = polyder(y, m - 1)\n",
      "    if truepoly:\n",
      "        val = poly1d(val)\n",
      "    return val\n",
      "docstring: polyder\n",
      "\n",
      "    Return the derivative of the specified order of a polynomial.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    p : poly1d or sequence\n",
      "        Polynomial to differentiate.\n",
      "        A sequence is interpreted as polynomial coefficients, see `poly1d`.\n",
      "    m : int, optional\n",
      "        Order of differentiation (default: 1)\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    der : poly1d\n",
      "        A new polynomial representing the derivative.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    polyint : Anti-derivative of a polynomial.\n",
      "    poly1d : Class for one-dimensional polynomials.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    The derivative of the polynomial :math:`x^3 + x^2 + x^1 + 1` is:\n",
      "\n",
      "    >>> p = np.poly1d([1,1,1,1])\n",
      "    >>> p2 = np.polyder(p)\n",
      "    >>> p2\n",
      "    poly1d([3, 2, 1])\n",
      "\n",
      "    which evaluates to:\n",
      "\n",
      "    >>> p2(2.)\n",
      "    17.0\n",
      "\n",
      "    We can verify this, approximating the derivative with\n",
      "    ``(f(x + h) - f(x))/h``:\n",
      "\n",
      "    >>> (p(2. + 0.001) - p(2.)) / 0.001\n",
      "    17.007000999997857\n",
      "\n",
      "    The fourth-order derivative of a 3rd-order polynomial is zero:\n",
      "\n",
      "    >>> np.polyder(p, 2)\n",
      "    poly1d([6, 2])\n",
      "    >>> np.polyder(p, 3)\n",
      "    poly1d([6])\n",
      "    >>> np.polyder(p, 4)\n",
      "    poly1d([0])\n",
      "\n",
      "    \n",
      "code: polyadd\n",
      "@array_function_dispatch(_binary_op_dispatcher)\n",
      "def polyadd(a1, a2):\n",
      "    truepoly = (isinstance(a1, poly1d) or isinstance(a2, poly1d))\n",
      "    a1 = atleast_1d(a1)\n",
      "    a2 = atleast_1d(a2)\n",
      "    diff = len(a2) - len(a1)\n",
      "    if diff == 0:\n",
      "        val = a1 + a2\n",
      "    elif diff > 0:\n",
      "        zr = NX.zeros(diff, a1.dtype)\n",
      "        val = NX.concatenate((zr, a1)) + a2\n",
      "    else:\n",
      "        zr = NX.zeros(abs(diff), a2.dtype)\n",
      "        val = a1 + NX.concatenate((zr, a2))\n",
      "    if truepoly:\n",
      "        val = poly1d(val)\n",
      "    return val\n",
      "docstring: polyadd\n",
      "\n",
      "    Find the sum of two polynomials.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    Returns the polynomial resulting from the sum of two input polynomials.\n",
      "    Each input must be either a poly1d object or a 1D sequence of polynomial\n",
      "    coefficients, from highest to lowest degree.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2 : array_like or poly1d object\n",
      "        Input polynomials.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray or poly1d object\n",
      "        The sum of the inputs. If either input is a poly1d object, then the\n",
      "        output is also a poly1d object. Otherwise, it is a 1D array of\n",
      "        polynomial coefficients from highest to lowest degree.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    poly1d : A one-dimensional polynomial class.\n",
      "    poly, polyadd, polyder, polydiv, polyfit, polyint, polysub, polyval\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.polyadd([1, 2], [9, 5, 4])\n",
      "    array([9, 6, 6])\n",
      "\n",
      "    Using poly1d objects:\n",
      "\n",
      "    >>> p1 = np.poly1d([1, 2])\n",
      "    >>> p2 = np.poly1d([9, 5, 4])\n",
      "    >>> print(p1)\n",
      "    1 x + 2\n",
      "    >>> print(p2)\n",
      "       2\n",
      "    9 x + 5 x + 4\n",
      "    >>> print(np.polyadd(p1, p2))\n",
      "       2\n",
      "    9 x + 6 x + 6\n",
      "\n",
      "    \n",
      "code: polysub\n",
      "@array_function_dispatch(_binary_op_dispatcher)\n",
      "def polysub(a1, a2):\n",
      "    truepoly = (isinstance(a1, poly1d) or isinstance(a2, poly1d))\n",
      "    a1 = atleast_1d(a1)\n",
      "    a2 = atleast_1d(a2)\n",
      "    diff = len(a2) - len(a1)\n",
      "    if diff == 0:\n",
      "        val = a1 - a2\n",
      "    elif diff > 0:\n",
      "        zr = NX.zeros(diff, a1.dtype)\n",
      "        val = NX.concatenate((zr, a1)) - a2\n",
      "    else:\n",
      "        zr = NX.zeros(abs(diff), a2.dtype)\n",
      "        val = a1 - NX.concatenate((zr, a2))\n",
      "    if truepoly:\n",
      "        val = poly1d(val)\n",
      "    return val\n",
      "docstring: polysub\n",
      "\n",
      "    Difference (subtraction) of two polynomials.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    Given two polynomials `a1` and `a2`, returns ``a1 - a2``.\n",
      "    `a1` and `a2` can be either array_like sequences of the polynomials'\n",
      "    coefficients (including coefficients equal to zero), or `poly1d` objects.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2 : array_like or poly1d\n",
      "        Minuend and subtrahend polynomials, respectively.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray or poly1d\n",
      "        Array or `poly1d` object of the difference polynomial's coefficients.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    polyval, polydiv, polymul, polyadd\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    .. math:: (2 x^2 + 10 x - 2) - (3 x^2 + 10 x -4) = (-x^2 + 2)\n",
      "\n",
      "    >>> np.polysub([2, 10, -2], [3, 10, -4])\n",
      "    array([-1,  0,  2])\n",
      "\n",
      "    \n",
      "code: polymul\n",
      "@array_function_dispatch(_binary_op_dispatcher)\n",
      "def polymul(a1, a2):\n",
      "    truepoly = (isinstance(a1, poly1d) or isinstance(a2, poly1d))\n",
      "    a1, a2 = poly1d(a1), poly1d(a2)\n",
      "    val = NX.convolve(a1, a2)\n",
      "    if truepoly:\n",
      "        val = poly1d(val)\n",
      "    return val\n",
      "docstring: polymul\n",
      "\n",
      "    Find the product of two polynomials.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    Finds the polynomial resulting from the multiplication of the two input\n",
      "    polynomials. Each input must be either a poly1d object or a 1D sequence\n",
      "    of polynomial coefficients, from highest to lowest degree.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2 : array_like or poly1d object\n",
      "        Input polynomials.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray or poly1d object\n",
      "        The polynomial resulting from the multiplication of the inputs. If\n",
      "        either inputs is a poly1d object, then the output is also a poly1d\n",
      "        object. Otherwise, it is a 1D array of polynomial coefficients from\n",
      "        highest to lowest degree.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    poly1d : A one-dimensional polynomial class.\n",
      "    poly, polyadd, polyder, polydiv, polyfit, polyint, polysub, polyval\n",
      "    convolve : Array convolution. Same output as polymul, but has parameter\n",
      "               for overlap mode.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.polymul([1, 2, 3], [9, 5, 1])\n",
      "    array([ 9, 23, 38, 17,  3])\n",
      "\n",
      "    Using poly1d objects:\n",
      "\n",
      "    >>> p1 = np.poly1d([1, 2, 3])\n",
      "    >>> p2 = np.poly1d([9, 5, 1])\n",
      "    >>> print(p1)\n",
      "       2\n",
      "    1 x + 2 x + 3\n",
      "    >>> print(p2)\n",
      "       2\n",
      "    9 x + 5 x + 1\n",
      "    >>> print(np.polymul(p1, p2))\n",
      "       4      3      2\n",
      "    9 x + 23 x + 38 x + 17 x + 3\n",
      "\n",
      "    \n",
      "code: polydiv\n",
      "@array_function_dispatch(_polydiv_dispatcher)\n",
      "def polydiv(u, v):\n",
      "    truepoly = (isinstance(u, poly1d) or isinstance(v, poly1d))\n",
      "    u = atleast_1d(u) + 0.0\n",
      "    v = atleast_1d(v) + 0.0\n",
      "    # w has the common type\n",
      "    w = u[0] + v[0]\n",
      "    m = len(u) - 1\n",
      "    n = len(v) - 1\n",
      "    scale = 1. / v[0]\n",
      "    q = NX.zeros((max(m - n + 1, 1),), w.dtype)\n",
      "    r = u.astype(w.dtype)\n",
      "    for k in range(0, m-n+1):\n",
      "        d = scale * r[k]\n",
      "        q[k] = d\n",
      "        r[k:k+n+1] -= d*v\n",
      "    while NX.allclose(r[0], 0, rtol=1e-14) and (r.shape[-1] > 1):\n",
      "        r = r[1:]\n",
      "    if truepoly:\n",
      "        return poly1d(q), poly1d(r)\n",
      "    return q, r\n",
      "docstring: polydiv\n",
      "\n",
      "    Returns the quotient and remainder of polynomial division.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    The input arrays are the coefficients (including any coefficients\n",
      "    equal to zero) of the \"numerator\" (dividend) and \"denominator\"\n",
      "    (divisor) polynomials, respectively.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    u : array_like or poly1d\n",
      "        Dividend polynomial's coefficients.\n",
      "\n",
      "    v : array_like or poly1d\n",
      "        Divisor polynomial's coefficients.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    q : ndarray\n",
      "        Coefficients, including those equal to zero, of the quotient.\n",
      "    r : ndarray\n",
      "        Coefficients, including those equal to zero, of the remainder.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    poly, polyadd, polyder, polydiv, polyfit, polyint, polymul, polysub\n",
      "    polyval\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Both `u` and `v` must be 0-d or 1-d (ndim = 0 or 1), but `u.ndim` need\n",
      "    not equal `v.ndim`. In other words, all four possible combinations -\n",
      "    ``u.ndim = v.ndim = 0``, ``u.ndim = v.ndim = 1``,\n",
      "    ``u.ndim = 1, v.ndim = 0``, and ``u.ndim = 0, v.ndim = 1`` - work.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    .. math:: \\frac{3x^2 + 5x + 2}{2x + 1} = 1.5x + 1.75, remainder 0.25\n",
      "\n",
      "    >>> x = np.array([3.0, 5.0, 2.0])\n",
      "    >>> y = np.array([2.0, 1.0])\n",
      "    >>> np.polydiv(x, y)\n",
      "    (array([1.5 , 1.75]), array([0.25]))\n",
      "\n",
      "    \n",
      "code: polyval\n",
      "@array_function_dispatch(_polyval_dispatcher)\n",
      "def polyval(p, x):\n",
      "    p = NX.asarray(p)\n",
      "    if isinstance(x, poly1d):\n",
      "        y = 0\n",
      "    else:\n",
      "        x = NX.asanyarray(x)\n",
      "        y = NX.zeros_like(x)\n",
      "    for pv in p:\n",
      "        y = y * x + pv\n",
      "    return y\n",
      "docstring: polyval\n",
      "\n",
      "    Evaluate a polynomial at specific values.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    If `p` is of length N, this function returns the value:\n",
      "\n",
      "        ``p[0]*x**(N-1) + p[1]*x**(N-2) + ... + p[N-2]*x + p[N-1]``\n",
      "\n",
      "    If `x` is a sequence, then ``p(x)`` is returned for each element of ``x``.\n",
      "    If `x` is another polynomial then the composite polynomial ``p(x(t))``\n",
      "    is returned.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    p : array_like or poly1d object\n",
      "       1D array of polynomial coefficients (including coefficients equal\n",
      "       to zero) from highest degree to the constant term, or an\n",
      "       instance of poly1d.\n",
      "    x : array_like or poly1d object\n",
      "       A number, an array of numbers, or an instance of poly1d, at\n",
      "       which to evaluate `p`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    values : ndarray or poly1d\n",
      "       If `x` is a poly1d instance, the result is the composition of the two\n",
      "       polynomials, i.e., `x` is \"substituted\" in `p` and the simplified\n",
      "       result is returned. In addition, the type of `x` - array_like or\n",
      "       poly1d - governs the type of the output: `x` array_like => `values`\n",
      "       array_like, `x` a poly1d object => `values` is also.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    poly1d: A polynomial class.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Horner's scheme [1]_ is used to evaluate the polynomial. Even so,\n",
      "    for polynomials of high degree the values may be inaccurate due to\n",
      "    rounding errors. Use carefully.\n",
      "\n",
      "    If `x` is a subtype of `ndarray` the return value will be of the same type.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] I. N. Bronshtein, K. A. Semendyayev, and K. A. Hirsch (Eng.\n",
      "       trans. Ed.), *Handbook of Mathematics*, New York, Van Nostrand\n",
      "       Reinhold Co., 1985, pg. 720.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.polyval([3,0,1], 5)  # 3 * 5**2 + 0 * 5**1 + 1\n",
      "    76\n",
      "    >>> np.polyval([3,0,1], np.poly1d(5))\n",
      "    poly1d([76])\n",
      "    >>> np.polyval(np.poly1d([3,0,1]), 5)\n",
      "    76\n",
      "    >>> np.polyval(np.poly1d([3,0,1]), np.poly1d(5))\n",
      "    poly1d([76])\n",
      "\n",
      "    \n",
      "code: poly1d.deriv\n",
      "    def deriv(self, m=1):\n",
      "        return poly1d(polyder(self.coeffs, m=m))\n",
      "docstring: poly1d.deriv\n",
      "\n",
      "        Return a derivative of this polynomial.\n",
      "\n",
      "        Refer to `polyder` for full documentation.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        polyder : equivalent function\n",
      "\n",
      "        \n",
      "code: poly1d.integ\n",
      "    def integ(self, m=1, k=0):\n",
      "        return poly1d(polyint(self.coeffs, m=m, k=k))\n",
      "docstring: poly1d.integ\n",
      "\n",
      "        Return an antiderivative (indefinite integral) of this polynomial.\n",
      "\n",
      "        Refer to `polyint` for full documentation.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        polyint : equivalent function\n",
      "\n",
      "        \n",
      "code: polyfit\n",
      "@array_function_dispatch(_polyfit_dispatcher)\n",
      "def polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False):\n",
      "    order = int(deg) + 1\n",
      "    x = NX.asarray(x) + 0.0\n",
      "    y = NX.asarray(y) + 0.0\n",
      " set rcond\n",
      "    if rcond is None:\n",
      "        rcond = len(x)*finfo(x.dtype).eps\n",
      " apply weighting\n",
      "    if w is not None:\n",
      "        w = NX.asarray(w) + 0.0\n",
      "        if w.ndim != 1:\n",
      "            raise TypeError(\"expected a 1-d array for weights\")\n",
      "        if w.shape[0] != y.shape[0]:\n",
      "            raise TypeError(\"expected w and y to have the same length\")\n",
      "        lhs *= w[:, NX.newaxis]\n",
      "        if rhs.ndim == 2:\n",
      "            rhs *= w[:, NX.newaxis]\n",
      "        else:\n",
      "            rhs *= w\n",
      " broadcast scale coefficients\n",
      " note, this used to be: fac = resids / (len(x) - order - 2.0)\n",
      " uncertainty analysis\") is not what the user expects\n",
      "            # (see gh-11196 and gh-11197)\n",
      "            fac = resids / (len(x) - order)\n",
      "        if y.ndim == 1:\n",
      "            return c, Vbase * fac\n",
      "        else:\n",
      "            return c, Vbase[:,:, NX.newaxis] * fac\n",
      "    else:\n",
      "        return c\n",
      "docstring: polyfit\n",
      "\n",
      "    Least squares polynomial fit.\n",
      "\n",
      "    .. note::\n",
      "       This forms part of the old polynomial API. Since version 1.4, the\n",
      "       new polynomial API defined in `numpy.polynomial` is preferred.\n",
      "       A summary of the differences can be found in the\n",
      "       :doc:`transition guide </reference/routines.polynomials>`.\n",
      "\n",
      "    Fit a polynomial ``p(x) = p[0] * x**deg + ... + p[deg]`` of degree `deg`\n",
      "    to points `(x, y)`. Returns a vector of coefficients `p` that minimises\n",
      "    the squared error in the order `deg`, `deg-1`, ... `0`.\n",
      "\n",
      "    The `Polynomial.fit <numpy.polynomial.polynomial.Polynomial.fit>` class\n",
      "    method is recommended for new code as it is more stable numerically. See\n",
      "    the documentation of the method for more information.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like, shape (M,)\n",
      "        x-coordinates of the M sample points ``(x[i], y[i])``.\n",
      "    y : array_like, shape (M,) or (M, K)\n",
      "        y-coordinates of the sample points. Several data sets of sample\n",
      "        points sharing the same x-coordinates can be fitted at once by\n",
      "        passing in a 2D-array that contains one dataset per column.\n",
      "    deg : int\n",
      "        Degree of the fitting polynomial\n",
      "    rcond : float, optional\n",
      "        Relative condition number of the fit. Singular values smaller than\n",
      "        this relative to the largest singular value will be ignored. The\n",
      "        default value is len(x)*eps, where eps is the relative precision of\n",
      "        the float type, about 2e-16 in most cases.\n",
      "    full : bool, optional\n",
      "        Switch determining nature of return value. When it is False (the\n",
      "        default) just the coefficients are returned, when True diagnostic\n",
      "        information from the singular value decomposition is also returned.\n",
      "    w : array_like, shape (M,), optional\n",
      "        Weights. If not None, the weight ``w[i]`` applies to the unsquared\n",
      "        residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are\n",
      "        chosen so that the errors of the products ``w[i]*y[i]`` all have the\n",
      "        same variance.  When using inverse-variance weighting, use\n",
      "        ``w[i] = 1/sigma(y[i])``.  The default value is None.\n",
      "    cov : bool or str, optional\n",
      "        If given and not `False`, return not just the estimate but also its\n",
      "        covariance matrix. By default, the covariance are scaled by\n",
      "        chi2/dof, where dof = M - (deg + 1), i.e., the weights are presumed\n",
      "        to be unreliable except in a relative sense and everything is scaled\n",
      "        such that the reduced chi2 is unity. This scaling is omitted if\n",
      "        ``cov='unscaled'``, as is relevant for the case that the weights are\n",
      "        w = 1/sigma, with sigma known to be a reliable estimate of the\n",
      "        uncertainty.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    p : ndarray, shape (deg + 1,) or (deg + 1, K)\n",
      "        Polynomial coefficients, highest power first.  If `y` was 2-D, the\n",
      "        coefficients for `k`-th data set are in ``p[:,k]``.\n",
      "\n",
      "    residuals, rank, singular_values, rcond\n",
      "        These values are only returned if ``full == True``\n",
      "\n",
      "        - residuals -- sum of squared residuals of the least squares fit\n",
      "        - rank -- the effective rank of the scaled Vandermonde\n",
      "           coefficient matrix\n",
      "        - singular_values -- singular values of the scaled Vandermonde\n",
      "           coefficient matrix\n",
      "        - rcond -- value of `rcond`.\n",
      "\n",
      "        For more details, see `numpy.linalg.lstsq`.\n",
      "\n",
      "    V : ndarray, shape (M,M) or (M,M,K)\n",
      "        Present only if ``full == False`` and ``cov == True``.  The covariance\n",
      "        matrix of the polynomial coefficient estimates.  The diagonal of\n",
      "        this matrix are the variance estimates for each coefficient.  If y\n",
      "        is a 2-D array, then the covariance matrix for the `k`-th data set\n",
      "        are in ``V[:,:,k]``\n",
      "\n",
      "\n",
      "    Warns\n",
      "    -----\n",
      "    RankWarning\n",
      "        The rank of the coefficient matrix in the least-squares fit is\n",
      "        deficient. The warning is only raised if ``full == False``.\n",
      "\n",
      "        The warnings can be turned off by\n",
      "\n",
      "        >>> import warnings\n",
      "        >>> warnings.simplefilter('ignore', np.RankWarning)\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    polyval : Compute polynomial values.\n",
      "    linalg.lstsq : Computes a least-squares fit.\n",
      "    scipy.interpolate.UnivariateSpline : Computes spline fits.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The solution minimizes the squared error\n",
      "\n",
      "    .. math::\n",
      "        E = \\sum_{j=0}^k |p(x_j) - y_j|^2\n",
      "\n",
      "    in the equations::\n",
      "\n",
      "        x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\n",
      "        x[1]**n * p[0] + ... + x[1] * p[n-1] + p[n] = y[1]\n",
      "        ...\n",
      "        x[k]**n * p[0] + ... + x[k] * p[n-1] + p[n] = y[k]\n",
      "\n",
      "    The coefficient matrix of the coefficients `p` is a Vandermonde matrix.\n",
      "\n",
      "    `polyfit` issues a `RankWarning` when the least-squares fit is badly\n",
      "    conditioned. This implies that the best fit is not well-defined due\n",
      "    to numerical error. The results may be improved by lowering the polynomial\n",
      "    degree or by replacing `x` by `x` - `x`.mean(). The `rcond` parameter\n",
      "    can also be set to a value smaller than its default, but the resulting\n",
      "    fit may be spurious: including contributions from the small singular\n",
      "    values can add numerical noise to the result.\n",
      "\n",
      "    Note that fitting polynomial coefficients is inherently badly conditioned\n",
      "    when the degree of the polynomial is large or the interval of sample points\n",
      "    is badly centered. The quality of the fit should always be checked in these\n",
      "    cases. When polynomial fits are not satisfactory, splines may be a good\n",
      "    alternative.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Wikipedia, \"Curve fitting\",\n",
      "           https://en.wikipedia.org/wiki/Curve_fitting\n",
      "    .. [2] Wikipedia, \"Polynomial interpolation\",\n",
      "           https://en.wikipedia.org/wiki/Polynomial_interpolation\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import warnings\n",
      "    >>> x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n",
      "    >>> y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n",
      "    >>> z = np.polyfit(x, y, 3)\n",
      "    >>> z\n",
      "    array([ 0.08703704, -0.81349206,  1.69312169, -0.03968254]) # may vary\n",
      "\n",
      "    It is convenient to use `poly1d` objects for dealing with polynomials:\n",
      "\n",
      "    >>> p = np.poly1d(z)\n",
      "    >>> p(0.5)\n",
      "    0.6143849206349179 # may vary\n",
      "    >>> p(3.5)\n",
      "    -0.34732142857143039 # may vary\n",
      "    >>> p(10)\n",
      "    22.579365079365115 # may vary\n",
      "\n",
      "    High-order polynomials may oscillate wildly:\n",
      "\n",
      "    >>> with warnings.catch_warnings():\n",
      "    ...     warnings.simplefilter('ignore', np.RankWarning)\n",
      "    ...     p30 = np.poly1d(np.polyfit(x, y, 30))\n",
      "    ...\n",
      "    >>> p30(4)\n",
      "    -0.80000000000000204 # may vary\n",
      "    >>> p30(5)\n",
      "    -0.99999999999999445 # may vary\n",
      "    >>> p30(4.5)\n",
      "    -0.10547061179440398 # may vary\n",
      "\n",
      "    Illustration:\n",
      "\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> xp = np.linspace(-2, 6, 100)\n",
      "    >>> _ = plt.plot(x, y, '.', xp, p(xp), '-', xp, p30(xp), '--')\n",
      "    >>> plt.ylim(-2,2)\n",
      "    (-2, 2)\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: issubclass_\n",
      "@set_module('numpy')\n",
      "def issubclass_(arg1, arg2):\n",
      "    try:\n",
      "        return issubclass(arg1, arg2)\n",
      "    except TypeError:\n",
      "        return False\n",
      "docstring: issubclass_\n",
      "\n",
      "    Determine if a class is a subclass of a second class.\n",
      "\n",
      "    `issubclass_` is equivalent to the Python built-in ``issubclass``,\n",
      "    except that it returns False instead of raising a TypeError if one\n",
      "    of the arguments is not a class.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arg1 : class\n",
      "        Input class. True is returned if `arg1` is a subclass of `arg2`.\n",
      "    arg2 : class or tuple of classes.\n",
      "        Input class. If a tuple of classes, True is returned if `arg1` is a\n",
      "        subclass of any of the tuple elements.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "        Whether `arg1` is a subclass of `arg2` or not.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    issubsctype, issubdtype, issctype\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.issubclass_(np.int32, int)\n",
      "    False\n",
      "    >>> np.issubclass_(np.int32, float)\n",
      "    False\n",
      "    >>> np.issubclass_(np.float64, float)\n",
      "    True\n",
      "\n",
      "    \n",
      "code: issubsctype\n",
      "@set_module('numpy')\n",
      "def issubsctype(arg1, arg2):\n",
      "    return issubclass(obj2sctype(arg1), obj2sctype(arg2))\n",
      "docstring: issubsctype\n",
      "\n",
      "    Determine if the first argument is a subclass of the second argument.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    arg1, arg2 : dtype or dtype specifier\n",
      "        Data-types.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : bool\n",
      "        The result.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    issctype, issubdtype, obj2sctype\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.issubsctype('S8', str)\n",
      "    False\n",
      "    >>> np.issubsctype(np.array([1]), int)\n",
      "    True\n",
      "    >>> np.issubsctype(np.array([1]), float)\n",
      "    False\n",
      "\n",
      "    \n",
      "code: deprecate\n",
      "def deprecate(*args, **kwargs):\n",
      " If run as a function, we initialise the decorator class\n",
      "    # and execute its __call__ method.\n",
      "    if args:\n",
      "        fn = args[0]\n",
      "        args = args[1:]\n",
      "        return _Deprecate(*args, **kwargs)(fn)\n",
      "    else:\n",
      "        return _Deprecate(*args, **kwargs)\n",
      "docstring: deprecate\n",
      "\n",
      "    Issues a DeprecationWarning, adds warning to `old_name`'s\n",
      "    docstring, rebinds ``old_name.__name__`` and returns the new\n",
      "    function object.\n",
      "\n",
      "    This function may also be used as a decorator.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    func : function\n",
      "        The function to be deprecated.\n",
      "    old_name : str, optional\n",
      "        The name of the function to be deprecated. Default is None, in\n",
      "        which case the name of `func` is used.\n",
      "    new_name : str, optional\n",
      "        The new name for the function. Default is None, in which case the\n",
      "        deprecation message is that `old_name` is deprecated. If given, the\n",
      "        deprecation message is that `old_name` is deprecated and `new_name`\n",
      "        should be used instead.\n",
      "    message : str, optional\n",
      "        Additional explanation of the deprecation.  Displayed in the\n",
      "        docstring after the warning.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    old_func : function\n",
      "        The deprecated function.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Note that ``olduint`` returns a value after printing Deprecation\n",
      "    Warning:\n",
      "\n",
      "    >>> olduint = np.deprecate(np.uint)\n",
      "    DeprecationWarning: `uint64` is deprecated! # may vary\n",
      "    >>> olduint(6)\n",
      "    6\n",
      "\n",
      "    \n",
      "code: deprecate_with_doc\n",
      "def deprecate_with_doc(msg):\n",
      "    return _Deprecate(message=msg)\n",
      "docstring: deprecate_with_doc\n",
      "\n",
      "    Deprecates a function and includes the deprecation in its docstring.\n",
      "\n",
      "    This function is used as a decorator. It returns an object that can be\n",
      "    used to issue a DeprecationWarning, by passing the to-be decorated\n",
      "    function as argument, this adds warning to the to-be decorated function's\n",
      "    docstring and returns the new function object.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    deprecate : Decorate a function such that it issues a `DeprecationWarning`\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    msg : str\n",
      "        Additional explanation of the deprecation. Displayed in the\n",
      "        docstring after the warning.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    obj : object\n",
      "\n",
      "    \n",
      "code: get_include\n",
      "def get_include():\n",
      "    import numpy\n",
      "    if numpy.show_config is None:\n",
      " using installed numpy core headers\n",
      "        import numpy.core as core\n",
      "        d = os.path.join(os.path.dirname(core.__file__), 'include')\n",
      "    return d\n",
      "docstring: get_include\n",
      "\n",
      "    Return the directory that contains the NumPy \\*.h header files.\n",
      "\n",
      "    Extension modules that need to compile against NumPy should use this\n",
      "    function to locate the appropriate include directory.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When using ``distutils``, for example in ``setup.py``::\n",
      "\n",
      "        import numpy as np\n",
      "        ...\n",
      "        Extension('extension_name', ...\n",
      "                include_dirs=[np.get_include()])\n",
      "        ...\n",
      "\n",
      "    \n",
      "code: info\n",
      "@set_module('numpy')\n",
      "def info(object=None, maxwidth=76, output=None, toplevel='numpy'):\n",
      "    global _namedict, _dictlist\n",
      "    # Local import to speed up numpy's import time.\n",
      "    import pydoc\n",
      "    import inspect\n",
      "    if (hasattr(object, '_ppimport_importer') or\n",
      "           hasattr(object, '_ppimport_module')):\n",
      "        object = object._ppimport_module\n",
      "    elif hasattr(object, '_ppimport_attr'):\n",
      "        object = object._ppimport_attr\n",
      "    if output is None:\n",
      "        output = sys.stdout\n",
      "    if object is None:\n",
      "        info(info)\n",
      "    elif isinstance(object, ndarray):\n",
      "        _info(object, output=output)\n",
      "    elif isinstance(object, str):\n",
      "        if _namedict is None:\n",
      "            _namedict, _dictlist = _makenamedict(toplevel)\n",
      "        numfound = 0\n",
      "        objlist = []\n",
      "        for namestr in _dictlist:\n",
      "            try:\n",
      "                obj = _namedict[namestr][object]\n",
      "                if id(obj) in objlist:\n",
      "                    print(\"\\n     \"\n",
      "                          \"*** Repeat reference found in %s *** \" % namestr,\n",
      "                          file=output\n",
      "                          )\n",
      "                else:\n",
      "                    objlist.append(id(obj))\n",
      "                    print(\"     *** Found in %s ***\" % namestr, file=output)\n",
      "                    info(obj)\n",
      "                    print(\"-\"*maxwidth, file=output)\n",
      "                numfound += 1\n",
      "            except KeyError:\n",
      "                pass\n",
      "        if numfound == 0:\n",
      "            print(\"Help for %s not found.\" % object, file=output)\n",
      "        else:\n",
      "            print(\"\\n     \"\n",
      "                  \"*** Total of %d references found. ***\" % numfound,\n",
      "                  file=output\n",
      "                  )\n",
      "    elif inspect.isfunction(object) or inspect.ismethod(object):\n",
      "        name = object.__name__\n",
      "        try:\n",
      "            arguments = str(inspect.signature(object))\n",
      "        except Exception:\n",
      "            arguments = \"()\"\n",
      "        if len(name+arguments) > maxwidth:\n",
      "            argstr = _split_line(name, arguments, maxwidth)\n",
      "        else:\n",
      "            argstr = name + arguments\n",
      "        print(\" \" + argstr + \"\\n\", file=output)\n",
      "        print(inspect.getdoc(object), file=output)\n",
      "    elif inspect.isclass(object):\n",
      "        name = object.__name__\n",
      "        try:\n",
      "            arguments = str(inspect.signature(object))\n",
      "        except Exception:\n",
      "            arguments = \"()\"\n",
      "        if len(name+arguments) > maxwidth:\n",
      "            argstr = _split_line(name, arguments, maxwidth)\n",
      "        else:\n",
      "            argstr = name + arguments\n",
      "        print(\" \" + argstr + \"\\n\", file=output)\n",
      "        doc1 = inspect.getdoc(object)\n",
      "        if doc1 is None:\n",
      "            if hasattr(object, '__init__'):\n",
      "                print(inspect.getdoc(object.__init__), file=output)\n",
      "        else:\n",
      "            print(inspect.getdoc(object), file=output)\n",
      "        methods = pydoc.allmethods(object)\n",
      "        public_methods = [meth for meth in methods if meth[0] != '_']\n",
      "        if public_methods:\n",
      "            print(\"\\n\\nMethods:\\n\", file=output)\n",
      "            for meth in public_methods:\n",
      "                thisobj = getattr(object, meth, None)\n",
      "                if thisobj is not None:\n",
      "                    methstr, other = pydoc.splitdoc(\n",
      "                            inspect.getdoc(thisobj) or \"None\"\n",
      "                            )\n",
      "                print(\"  %s  --  %s\" % (meth, methstr), file=output)\n",
      "    elif hasattr(object, '__doc__'):\n",
      "        print(inspect.getdoc(object), file=output)\n",
      "docstring: info\n",
      "\n",
      "    Get help information for a function, class, or module.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    object : object or str, optional\n",
      "        Input object or name to get information about. If `object` is a\n",
      "        numpy object, its docstring is given. If it is a string, available\n",
      "        modules are searched for matching objects.  If None, information\n",
      "        about `info` itself is returned.\n",
      "    maxwidth : int, optional\n",
      "        Printing width.\n",
      "    output : file like object, optional\n",
      "        File like object that the output is written to, default is\n",
      "        ``None``, in which case ``sys.stdout`` will be used.\n",
      "        The object has to be opened in 'w' or 'a' mode.\n",
      "    toplevel : str, optional\n",
      "        Start search at this level.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    source, lookfor\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When used interactively with an object, ``np.info(obj)`` is equivalent\n",
      "    to ``help(obj)`` on the Python prompt or ``obj?`` on the IPython\n",
      "    prompt.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.info(np.polyval) # doctest: +SKIP\n",
      "       polyval(p, x)\n",
      "         Evaluate the polynomial p at x.\n",
      "         ...\n",
      "\n",
      "    When using a string for `object` it is possible to get multiple results.\n",
      "\n",
      "    >>> np.info('fft') # doctest: +SKIP\n",
      "         *** Found in numpy ***\n",
      "    Core FFT routines\n",
      "    ...\n",
      "         *** Found in numpy.fft ***\n",
      "     fft(a, n=None, axis=-1)\n",
      "    ...\n",
      "         *** Repeat reference found in numpy.fft.fftpack ***\n",
      "         *** Total of 3 references found. ***\n",
      "\n",
      "    \n",
      "code: source\n",
      "@set_module('numpy')\n",
      "def source(object, output=sys.stdout):\n",
      "    # Local import to speed up numpy's import time.\n",
      "    import inspect\n",
      "    try:\n",
      "        print(\"In file: %s\\n\" % inspect.getsourcefile(object), file=output)\n",
      "        print(inspect.getsource(object), file=output)\n",
      "    except Exception:\n",
      "        print(\"Not available for this object.\", file=output)\n",
      "docstring: source\n",
      "\n",
      "    Print or write to a file the source code for a NumPy object.\n",
      "\n",
      "    The source code is only returned for objects written in Python. Many\n",
      "    functions and classes are defined in C and will therefore not return\n",
      "    useful information.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    object : numpy object\n",
      "        Input object. This can be any object (function, class, module,\n",
      "        ...).\n",
      "    output : file object, optional\n",
      "        If `output` not supplied then source code is printed to screen\n",
      "        (sys.stdout).  File object must be created with either write 'w' or\n",
      "        append 'a' modes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    lookfor, info\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.source(np.interp)                        #doctest: +SKIP\n",
      "    In file: /usr/lib/python2.6/dist-packages/numpy/lib/function_base.py\n",
      "    def interp(x, xp, fp, left=None, right=None):\n",
      "        \"\"\".... (full docstring printed)\"\"\"\n",
      "        if isinstance(x, (float, int, number)):\n",
      "            return compiled_interp([x], xp, fp, left, right).item()\n",
      "        else:\n",
      "            return compiled_interp(x, xp, fp, left, right)\n",
      "\n",
      "    The source code is only returned for objects written in Python.\n",
      "\n",
      "    >>> np.source(np.array)                         #doctest: +SKIP\n",
      "    Not available for this object.\n",
      "\n",
      "    \n",
      "code: who\n",
      "def who(vardict=None):\n",
      "    if vardict is None:\n",
      "        frame = sys._getframe().f_back\n",
      "        vardict = frame.f_globals\n",
      "    sta = []\n",
      "    cache = {}\n",
      "    for name in vardict.keys():\n",
      "        if isinstance(vardict[name], ndarray):\n",
      "            var = vardict[name]\n",
      "            idv = id(var)\n",
      "            if idv in cache.keys():\n",
      "                namestr = name + \" (%s)\" % cache[idv]\n",
      "                original = 0\n",
      "            else:\n",
      "                cache[idv] = name\n",
      "                namestr = name\n",
      "                original = 1\n",
      "            shapestr = \" x \".join(map(str, var.shape))\n",
      "            bytestr = str(var.nbytes)\n",
      "            sta.append([namestr, shapestr, bytestr, var.dtype.name,\n",
      "                        original])\n",
      "    maxname = 0\n",
      "    maxshape = 0\n",
      "    maxbyte = 0\n",
      "    totalbytes = 0\n",
      "    for val in sta:\n",
      "        if maxname < len(val[0]):\n",
      "            maxname = len(val[0])\n",
      "        if maxshape < len(val[1]):\n",
      "            maxshape = len(val[1])\n",
      "        if maxbyte < len(val[2]):\n",
      "            maxbyte = len(val[2])\n",
      "        if val[4]:\n",
      "            totalbytes += int(val[2])\n",
      "    if len(sta) > 0:\n",
      "        sp1 = max(10, maxname)\n",
      "        sp2 = max(10, maxshape)\n",
      "        sp3 = max(10, maxbyte)\n",
      "        prval = \"Name %s Shape %s Bytes %s Type\" % (sp1*' ', sp2*' ', sp3*' ')\n",
      "        print(prval + \"\\n\" + \"=\"*(len(prval)+5) + \"\\n\")\n",
      "    for val in sta:\n",
      "        print(\"%s %s %s %s %s %s %s\" % (val[0], ' '*(sp1-len(val[0])+4),\n",
      "                                        val[1], ' '*(sp2-len(val[1])+5),\n",
      "                                        val[2], ' '*(sp3-len(val[2])+5),\n",
      "                                        val[3]))\n",
      "    print(\"\\nUpper bound on total bytes  =       %d\" % totalbytes)\n",
      "    return\n",
      "docstring: who\n",
      "\n",
      "    Print the NumPy arrays in the given dictionary.\n",
      "\n",
      "    If there is no dictionary passed in or `vardict` is None then returns\n",
      "    NumPy arrays in the globals() dictionary (all NumPy arrays in the\n",
      "    namespace).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    vardict : dict, optional\n",
      "        A dictionary possibly containing ndarrays.  Default is globals().\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : None\n",
      "        Returns 'None'.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Prints out the name, shape, bytes and type of all of the ndarrays\n",
      "    present in `vardict`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(10)\n",
      "    >>> b = np.ones(20)\n",
      "    >>> np.who()\n",
      "    Name            Shape            Bytes            Type\n",
      "    ===========================================================\n",
      "    a               10               80               int64\n",
      "    b               20               160              float64\n",
      "    Upper bound on total bytes  =       240\n",
      "\n",
      "    >>> d = {'x': np.arange(2.0), 'y': np.arange(3.0), 'txt': 'Some str',\n",
      "    ... 'idx':5}\n",
      "    >>> np.who(d)\n",
      "    Name            Shape            Bytes            Type\n",
      "    ===========================================================\n",
      "    x               2                16               float64\n",
      "    y               3                24               float64\n",
      "    Upper bound on total bytes  =       40\n",
      "\n",
      "    \n",
      "code: lookfor\n",
      "@set_module('numpy')\n",
      "def lookfor(what, module=None, import_modules=True, regenerate=False,\n",
      "            output=None):\n",
      "    import pydoc\n",
      " Search\n",
      " don't show modules or objects\n",
      "            continue\n",
      "        doc = docstring.lower()\n",
      "        if all(w in doc for w in whats):\n",
      "            found.append(name)\n",
      " XXX: this is full Harrison-Stetson heuristics now,\n",
      " do the keywords occur within the start of the docstring?\n",
      "        first_doc = \"\\n\".join(docstr.lower().strip().split(\"\\n\")[:3])\n",
      "        r += sum([200 for w in whats if w in first_doc])\n",
      " is the full name long?\n",
      "        r += -len(name) * 5\n",
      " is the object deep in namespace hierarchy?\n",
      "        r += -name.count('.') * 10\n",
      "        r += max(-index / 100, -100)\n",
      "        return r\n",
      "    def relevance_value(a):\n",
      "        return relevance(a, *cache[a])\n",
      "    found.sort(key=relevance_value)\n",
      " find a suitable short description\n",
      "        try:\n",
      "            first_doc = doclines[0].strip()\n",
      "            if _function_signature_re.search(first_doc):\n",
      "                first_doc = doclines[1].strip()\n",
      "        except IndexError:\n",
      "            first_doc = \"\"\n",
      "        help_text.append(\"%s\\n    %s\" % (name, first_doc))\n",
      "    if not found:\n",
      "        help_text.append(\"Nothing found.\")\n",
      "    # Output\n",
      "    if output is not None:\n",
      "        output.write(\"\\n\".join(help_text))\n",
      "    elif len(help_text) > 10:\n",
      "        pager = pydoc.getpager()\n",
      "        pager(\"\\n\".join(help_text))\n",
      "    else:\n",
      "        print(\"\\n\".join(help_text))\n",
      "docstring: lookfor\n",
      "\n",
      "    Do a keyword search on docstrings.\n",
      "\n",
      "    A list of objects that matched the search is displayed,\n",
      "    sorted by relevance. All given keywords need to be found in the\n",
      "    docstring for it to be returned as a result, but the order does\n",
      "    not matter.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    what : str\n",
      "        String containing words to look for.\n",
      "    module : str or list, optional\n",
      "        Name of module(s) whose docstrings to go through.\n",
      "    import_modules : bool, optional\n",
      "        Whether to import sub-modules in packages. Default is True.\n",
      "    regenerate : bool, optional\n",
      "        Whether to re-generate the docstring cache. Default is False.\n",
      "    output : file-like, optional\n",
      "        File-like object to write the output to. If omitted, use a pager.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    source, info\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Relevance is determined only roughly, by checking if the keywords occur\n",
      "    in the function name, at the start of a docstring, etc.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.lookfor('binary representation') # doctest: +SKIP\n",
      "    Search results for 'binary representation'\n",
      "    ------------------------------------------\n",
      "    numpy.binary_repr\n",
      "        Return the binary representation of the input number as a string.\n",
      "    numpy.core.setup_common.long_double_representation\n",
      "        Given a binary dump as given by GNU od -b, look for long double\n",
      "    numpy.base_repr\n",
      "        Return a string representation of a number in the given base system.\n",
      "    ...\n",
      "\n",
      "    \n",
      "code: byte_bounds\n",
      "def byte_bounds(a):\n",
      "    ai = a.__array_interface__\n",
      "    a_data = ai['data'][0]\n",
      "    astrides = ai['strides']\n",
      "    ashape = ai['shape']\n",
      "    bytes_a = asarray(a).dtype.itemsize\n",
      "    a_low = a_high = a_data\n",
      "    if astrides is None:\n",
      "        # contiguous case\n",
      "        a_high += a.size * bytes_a\n",
      "    else:\n",
      "        for shape, stride in zip(ashape, astrides):\n",
      "            if stride < 0:\n",
      "                a_low += (shape-1)*stride\n",
      "            else:\n",
      "                a_high += (shape-1)*stride\n",
      "        a_high += bytes_a\n",
      "    return a_low, a_high\n",
      "docstring: byte_bounds\n",
      "\n",
      "    Returns pointers to the end-points of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : ndarray\n",
      "        Input array. It must conform to the Python-side of the array\n",
      "        interface.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    (low, high) : tuple of 2 integers\n",
      "        The first integer is the first byte of the array, the second\n",
      "        integer is just past the last byte of the array.  If `a` is not\n",
      "        contiguous it will not use every byte between the (`low`, `high`)\n",
      "        values.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> I = np.eye(2, dtype='f'); I.dtype\n",
      "    dtype('float32')\n",
      "    >>> low, high = np.byte_bounds(I)\n",
      "    >>> high - low == I.size*I.itemsize\n",
      "    True\n",
      "    >>> I = np.eye(2); I.dtype\n",
      "    dtype('float64')\n",
      "    >>> low, high = np.byte_bounds(I)\n",
      "    >>> high - low == I.size*I.itemsize\n",
      "    True\n",
      "\n",
      "    \n",
      "code: safe_eval\n",
      "def safe_eval(source):\n",
      "    # Local import to speed up numpy's import time.\n",
      "    import ast\n",
      "    return ast.literal_eval(source)\n",
      "docstring: safe_eval\n",
      "\n",
      "    Protected string evaluation.\n",
      "\n",
      "    Evaluate a string containing a Python literal expression without\n",
      "    allowing the execution of arbitrary non-literal code.\n",
      "\n",
      "    .. warning::\n",
      "\n",
      "        This function is identical to :py:meth:`ast.literal_eval` and\n",
      "        has the same security implications.  It may not always be safe\n",
      "        to evaluate large input strings.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    source : str\n",
      "        The string to evaluate.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    obj : object\n",
      "       The result of evaluating `source`.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    SyntaxError\n",
      "        If the code has invalid Python syntax, or if it contains\n",
      "        non-literal code.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.safe_eval('1')\n",
      "    1\n",
      "    >>> np.safe_eval('[1, 2, 3]')\n",
      "    [1, 2, 3]\n",
      "    >>> np.safe_eval('{\"foo\": (\"bar\", 10.0)}')\n",
      "    {'foo': ('bar', 10.0)}\n",
      "\n",
      "    >>> np.safe_eval('import os')\n",
      "    Traceback (most recent call last):\n",
      "      ...\n",
      "    SyntaxError: invalid syntax\n",
      "\n",
      "    >>> np.safe_eval('open(\"/home/user/.ssh/id_dsa\").read()')\n",
      "    Traceback (most recent call last):\n",
      "      ...\n",
      "    ValueError: malformed node or string: <_ast.Call object at 0x...>\n",
      "\n",
      "    \n",
      "code: show_runtime\n",
      "def show_runtime():\n",
      "    from numpy.core._multiarray_umath import (\n",
      "        __cpu_features__, __cpu_baseline__, __cpu_dispatch__\n",
      "    )\n",
      "    from pprint import pprint\n",
      "    config_found = []\n",
      "    features_found, features_not_found = [], []\n",
      "    for feature in __cpu_dispatch__:\n",
      "        if __cpu_features__[feature]:\n",
      "            features_found.append(feature)\n",
      "        else:\n",
      "            features_not_found.append(feature)\n",
      "    config_found.append({\n",
      "        \"simd_extensions\": {\n",
      "            \"baseline\": __cpu_baseline__,\n",
      "            \"found\": features_found,\n",
      "            \"not_found\": features_not_found\n",
      "        }\n",
      "    })\n",
      "    try:\n",
      "        from threadpoolctl import threadpool_info\n",
      "        config_found.extend(threadpool_info())\n",
      "    except ImportError:\n",
      "        print(\"WARNING: `threadpoolctl` not found in system!\"\n",
      "              \" Install it by `pip install threadpoolctl`.\"\n",
      "              \" Once installed, try `np.show_runtime` again\"\n",
      "              \" for more detailed build information\")\n",
      "    pprint(config_found)\n",
      "docstring: show_runtime\n",
      "\n",
      "    Print information about various resources in the system\n",
      "    including available intrinsic support and BLAS/LAPACK library\n",
      "    in use\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    show_config : Show libraries in the system on which NumPy was built.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    1. Information is derived with the help of `threadpoolctl <https://pypi.org/project/threadpoolctl/>`_\n",
      "       library.\n",
      "    2. SIMD related information is derived from ``__cpu_features__``,\n",
      "       ``__cpu_baseline__`` and ``__cpu_dispatch__``\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> np.show_runtime()\n",
      "    [{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],\n",
      "                          'found': ['SSSE3',\n",
      "                                    'SSE41',\n",
      "                                    'POPCNT',\n",
      "                                    'SSE42',\n",
      "                                    'AVX',\n",
      "                                    'F16C',\n",
      "                                    'FMA3',\n",
      "                                    'AVX2'],\n",
      "                          'not_found': ['AVX512F',\n",
      "                                        'AVX512CD',\n",
      "                                        'AVX512_KNL',\n",
      "                                        'AVX512_KNM',\n",
      "                                        'AVX512_SKX',\n",
      "                                        'AVX512_CLX',\n",
      "                                        'AVX512_CNL',\n",
      "                                        'AVX512_ICL']}},\n",
      "     {'architecture': 'Zen',\n",
      "      'filepath': '/usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so',\n",
      "      'internal_api': 'openblas',\n",
      "      'num_threads': 12,\n",
      "      'prefix': 'libopenblas',\n",
      "      'threading_layer': 'pthreads',\n",
      "      'user_api': 'blas',\n",
      "      'version': '0.3.20'}]\n",
      "    \n",
      "code: ediff1d\n",
      "@array_function_dispatch(_ediff1d_dispatcher)\n",
      "def ediff1d(ary, to_end=None, to_begin=None):\n",
      " enforce that the dtype of `ary` is used for the output\n",
      "    dtype_req = ary.dtype\n",
      " do the calculation in place and copy to_begin and to_end\n",
      "    l_diff = max(len(ary) - 1, 0)\n",
      "    result = np.empty(l_diff + l_begin + l_end, dtype=ary.dtype)\n",
      "    result = ary.__array_wrap__(result)\n",
      "    if l_begin > 0:\n",
      "        result[:l_begin] = to_begin\n",
      "    if l_end > 0:\n",
      "        result[l_begin + l_diff:] = to_end\n",
      "    np.subtract(ary[1:], ary[:-1], result[l_begin:l_begin + l_diff])\n",
      "    return result\n",
      "docstring: ediff1d\n",
      "\n",
      "    The differences between consecutive elements of an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ary : array_like\n",
      "        If necessary, will be flattened before the differences are taken.\n",
      "    to_end : array_like, optional\n",
      "        Number(s) to append at the end of the returned differences.\n",
      "    to_begin : array_like, optional\n",
      "        Number(s) to prepend at the beginning of the returned differences.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    ediff1d : ndarray\n",
      "        The differences. Loosely, this is ``ary.flat[1:] - ary.flat[:-1]``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    diff, gradient\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When applied to masked arrays, this function drops the mask information\n",
      "    if the `to_begin` and/or `to_end` parameters are used.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([1, 2, 4, 7, 0])\n",
      "    >>> np.ediff1d(x)\n",
      "    array([ 1,  2,  3, -7])\n",
      "\n",
      "    >>> np.ediff1d(x, to_begin=-99, to_end=np.array([88, 99]))\n",
      "    array([-99,   1,   2, ...,  -7,  88,  99])\n",
      "\n",
      "    The returned array is always 1D.\n",
      "\n",
      "    >>> y = [[1, 2, 4], [1, 6, 24]]\n",
      "    >>> np.ediff1d(y)\n",
      "    array([ 1,  2, -3,  5, 18])\n",
      "\n",
      "    \n",
      "code: intersect1d\n",
      "@array_function_dispatch(_intersect1d_dispatcher)\n",
      "def intersect1d(ar1, ar2, assume_unique=False, return_indices=False):\n",
      "    ar1 = np.asanyarray(ar1)\n",
      "    ar2 = np.asanyarray(ar2)\n",
      "    if not assume_unique:\n",
      "        if return_indices:\n",
      "            ar1, ind1 = unique(ar1, return_index=True)\n",
      "            ar2, ind2 = unique(ar2, return_index=True)\n",
      "        else:\n",
      "            ar1 = unique(ar1)\n",
      "            ar2 = unique(ar2)\n",
      "    else:\n",
      "        ar1 = ar1.ravel()\n",
      "        ar2 = ar2.ravel()\n",
      "    aux = np.concatenate((ar1, ar2))\n",
      "    if return_indices:\n",
      "        aux_sort_indices = np.argsort(aux, kind='mergesort')\n",
      "        aux = aux[aux_sort_indices]\n",
      "    else:\n",
      "        aux.sort()\n",
      "    mask = aux[1:] == aux[:-1]\n",
      "    int1d = aux[:-1][mask]\n",
      "    if return_indices:\n",
      "        ar1_indices = aux_sort_indices[:-1][mask]\n",
      "        ar2_indices = aux_sort_indices[1:][mask] - ar1.size\n",
      "        if not assume_unique:\n",
      "            ar1_indices = ind1[ar1_indices]\n",
      "            ar2_indices = ind2[ar2_indices]\n",
      "        return int1d, ar1_indices, ar2_indices\n",
      "    else:\n",
      "        return int1d\n",
      "docstring: intersect1d\n",
      "\n",
      "    Find the intersection of two arrays.\n",
      "\n",
      "    Return the sorted, unique values that are in both of the input arrays.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ar1, ar2 : array_like\n",
      "        Input arrays. Will be flattened if not already 1D.\n",
      "    assume_unique : bool\n",
      "        If True, the input arrays are both assumed to be unique, which\n",
      "        can speed up the calculation.  If True but ``ar1`` or ``ar2`` are not\n",
      "        unique, incorrect results and out-of-bounds indices could result.\n",
      "        Default is False.\n",
      "    return_indices : bool\n",
      "        If True, the indices which correspond to the intersection of the two\n",
      "        arrays are returned. The first instance of a value is used if there are\n",
      "        multiple. Default is False.\n",
      "\n",
      "        .. versionadded:: 1.15.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    intersect1d : ndarray\n",
      "        Sorted 1D array of common and unique elements.\n",
      "    comm1 : ndarray\n",
      "        The indices of the first occurrences of the common values in `ar1`.\n",
      "        Only provided if `return_indices` is True.\n",
      "    comm2 : ndarray\n",
      "        The indices of the first occurrences of the common values in `ar2`.\n",
      "        Only provided if `return_indices` is True.\n",
      "\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.lib.arraysetops : Module with a number of other functions for\n",
      "                            performing set operations on arrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.intersect1d([1, 3, 4, 3], [3, 1, 2, 1])\n",
      "    array([1, 3])\n",
      "\n",
      "    To intersect more than two arrays, use functools.reduce:\n",
      "\n",
      "    >>> from functools import reduce\n",
      "    >>> reduce(np.intersect1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2]))\n",
      "    array([3])\n",
      "\n",
      "    To return the indices of the values common to the input arrays\n",
      "    along with the intersected values:\n",
      "\n",
      "    >>> x = np.array([1, 1, 2, 3, 4])\n",
      "    >>> y = np.array([2, 1, 4, 6])\n",
      "    >>> xy, x_ind, y_ind = np.intersect1d(x, y, return_indices=True)\n",
      "    >>> x_ind, y_ind\n",
      "    (array([0, 2, 4]), array([1, 0, 2]))\n",
      "    >>> xy, x[x_ind], y[y_ind]\n",
      "    (array([1, 2, 4]), array([1, 2, 4]), array([1, 2, 4]))\n",
      "\n",
      "    \n",
      "code: setxor1d\n",
      "@array_function_dispatch(_setxor1d_dispatcher)\n",
      "def setxor1d(ar1, ar2, assume_unique=False):\n",
      "    if not assume_unique:\n",
      "        ar1 = unique(ar1)\n",
      "        ar2 = unique(ar2)\n",
      "    aux = np.concatenate((ar1, ar2))\n",
      "    if aux.size == 0:\n",
      "        return aux\n",
      "    aux.sort()\n",
      "    flag = np.concatenate(([True], aux[1:] != aux[:-1], [True]))\n",
      "    return aux[flag[1:] & flag[:-1]]\n",
      "docstring: setxor1d\n",
      "\n",
      "    Find the set exclusive-or of two arrays.\n",
      "\n",
      "    Return the sorted, unique values that are in only one (not both) of the\n",
      "    input arrays.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ar1, ar2 : array_like\n",
      "        Input arrays.\n",
      "    assume_unique : bool\n",
      "        If True, the input arrays are both assumed to be unique, which\n",
      "        can speed up the calculation.  Default is False.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    setxor1d : ndarray\n",
      "        Sorted 1D array of unique values that are in only one of the input\n",
      "        arrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1, 2, 3, 2, 4])\n",
      "    >>> b = np.array([2, 3, 5, 7, 5])\n",
      "    >>> np.setxor1d(a,b)\n",
      "    array([1, 4, 5, 7])\n",
      "\n",
      "    \n",
      "code: union1d\n",
      "@array_function_dispatch(_union1d_dispatcher)\n",
      "def union1d(ar1, ar2):\n",
      "    return unique(np.concatenate((ar1, ar2), axis=None))\n",
      "docstring: union1d\n",
      "\n",
      "    Find the union of two arrays.\n",
      "\n",
      "    Return the unique, sorted array of values that are in either of the two\n",
      "    input arrays.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ar1, ar2 : array_like\n",
      "        Input arrays. They are flattened if they are not already 1D.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    union1d : ndarray\n",
      "        Unique, sorted union of the input arrays.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.lib.arraysetops : Module with a number of other functions for\n",
      "                            performing set operations on arrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.union1d([-1, 0, 1], [-2, 0, 2])\n",
      "    array([-2, -1,  0,  1,  2])\n",
      "\n",
      "    To find the union of more than two arrays, use functools.reduce:\n",
      "\n",
      "    >>> from functools import reduce\n",
      "    >>> reduce(np.union1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2]))\n",
      "    array([1, 2, 3, 4, 6])\n",
      "    \n",
      "code: setdiff1d\n",
      "@array_function_dispatch(_setdiff1d_dispatcher)\n",
      "def setdiff1d(ar1, ar2, assume_unique=False):\n",
      "    if assume_unique:\n",
      "        ar1 = np.asarray(ar1).ravel()\n",
      "    else:\n",
      "        ar1 = unique(ar1)\n",
      "        ar2 = unique(ar2)\n",
      "    return ar1[in1d(ar1, ar2, assume_unique=True, invert=True)]\n",
      "docstring: setdiff1d\n",
      "\n",
      "    Find the set difference of two arrays.\n",
      "\n",
      "    Return the unique values in `ar1` that are not in `ar2`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ar1 : array_like\n",
      "        Input array.\n",
      "    ar2 : array_like\n",
      "        Input comparison array.\n",
      "    assume_unique : bool\n",
      "        If True, the input arrays are both assumed to be unique, which\n",
      "        can speed up the calculation.  Default is False.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    setdiff1d : ndarray\n",
      "        1D array of values in `ar1` that are not in `ar2`. The result\n",
      "        is sorted when `assume_unique=False`, but otherwise only sorted\n",
      "        if the input is sorted.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.lib.arraysetops : Module with a number of other functions for\n",
      "                            performing set operations on arrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1, 2, 3, 2, 4, 1])\n",
      "    >>> b = np.array([3, 4, 5, 6])\n",
      "    >>> np.setdiff1d(a, b)\n",
      "    array([1, 2])\n",
      "\n",
      "    \n",
      "code: unique\n",
      "@array_function_dispatch(_unique_dispatcher)\n",
      "def unique(ar, return_index=False, return_inverse=False,\n",
      "           return_counts=False, axis=None, *, equal_nan=True):\n",
      "    ar = np.asanyarray(ar)\n",
      "    if axis is None:\n",
      "        ret = _unique1d(ar, return_index, return_inverse, return_counts,\n",
      "                        equal_nan=equal_nan)\n",
      "        return _unpack_tuple(ret)\n",
      " this removes the \"axis1\" or \"axis2\" prefix from the error message\n",
      "        raise np.AxisError(axis, ar.ndim) from None\n",
      " At this point, `ar` has shape `(n, m)`, and `dtype` is a structured\n",
      " In the following, we create the array `consolidated`, which has\n",
      " If ar.shape[1] == 0, then dtype will be `np.dtype([])`, which is\n",
      " fail.  Instead, we'll use `np.empty` to explicitly create the\n",
      " itemsize 0, the total size of the result is still 0 bytes.\n",
      "            consolidated = np.empty(len(ar), dtype=dtype)\n",
      "    except TypeError as e:\n",
      "        # There's no good way to do this for object arrays, etc...\n",
      "        msg = 'The axis argument to unique is not supported for dtype {dt}'\n",
      "        raise TypeError(msg.format(dt=ar.dtype)) from e\n",
      "    def reshape_uniq(uniq):\n",
      "        n = len(uniq)\n",
      "        uniq = uniq.view(orig_dtype)\n",
      "        uniq = uniq.reshape(n, *orig_shape[1:])\n",
      "        uniq = np.moveaxis(uniq, 0, axis)\n",
      "        return uniq\n",
      "    output = _unique1d(consolidated, return_index,\n",
      "                       return_inverse, return_counts, equal_nan=equal_nan)\n",
      "    output = (reshape_uniq(output[0]),) + output[1:]\n",
      "    return _unpack_tuple(output)\n",
      "docstring: unique\n",
      "\n",
      "    Find the unique elements of an array.\n",
      "\n",
      "    Returns the sorted unique elements of an array. There are three optional\n",
      "    outputs in addition to the unique elements:\n",
      "\n",
      "    * the indices of the input array that give the unique values\n",
      "    * the indices of the unique array that reconstruct the input array\n",
      "    * the number of times each unique value comes up in the input array\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ar : array_like\n",
      "        Input array. Unless `axis` is specified, this will be flattened if it\n",
      "        is not already 1-D.\n",
      "    return_index : bool, optional\n",
      "        If True, also return the indices of `ar` (along the specified axis,\n",
      "        if provided, or in the flattened array) that result in the unique array.\n",
      "    return_inverse : bool, optional\n",
      "        If True, also return the indices of the unique array (for the specified\n",
      "        axis, if provided) that can be used to reconstruct `ar`.\n",
      "    return_counts : bool, optional\n",
      "        If True, also return the number of times each unique item appears\n",
      "        in `ar`.\n",
      "    axis : int or None, optional\n",
      "        The axis to operate on. If None, `ar` will be flattened. If an integer,\n",
      "        the subarrays indexed by the given axis will be flattened and treated\n",
      "        as the elements of a 1-D array with the dimension of the given axis,\n",
      "        see the notes for more details.  Object arrays or structured arrays\n",
      "        that contain objects are not supported if the `axis` kwarg is used. The\n",
      "        default is None.\n",
      "\n",
      "        .. versionadded:: 1.13.0\n",
      "\n",
      "    equal_nan : bool, optional\n",
      "        If True, collapses multiple NaN values in the return array into one.\n",
      "\n",
      "        .. versionadded:: 1.24\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    unique : ndarray\n",
      "        The sorted unique values.\n",
      "    unique_indices : ndarray, optional\n",
      "        The indices of the first occurrences of the unique values in the\n",
      "        original array. Only provided if `return_index` is True.\n",
      "    unique_inverse : ndarray, optional\n",
      "        The indices to reconstruct the original array from the\n",
      "        unique array. Only provided if `return_inverse` is True.\n",
      "    unique_counts : ndarray, optional\n",
      "        The number of times each of the unique values comes up in the\n",
      "        original array. Only provided if `return_counts` is True.\n",
      "\n",
      "        .. versionadded:: 1.9.0\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.lib.arraysetops : Module with a number of other functions for\n",
      "                            performing set operations on arrays.\n",
      "    repeat : Repeat elements of an array.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When an axis is specified the subarrays indexed by the axis are sorted.\n",
      "    This is done by making the specified axis the first dimension of the array\n",
      "    (move the axis to the first dimension to keep the order of the other axes)\n",
      "    and then flattening the subarrays in C order. The flattened subarrays are\n",
      "    then viewed as a structured type with each element given a label, with the\n",
      "    effect that we end up with a 1-D array of structured types that can be\n",
      "    treated in the same way as any other 1-D array. The result is that the\n",
      "    flattened subarrays are sorted in lexicographic order starting with the\n",
      "    first element.\n",
      "\n",
      "    .. versionchanged: NumPy 1.21\n",
      "        If nan values are in the input array, a single nan is put\n",
      "        to the end of the sorted unique values.\n",
      "\n",
      "        Also for complex arrays all NaN values are considered equivalent\n",
      "        (no matter whether the NaN is in the real or imaginary part).\n",
      "        As the representant for the returned array the smallest one in the\n",
      "        lexicographical order is chosen - see np.sort for how the lexicographical\n",
      "        order is defined for complex arrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.unique([1, 1, 2, 2, 3, 3])\n",
      "    array([1, 2, 3])\n",
      "    >>> a = np.array([[1, 1], [2, 3]])\n",
      "    >>> np.unique(a)\n",
      "    array([1, 2, 3])\n",
      "\n",
      "    Return the unique rows of a 2D array\n",
      "\n",
      "    >>> a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])\n",
      "    >>> np.unique(a, axis=0)\n",
      "    array([[1, 0, 0], [2, 3, 4]])\n",
      "\n",
      "    Return the indices of the original array that give the unique values:\n",
      "\n",
      "    >>> a = np.array(['a', 'b', 'b', 'c', 'a'])\n",
      "    >>> u, indices = np.unique(a, return_index=True)\n",
      "    >>> u\n",
      "    array(['a', 'b', 'c'], dtype='<U1')\n",
      "    >>> indices\n",
      "    array([0, 1, 3])\n",
      "    >>> a[indices]\n",
      "    array(['a', 'b', 'c'], dtype='<U1')\n",
      "\n",
      "    Reconstruct the input array from the unique values and inverse:\n",
      "\n",
      "    >>> a = np.array([1, 2, 6, 4, 2, 3, 2])\n",
      "    >>> u, indices = np.unique(a, return_inverse=True)\n",
      "    >>> u\n",
      "    array([1, 2, 3, 4, 6])\n",
      "    >>> indices\n",
      "    array([0, 1, 4, 3, 1, 2, 1])\n",
      "    >>> u[indices]\n",
      "    array([1, 2, 6, 4, 2, 3, 2])\n",
      "\n",
      "    Reconstruct the input values from the unique values and counts:\n",
      "\n",
      "    >>> a = np.array([1, 2, 6, 4, 2, 3, 2])\n",
      "    >>> values, counts = np.unique(a, return_counts=True)\n",
      "    >>> values\n",
      "    array([1, 2, 3, 4, 6])\n",
      "    >>> counts\n",
      "    array([1, 3, 1, 1, 1])\n",
      "    >>> np.repeat(values, counts)\n",
      "    array([1, 2, 2, 2, 3, 4, 6])    # original order not preserved\n",
      "\n",
      "    \n",
      "code: in1d\n",
      "@array_function_dispatch(_in1d_dispatcher)\n",
      "def in1d(ar1, ar2, assume_unique=False, invert=False, *, kind=None):\n",
      " Ensure that iteration through object arrays yields size-1 arrays\n",
      "    if ar2.dtype == object:\n",
      "        ar2 = ar2.reshape(-1, 1)\n",
      "    if kind not in {None, 'sort', 'table'}:\n",
      "        raise ValueError(\n",
      "            f\"Invalid kind: '{kind}'. Please use None, 'sort' or 'table'.\")\n",
      " Convert booleans to uint8 so we can use the fast integer algorithm\n",
      "        if ar1.dtype == bool:\n",
      "            ar1 = ar1.astype(np.uint8)\n",
      "        if ar2.dtype == bool:\n",
      "            ar2 = ar2.astype(np.uint8)\n",
      "        ar2_min = np.min(ar2)\n",
      "        ar2_max = np.max(ar2)\n",
      "        ar2_range = int(ar2_max) - int(ar2_min)\n",
      "  1. Assert memory usage is not too large\n",
      "        below_memory_constraint = ar2_range <= 6 * (ar1.size + ar2.size)\n",
      "  3. Check overflows for (ar1 - ar2_min); dtype=ar1.dtype\n",
      "        if ar1.size > 0:\n",
      "            ar1_min = np.min(ar1)\n",
      "            ar1_max = np.max(ar1)\n",
      " within the range of ar2:\n",
      "            ar1_upper = min(int(ar1_max), int(ar2_max))\n",
      "            ar1_lower = max(int(ar1_min), int(ar2_min))\n",
      "            range_safe_from_overflow &= all((\n",
      "                ar1_upper - int(ar2_min) <= np.iinfo(ar1.dtype).max,\n",
      "                ar1_lower - int(ar2_min) >= np.iinfo(ar1.dtype).min\n",
      "            ))\n",
      " log10(size) > (log10(range) - 2.27) / 0.927.\n",
      " the intermediate array can only be 6x\n",
      " arrays. See discussion on\n",
      " Make elements 1 where the integer exists in ar2\n",
      "            if invert:\n",
      "                isin_helper_ar = np.ones(ar2_range + 1, dtype=bool)\n",
      "                isin_helper_ar[ar2 - ar2_min] = 0\n",
      "            else:\n",
      "                isin_helper_ar = np.zeros(ar2_range + 1, dtype=bool)\n",
      "                isin_helper_ar[ar2 - ar2_min] = 1\n",
      " not range_safe_from_overflow\n",
      "            raise RuntimeError(\n",
      "                \"You have specified kind='table', \"\n",
      "                \"but the range of values in `ar2` or `ar1` exceed the \"\n",
      "                \"maximum integer of the datatype. \"\n",
      "                \"Please set `kind` to None or 'sort'.\"\n",
      "            )\n",
      "    elif kind == 'table':\n",
      "        raise ValueError(\n",
      "            \"The 'table' method is only \"\n",
      "            \"supported for boolean or integer arrays. \"\n",
      "            \"Please select 'sort' or None for kind.\"\n",
      "        )\n",
      " This code is run when\n",
      " b) the second condition is true (i.e. `ar1` or `ar2` may contain\n",
      " Otherwise use sorting\n",
      "    if not assume_unique:\n",
      "        ar1, rev_idx = np.unique(ar1, return_inverse=True)\n",
      "        ar2 = np.unique(ar2)\n",
      "    ar = np.concatenate((ar1, ar2))\n",
      " here. The values from the first array should always come before\n",
      "    # the values from the second array.\n",
      "    order = ar.argsort(kind='mergesort')\n",
      "    sar = ar[order]\n",
      "    if invert:\n",
      "        bool_ar = (sar[1:] != sar[:-1])\n",
      "    else:\n",
      "        bool_ar = (sar[1:] == sar[:-1])\n",
      "    flag = np.concatenate((bool_ar, [invert]))\n",
      "    ret = np.empty(ar.shape, dtype=bool)\n",
      "    ret[order] = flag\n",
      "    if assume_unique:\n",
      "        return ret[:len(ar1)]\n",
      "    else:\n",
      "        return ret[rev_idx]\n",
      "docstring: in1d\n",
      "\n",
      "    Test whether each element of a 1-D array is also present in a second array.\n",
      "\n",
      "    Returns a boolean array the same length as `ar1` that is True\n",
      "    where an element of `ar1` is in `ar2` and False otherwise.\n",
      "\n",
      "    We recommend using :func:`isin` instead of `in1d` for new code.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ar1 : (M,) array_like\n",
      "        Input array.\n",
      "    ar2 : array_like\n",
      "        The values against which to test each value of `ar1`.\n",
      "    assume_unique : bool, optional\n",
      "        If True, the input arrays are both assumed to be unique, which\n",
      "        can speed up the calculation.  Default is False.\n",
      "    invert : bool, optional\n",
      "        If True, the values in the returned array are inverted (that is,\n",
      "        False where an element of `ar1` is in `ar2` and True otherwise).\n",
      "        Default is False. ``np.in1d(a, b, invert=True)`` is equivalent\n",
      "        to (but is faster than) ``np.invert(in1d(a, b))``.\n",
      "    kind : {None, 'sort', 'table'}, optional\n",
      "        The algorithm to use. This will not affect the final result,\n",
      "        but will affect the speed and memory use. The default, None,\n",
      "        will select automatically based on memory considerations.\n",
      "\n",
      "        * If 'sort', will use a mergesort-based approach. This will have\n",
      "          a memory usage of roughly 6 times the sum of the sizes of\n",
      "          `ar1` and `ar2`, not accounting for size of dtypes.\n",
      "        * If 'table', will use a lookup table approach similar\n",
      "          to a counting sort. This is only available for boolean and\n",
      "          integer arrays. This will have a memory usage of the\n",
      "          size of `ar1` plus the max-min value of `ar2`. `assume_unique`\n",
      "          has no effect when the 'table' option is used.\n",
      "        * If None, will automatically choose 'table' if\n",
      "          the required memory allocation is less than or equal to\n",
      "          6 times the sum of the sizes of `ar1` and `ar2`,\n",
      "          otherwise will use 'sort'. This is done to not use\n",
      "          a large amount of memory by default, even though\n",
      "          'table' may be faster in most cases. If 'table' is chosen,\n",
      "          `assume_unique` will have no effect.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    in1d : (M,) ndarray, bool\n",
      "        The values `ar1[in1d]` are in `ar2`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    isin                  : Version of this function that preserves the\n",
      "                            shape of ar1.\n",
      "    numpy.lib.arraysetops : Module with a number of other functions for\n",
      "                            performing set operations on arrays.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    `in1d` can be considered as an element-wise function version of the\n",
      "    python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is roughly\n",
      "    equivalent to ``np.array([item in b for item in a])``.\n",
      "    However, this idea fails if `ar2` is a set, or similar (non-sequence)\n",
      "    container:  As ``ar2`` is converted to an array, in those cases\n",
      "    ``asarray(ar2)`` is an object array rather than the expected array of\n",
      "    contained values.\n",
      "\n",
      "    Using ``kind='table'`` tends to be faster than `kind='sort'` if the\n",
      "    following relationship is true:\n",
      "    ``log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927``,\n",
      "    but may use greater memory. The default value for `kind` will\n",
      "    be automatically selected based only on memory usage, so one may\n",
      "    manually set ``kind='table'`` if memory constraints can be relaxed.\n",
      "\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> test = np.array([0, 1, 2, 5, 0])\n",
      "    >>> states = [0, 2]\n",
      "    >>> mask = np.in1d(test, states)\n",
      "    >>> mask\n",
      "    array([ True, False,  True, False,  True])\n",
      "    >>> test[mask]\n",
      "    array([0, 2, 0])\n",
      "    >>> mask = np.in1d(test, states, invert=True)\n",
      "    >>> mask\n",
      "    array([False,  True, False,  True, False])\n",
      "    >>> test[mask]\n",
      "    array([1, 5])\n",
      "    \n",
      "code: isin\n",
      "@array_function_dispatch(_isin_dispatcher)\n",
      "def isin(element, test_elements, assume_unique=False, invert=False, *,\n",
      "         kind=None):\n",
      "    element = np.asarray(element)\n",
      "    return in1d(element, test_elements, assume_unique=assume_unique,\n",
      "                invert=invert, kind=kind).reshape(element.shape)\n",
      "docstring: isin\n",
      "\n",
      "    Calculates ``element in test_elements``, broadcasting over `element` only.\n",
      "    Returns a boolean array of the same shape as `element` that is True\n",
      "    where an element of `element` is in `test_elements` and False otherwise.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    element : array_like\n",
      "        Input array.\n",
      "    test_elements : array_like\n",
      "        The values against which to test each value of `element`.\n",
      "        This argument is flattened if it is an array or array_like.\n",
      "        See notes for behavior with non-array-like parameters.\n",
      "    assume_unique : bool, optional\n",
      "        If True, the input arrays are both assumed to be unique, which\n",
      "        can speed up the calculation.  Default is False.\n",
      "    invert : bool, optional\n",
      "        If True, the values in the returned array are inverted, as if\n",
      "        calculating `element not in test_elements`. Default is False.\n",
      "        ``np.isin(a, b, invert=True)`` is equivalent to (but faster\n",
      "        than) ``np.invert(np.isin(a, b))``.\n",
      "    kind : {None, 'sort', 'table'}, optional\n",
      "        The algorithm to use. This will not affect the final result,\n",
      "        but will affect the speed and memory use. The default, None,\n",
      "        will select automatically based on memory considerations.\n",
      "\n",
      "        * If 'sort', will use a mergesort-based approach. This will have\n",
      "          a memory usage of roughly 6 times the sum of the sizes of\n",
      "          `ar1` and `ar2`, not accounting for size of dtypes.\n",
      "        * If 'table', will use a lookup table approach similar\n",
      "          to a counting sort. This is only available for boolean and\n",
      "          integer arrays. This will have a memory usage of the\n",
      "          size of `ar1` plus the max-min value of `ar2`. `assume_unique`\n",
      "          has no effect when the 'table' option is used.\n",
      "        * If None, will automatically choose 'table' if\n",
      "          the required memory allocation is less than or equal to\n",
      "          6 times the sum of the sizes of `ar1` and `ar2`,\n",
      "          otherwise will use 'sort'. This is done to not use\n",
      "          a large amount of memory by default, even though\n",
      "          'table' may be faster in most cases. If 'table' is chosen,\n",
      "          `assume_unique` will have no effect.\n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    isin : ndarray, bool\n",
      "        Has the same shape as `element`. The values `element[isin]`\n",
      "        are in `test_elements`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    in1d                  : Flattened version of this function.\n",
      "    numpy.lib.arraysetops : Module with a number of other functions for\n",
      "                            performing set operations on arrays.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "\n",
      "    `isin` is an element-wise function version of the python keyword `in`.\n",
      "    ``isin(a, b)`` is roughly equivalent to\n",
      "    ``np.array([item in b for item in a])`` if `a` and `b` are 1-D sequences.\n",
      "\n",
      "    `element` and `test_elements` are converted to arrays if they are not\n",
      "    already. If `test_elements` is a set (or other non-sequence collection)\n",
      "    it will be converted to an object array with one element, rather than an\n",
      "    array of the values contained in `test_elements`. This is a consequence\n",
      "    of the `array` constructor's way of handling non-sequence collections.\n",
      "    Converting the set to a list usually gives the desired behavior.\n",
      "\n",
      "    Using ``kind='table'`` tends to be faster than `kind='sort'` if the\n",
      "    following relationship is true:\n",
      "    ``log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927``,\n",
      "    but may use greater memory. The default value for `kind` will\n",
      "    be automatically selected based only on memory usage, so one may\n",
      "    manually set ``kind='table'`` if memory constraints can be relaxed.\n",
      "\n",
      "    .. versionadded:: 1.13.0\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> element = 2*np.arange(4).reshape((2, 2))\n",
      "    >>> element\n",
      "    array([[0, 2],\n",
      "           [4, 6]])\n",
      "    >>> test_elements = [1, 2, 4, 8]\n",
      "    >>> mask = np.isin(element, test_elements)\n",
      "    >>> mask\n",
      "    array([[False,  True],\n",
      "           [ True, False]])\n",
      "    >>> element[mask]\n",
      "    array([2, 4])\n",
      "\n",
      "    The indices of the matched values can be obtained with `nonzero`:\n",
      "\n",
      "    >>> np.nonzero(mask)\n",
      "    (array([0, 1]), array([1, 0]))\n",
      "\n",
      "    The test can also be inverted:\n",
      "\n",
      "    >>> mask = np.isin(element, test_elements, invert=True)\n",
      "    >>> mask\n",
      "    array([[ True, False],\n",
      "           [False,  True]])\n",
      "    >>> element[mask]\n",
      "    array([0, 6])\n",
      "\n",
      "    Because of how `array` handles sets, the following does not\n",
      "    work as expected:\n",
      "\n",
      "    >>> test_set = {1, 2, 4, 8}\n",
      "    >>> np.isin(element, test_set)\n",
      "    array([[False, False],\n",
      "           [False, False]])\n",
      "\n",
      "    Casting the set to a list gives the expected result:\n",
      "\n",
      "    >>> np.isin(element, list(test_set))\n",
      "    array([[False,  True],\n",
      "           [ True, False]])\n",
      "    \n",
      "code: savetxt\n",
      "@array_function_dispatch(_savetxt_dispatcher)\n",
      "def savetxt(fname, X, fmt='%.18e', delimiter=' ', newline='\\n', header='',\n",
      "            footer='', comments='# ', encoding=None):\n",
      " input is probably a bytestream\n",
      "                self.write_bytes(v)\n",
      "                self.write = self.write_bytes\n",
      "    own_fh = False\n",
      "    if isinstance(fname, os_PathLike):\n",
      "        fname = os_fspath(fname)\n",
      "    if _is_string_like(fname):\n",
      " wrap to handle byte output streams\n",
      "        fh = WriteWrap(fname, encoding or 'latin1')\n",
      "    else:\n",
      "        raise ValueError('fname must be a string or file handle')\n",
      "    try:\n",
      "        X = np.asarray(X)\n",
      " Common case -- 1d array of numbers\n",
      "            if X.dtype.names is None:\n",
      "                X = np.atleast_2d(X).T\n",
      "                ncol = 1\n",
      " `fmt` can be a string with multiple insertion points or a\n",
      "        # list of formats.  E.g. '%10.5f\\t%10d' or ('%10.5f', '$10d')\n",
      "        if type(fmt) in (list, tuple):\n",
      "            if len(fmt) != ncol:\n",
      "                raise AttributeError('fmt has wrong shape.  %s' % str(fmt))\n",
      "            format = asstr(delimiter).join(map(asstr, fmt))\n",
      "        elif isinstance(fmt, str):\n",
      "            n_fmt_chars = fmt.count('%')\n",
      "            error = ValueError('fmt has wrong number of %% formats:  %s' % fmt)\n",
      "            if n_fmt_chars == 1:\n",
      "                if iscomplex_X:\n",
      "                    fmt = [' (%s+%sj)' % (fmt, fmt), ] * ncol\n",
      "                else:\n",
      "                    fmt = [fmt, ] * ncol\n",
      "                format = delimiter.join(fmt)\n",
      "            elif iscomplex_X and n_fmt_chars != (2 * ncol):\n",
      "                raise error\n",
      "            elif ((not iscomplex_X) and n_fmt_chars != ncol):\n",
      "                raise error\n",
      "            else:\n",
      "                format = fmt\n",
      "        else:\n",
      "            raise ValueError('invalid fmt: %r' % (fmt,))\n",
      "        if len(header) > 0:\n",
      "            header = header.replace('\\n', '\\n' + comments)\n",
      "            fh.write(comments + header + newline)\n",
      "        if iscomplex_X:\n",
      "            for row in X:\n",
      "                row2 = []\n",
      "                for number in row:\n",
      "                    row2.append(number.real)\n",
      "                    row2.append(number.imag)\n",
      "                s = format % tuple(row2) + newline\n",
      "                fh.write(s.replace('+-', '-'))\n",
      "        else:\n",
      "            for row in X:\n",
      "                try:\n",
      "                    v = format % tuple(row) + newline\n",
      "                except TypeError as e:\n",
      "                    raise TypeError(\"Mismatch between array dtype ('%s') and \"\n",
      "                                    \"format specifier ('%s')\"\n",
      "                                    % (str(X.dtype), format)) from e\n",
      "                fh.write(v)\n",
      "        if len(footer) > 0:\n",
      "            footer = footer.replace('\\n', '\\n' + comments)\n",
      "            fh.write(comments + footer + newline)\n",
      "    finally:\n",
      "        if own_fh:\n",
      "            fh.close()\n",
      "docstring: savetxt\n",
      "\n",
      "    Save an array to a text file.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : filename or file handle\n",
      "        If the filename ends in ``.gz``, the file is automatically saved in\n",
      "        compressed gzip format.  `loadtxt` understands gzipped files\n",
      "        transparently.\n",
      "    X : 1D or 2D array_like\n",
      "        Data to be saved to a text file.\n",
      "    fmt : str or sequence of strs, optional\n",
      "        A single format (%10.5f), a sequence of formats, or a\n",
      "        multi-format string, e.g. 'Iteration %d -- %10.5f', in which\n",
      "        case `delimiter` is ignored. For complex `X`, the legal options\n",
      "        for `fmt` are:\n",
      "\n",
      "        * a single specifier, `fmt='%.4e'`, resulting in numbers formatted\n",
      "          like `' (%s+%sj)' % (fmt, fmt)`\n",
      "        * a full string specifying every real and imaginary part, e.g.\n",
      "          `' %.4e %+.4ej %.4e %+.4ej %.4e %+.4ej'` for 3 columns\n",
      "        * a list of specifiers, one per column - in this case, the real\n",
      "          and imaginary part must have separate specifiers,\n",
      "          e.g. `['%.3e + %.3ej', '(%.15e%+.15ej)']` for 2 columns\n",
      "    delimiter : str, optional\n",
      "        String or character separating columns.\n",
      "    newline : str, optional\n",
      "        String or character separating lines.\n",
      "\n",
      "        .. versionadded:: 1.5.0\n",
      "    header : str, optional\n",
      "        String that will be written at the beginning of the file.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "    footer : str, optional\n",
      "        String that will be written at the end of the file.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "    comments : str, optional\n",
      "        String that will be prepended to the ``header`` and ``footer`` strings,\n",
      "        to mark them as comments. Default: '# ',  as expected by e.g.\n",
      "        ``numpy.loadtxt``.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "    encoding : {None, str}, optional\n",
      "        Encoding used to encode the outputfile. Does not apply to output\n",
      "        streams. If the encoding is something other than 'bytes' or 'latin1'\n",
      "        you will not be able to load the file in NumPy versions < 1.14. Default\n",
      "        is 'latin1'.\n",
      "\n",
      "        .. versionadded:: 1.14.0\n",
      "\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    save : Save an array to a binary file in NumPy ``.npy`` format\n",
      "    savez : Save several arrays into an uncompressed ``.npz`` archive\n",
      "    savez_compressed : Save several arrays into a compressed ``.npz`` archive\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Further explanation of the `fmt` parameter\n",
      "    (``%[flag]width[.precision]specifier``):\n",
      "\n",
      "    flags:\n",
      "        ``-`` : left justify\n",
      "\n",
      "        ``+`` : Forces to precede result with + or -.\n",
      "\n",
      "        ``0`` : Left pad the number with zeros instead of space (see width).\n",
      "\n",
      "    width:\n",
      "        Minimum number of characters to be printed. The value is not truncated\n",
      "        if it has more characters.\n",
      "\n",
      "    precision:\n",
      "        - For integer specifiers (eg. ``d,i,o,x``), the minimum number of\n",
      "          digits.\n",
      "        - For ``e, E`` and ``f`` specifiers, the number of digits to print\n",
      "          after the decimal point.\n",
      "        - For ``g`` and ``G``, the maximum number of significant digits.\n",
      "        - For ``s``, the maximum number of characters.\n",
      "\n",
      "    specifiers:\n",
      "        ``c`` : character\n",
      "\n",
      "        ``d`` or ``i`` : signed decimal integer\n",
      "\n",
      "        ``e`` or ``E`` : scientific notation with ``e`` or ``E``.\n",
      "\n",
      "        ``f`` : decimal floating point\n",
      "\n",
      "        ``g,G`` : use the shorter of ``e,E`` or ``f``\n",
      "\n",
      "        ``o`` : signed octal\n",
      "\n",
      "        ``s`` : string of characters\n",
      "\n",
      "        ``u`` : unsigned decimal integer\n",
      "\n",
      "        ``x,X`` : unsigned hexadecimal integer\n",
      "\n",
      "    This explanation of ``fmt`` is not complete, for an exhaustive\n",
      "    specification see [1]_.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Format Specification Mini-Language\n",
      "           <https://docs.python.org/library/string.html#format-specification-mini-language>`_,\n",
      "           Python Documentation.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = y = z = np.arange(0.0,5.0,1.0)\n",
      "    >>> np.savetxt('test.out', x, delimiter=',')   # X is an array\n",
      "    >>> np.savetxt('test.out', (x,y,z))   # x,y,z equal sized 1D arrays\n",
      "    >>> np.savetxt('test.out', x, fmt='%1.4e')   # use exponential notation\n",
      "\n",
      "    \n",
      "code: loadtxt\n",
      "@set_array_function_like_doc\n",
      "@set_module('numpy')\n",
      "def loadtxt(fname, dtype=float, comments='#', delimiter=None,\n",
      "            converters=None, skiprows=0, usecols=None, unpack=False,\n",
      "            ndmin=0, encoding='bytes', max_rows=None, *, quotechar=None,\n",
      "            like=None):\n",
      "    r\"\"\"\n",
      "    Load data from a text file.\n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : file, str, pathlib.Path, list of str, generator\n",
      "        File, filename, list, or generator to read.  If the filename\n",
      "        extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\n",
      "        that generators must return bytes or strings. The strings\n",
      "        in a list or produced by a generator are treated as lines.\n",
      "    dtype : data-type, optional\n",
      "        Data-type of the resulting array; default: float.  If this is a\n",
      "        structured data-type, the resulting array will be 1-dimensional, and\n",
      "        each row will be interpreted as an element of the array.  In this\n",
      "        case, the number of columns used must match the number of fields in\n",
      "        the data-type.\n",
      "    comments : str or sequence of str or None, optional\n",
      "        The characters or list of characters used to indicate the start of a\n",
      "        comment. None implies no comments. For backwards compatibility, byte\n",
      "        strings will be decoded as 'latin1'. The default is '#'.\n",
      "    delimiter : str, optional\n",
      "        The character used to separate the values. For backwards compatibility,\n",
      "        byte strings will be decoded as 'latin1'. The default is whitespace.\n",
      "        .. versionchanged:: 1.23.0\n",
      "           Only single character delimiters are supported. Newline characters\n",
      "           cannot be used as the delimiter.\n",
      "    converters : dict or callable, optional\n",
      "        Converter functions to customize value parsing. If `converters` is\n",
      "        callable, the function is applied to all columns, else it must be a\n",
      "        dict that maps column number to a parser function.\n",
      "        See examples for further details.\n",
      "        Default: None.\n",
      "        .. versionchanged:: 1.23.0\n",
      "           The ability to pass a single callable to be applied to all columns\n",
      "           was added.\n",
      "    skiprows : int, optional\n",
      "        Skip the first `skiprows` lines, including comments; default: 0.\n",
      "    usecols : int or sequence, optional\n",
      "        Which columns to read, with 0 being the first. For example,\n",
      "        ``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns.\n",
      "        The default, None, results in all columns being read.\n",
      "        .. versionchanged:: 1.11.0\n",
      "            When a single column has to be read it is possible to use\n",
      "            an integer instead of a tuple. E.g ``usecols = 3`` reads the\n",
      "            fourth column the same way as ``usecols = (3,)`` would.\n",
      "    unpack : bool, optional\n",
      "        If True, the returned array is transposed, so that arguments may be\n",
      "        unpacked using ``x, y, z = loadtxt(...)``.  When used with a\n",
      "        structured data-type, arrays are returned for each field.\n",
      "        Default is False.\n",
      "    ndmin : int, optional\n",
      "        The returned array will have at least `ndmin` dimensions.\n",
      "        Otherwise mono-dimensional axes will be squeezed.\n",
      "        Legal values: 0 (default), 1 or 2.\n",
      "        .. versionadded:: 1.6.0\n",
      "    encoding : str, optional\n",
      "        Encoding used to decode the inputfile. Does not apply to input streams.\n",
      "        The special value 'bytes' enables backward compatibility workarounds\n",
      "        that ensures you receive byte arrays as results if possible and passes\n",
      "        'latin1' encoded strings to converters. Override this value to receive\n",
      "        unicode arrays and pass strings as input to converters.  If set to None\n",
      "        the system default is used. The default value is 'bytes'.\n",
      "        .. versionadded:: 1.14.0\n",
      "    max_rows : int, optional\n",
      "        Read `max_rows` rows of content after `skiprows` lines. The default is\n",
      "        to read all the rows. Note that empty rows containing no data such as\n",
      "        empty lines and comment lines are not counted towards `max_rows`,\n",
      "        while such lines are counted in `skiprows`.\n",
      "        .. versionadded:: 1.16.0\n",
      "        .. versionchanged:: 1.23.0\n",
      "            Lines containing no data, including comment lines (e.g., lines\n",
      "            starting with '#' or as specified via `comments`) are not counted\n",
      "            towards `max_rows`.\n",
      "    quotechar : unicode character or None, optional\n",
      "        The character used to denote the start and end of a quoted item.\n",
      "        Occurrences of the delimiter or comment characters are ignored within\n",
      "        a quoted item. The default value is ``quotechar=None``, which means\n",
      "        quoting support is disabled.\n",
      "        If two consecutive instances of `quotechar` are found within a quoted\n",
      "        field, the first is treated as an escape character. See examples.\n",
      "        .. versionadded:: 1.23.0\n",
      "    ${ARRAY_FUNCTION_LIKE}\n",
      "        .. versionadded:: 1.20.0\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Data read from the text file.\n",
      "    See Also\n",
      "    --------\n",
      "    load, fromstring, fromregex\n",
      "    genfromtxt : Load data with missing values handled as specified.\n",
      "    scipy.io.loadmat : reads MATLAB data files\n",
      "    Notes\n",
      "    -----\n",
      "    This function aims to be a fast reader for simply formatted files.  The\n",
      "    `genfromtxt` function provides more sophisticated handling of, e.g.,\n",
      "    lines with missing values.\n",
      "    Each row in the input text file must have the same number of values to be\n",
      "    able to read all values. If all rows do not have same number of values, a\n",
      "    subset of up to n columns (where n is the least number of values present\n",
      "    in all rows) can be read by specifying the columns via `usecols`.\n",
      "    .. versionadded:: 1.10.0\n",
      "    The strings produced by the Python float.hex method can be used as\n",
      "    input for floats.\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from io import StringIO   # StringIO behaves like a file object\n",
      "    >>> c = StringIO(\"0 1\\n2 3\")\n",
      "    >>> np.loadtxt(c)\n",
      "    array([[0., 1.],\n",
      "           [2., 3.]])\n",
      "    >>> d = StringIO(\"M 21 72\\nF 35 58\")\n",
      "    >>> np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),\n",
      "    ...                      'formats': ('S1', 'i4', 'f4')})\n",
      "    array([(b'M', 21, 72.), (b'F', 35, 58.)],\n",
      "          dtype=[('gender', 'S1'), ('age', '<i4'), ('weight', '<f4')])\n",
      "    >>> c = StringIO(\"1,0,2\\n3,0,4\")\n",
      "    >>> x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True)\n",
      "    >>> x\n",
      "    array([1., 3.])\n",
      "    >>> y\n",
      "    array([2., 4.])\n",
      "    The `converters` argument is used to specify functions to preprocess the\n",
      "    text prior to parsing. `converters` can be a dictionary that maps\n",
      "    preprocessing functions to each column:\n",
      "    >>> s = StringIO(\"1.618, 2.296\\n3.141, 4.669\\n\")\n",
      "    >>> conv = {\n",
      "    ...     0: lambda x: np.floor(float(x)),  # conversion fn for column 0\n",
      "    ...     1: lambda x: np.ceil(float(x)),  # conversion fn for column 1\n",
      "    ... }\n",
      "    >>> np.loadtxt(s, delimiter=\",\", converters=conv)\n",
      "    array([[1., 3.],\n",
      "           [3., 5.]])\n",
      "    `converters` can be a callable instead of a dictionary, in which case it\n",
      "    is applied to all columns:\n",
      "    >>> s = StringIO(\"0xDE 0xAD\\n0xC0 0xDE\")\n",
      "    >>> import functools\n",
      "    >>> conv = functools.partial(int, base=16)\n",
      "    >>> np.loadtxt(s, converters=conv)\n",
      "    array([[222., 173.],\n",
      "           [192., 222.]])\n",
      "    This example shows how `converters` can be used to convert a field\n",
      "    with a trailing minus sign into a negative number.\n",
      "    >>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n",
      "    >>> def conv(fld):\n",
      "    ...     return -float(fld[:-1]) if fld.endswith(b'-') else float(fld)\n",
      "    ...\n",
      "    >>> np.loadtxt(s, converters=conv)\n",
      "    array([[ 10.01, -31.25],\n",
      "           [ 19.22,  64.31],\n",
      "           [-17.57,  63.94]])\n",
      "    Using a callable as the converter can be particularly useful for handling\n",
      "    values with different formatting, e.g. floats with underscores:\n",
      "    >>> s = StringIO(\"1 2.7 100_000\")\n",
      "    >>> np.loadtxt(s, converters=float)\n",
      "    array([1.e+00, 2.7e+00, 1.e+05])\n",
      "    This idea can be extended to automatically handle values specified in\n",
      "    many different formats:\n",
      "    >>> def conv(val):\n",
      "    ...     try:\n",
      "    ...         return float(val)\n",
      "    ...     except ValueError:\n",
      "    ...         return float.fromhex(val)\n",
      "    >>> s = StringIO(\"1, 2.5, 3_000, 0b4, 0x1.4000000000000p+2\")\n",
      "    >>> np.loadtxt(s, delimiter=\",\", converters=conv, encoding=None)\n",
      "    array([1.0e+00, 2.5e+00, 3.0e+03, 1.8e+02, 5.0e+00])\n",
      "    Note that with the default ``encoding=\"bytes\"``, the inputs to the\n",
      "    converter function are latin-1 encoded byte strings. To deactivate the\n",
      "    implicit encoding prior to conversion, use ``encoding=None``\n",
      "    >>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n",
      "    >>> conv = lambda x: -float(x[:-1]) if x.endswith('-') else float(x)\n",
      "    >>> np.loadtxt(s, converters=conv, encoding=None)\n",
      "    array([[ 10.01, -31.25],\n",
      "           [ 19.22,  64.31],\n",
      "           [-17.57,  63.94]])\n",
      "    Support for quoted fields is enabled with the `quotechar` parameter.\n",
      "    Comment and delimiter characters are ignored when they appear within a\n",
      "    quoted item delineated by `quotechar`:\n",
      "    >>> s = StringIO('\"alpha, #42\", 10.0\\n\"beta, #64\", 2.0\\n')\n",
      "    >>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n",
      "    >>> np.loadtxt(s, dtype=dtype, delimiter=\",\", quotechar='\"')\n",
      "    array([('alpha, #42', 10.), ('beta, #64',  2.)],\n",
      "          dtype=[('label', '<U12'), ('value', '<f8')])\n",
      "    Two consecutive quote characters within a quoted field are treated as a\n",
      "    single escaped character:\n",
      "    >>> s = StringIO('\"Hello, my name is \"\"Monty\"\"!\"')\n",
      "    >>> np.loadtxt(s, dtype=\"U\", delimiter=\",\", quotechar='\"')\n",
      "    array('Hello, my name is \"Monty\"!', dtype='<U26')\n",
      "    Read subset of columns when all rows do not contain equal number of values:\n",
      "    >>> d = StringIO(\"1 2\\n2 4\\n3 9 12\\n4 16 20\")\n",
      "    >>> np.loadtxt(d, usecols=(0, 1))\n",
      "    array([[ 1.,  2.],\n",
      "           [ 2.,  4.],\n",
      "           [ 3.,  9.],\n",
      "           [ 4., 16.]])\n",
      "    \"\"\"\n",
      "    if like is not None:\n",
      "        return _loadtxt_with_like(\n",
      "            fname, dtype=dtype, comments=comments, delimiter=delimiter,\n",
      "            converters=converters, skiprows=skiprows, usecols=usecols,\n",
      "            unpack=unpack, ndmin=ndmin, encoding=encoding,\n",
      "            max_rows=max_rows, like=like\n",
      "        )\n",
      "    if isinstance(delimiter, bytes):\n",
      "        delimiter.decode(\"latin1\")\n",
      "    if dtype is None:\n",
      "        dtype = np.float64\n",
      "    comment = comments\n",
      "    # Control character type conversions for Py3 convenience\n",
      "    if comment is not None:\n",
      "        if isinstance(comment, (str, bytes)):\n",
      "            comment = [comment]\n",
      "        comment = [\n",
      "            x.decode('latin1') if isinstance(x, bytes) else x for x in comment]\n",
      "    if isinstance(delimiter, bytes):\n",
      "        delimiter = delimiter.decode('latin1')\n",
      "    arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n",
      "                converters=converters, skiplines=skiprows, usecols=usecols,\n",
      "                unpack=unpack, ndmin=ndmin, encoding=encoding,\n",
      "                max_rows=max_rows, quote=quotechar)\n",
      "    return arr\n",
      "docstring: loadtxt\n",
      "\n",
      "    Load data from a text file.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : file, str, pathlib.Path, list of str, generator\n",
      "        File, filename, list, or generator to read.  If the filename\n",
      "        extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\n",
      "        that generators must return bytes or strings. The strings\n",
      "        in a list or produced by a generator are treated as lines.\n",
      "    dtype : data-type, optional\n",
      "        Data-type of the resulting array; default: float.  If this is a\n",
      "        structured data-type, the resulting array will be 1-dimensional, and\n",
      "        each row will be interpreted as an element of the array.  In this\n",
      "        case, the number of columns used must match the number of fields in\n",
      "        the data-type.\n",
      "    comments : str or sequence of str or None, optional\n",
      "        The characters or list of characters used to indicate the start of a\n",
      "        comment. None implies no comments. For backwards compatibility, byte\n",
      "        strings will be decoded as 'latin1'. The default is '#'.\n",
      "    delimiter : str, optional\n",
      "        The character used to separate the values. For backwards compatibility,\n",
      "        byte strings will be decoded as 'latin1'. The default is whitespace.\n",
      "\n",
      "        .. versionchanged:: 1.23.0\n",
      "           Only single character delimiters are supported. Newline characters\n",
      "           cannot be used as the delimiter.\n",
      "\n",
      "    converters : dict or callable, optional\n",
      "        Converter functions to customize value parsing. If `converters` is\n",
      "        callable, the function is applied to all columns, else it must be a\n",
      "        dict that maps column number to a parser function.\n",
      "        See examples for further details.\n",
      "        Default: None.\n",
      "\n",
      "        .. versionchanged:: 1.23.0\n",
      "           The ability to pass a single callable to be applied to all columns\n",
      "           was added.\n",
      "\n",
      "    skiprows : int, optional\n",
      "        Skip the first `skiprows` lines, including comments; default: 0.\n",
      "    usecols : int or sequence, optional\n",
      "        Which columns to read, with 0 being the first. For example,\n",
      "        ``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns.\n",
      "        The default, None, results in all columns being read.\n",
      "\n",
      "        .. versionchanged:: 1.11.0\n",
      "            When a single column has to be read it is possible to use\n",
      "            an integer instead of a tuple. E.g ``usecols = 3`` reads the\n",
      "            fourth column the same way as ``usecols = (3,)`` would.\n",
      "    unpack : bool, optional\n",
      "        If True, the returned array is transposed, so that arguments may be\n",
      "        unpacked using ``x, y, z = loadtxt(...)``.  When used with a\n",
      "        structured data-type, arrays are returned for each field.\n",
      "        Default is False.\n",
      "    ndmin : int, optional\n",
      "        The returned array will have at least `ndmin` dimensions.\n",
      "        Otherwise mono-dimensional axes will be squeezed.\n",
      "        Legal values: 0 (default), 1 or 2.\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "    encoding : str, optional\n",
      "        Encoding used to decode the inputfile. Does not apply to input streams.\n",
      "        The special value 'bytes' enables backward compatibility workarounds\n",
      "        that ensures you receive byte arrays as results if possible and passes\n",
      "        'latin1' encoded strings to converters. Override this value to receive\n",
      "        unicode arrays and pass strings as input to converters.  If set to None\n",
      "        the system default is used. The default value is 'bytes'.\n",
      "\n",
      "        .. versionadded:: 1.14.0\n",
      "    max_rows : int, optional\n",
      "        Read `max_rows` rows of content after `skiprows` lines. The default is\n",
      "        to read all the rows. Note that empty rows containing no data such as\n",
      "        empty lines and comment lines are not counted towards `max_rows`,\n",
      "        while such lines are counted in `skiprows`.\n",
      "\n",
      "        .. versionadded:: 1.16.0\n",
      "        \n",
      "        .. versionchanged:: 1.23.0\n",
      "            Lines containing no data, including comment lines (e.g., lines \n",
      "            starting with '#' or as specified via `comments`) are not counted \n",
      "            towards `max_rows`.\n",
      "    quotechar : unicode character or None, optional\n",
      "        The character used to denote the start and end of a quoted item.\n",
      "        Occurrences of the delimiter or comment characters are ignored within\n",
      "        a quoted item. The default value is ``quotechar=None``, which means\n",
      "        quoting support is disabled.\n",
      "\n",
      "        If two consecutive instances of `quotechar` are found within a quoted\n",
      "        field, the first is treated as an escape character. See examples.\n",
      "\n",
      "        .. versionadded:: 1.23.0\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Data read from the text file.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    load, fromstring, fromregex\n",
      "    genfromtxt : Load data with missing values handled as specified.\n",
      "    scipy.io.loadmat : reads MATLAB data files\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    This function aims to be a fast reader for simply formatted files.  The\n",
      "    `genfromtxt` function provides more sophisticated handling of, e.g.,\n",
      "    lines with missing values.\n",
      "\n",
      "    Each row in the input text file must have the same number of values to be\n",
      "    able to read all values. If all rows do not have same number of values, a\n",
      "    subset of up to n columns (where n is the least number of values present\n",
      "    in all rows) can be read by specifying the columns via `usecols`.\n",
      "\n",
      "    .. versionadded:: 1.10.0\n",
      "\n",
      "    The strings produced by the Python float.hex method can be used as\n",
      "    input for floats.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from io import StringIO   # StringIO behaves like a file object\n",
      "    >>> c = StringIO(\"0 1\\n2 3\")\n",
      "    >>> np.loadtxt(c)\n",
      "    array([[0., 1.],\n",
      "           [2., 3.]])\n",
      "\n",
      "    >>> d = StringIO(\"M 21 72\\nF 35 58\")\n",
      "    >>> np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),\n",
      "    ...                      'formats': ('S1', 'i4', 'f4')})\n",
      "    array([(b'M', 21, 72.), (b'F', 35, 58.)],\n",
      "          dtype=[('gender', 'S1'), ('age', '<i4'), ('weight', '<f4')])\n",
      "\n",
      "    >>> c = StringIO(\"1,0,2\\n3,0,4\")\n",
      "    >>> x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True)\n",
      "    >>> x\n",
      "    array([1., 3.])\n",
      "    >>> y\n",
      "    array([2., 4.])\n",
      "\n",
      "    The `converters` argument is used to specify functions to preprocess the\n",
      "    text prior to parsing. `converters` can be a dictionary that maps\n",
      "    preprocessing functions to each column:\n",
      "\n",
      "    >>> s = StringIO(\"1.618, 2.296\\n3.141, 4.669\\n\")\n",
      "    >>> conv = {\n",
      "    ...     0: lambda x: np.floor(float(x)),  # conversion fn for column 0\n",
      "    ...     1: lambda x: np.ceil(float(x)),  # conversion fn for column 1\n",
      "    ... }\n",
      "    >>> np.loadtxt(s, delimiter=\",\", converters=conv)\n",
      "    array([[1., 3.],\n",
      "           [3., 5.]])\n",
      "\n",
      "    `converters` can be a callable instead of a dictionary, in which case it\n",
      "    is applied to all columns:\n",
      "\n",
      "    >>> s = StringIO(\"0xDE 0xAD\\n0xC0 0xDE\")\n",
      "    >>> import functools\n",
      "    >>> conv = functools.partial(int, base=16)\n",
      "    >>> np.loadtxt(s, converters=conv)\n",
      "    array([[222., 173.],\n",
      "           [192., 222.]])\n",
      "\n",
      "    This example shows how `converters` can be used to convert a field\n",
      "    with a trailing minus sign into a negative number.\n",
      "\n",
      "    >>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n",
      "    >>> def conv(fld):\n",
      "    ...     return -float(fld[:-1]) if fld.endswith(b'-') else float(fld)\n",
      "    ...\n",
      "    >>> np.loadtxt(s, converters=conv)\n",
      "    array([[ 10.01, -31.25],\n",
      "           [ 19.22,  64.31],\n",
      "           [-17.57,  63.94]])\n",
      "\n",
      "    Using a callable as the converter can be particularly useful for handling\n",
      "    values with different formatting, e.g. floats with underscores:\n",
      "\n",
      "    >>> s = StringIO(\"1 2.7 100_000\")\n",
      "    >>> np.loadtxt(s, converters=float)\n",
      "    array([1.e+00, 2.7e+00, 1.e+05])\n",
      "\n",
      "    This idea can be extended to automatically handle values specified in\n",
      "    many different formats:\n",
      "\n",
      "    >>> def conv(val):\n",
      "    ...     try:\n",
      "    ...         return float(val)\n",
      "    ...     except ValueError:\n",
      "    ...         return float.fromhex(val)\n",
      "    >>> s = StringIO(\"1, 2.5, 3_000, 0b4, 0x1.4000000000000p+2\")\n",
      "    >>> np.loadtxt(s, delimiter=\",\", converters=conv, encoding=None)\n",
      "    array([1.0e+00, 2.5e+00, 3.0e+03, 1.8e+02, 5.0e+00])\n",
      "\n",
      "    Note that with the default ``encoding=\"bytes\"``, the inputs to the\n",
      "    converter function are latin-1 encoded byte strings. To deactivate the\n",
      "    implicit encoding prior to conversion, use ``encoding=None``\n",
      "\n",
      "    >>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n",
      "    >>> conv = lambda x: -float(x[:-1]) if x.endswith('-') else float(x)\n",
      "    >>> np.loadtxt(s, converters=conv, encoding=None)\n",
      "    array([[ 10.01, -31.25],\n",
      "           [ 19.22,  64.31],\n",
      "           [-17.57,  63.94]])\n",
      "\n",
      "    Support for quoted fields is enabled with the `quotechar` parameter.\n",
      "    Comment and delimiter characters are ignored when they appear within a\n",
      "    quoted item delineated by `quotechar`:\n",
      "\n",
      "    >>> s = StringIO('\"alpha, #42\", 10.0\\n\"beta, #64\", 2.0\\n')\n",
      "    >>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n",
      "    >>> np.loadtxt(s, dtype=dtype, delimiter=\",\", quotechar='\"')\n",
      "    array([('alpha, #42', 10.), ('beta, #64',  2.)],\n",
      "          dtype=[('label', '<U12'), ('value', '<f8')])\n",
      "\n",
      "    Two consecutive quote characters within a quoted field are treated as a\n",
      "    single escaped character:\n",
      "\n",
      "    >>> s = StringIO('\"Hello, my name is \"\"Monty\"\"!\"')\n",
      "    >>> np.loadtxt(s, dtype=\"U\", delimiter=\",\", quotechar='\"')\n",
      "    array('Hello, my name is \"Monty\"!', dtype='<U26')\n",
      "\n",
      "    Read subset of columns when all rows do not contain equal number of values:\n",
      "\n",
      "    >>> d = StringIO(\"1 2\\n2 4\\n3 9 12\\n4 16 20\")\n",
      "    >>> np.loadtxt(d, usecols=(0, 1))\n",
      "    array([[ 1.,  2.],\n",
      "           [ 2.,  4.],\n",
      "           [ 3.,  9.],\n",
      "           [ 4., 16.]])\n",
      "\n",
      "    \n",
      "code: genfromtxt\n",
      "@set_array_function_like_doc\n",
      "@set_module('numpy')\n",
      "def genfromtxt(fname, dtype=float, comments='#', delimiter=None,\n",
      "               skip_header=0, skip_footer=0, converters=None,\n",
      "               missing_values=None, filling_values=None, usecols=None,\n",
      "               names=None, excludelist=None,\n",
      "               deletechars=''.join(sorted(NameValidator.defaultdeletechars)),\n",
      "               replace_space='_', autostrip=False, case_sensitive=True,\n",
      "               defaultfmt=\"f%i\", unpack=None, usemask=False, loose=True,\n",
      "               invalid_raise=True, max_rows=None, encoding='bytes',\n",
      "               *, ndmin=0, like=None):\n",
      "    if like is not None:\n",
      "        return _genfromtxt_with_like(\n",
      "            fname, dtype=dtype, comments=comments, delimiter=delimiter,\n",
      "            skip_header=skip_header, skip_footer=skip_footer,\n",
      "            converters=converters, missing_values=missing_values,\n",
      "            filling_values=filling_values, usecols=usecols, names=names,\n",
      "            excludelist=excludelist, deletechars=deletechars,\n",
      "            replace_space=replace_space, autostrip=autostrip,\n",
      "            case_sensitive=case_sensitive, defaultfmt=defaultfmt,\n",
      "            unpack=unpack, usemask=usemask, loose=loose,\n",
      "            invalid_raise=invalid_raise, max_rows=max_rows, encoding=encoding,\n",
      "            ndmin=ndmin,\n",
      "            like=like\n",
      "        )\n",
      "    _ensure_ndmin_ndarray_check_param(ndmin)\n",
      "    if max_rows is not None:\n",
      "        if skip_footer:\n",
      "            raise ValueError(\n",
      "                    \"The keywords 'skip_footer' and 'max_rows' can not be \"\n",
      "                    \"specified at the same time.\")\n",
      "        if max_rows < 1:\n",
      "            raise ValueError(\"'max_rows' must be at least 1.\")\n",
      "    if usemask:\n",
      "        from numpy.ma import MaskedArray, make_mask_descr\n",
      " Initialize the filehandle, the LineSplitter and the NameValidator\n",
      "    if isinstance(fname, os_PathLike):\n",
      "        fname = os_fspath(fname)\n",
      "    if isinstance(fname, str):\n",
      "        fid = np.lib._datasource.open(fname, 'rt', encoding=encoding)\n",
      "        fid_ctx = contextlib.closing(fid)\n",
      "    else:\n",
      "        fid = fname\n",
      "        fid_ctx = contextlib.nullcontext(fid)\n",
      "    try:\n",
      "        fhd = iter(fid)\n",
      "    except TypeError as e:\n",
      "        raise TypeError(\n",
      "            \"fname must be a string, a filehandle, a sequence of strings,\\n\"\n",
      "            f\"or an iterator of strings. Got {type(fname)} instead.\"\n",
      "        ) from e\n",
      "    with fid_ctx:\n",
      "        split_line = LineSplitter(delimiter=delimiter, comments=comments,\n",
      "                                  autostrip=autostrip, encoding=encoding)\n",
      "        validate_names = NameValidator(excludelist=excludelist,\n",
      "                                       deletechars=deletechars,\n",
      "                                       case_sensitive=case_sensitive,\n",
      "                                       replace_space=replace_space)\n",
      " Keep on until we find the first valid values\n",
      "            first_values = None\n",
      "            while not first_values:\n",
      "                first_line = _decode_line(next(fhd), encoding)\n",
      "                if (names is True) and (comments is not None):\n",
      "                    if comments in first_line:\n",
      "                        first_line = (\n",
      "                            ''.join(first_line.split(comments)[1:]))\n",
      "                first_values = split_line(first_line)\n",
      "        except StopIteration:\n",
      " Should we take the first values as names ?\n",
      "        if names is True:\n",
      "            fval = first_values[0].strip()\n",
      "            if comments is not None:\n",
      "                if fval in comments:\n",
      "                    del first_values[0]\n",
      " Check the names and overwrite the dtype.names if needed\n",
      "        if names is True:\n",
      "            names = validate_names([str(_.strip()) for _ in first_values])\n",
      "            first_line = ''\n",
      "        elif _is_string_like(names):\n",
      "            names = validate_names([_.strip() for _ in names.split(',')])\n",
      "        elif names:\n",
      "            names = validate_names(names)\n",
      " Make sure the names is a list (for 2.5)\n",
      "        if names is not None:\n",
      "            names = list(names)\n",
      "        if usecols:\n",
      "            for (i, current) in enumerate(usecols):\n",
      " If the dtype is not None, make sure we update it\n",
      "            if (dtype is not None) and (len(dtype) > nbcols):\n",
      "                descr = dtype.descr\n",
      "                dtype = np.dtype([descr[_] for _ in usecols])\n",
      "                names = list(dtype.names)\n",
      " Process the missing values ...............................\n",
      " Define the list of missing_values (one column: one list)\n",
      "        missing_values = [list(['']) for _ in range(nbcols)]\n",
      " Loop on the items\n",
      "            for (key, val) in user_missing_values.items():\n",
      " Transform it into an integer\n",
      "                        key = names.index(key)\n",
      "                    except ValueError:\n",
      " Redefine the key as needed if it's a column number\n",
      "                if usecols:\n",
      "                    try:\n",
      "                        key = usecols.index(key)\n",
      "                    except ValueError:\n",
      "                        pass\n",
      " Add the value(s) to the current list of missing\n",
      "                if key is None:\n",
      " We have a sequence : each item matches a column\n",
      "        elif isinstance(user_missing_values, (list, tuple)):\n",
      "            for (value, entry) in zip(user_missing_values, missing_values):\n",
      "                value = str(value)\n",
      "                if value not in entry:\n",
      "                    entry.append(value)\n",
      " We have something else: apply it to all entries\n",
      "        else:\n",
      "            for entry in missing_values:\n",
      "                entry.extend([str(user_missing_values)])\n",
      " Rename the input for convenience\n",
      "        user_filling_values = filling_values\n",
      "        if user_filling_values is None:\n",
      "            user_filling_values = []\n",
      " We have a dictionary : update each entry individually\n",
      "        if isinstance(user_filling_values, dict):\n",
      "            for (key, val) in user_filling_values.items():\n",
      "                if _is_string_like(key):\n",
      "                    try:\n",
      " We couldn't find it: the name must have been dropped,\n",
      "                        continue\n",
      " Add the value to the list\n",
      "                filling_values[key] = val\n",
      " We have something else : use it for all entries\n",
      "        else:\n",
      "            filling_values = [user_filling_values] * nbcols\n",
      " Note: we can't use a [...]*nbcols, as we would have 3 times the same\n",
      " Initialize the converters\n",
      "            if len(dtype_flat) > 1:\n",
      " Set to a default converter (but w/ different missing values)\n",
      "                zipit = zip(missing_values, filling_values)\n",
      "                converters = [StringConverter(dtype, locked=True,\n",
      "                                              missing_values=miss, default=fill)\n",
      "                              for (miss, fill) in zipit]\n",
      " If the converter is specified by column names, use the index instead\n",
      "            if _is_string_like(j):\n",
      "                try:\n",
      "                    j = names.index(j)\n",
      "                    i = j\n",
      "                except ValueError:\n",
      "                    continue\n",
      "            elif usecols:\n",
      "                try:\n",
      "                    i = usecols.index(j)\n",
      "                except ValueError:\n",
      " Find the value to test - first_line is not filtered by usecols:\n",
      "            if len(first_line):\n",
      "                testing_value = first_values[j]\n",
      "            else:\n",
      "                testing_value = None\n",
      "            if conv is bytes:\n",
      "                user_conv = asbytes\n",
      "            elif byte_converters:\n",
      " so encode the string again before passing to the user converter\n",
      "                def tobytes_first(x, conv):\n",
      "                    if type(x) is bytes:\n",
      "                        return conv(x)\n",
      "                    return conv(x.encode(\"latin1\"))\n",
      "                user_conv = functools.partial(tobytes_first, conv=conv)\n",
      "            else:\n",
      "                user_conv = conv\n",
      "            converters[i].update(user_conv, locked=True,\n",
      "                                 testing_value=testing_value,\n",
      "                                 default=filling_values[i],\n",
      "                                 missing_values=missing_values[i],)\n",
      "            uc_update.append((i, user_conv))\n",
      " Fixme: possible error as following variable never used.\n",
      " Initialize the output lists ...\n",
      " ... masks\n",
      "        if usemask:\n",
      "            masks = []\n",
      "            append_to_masks = masks.append\n",
      " Parse each line\n",
      "        for (i, line) in enumerate(itertools.chain([first_line, ], fhd)):\n",
      "            values = split_line(line)\n",
      "            nbvalues = len(values)\n",
      " Select only the columns we need\n",
      "                try:\n",
      "                    values = [values[_] for _ in usecols]\n",
      "                except IndexError:\n",
      "                    append_to_invalid((i + skip_header + 1, nbvalues))\n",
      "                    continue\n",
      "            elif nbvalues != nbcols:\n",
      "                append_to_invalid((i + skip_header + 1, nbvalues))\n",
      "                continue\n",
      " Upgrade the converters (if needed)\n",
      "    if dtype is None:\n",
      "        for (i, converter) in enumerate(converters):\n",
      "            current_column = [itemgetter(i)(_m) for _m in rows]\n",
      "            try:\n",
      "                converter.iterupgrade(current_column)\n",
      "            except ConverterLockError:\n",
      "                errmsg = \"Converter #%i is locked and cannot be upgraded: \" % i\n",
      "                current_column = map(itemgetter(i), rows)\n",
      "                for (j, value) in enumerate(current_column):\n",
      "                    try:\n",
      "                        converter.upgrade(value)\n",
      "                    except (ConverterError, ValueError):\n",
      "                        errmsg += \"(occurred line #%i for value '%s')\"\n",
      "                        errmsg %= (j + 1 + skip_header, value)\n",
      "                        raise ConverterError(errmsg)\n",
      " Construct the error message\n",
      "        template = \"    Line #%%i (got %%i columns instead of %i)\" % nbcols\n",
      "        if skip_footer > 0:\n",
      "            nbinvalid_skipped = len([_ for _ in invalid\n",
      "                                     if _[0] > nbrows + skip_header])\n",
      "            invalid = invalid[:nbinvalid - nbinvalid_skipped]\n",
      "            skip_footer -= nbinvalid_skipped\n",
      "            nbrows -= skip_footer\n",
      "                      for (i, nb) in invalid if i < nbrows]\n",
      " Raise an exception ?\n",
      "            if invalid_raise:\n",
      "                raise ValueError(errmsg)\n",
      " Strip the last skip_footer data\n",
      "    if skip_footer > 0:\n",
      "        rows = rows[:-skip_footer]\n",
      "        if usemask:\n",
      "            masks = masks[:-skip_footer]\n",
      " We want to modify the list in place to avoid creating a new one...\n",
      "    if loose:\n",
      "        rows = list(\n",
      "            zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n",
      "                  for (i, conv) in enumerate(converters)]))\n",
      "    else:\n",
      "        rows = list(\n",
      "            zip(*[[conv._strict_call(_r) for _r in map(itemgetter(i), rows)]\n",
      "                  for (i, conv) in enumerate(converters)]))\n",
      " Get the dtypes from the types of the converters\n",
      "        column_types = [conv.type for conv in converters]\n",
      " convert strings back to bytes for backward compatibility\n",
      "            warnings.warn(\n",
      "                \"Reading unicode strings without specifying the encoding \"\n",
      "                \"argument is deprecated. Set the encoding, use None for the \"\n",
      "                \"system default.\",\n",
      "                np.VisibleDeprecationWarning, stacklevel=2)\n",
      "            def encode_unicode_cols(row_tup):\n",
      "                row = list(row_tup)\n",
      "                for i in strcolidx:\n",
      "                    row[i] = row[i].encode('latin1')\n",
      "                return tuple(row)\n",
      "            try:\n",
      "                data = [encode_unicode_cols(r) for r in data]\n",
      "            except UnicodeEncodeError:\n",
      "                pass\n",
      "            else:\n",
      "                for i in strcolidx:\n",
      "                    column_types[i] = np.bytes_\n",
      " If the dtype is uniform (before sizing strings)\n",
      "            base = {\n",
      "                c_type\n",
      "                for c, c_type in zip(converters, column_types)\n",
      "                if c._checked}\n",
      "            if len(base) == 1:\n",
      "                uniform_type, = base\n",
      "                (ddtype, mdtype) = (uniform_type, bool)\n",
      "            else:\n",
      "                ddtype = [(defaultfmt % i, dt)\n",
      "                          for (i, dt) in enumerate(sized_column_types)]\n",
      "                if usemask:\n",
      "                    mdtype = [(defaultfmt % i, bool)\n",
      "                              for (i, dt) in enumerate(sized_column_types)]\n",
      "        else:\n",
      "            ddtype = list(zip(names, sized_column_types))\n",
      "            mdtype = list(zip(names, [bool] * len(sized_column_types)))\n",
      "        output = np.array(data, dtype=ddtype)\n",
      "        if usemask:\n",
      "            outputmask = np.array(masks, dtype=mdtype)\n",
      "    else:\n",
      " Case 1. We have a structured type\n",
      "        if len(dtype_flat) > 1:\n",
      " First, create the array using a flattened dtype:\n",
      " Then, view the array using the specified dtype.\n",
      "            if 'O' in (_.char for _ in dtype_flat):\n",
      "                if has_nested_fields(dtype):\n",
      "                    raise NotImplementedError(\n",
      "                        \"Nested fields involving objects are not supported...\")\n",
      "                else:\n",
      "                    output = np.array(data, dtype=dtype)\n",
      "            else:\n",
      "                rows = np.array(data, dtype=[('', _) for _ in dtype_flat])\n",
      "                output = rows.view(dtype)\n",
      " Construct the new dtype\n",
      "                mdtype = make_mask_descr(dtype)\n",
      "                outputmask = rowmasks.view(mdtype)\n",
      "2. We have a basic dtype\n",
      "        else:\n",
      " Keep the dtype of the current converter\n",
      "                    if i in user_converters:\n",
      "                        ishomogeneous &= (ttype == dtype.type)\n",
      "                        if np.issubdtype(ttype, np.character):\n",
      "                            ttype = (ttype, max(len(row[i]) for row in data))\n",
      "                        descr.append(('', ttype))\n",
      "                    else:\n",
      "                        descr.append(('', dtype))\n",
      " We have more than one field\n",
      "                    if len(descr) > 1:\n",
      "                        dtype = np.dtype(descr)\n",
      "            output = np.array(data, dtype)\n",
      "            if usemask:\n",
      "                if dtype.names is not None:\n",
      "                    mdtype = [(_, bool) for _ in dtype.names]\n",
      "                else:\n",
      "                    mdtype = bool\n",
      "                outputmask = np.array(masks, dtype=mdtype)\n",
      " Construct the final array\n",
      "    if usemask:\n",
      "        output = output.view(MaskedArray)\n",
      "        output._mask = outputmask\n",
      "    output = _ensure_ndmin_ndarray(output, ndmin=ndmin)\n",
      "    if unpack:\n",
      "        if names is None:\n",
      "            return output.T\n",
      "        elif len(names) == 1:\n",
      " For structured arrays with multiple fields,\n",
      "            # return an array for each field.\n",
      "            return [output[field] for field in names]\n",
      "    return output\n",
      "docstring: genfromtxt\n",
      "\n",
      "    Load data from a text file, with missing values handled as specified.\n",
      "\n",
      "    Each line past the first `skip_header` lines is split at the `delimiter`\n",
      "    character, and characters following the `comments` character are discarded.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : file, str, pathlib.Path, list of str, generator\n",
      "        File, filename, list, or generator to read.  If the filename\n",
      "        extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\n",
      "        that generators must return bytes or strings. The strings\n",
      "        in a list or produced by a generator are treated as lines.\n",
      "    dtype : dtype, optional\n",
      "        Data type of the resulting array.\n",
      "        If None, the dtypes will be determined by the contents of each\n",
      "        column, individually.\n",
      "    comments : str, optional\n",
      "        The character used to indicate the start of a comment.\n",
      "        All the characters occurring on a line after a comment are discarded.\n",
      "    delimiter : str, int, or sequence, optional\n",
      "        The string used to separate values.  By default, any consecutive\n",
      "        whitespaces act as delimiter.  An integer or sequence of integers\n",
      "        can also be provided as width(s) of each field.\n",
      "    skiprows : int, optional\n",
      "        `skiprows` was removed in numpy 1.10. Please use `skip_header` instead.\n",
      "    skip_header : int, optional\n",
      "        The number of lines to skip at the beginning of the file.\n",
      "    skip_footer : int, optional\n",
      "        The number of lines to skip at the end of the file.\n",
      "    converters : variable, optional\n",
      "        The set of functions that convert the data of a column to a value.\n",
      "        The converters can also be used to provide a default value\n",
      "        for missing data: ``converters = {3: lambda s: float(s or 0)}``.\n",
      "    missing : variable, optional\n",
      "        `missing` was removed in numpy 1.10. Please use `missing_values`\n",
      "        instead.\n",
      "    missing_values : variable, optional\n",
      "        The set of strings corresponding to missing data.\n",
      "    filling_values : variable, optional\n",
      "        The set of values to be used as default when the data are missing.\n",
      "    usecols : sequence, optional\n",
      "        Which columns to read, with 0 being the first.  For example,\n",
      "        ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns.\n",
      "    names : {None, True, str, sequence}, optional\n",
      "        If `names` is True, the field names are read from the first line after\n",
      "        the first `skip_header` lines. This line can optionally be preceded\n",
      "        by a comment delimiter. If `names` is a sequence or a single-string of\n",
      "        comma-separated names, the names will be used to define the field names\n",
      "        in a structured dtype. If `names` is None, the names of the dtype\n",
      "        fields will be used, if any.\n",
      "    excludelist : sequence, optional\n",
      "        A list of names to exclude. This list is appended to the default list\n",
      "        ['return','file','print']. Excluded names are appended with an\n",
      "        underscore: for example, `file` would become `file_`.\n",
      "    deletechars : str, optional\n",
      "        A string combining invalid characters that must be deleted from the\n",
      "        names.\n",
      "    defaultfmt : str, optional\n",
      "        A format used to define default field names, such as \"f%i\" or \"f_%02i\".\n",
      "    autostrip : bool, optional\n",
      "        Whether to automatically strip white spaces from the variables.\n",
      "    replace_space : char, optional\n",
      "        Character(s) used in replacement of white spaces in the variable\n",
      "        names. By default, use a '_'.\n",
      "    case_sensitive : {True, False, 'upper', 'lower'}, optional\n",
      "        If True, field names are case sensitive.\n",
      "        If False or 'upper', field names are converted to upper case.\n",
      "        If 'lower', field names are converted to lower case.\n",
      "    unpack : bool, optional\n",
      "        If True, the returned array is transposed, so that arguments may be\n",
      "        unpacked using ``x, y, z = genfromtxt(...)``.  When used with a\n",
      "        structured data-type, arrays are returned for each field.\n",
      "        Default is False.\n",
      "    usemask : bool, optional\n",
      "        If True, return a masked array.\n",
      "        If False, return a regular array.\n",
      "    loose : bool, optional\n",
      "        If True, do not raise errors for invalid values.\n",
      "    invalid_raise : bool, optional\n",
      "        If True, an exception is raised if an inconsistency is detected in the\n",
      "        number of columns.\n",
      "        If False, a warning is emitted and the offending lines are skipped.\n",
      "    max_rows : int,  optional\n",
      "        The maximum number of rows to read. Must not be used with skip_footer\n",
      "        at the same time.  If given, the value must be at least 1. Default is\n",
      "        to read the entire file.\n",
      "\n",
      "        .. versionadded:: 1.10.0\n",
      "    encoding : str, optional\n",
      "        Encoding used to decode the inputfile. Does not apply when `fname` is\n",
      "        a file object.  The special value 'bytes' enables backward compatibility\n",
      "        workarounds that ensure that you receive byte arrays when possible\n",
      "        and passes latin1 encoded strings to converters. Override this value to\n",
      "        receive unicode arrays and pass strings as input to converters.  If set\n",
      "        to None the system default is used. The default value is 'bytes'.\n",
      "\n",
      "        .. versionadded:: 1.14.0\n",
      "    ndmin : int, optional\n",
      "        Same parameter as `loadtxt`\n",
      "\n",
      "        .. versionadded:: 1.23.0\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Data read from the text file. If `usemask` is True, this is a\n",
      "        masked array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.loadtxt : equivalent function when no data is missing.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    * When spaces are used as delimiters, or when no delimiter has been given\n",
      "      as input, there should not be any missing data between two fields.\n",
      "    * When the variables are named (either by a flexible dtype or with `names`),\n",
      "      there must not be any header in the file (else a ValueError\n",
      "      exception is raised).\n",
      "    * Individual values are not stripped of spaces by default.\n",
      "      When using a custom converter, make sure the function does remove spaces.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] NumPy User Guide, section `I/O with NumPy\n",
      "           <https://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html>`_.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from io import StringIO\n",
      "    >>> import numpy as np\n",
      "\n",
      "    Comma delimited file with mixed dtype\n",
      "\n",
      "    >>> s = StringIO(u\"1,1.3,abcde\")\n",
      "    >>> data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'),\n",
      "    ... ('mystring','S5')], delimiter=\",\")\n",
      "    >>> data\n",
      "    array((1, 1.3, b'abcde'),\n",
      "          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\n",
      "\n",
      "    Using dtype = None\n",
      "\n",
      "    >>> _ = s.seek(0) # needed for StringIO example only\n",
      "    >>> data = np.genfromtxt(s, dtype=None,\n",
      "    ... names = ['myint','myfloat','mystring'], delimiter=\",\")\n",
      "    >>> data\n",
      "    array((1, 1.3, b'abcde'),\n",
      "          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\n",
      "\n",
      "    Specifying dtype and names\n",
      "\n",
      "    >>> _ = s.seek(0)\n",
      "    >>> data = np.genfromtxt(s, dtype=\"i8,f8,S5\",\n",
      "    ... names=['myint','myfloat','mystring'], delimiter=\",\")\n",
      "    >>> data\n",
      "    array((1, 1.3, b'abcde'),\n",
      "          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\n",
      "\n",
      "    An example with fixed-width columns\n",
      "\n",
      "    >>> s = StringIO(u\"11.3abcde\")\n",
      "    >>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'],\n",
      "    ...     delimiter=[1,3,5])\n",
      "    >>> data\n",
      "    array((1, 1.3, b'abcde'),\n",
      "          dtype=[('intvar', '<i8'), ('fltvar', '<f8'), ('strvar', 'S5')])\n",
      "\n",
      "    An example to show comments\n",
      "\n",
      "    >>> f = StringIO('''\n",
      "    ... text,# of chars\n",
      "    ... hello world,11\n",
      "    ... numpy,5''')\n",
      "    >>> np.genfromtxt(f, dtype='S12,S12', delimiter=',')\n",
      "    array([(b'text', b''), (b'hello world', b'11'), (b'numpy', b'5')],\n",
      "      dtype=[('f0', 'S12'), ('f1', 'S12')])\n",
      "\n",
      "    \n",
      "code: recfromtxt\n",
      "def recfromtxt(fname, **kwargs):\n",
      "    kwargs.setdefault(\"dtype\", None)\n",
      "    usemask = kwargs.get('usemask', False)\n",
      "    output = genfromtxt(fname, **kwargs)\n",
      "    if usemask:\n",
      "        from numpy.ma.mrecords import MaskedRecords\n",
      "        output = output.view(MaskedRecords)\n",
      "    else:\n",
      "        output = output.view(np.recarray)\n",
      "    return output\n",
      "docstring: recfromtxt\n",
      "\n",
      "    Load ASCII data from a file and return it in a record array.\n",
      "\n",
      "    If ``usemask=False`` a standard `recarray` is returned,\n",
      "    if ``usemask=True`` a MaskedRecords array is returned.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    fname, kwargs : For a description of input parameters, see `genfromtxt`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.genfromtxt : generic function\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    By default, `dtype` is None, which means that the data-type of the output\n",
      "    array will be determined from the data.\n",
      "\n",
      "    \n",
      "code: recfromcsv\n",
      "def recfromcsv(fname, **kwargs):\n",
      "    # Set default kwargs for genfromtxt as relevant to csv import.\n",
      "    kwargs.setdefault(\"case_sensitive\", \"lower\")\n",
      "    kwargs.setdefault(\"names\", True)\n",
      "    kwargs.setdefault(\"delimiter\", \",\")\n",
      "    kwargs.setdefault(\"dtype\", None)\n",
      "    output = genfromtxt(fname, **kwargs)\n",
      "    usemask = kwargs.get(\"usemask\", False)\n",
      "    if usemask:\n",
      "        from numpy.ma.mrecords import MaskedRecords\n",
      "        output = output.view(MaskedRecords)\n",
      "    else:\n",
      "        output = output.view(np.recarray)\n",
      "    return output\n",
      "docstring: recfromcsv\n",
      "\n",
      "    Load ASCII data stored in a comma-separated file.\n",
      "\n",
      "    The returned array is a record array (if ``usemask=False``, see\n",
      "    `recarray`) or a masked record array (if ``usemask=True``,\n",
      "    see `ma.mrecords.MaskedRecords`).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    fname, kwargs : For a description of input parameters, see `genfromtxt`.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.genfromtxt : generic function to load ASCII data.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    By default, `dtype` is None, which means that the data-type of the output\n",
      "    array will be determined from the data.\n",
      "\n",
      "    \n",
      "code: load\n",
      "@set_module('numpy')\n",
      "def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,\n",
      "         encoding='ASCII', *, max_header_size=format._MAX_HEADER_SIZE):\n",
      "    if encoding not in ('ASCII', 'latin1', 'bytes'):\n",
      " the serialized binary data of NumPy arrays is loaded\n",
      " NumPy. The unpickling code in numpy.core.multiarray is\n",
      " should be is in 'latin1'. 'bytes' is also safe, as is 'ASCII'.\n",
      " Other encoding values can corrupt binary data, and we\n",
      " argument is not exposed, as values other than 'strict'\n",
      " Code to distinguish from NumPy binary files and pickles.\n",
      "        _ZIP_PREFIX = b'PK\\x03\\x04'\n",
      "        _ZIP_SUFFIX = b'PK\\x05\\x06' # empty zip files start with this\n",
      "        N = len(format.MAGIC_PREFIX)\n",
      "        magic = fid.read(N)\n",
      " to seek past the beginning of the file\n",
      "        fid.seek(-min(N, len(magic)), 1)  # back-up\n",
      "        if magic.startswith(_ZIP_PREFIX) or magic.startswith(_ZIP_SUFFIX):\n",
      " Potentially transfer file ownership to NpzFile\n",
      "            stack.pop_all()\n",
      "            ret = NpzFile(fid, own_fid=own_fid, allow_pickle=allow_pickle,\n",
      "                          pickle_kwargs=pickle_kwargs,\n",
      "                          max_header_size=max_header_size)\n",
      "            return ret\n",
      "        elif magic == format.MAGIC_PREFIX:\n",
      " Try a pickle\n",
      "            if not allow_pickle:\n",
      "                raise ValueError(\"Cannot load file containing pickled data \"\n",
      "                                 \"when allow_pickle=False\")\n",
      "            try:\n",
      "                return pickle.load(fid, **pickle_kwargs)\n",
      "            except Exception as e:\n",
      "                raise pickle.UnpicklingError(\n",
      "                    f\"Failed to interpret file {file!r} as a pickle\") from e\n",
      "docstring: load\n",
      "\n",
      "    Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n",
      "\n",
      "    .. warning:: Loading files that contain object arrays uses the ``pickle``\n",
      "                 module, which is not secure against erroneous or maliciously\n",
      "                 constructed data. Consider passing ``allow_pickle=False`` to\n",
      "                 load data that is known not to contain object arrays for the\n",
      "                 safer handling of untrusted sources.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    file : file-like object, string, or pathlib.Path\n",
      "        The file to read. File-like objects must support the\n",
      "        ``seek()`` and ``read()`` methods and must always\n",
      "        be opened in binary mode.  Pickled files require that the\n",
      "        file-like object support the ``readline()`` method as well.\n",
      "    mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n",
      "        If not None, then memory-map the file, using the given mode (see\n",
      "        `numpy.memmap` for a detailed description of the modes).  A\n",
      "        memory-mapped array is kept on disk. However, it can be accessed\n",
      "        and sliced like any ndarray.  Memory mapping is especially useful\n",
      "        for accessing small fragments of large files without reading the\n",
      "        entire file into memory.\n",
      "    allow_pickle : bool, optional\n",
      "        Allow loading pickled object arrays stored in npy files. Reasons for\n",
      "        disallowing pickles include security, as loading pickled data can\n",
      "        execute arbitrary code. If pickles are disallowed, loading object\n",
      "        arrays will fail. Default: False\n",
      "\n",
      "        .. versionchanged:: 1.16.3\n",
      "            Made default False in response to CVE-2019-6446.\n",
      "\n",
      "    fix_imports : bool, optional\n",
      "        Only useful when loading Python 2 generated pickled files on Python 3,\n",
      "        which includes npy/npz files containing object arrays. If `fix_imports`\n",
      "        is True, pickle will try to map the old Python 2 names to the new names\n",
      "        used in Python 3.\n",
      "    encoding : str, optional\n",
      "        What encoding to use when reading Python 2 strings. Only useful when\n",
      "        loading Python 2 generated pickled files in Python 3, which includes\n",
      "        npy/npz files containing object arrays. Values other than 'latin1',\n",
      "        'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n",
      "        data. Default: 'ASCII'\n",
      "    max_header_size : int, optional\n",
      "        Maximum allowed size of the header.  Large headers may not be safe\n",
      "        to load securely and thus require explicitly passing a larger value.\n",
      "        See :py:meth:`ast.literal_eval()` for details.\n",
      "        This option is ignored when `allow_pickle` is passed.  In that case\n",
      "        the file is by definition trusted and the limit is unnecessary.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    result : array, tuple, dict, etc.\n",
      "        Data stored in the file. For ``.npz`` files, the returned instance\n",
      "        of NpzFile class must be closed to avoid leaking file descriptors.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    OSError\n",
      "        If the input file does not exist or cannot be read.\n",
      "    UnpicklingError\n",
      "        If ``allow_pickle=True``, but the file cannot be loaded as a pickle.\n",
      "    ValueError\n",
      "        The file contains an object array, but ``allow_pickle=False`` given.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    save, savez, savez_compressed, loadtxt\n",
      "    memmap : Create a memory-map to an array stored in a file on disk.\n",
      "    lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    - If the file contains pickle data, then whatever object is stored\n",
      "      in the pickle is returned.\n",
      "    - If the file is a ``.npy`` file, then a single array is returned.\n",
      "    - If the file is a ``.npz`` file, then a dictionary-like object is\n",
      "      returned, containing ``{filename: array}`` key-value pairs, one for\n",
      "      each file in the archive.\n",
      "    - If the file is a ``.npz`` file, the returned value supports the\n",
      "      context manager protocol in a similar fashion to the open function::\n",
      "\n",
      "        with load('foo.npz') as data:\n",
      "            a = data['a']\n",
      "\n",
      "      The underlying file descriptor is closed when exiting the 'with'\n",
      "      block.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    Store data to disk, and load it again:\n",
      "\n",
      "    >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n",
      "    >>> np.load('/tmp/123.npy')\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "\n",
      "    Store compressed data to disk, and load it again:\n",
      "\n",
      "    >>> a=np.array([[1, 2, 3], [4, 5, 6]])\n",
      "    >>> b=np.array([1, 2])\n",
      "    >>> np.savez('/tmp/123.npz', a=a, b=b)\n",
      "    >>> data = np.load('/tmp/123.npz')\n",
      "    >>> data['a']\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "    >>> data['b']\n",
      "    array([1, 2])\n",
      "    >>> data.close()\n",
      "\n",
      "    Mem-map the stored array, and then access the second row\n",
      "    directly from disk:\n",
      "\n",
      "    >>> X = np.load('/tmp/123.npy', mmap_mode='r')\n",
      "    >>> X[1, :]\n",
      "    memmap([4, 5, 6])\n",
      "\n",
      "    \n",
      "code: save\n",
      "@array_function_dispatch(_save_dispatcher)\n",
      "def save(file, arr, allow_pickle=True, fix_imports=True):\n",
      "    if hasattr(file, 'write'):\n",
      "        file_ctx = contextlib.nullcontext(file)\n",
      "    else:\n",
      "        file = os_fspath(file)\n",
      "        if not file.endswith('.npy'):\n",
      "            file = file + '.npy'\n",
      "        file_ctx = open(file, \"wb\")\n",
      "    with file_ctx as fid:\n",
      "        arr = np.asanyarray(arr)\n",
      "        format.write_array(fid, arr, allow_pickle=allow_pickle,\n",
      "                           pickle_kwargs=dict(fix_imports=fix_imports))\n",
      "docstring: save\n",
      "\n",
      "    Save an array to a binary file in NumPy ``.npy`` format.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    file : file, str, or pathlib.Path\n",
      "        File or filename to which the data is saved.  If file is a file-object,\n",
      "        then the filename is unchanged.  If file is a string or Path, a ``.npy``\n",
      "        extension will be appended to the filename if it does not already\n",
      "        have one.\n",
      "    arr : array_like\n",
      "        Array data to be saved.\n",
      "    allow_pickle : bool, optional\n",
      "        Allow saving object arrays using Python pickles. Reasons for disallowing\n",
      "        pickles include security (loading pickled data can execute arbitrary\n",
      "        code) and portability (pickled objects may not be loadable on different\n",
      "        Python installations, for example if the stored objects require libraries\n",
      "        that are not available, and not all pickled data is compatible between\n",
      "        Python 2 and Python 3).\n",
      "        Default: True\n",
      "    fix_imports : bool, optional\n",
      "        Only useful in forcing objects in object arrays on Python 3 to be\n",
      "        pickled in a Python 2 compatible way. If `fix_imports` is True, pickle\n",
      "        will try to map the new Python 3 names to the old module names used in\n",
      "        Python 2, so that the pickle data stream is readable with Python 2.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    savez : Save several arrays into a ``.npz`` archive\n",
      "    savetxt, load\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    For a description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.\n",
      "\n",
      "    Any data saved to the file is appended to the end of the file.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from tempfile import TemporaryFile\n",
      "    >>> outfile = TemporaryFile()\n",
      "\n",
      "    >>> x = np.arange(10)\n",
      "    >>> np.save(outfile, x)\n",
      "\n",
      "    >>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file\n",
      "    >>> np.load(outfile)\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "\n",
      "    >>> with open('test.npy', 'wb') as f:\n",
      "    ...     np.save(f, np.array([1, 2]))\n",
      "    ...     np.save(f, np.array([1, 3]))\n",
      "    >>> with open('test.npy', 'rb') as f:\n",
      "    ...     a = np.load(f)\n",
      "    ...     b = np.load(f)\n",
      "    >>> print(a, b)\n",
      "    # [1 2] [1 3]\n",
      "    \n",
      "code: savez\n",
      "@array_function_dispatch(_savez_dispatcher)\n",
      "def savez(file, *args, **kwds):\n",
      "    _savez(file, args, kwds, False)\n",
      "docstring: savez\n",
      "Save several arrays into a single file in uncompressed ``.npz`` format.\n",
      "\n",
      "    Provide arrays as keyword arguments to store them under the\n",
      "    corresponding name in the output file: ``savez(fn, x=x, y=y)``.\n",
      "\n",
      "    If arrays are specified as positional arguments, i.e., ``savez(fn,\n",
      "    x, y)``, their names will be `arr_0`, `arr_1`, etc.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    file : str or file\n",
      "        Either the filename (string) or an open file (file-like object)\n",
      "        where the data will be saved. If file is a string or a Path, the\n",
      "        ``.npz`` extension will be appended to the filename if it is not\n",
      "        already there.\n",
      "    args : Arguments, optional\n",
      "        Arrays to save to the file. Please use keyword arguments (see\n",
      "        `kwds` below) to assign names to arrays.  Arrays specified as\n",
      "        args will be named \"arr_0\", \"arr_1\", and so on.\n",
      "    kwds : Keyword arguments, optional\n",
      "        Arrays to save to the file. Each array will be saved to the\n",
      "        output file with its corresponding keyword name.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    None\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    save : Save a single array to a binary file in NumPy format.\n",
      "    savetxt : Save an array to a file as plain text.\n",
      "    savez_compressed : Save several arrays into a compressed ``.npz`` archive\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The ``.npz`` file format is a zipped archive of files named after the\n",
      "    variables they contain.  The archive is not compressed and each file\n",
      "    in the archive contains one variable in ``.npy`` format. For a\n",
      "    description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.\n",
      "\n",
      "    When opening the saved ``.npz`` file with `load` a `NpzFile` object is\n",
      "    returned. This is a dictionary-like object which can be queried for\n",
      "    its list of arrays (with the ``.files`` attribute), and for the arrays\n",
      "    themselves.\n",
      "\n",
      "    Keys passed in `kwds` are used as filenames inside the ZIP archive.\n",
      "    Therefore, keys should be valid filenames; e.g., avoid keys that begin with\n",
      "    ``/`` or contain ``.``.\n",
      "\n",
      "    When naming variables with keyword arguments, it is not possible to name a\n",
      "    variable ``file``, as this would cause the ``file`` argument to be defined\n",
      "    twice in the call to ``savez``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from tempfile import TemporaryFile\n",
      "    >>> outfile = TemporaryFile()\n",
      "    >>> x = np.arange(10)\n",
      "    >>> y = np.sin(x)\n",
      "\n",
      "    Using `savez` with \\*args, the arrays are saved with default names.\n",
      "\n",
      "    >>> np.savez(outfile, x, y)\n",
      "    >>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file\n",
      "    >>> npzfile = np.load(outfile)\n",
      "    >>> npzfile.files\n",
      "    ['arr_0', 'arr_1']\n",
      "    >>> npzfile['arr_0']\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "    Using `savez` with \\**kwds, the arrays are saved with the keyword names.\n",
      "\n",
      "    >>> outfile = TemporaryFile()\n",
      "    >>> np.savez(outfile, x=x, y=y)\n",
      "    >>> _ = outfile.seek(0)\n",
      "    >>> npzfile = np.load(outfile)\n",
      "    >>> sorted(npzfile.files)\n",
      "    ['x', 'y']\n",
      "    >>> npzfile['x']\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "    \n",
      "code: savez_compressed\n",
      "@array_function_dispatch(_savez_compressed_dispatcher)\n",
      "def savez_compressed(file, *args, **kwds):\n",
      "    _savez(file, args, kwds, True)\n",
      "docstring: savez_compressed\n",
      "\n",
      "    Save several arrays into a single file in compressed ``.npz`` format.\n",
      "\n",
      "    Provide arrays as keyword arguments to store them under the\n",
      "    corresponding name in the output file: ``savez(fn, x=x, y=y)``.\n",
      "\n",
      "    If arrays are specified as positional arguments, i.e., ``savez(fn,\n",
      "    x, y)``, their names will be `arr_0`, `arr_1`, etc.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    file : str or file\n",
      "        Either the filename (string) or an open file (file-like object)\n",
      "        where the data will be saved. If file is a string or a Path, the\n",
      "        ``.npz`` extension will be appended to the filename if it is not\n",
      "        already there.\n",
      "    args : Arguments, optional\n",
      "        Arrays to save to the file. Please use keyword arguments (see\n",
      "        `kwds` below) to assign names to arrays.  Arrays specified as\n",
      "        args will be named \"arr_0\", \"arr_1\", and so on.\n",
      "    kwds : Keyword arguments, optional\n",
      "        Arrays to save to the file. Each array will be saved to the\n",
      "        output file with its corresponding keyword name.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    None\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.save : Save a single array to a binary file in NumPy format.\n",
      "    numpy.savetxt : Save an array to a file as plain text.\n",
      "    numpy.savez : Save several arrays into an uncompressed ``.npz`` file format\n",
      "    numpy.load : Load the files created by savez_compressed.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The ``.npz`` file format is a zipped archive of files named after the\n",
      "    variables they contain.  The archive is compressed with\n",
      "    ``zipfile.ZIP_DEFLATED`` and each file in the archive contains one variable\n",
      "    in ``.npy`` format. For a description of the ``.npy`` format, see\n",
      "    :py:mod:`numpy.lib.format`.\n",
      "\n",
      "\n",
      "    When opening the saved ``.npz`` file with `load` a `NpzFile` object is\n",
      "    returned. This is a dictionary-like object which can be queried for\n",
      "    its list of arrays (with the ``.files`` attribute), and for the arrays\n",
      "    themselves.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> test_array = np.random.rand(3, 2)\n",
      "    >>> test_vector = np.random.rand(4)\n",
      "    >>> np.savez_compressed('/tmp/123', a=test_array, b=test_vector)\n",
      "    >>> loaded = np.load('/tmp/123.npz')\n",
      "    >>> print(np.array_equal(test_array, loaded['a']))\n",
      "    True\n",
      "    >>> print(np.array_equal(test_vector, loaded['b']))\n",
      "    True\n",
      "\n",
      "    \n",
      "code: packbits\n",
      "\n",
      "docstring: packbits\n",
      "\n",
      "    packbits(a, /, axis=None, bitorder='big')\n",
      "\n",
      "    Packs the elements of a binary-valued array into bits in a uint8 array.\n",
      "\n",
      "    The result is padded to full bytes by inserting zero bits at the end.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        An array of integers or booleans whose elements should be packed to\n",
      "        bits.\n",
      "    axis : int, optional\n",
      "        The dimension over which bit-packing is done.\n",
      "        ``None`` implies packing the flattened array.\n",
      "    bitorder : {'big', 'little'}, optional\n",
      "        The order of the input bits. 'big' will mimic bin(val),\n",
      "        ``[0, 0, 0, 0, 0, 0, 1, 1] => 3 = 0b00000011``, 'little' will\n",
      "        reverse the order so ``[1, 1, 0, 0, 0, 0, 0, 0] => 3``.\n",
      "        Defaults to 'big'.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    packed : ndarray\n",
      "        Array of type uint8 whose elements represent bits corresponding to the\n",
      "        logical (0 or nonzero) value of the input elements. The shape of\n",
      "        `packed` has the same number of dimensions as the input (unless `axis`\n",
      "        is None, in which case the output is 1-D).\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    unpackbits: Unpacks elements of a uint8 array into a binary-valued output\n",
      "                array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[[1,0,1],\n",
      "    ...                [0,1,0]],\n",
      "    ...               [[1,1,0],\n",
      "    ...                [0,0,1]]])\n",
      "    >>> b = np.packbits(a, axis=-1)\n",
      "    >>> b\n",
      "    array([[[160],\n",
      "            [ 64]],\n",
      "           [[192],\n",
      "            [ 32]]], dtype=uint8)\n",
      "\n",
      "    Note that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000,\n",
      "    and 32 = 0010 0000.\n",
      "\n",
      "    \n",
      "code: unpackbits\n",
      "\n",
      "docstring: unpackbits\n",
      "\n",
      "    unpackbits(a, /, axis=None, count=None, bitorder='big')\n",
      "\n",
      "    Unpacks elements of a uint8 array into a binary-valued output array.\n",
      "\n",
      "    Each element of `a` represents a bit-field that should be unpacked\n",
      "    into a binary-valued output array. The shape of the output array is\n",
      "    either 1-D (if `axis` is ``None``) or the same shape as the input\n",
      "    array with unpacking done along the axis specified.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : ndarray, uint8 type\n",
      "       Input array.\n",
      "    axis : int, optional\n",
      "        The dimension over which bit-unpacking is done.\n",
      "        ``None`` implies unpacking the flattened array.\n",
      "    count : int or None, optional\n",
      "        The number of elements to unpack along `axis`, provided as a way\n",
      "        of undoing the effect of packing a size that is not a multiple\n",
      "        of eight. A non-negative number means to only unpack `count`\n",
      "        bits. A negative number means to trim off that many bits from\n",
      "        the end. ``None`` means to unpack the entire array (the\n",
      "        default). Counts larger than the available number of bits will\n",
      "        add zero padding to the output. Negative counts must not\n",
      "        exceed the available number of bits.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    bitorder : {'big', 'little'}, optional\n",
      "        The order of the returned bits. 'big' will mimic bin(val),\n",
      "        ``3 = 0b00000011 => [0, 0, 0, 0, 0, 0, 1, 1]``, 'little' will reverse\n",
      "        the order to ``[1, 1, 0, 0, 0, 0, 0, 0]``.\n",
      "        Defaults to 'big'.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    unpacked : ndarray, uint8 type\n",
      "       The elements are binary-valued (0 or 1).\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    packbits : Packs the elements of a binary-valued array into bits in\n",
      "               a uint8 array.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[2], [7], [23]], dtype=np.uint8)\n",
      "    >>> a\n",
      "    array([[ 2],\n",
      "           [ 7],\n",
      "           [23]], dtype=uint8)\n",
      "    >>> b = np.unpackbits(a, axis=1)\n",
      "    >>> b\n",
      "    array([[0, 0, 0, 0, 0, 0, 1, 0],\n",
      "           [0, 0, 0, 0, 0, 1, 1, 1],\n",
      "           [0, 0, 0, 1, 0, 1, 1, 1]], dtype=uint8)\n",
      "    >>> c = np.unpackbits(a, axis=1, count=-3)\n",
      "    >>> c\n",
      "    array([[0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 1, 0]], dtype=uint8)\n",
      "\n",
      "    >>> p = np.packbits(b, axis=0)\n",
      "    >>> np.unpackbits(p, axis=0)\n",
      "    array([[0, 0, 0, 0, 0, 0, 1, 0],\n",
      "           [0, 0, 0, 0, 0, 1, 1, 1],\n",
      "           [0, 0, 0, 1, 0, 1, 1, 1],\n",
      "           [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n",
      "    >>> np.array_equal(b, np.unpackbits(p, axis=0, count=b.shape[0]))\n",
      "    True\n",
      "\n",
      "    \n",
      "code: fromregex\n",
      "@set_module('numpy')\n",
      "def fromregex(file, regexp, dtype, encoding=None):\n",
      "    r\"\"\"\n",
      "    Construct an array from a text file, using regular expression parsing.\n",
      "    The returned array is always a structured array, and is constructed from\n",
      "    all matches of the regular expression in the file. Groups in the regular\n",
      "    expression are converted to fields of the structured array.\n",
      "    Parameters\n",
      "    ----------\n",
      "    file : path or file\n",
      "        Filename or file object to read.\n",
      "        .. versionchanged:: 1.22.0\n",
      "            Now accepts `os.PathLike` implementations.\n",
      "    regexp : str or regexp\n",
      "        Regular expression used to parse the file.\n",
      "        Groups in the regular expression correspond to fields in the dtype.\n",
      "    dtype : dtype or list of dtypes\n",
      "        Dtype for the structured array; must be a structured datatype.\n",
      "    encoding : str, optional\n",
      "        Encoding used to decode the inputfile. Does not apply to input streams.\n",
      "        .. versionadded:: 1.14.0\n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        The output array, containing the part of the content of `file` that\n",
      "        was matched by `regexp`. `output` is always a structured array.\n",
      "    Raises\n",
      "    ------\n",
      "    TypeError\n",
      "        When `dtype` is not a valid dtype for a structured array.\n",
      "    See Also\n",
      "    --------\n",
      "    fromstring, loadtxt\n",
      "    Notes\n",
      "    -----\n",
      "    Dtypes for structured arrays can be specified in several forms, but all\n",
      "    forms specify at least the data type and field name. For details see\n",
      "    `basics.rec`.\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from io import StringIO\n",
      "    >>> text = StringIO(\"1312 foo\\n1534  bar\\n444   qux\")\n",
      "    >>> regexp = r\"(\\d+)\\s+(...)\"  # match [digits, whitespace, anything]\n",
      "    >>> output = np.fromregex(text, regexp,\n",
      "    ...                       [('num', np.int64), ('key', 'S3')])\n",
      "    >>> output\n",
      "    array([(1312, b'foo'), (1534, b'bar'), ( 444, b'qux')],\n",
      "          dtype=[('num', '<i8'), ('key', 'S3')])\n",
      "    >>> output['num']\n",
      "    array([1312, 1534,  444])\n",
      "    \"\"\"\n",
      "    own_fh = False\n",
      "    if not hasattr(file, \"read\"):\n",
      "        file = os.fspath(file)\n",
      "        file = np.lib._datasource.open(file, 'rt', encoding=encoding)\n",
      "        own_fh = True\n",
      "    try:\n",
      "        if not isinstance(dtype, np.dtype):\n",
      "            dtype = np.dtype(dtype)\n",
      "        if dtype.names is None:\n",
      "            raise TypeError('dtype must be a structured datatype.')\n",
      "        content = file.read()\n",
      "        if isinstance(content, bytes) and isinstance(regexp, str):\n",
      "            regexp = asbytes(regexp)\n",
      "        elif isinstance(content, str) and isinstance(regexp, bytes):\n",
      "            regexp = asstr(regexp)\n",
      "        if not hasattr(regexp, 'match'):\n",
      "            regexp = re.compile(regexp)\n",
      "        seq = regexp.findall(content)\n",
      "        if seq and not isinstance(seq[0], tuple):\n",
      " Create the new array as a single data-type and then\n",
      "            #   re-interpret as a single-field structured array.\n",
      "            newdtype = np.dtype(dtype[dtype.names[0]])\n",
      "            output = np.array(seq, dtype=newdtype)\n",
      "            output.dtype = dtype\n",
      "        else:\n",
      "            output = np.array(seq, dtype=dtype)\n",
      "        return output\n",
      "    finally:\n",
      "        if own_fh:\n",
      "            file.close()\n",
      "docstring: fromregex\n",
      "\n",
      "    Construct an array from a text file, using regular expression parsing.\n",
      "\n",
      "    The returned array is always a structured array, and is constructed from\n",
      "    all matches of the regular expression in the file. Groups in the regular\n",
      "    expression are converted to fields of the structured array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    file : path or file\n",
      "        Filename or file object to read.\n",
      "\n",
      "        .. versionchanged:: 1.22.0\n",
      "            Now accepts `os.PathLike` implementations.\n",
      "    regexp : str or regexp\n",
      "        Regular expression used to parse the file.\n",
      "        Groups in the regular expression correspond to fields in the dtype.\n",
      "    dtype : dtype or list of dtypes\n",
      "        Dtype for the structured array; must be a structured datatype.\n",
      "    encoding : str, optional\n",
      "        Encoding used to decode the inputfile. Does not apply to input streams.\n",
      "\n",
      "        .. versionadded:: 1.14.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        The output array, containing the part of the content of `file` that\n",
      "        was matched by `regexp`. `output` is always a structured array.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    TypeError\n",
      "        When `dtype` is not a valid dtype for a structured array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    fromstring, loadtxt\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Dtypes for structured arrays can be specified in several forms, but all\n",
      "    forms specify at least the data type and field name. For details see\n",
      "    `basics.rec`.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from io import StringIO\n",
      "    >>> text = StringIO(\"1312 foo\\n1534  bar\\n444   qux\")\n",
      "\n",
      "    >>> regexp = r\"(\\d+)\\s+(...)\"  # match [digits, whitespace, anything]\n",
      "    >>> output = np.fromregex(text, regexp,\n",
      "    ...                       [('num', np.int64), ('key', 'S3')])\n",
      "    >>> output\n",
      "    array([(1312, b'foo'), (1534, b'bar'), ( 444, b'qux')],\n",
      "          dtype=[('num', '<i8'), ('key', 'S3')])\n",
      "    >>> output['num']\n",
      "    array([1312, 1534,  444])\n",
      "\n",
      "    \n",
      "code: DataSource.__init__\n",
      "    def __init__(self, destpath=os.curdir):\n",
      "        if destpath:\n",
      "            self._destpath = os.path.abspath(destpath)\n",
      "            self._istmpdest = False\n",
      "        else:\n",
      "            import tempfile  # deferring import to improve startup time\n",
      "            self._destpath = tempfile.mkdtemp()\n",
      "            self._istmpdest = True\n",
      "docstring: DataSource.__init__\n",
      "Create a DataSource with a local path at destpath.\n",
      "code: DataSource._cache\n",
      "    def _cache(self, path):\n",
      " a significant fraction of numpy's total import time.\n",
      "        import shutil\n",
      "        from urllib.request import urlopen\n",
      "        upath = self.abspath(path)\n",
      " TODO: Doesn't handle compressed files!\n",
      "        if self._isurl(path):\n",
      "            with urlopen(path) as openedurl:\n",
      "                with _open(upath, 'wb') as f:\n",
      "                    shutil.copyfileobj(openedurl, f)\n",
      "        else:\n",
      "            shutil.copyfile(path, upath)\n",
      "        return upath\n",
      "docstring: DataSource._cache\n",
      "Cache the file specified by path.\n",
      "\n",
      "        Creates a copy of the file in the datasource cache.\n",
      "\n",
      "        \n",
      "code: DataSource._findfile\n",
      "    def _findfile(self, path):\n",
      " Valid local paths\n",
      "            filelist = self._possible_names(path)\n",
      " Cached URLs in self._destpath\n",
      "            filelist = self._possible_names(self.abspath(path))\n",
      "            # Remote URLs\n",
      "            filelist = filelist + self._possible_names(path)\n",
      "        for name in filelist:\n",
      "            if self.exists(name):\n",
      "                if self._isurl(name):\n",
      "                    name = self._cache(name)\n",
      "                return name\n",
      "        return None\n",
      "docstring: DataSource._findfile\n",
      "Searches for ``path`` and returns full path if found.\n",
      "\n",
      "        If path is an URL, _findfile will cache a local copy and return the\n",
      "        path to the cached file.  If path is a local file, _findfile will\n",
      "        return a path to that local file.\n",
      "\n",
      "        The search will include possible compressed versions of the file\n",
      "        and return the first occurrence found.\n",
      "\n",
      "        \n",
      "code: DataSource._isurl\n",
      "    def _isurl(self, path):\n",
      " BUG : URLs require a scheme string ('http://') to be used.\n",
      "       Should we prepend the scheme for those that don't have it and\n",
      "       for compressed versions of files.\n",
      "        scheme, netloc, upath, uparams, uquery, ufrag = urlparse(path)\n",
      "        return bool(scheme and netloc)\n",
      "docstring: DataSource._isurl\n",
      "Test if path is a net location.  Tests the scheme and netloc.\n",
      "code: DataSource._iswritemode\n",
      "    def _iswritemode(self, mode):\n",
      "        # Currently only used to test the bz2 files.\n",
      "        _writemodes = (\"w\", \"+\")\n",
      "        for c in mode:\n",
      "            if c in _writemodes:\n",
      "                return True\n",
      "        return False\n",
      "docstring: DataSource._iswritemode\n",
      "Test if the given mode will open a file for writing.\n",
      "code: DataSource._iszip\n",
      "    def _iszip(self, filename):\n",
      "        fname, ext = os.path.splitext(filename)\n",
      "        return ext in _file_openers.keys()\n",
      "docstring: DataSource._iszip\n",
      "Test if the filename is a zip file by looking at the file extension.\n",
      "\n",
      "        \n",
      "code: DataSource._possible_names\n",
      "    def _possible_names(self, filename):\n",
      "        names = [filename]\n",
      "        if not self._iszip(filename):\n",
      "            for zipext in _file_openers.keys():\n",
      "                if zipext:\n",
      "                    names.append(filename+zipext)\n",
      "        return names\n",
      "docstring: DataSource._possible_names\n",
      "Return a tuple containing compressed filename variations.\n",
      "code: DataSource._sanitize_relative_path\n",
      "    def _sanitize_relative_path(self, path):\n",
      "        last = None\n",
      "        path = os.path.normpath(path)\n",
      "        while path != last:\n",
      "            last = path\n",
      " for Windows\n",
      "        return path\n",
      "docstring: DataSource._sanitize_relative_path\n",
      "Return a sanitised relative path for which\n",
      "        os.path.abspath(os.path.join(base, path)).startswith(base)\n",
      "        \n",
      "code: DataSource._splitzipext\n",
      "    def _splitzipext(self, filename):\n",
      "        if self._iszip(filename):\n",
      "            return os.path.splitext(filename)\n",
      "        else:\n",
      "            return filename, None\n",
      "docstring: DataSource._splitzipext\n",
      "Split zip extension from filename and return filename.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        base, zip_ext : {tuple}\n",
      "\n",
      "        \n",
      "code: DataSource.abspath\n",
      "    def abspath(self, path):\n",
      " TODO:  This should be more robust.  Handles case where path includes\n",
      "        path = /home/guido/datafile.txt\n",
      "        upath = self.abspath(path)\n",
      " handle case where path includes self._destpath\n",
      "        splitpath = path.split(self._destpath, 2)\n",
      "        if len(splitpath) > 1:\n",
      "            path = splitpath[1]\n",
      "        scheme, netloc, upath, uparams, uquery, ufrag = urlparse(path)\n",
      "        netloc = self._sanitize_relative_path(netloc)\n",
      "        upath = self._sanitize_relative_path(upath)\n",
      "        return os.path.join(self._destpath, netloc, upath)\n",
      "docstring: DataSource.abspath\n",
      "\n",
      "        Return absolute path of file in the DataSource directory.\n",
      "\n",
      "        If `path` is an URL, then `abspath` will return either the location\n",
      "        the file exists locally or the location it would exist when opened\n",
      "        using the `open` method.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        path : str\n",
      "            Can be a local file or a remote URL.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        out : str\n",
      "            Complete path, including the `DataSource` destination directory.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        The functionality is based on `os.path.abspath`.\n",
      "\n",
      "        \n",
      "code: DataSource.exists\n",
      "    def exists(self, path):\n",
      " We import this here because importing urllib is slow and\n",
      " Test cached url\n",
      "        upath = self.abspath(path)\n",
      "        if os.path.exists(upath):\n",
      "            return True\n",
      "        # Test remote url\n",
      "        if self._isurl(path):\n",
      "            try:\n",
      "                netfile = urlopen(path)\n",
      "                netfile.close()\n",
      "                del(netfile)\n",
      "                return True\n",
      "            except URLError:\n",
      "                return False\n",
      "        return False\n",
      "docstring: DataSource.exists\n",
      "\n",
      "        Test if path exists.\n",
      "\n",
      "        Test if `path` exists as (and in this order):\n",
      "\n",
      "        - a local file.\n",
      "        - a remote URL that has been downloaded and stored locally in the\n",
      "          `DataSource` directory.\n",
      "        - a remote URL that has not been downloaded, but is valid and\n",
      "          accessible.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        path : str\n",
      "            Can be a local file or a remote URL.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        out : bool\n",
      "            True if `path` exists.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        When `path` is an URL, `exists` will return True if it's either\n",
      "        stored locally in the `DataSource` directory, or is a valid remote\n",
      "        URL.  `DataSource` does not discriminate between the two, the file\n",
      "        is accessible if it exists in either location.\n",
      "\n",
      "        \n",
      "code: DataSource.open\n",
      "    def open(self, path, mode='r', encoding=None, newline=None):\n",
      "       doesn't exist yet (creating a file).  Should there be?\n",
      "       used to store URLs in self._destpath.\n",
      "        if self._isurl(path) and self._iswritemode(mode):\n",
      "            raise ValueError(\"URLs are not writeable\")\n",
      "        # NOTE: _findfile will fail on a new file opened for writing.\n",
      "        found = self._findfile(path)\n",
      "        if found:\n",
      "            _fname, ext = self._splitzipext(found)\n",
      "            if ext == 'bz2':\n",
      "                mode.replace(\"+\", \"\")\n",
      "            return _file_openers[ext](found, mode=mode,\n",
      "                                      encoding=encoding, newline=newline)\n",
      "        else:\n",
      "            raise FileNotFoundError(f\"{path} not found.\")\n",
      "docstring: DataSource.open\n",
      "\n",
      "        Open and return file-like object.\n",
      "\n",
      "        If `path` is an URL, it will be downloaded, stored in the\n",
      "        `DataSource` directory and opened from there.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        path : str\n",
      "            Local file path or URL to open.\n",
      "        mode : {'r', 'w', 'a'}, optional\n",
      "            Mode to open `path`.  Mode 'r' for reading, 'w' for writing,\n",
      "            'a' to append. Available modes depend on the type of object\n",
      "            specified by `path`. Default is 'r'.\n",
      "        encoding : {None, str}, optional\n",
      "            Open text file with given encoding. The default encoding will be\n",
      "            what `io.open` uses.\n",
      "        newline : {None, str}, optional\n",
      "            Newline to use when reading text file.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        out : file object\n",
      "            File object.\n",
      "\n",
      "        \n",
      "code: nansum\n",
      "@array_function_dispatch(_nansum_dispatcher)\n",
      "def nansum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n",
      "           initial=np._NoValue, where=np._NoValue):\n",
      "    a, mask = _replace_nan(a, 0)\n",
      "    return np.sum(a, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n",
      "                  initial=initial, where=where)\n",
      "docstring: nansum\n",
      "\n",
      "    Return the sum of array elements over a given axis treating Not a\n",
      "    Numbers (NaNs) as zero.\n",
      "\n",
      "    In NumPy versions <= 1.9.0 Nan is returned for slices that are all-NaN or\n",
      "    empty. In later versions zero is returned.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose sum is desired. If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the sum is computed. The default is to compute the\n",
      "        sum of the flattened array.\n",
      "    dtype : data-type, optional\n",
      "        The type of the returned array and of the accumulator in which the\n",
      "        elements are summed.  By default, the dtype of `a` is used.  An\n",
      "        exception is when `a` has an integer type with less precision than\n",
      "        the platform (u)intp. In that case, the default will be either\n",
      "        (u)int32 or (u)int64 depending on whether the platform is 32 or 64\n",
      "        bits. For inexact inputs, dtype must be inexact.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  The default\n",
      "        is ``None``. If provided, it must have the same shape as the\n",
      "        expected output, but the type will be cast if necessary.  See\n",
      "        :ref:`ufuncs-output-type` for more details. The casting of NaN to integer\n",
      "        can yield unexpected results.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `a`.\n",
      "\n",
      "\n",
      "        If the value is anything but the default, then\n",
      "        `keepdims` will be passed through to the `mean` or `sum` methods\n",
      "        of sub-classes of `ndarray`.  If the sub-classes methods\n",
      "        does not implement `keepdims` any exceptions will be raised.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "    initial : scalar, optional\n",
      "        Starting value for the sum. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the sum. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    nansum : ndarray.\n",
      "        A new array holding the result is returned unless `out` is\n",
      "        specified, in which it is returned. The result has the same\n",
      "        size as `a`, and the same shape as `a` if `axis` is not None\n",
      "        or `a` is a 1-d array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.sum : Sum across array propagating NaNs.\n",
      "    isnan : Show which elements are NaN.\n",
      "    isfinite : Show which elements are not NaN or +/-inf.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    If both positive and negative infinity are present, the sum will be Not\n",
      "    A Number (NaN).\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.nansum(1)\n",
      "    1\n",
      "    >>> np.nansum([1])\n",
      "    1\n",
      "    >>> np.nansum([1, np.nan])\n",
      "    1.0\n",
      "    >>> a = np.array([[1, 1], [1, np.nan]])\n",
      "    >>> np.nansum(a)\n",
      "    3.0\n",
      "    >>> np.nansum(a, axis=0)\n",
      "    array([2.,  1.])\n",
      "    >>> np.nansum([1, np.nan, np.inf])\n",
      "    inf\n",
      "    >>> np.nansum([1, np.nan, np.NINF])\n",
      "    -inf\n",
      "    >>> from numpy.testing import suppress_warnings\n",
      "    >>> with suppress_warnings() as sup:\n",
      "    ...     sup.filter(RuntimeWarning)\n",
      "    ...     np.nansum([1, np.nan, np.inf, -np.inf]) # both +/- infinity present\n",
      "    nan\n",
      "\n",
      "    \n",
      "code: nanmax\n",
      "@array_function_dispatch(_nanmax_dispatcher)\n",
      "def nanmax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n",
      "           where=np._NoValue):\n",
      "    kwargs = {}\n",
      "    if keepdims is not np._NoValue:\n",
      "        kwargs['keepdims'] = keepdims\n",
      "    if initial is not np._NoValue:\n",
      "        kwargs['initial'] = initial\n",
      "    if where is not np._NoValue:\n",
      "        kwargs['where'] = where\n",
      "    if type(a) is np.ndarray and a.dtype != np.object_:\n",
      " which do not implement isnan (gh-9009), or fmax correctly (gh-8975)\n",
      "        res = np.fmax.reduce(a, axis=axis, out=out, **kwargs)\n",
      "        if np.isnan(res).any():\n",
      "            warnings.warn(\"All-NaN slice encountered\", RuntimeWarning,\n",
      "                          stacklevel=3)\n",
      "    else:\n",
      " Check for all-NaN axis\n",
      "        kwargs.pop(\"initial\", None)\n",
      "        mask = np.all(mask, axis=axis, **kwargs)\n",
      "        if np.any(mask):\n",
      "            res = _copyto(res, np.nan, mask)\n",
      "            warnings.warn(\"All-NaN axis encountered\", RuntimeWarning,\n",
      "                          stacklevel=3)\n",
      "    return res\n",
      "docstring: nanmax\n",
      "\n",
      "    Return the maximum of an array or maximum along an axis, ignoring any\n",
      "    NaNs.  When all-NaN slices are encountered a ``RuntimeWarning`` is\n",
      "    raised and NaN is returned for that slice.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose maximum is desired. If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the maximum is computed. The default is to compute\n",
      "        the maximum of the flattened array.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  The default\n",
      "        is ``None``; if provided, it must have the same shape as the\n",
      "        expected output, but the type will be cast if necessary. See\n",
      "        :ref:`ufuncs-output-type` for more details.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `a`.\n",
      "\n",
      "        If the value is anything but the default, then\n",
      "        `keepdims` will be passed through to the `max` method\n",
      "        of sub-classes of `ndarray`.  If the sub-classes methods\n",
      "        does not implement `keepdims` any exceptions will be raised.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "    initial : scalar, optional\n",
      "        The minimum value of an output element. Must be present to allow\n",
      "        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "    where : array_like of bool, optional\n",
      "        Elements to compare for the maximum. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    nanmax : ndarray\n",
      "        An array with the same shape as `a`, with the specified axis removed.\n",
      "        If `a` is a 0-d array, or if axis is None, an ndarray scalar is\n",
      "        returned.  The same dtype as `a` is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    nanmin :\n",
      "        The minimum value of an array along a given axis, ignoring any NaNs.\n",
      "    amax :\n",
      "        The maximum value of an array along a given axis, propagating any NaNs.\n",
      "    fmax :\n",
      "        Element-wise maximum of two arrays, ignoring any NaNs.\n",
      "    maximum :\n",
      "        Element-wise maximum of two arrays, propagating any NaNs.\n",
      "    isnan :\n",
      "        Shows which elements are Not a Number (NaN).\n",
      "    isfinite:\n",
      "        Shows which elements are neither NaN nor infinity.\n",
      "\n",
      "    amin, fmin, minimum\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n",
      "    (IEEE 754). This means that Not a Number is not equivalent to infinity.\n",
      "    Positive infinity is treated as a very large number and negative\n",
      "    infinity is treated as a very small (i.e. negative) number.\n",
      "\n",
      "    If the input has a integer type the function is equivalent to np.max.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, np.nan]])\n",
      "    >>> np.nanmax(a)\n",
      "    3.0\n",
      "    >>> np.nanmax(a, axis=0)\n",
      "    array([3.,  2.])\n",
      "    >>> np.nanmax(a, axis=1)\n",
      "    array([2.,  3.])\n",
      "\n",
      "    When positive infinity and negative infinity are present:\n",
      "\n",
      "    >>> np.nanmax([1, 2, np.nan, np.NINF])\n",
      "    2.0\n",
      "    >>> np.nanmax([1, 2, np.nan, np.inf])\n",
      "    inf\n",
      "\n",
      "    \n",
      "code: nanmin\n",
      "@array_function_dispatch(_nanmin_dispatcher)\n",
      "def nanmin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n",
      "           where=np._NoValue):\n",
      "    kwargs = {}\n",
      "    if keepdims is not np._NoValue:\n",
      "        kwargs['keepdims'] = keepdims\n",
      "    if initial is not np._NoValue:\n",
      "        kwargs['initial'] = initial\n",
      "    if where is not np._NoValue:\n",
      "        kwargs['where'] = where\n",
      "    if type(a) is np.ndarray and a.dtype != np.object_:\n",
      " which do not implement isnan (gh-9009), or fmin correctly (gh-8975)\n",
      "        res = np.fmin.reduce(a, axis=axis, out=out, **kwargs)\n",
      "        if np.isnan(res).any():\n",
      "            warnings.warn(\"All-NaN slice encountered\", RuntimeWarning,\n",
      "                          stacklevel=3)\n",
      "    else:\n",
      " Check for all-NaN axis\n",
      "        kwargs.pop(\"initial\", None)\n",
      "        mask = np.all(mask, axis=axis, **kwargs)\n",
      "        if np.any(mask):\n",
      "            res = _copyto(res, np.nan, mask)\n",
      "            warnings.warn(\"All-NaN axis encountered\", RuntimeWarning,\n",
      "                          stacklevel=3)\n",
      "    return res\n",
      "docstring: nanmin\n",
      "\n",
      "    Return minimum of an array or minimum along an axis, ignoring any NaNs.\n",
      "    When all-NaN slices are encountered a ``RuntimeWarning`` is raised and\n",
      "    Nan is returned for that slice.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose minimum is desired. If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the minimum is computed. The default is to compute\n",
      "        the minimum of the flattened array.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  The default\n",
      "        is ``None``; if provided, it must have the same shape as the\n",
      "        expected output, but the type will be cast if necessary. See\n",
      "        :ref:`ufuncs-output-type` for more details.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `a`.\n",
      "\n",
      "        If the value is anything but the default, then\n",
      "        `keepdims` will be passed through to the `min` method\n",
      "        of sub-classes of `ndarray`.  If the sub-classes methods\n",
      "        does not implement `keepdims` any exceptions will be raised.\n",
      "\n",
      "        .. versionadded:: 1.8.0\n",
      "    initial : scalar, optional\n",
      "        The maximum value of an output element. Must be present to allow\n",
      "        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "    where : array_like of bool, optional\n",
      "        Elements to compare for the minimum. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    nanmin : ndarray\n",
      "        An array with the same shape as `a`, with the specified axis\n",
      "        removed.  If `a` is a 0-d array, or if axis is None, an ndarray\n",
      "        scalar is returned.  The same dtype as `a` is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    nanmax :\n",
      "        The maximum value of an array along a given axis, ignoring any NaNs.\n",
      "    amin :\n",
      "        The minimum value of an array along a given axis, propagating any NaNs.\n",
      "    fmin :\n",
      "        Element-wise minimum of two arrays, ignoring any NaNs.\n",
      "    minimum :\n",
      "        Element-wise minimum of two arrays, propagating any NaNs.\n",
      "    isnan :\n",
      "        Shows which elements are Not a Number (NaN).\n",
      "    isfinite:\n",
      "        Shows which elements are neither NaN nor infinity.\n",
      "\n",
      "    amax, fmax, maximum\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n",
      "    (IEEE 754). This means that Not a Number is not equivalent to infinity.\n",
      "    Positive infinity is treated as a very large number and negative\n",
      "    infinity is treated as a very small (i.e. negative) number.\n",
      "\n",
      "    If the input has a integer type the function is equivalent to np.min.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, np.nan]])\n",
      "    >>> np.nanmin(a)\n",
      "    1.0\n",
      "    >>> np.nanmin(a, axis=0)\n",
      "    array([1.,  2.])\n",
      "    >>> np.nanmin(a, axis=1)\n",
      "    array([1.,  3.])\n",
      "\n",
      "    When positive infinity and negative infinity are present:\n",
      "\n",
      "    >>> np.nanmin([1, 2, np.nan, np.inf])\n",
      "    1.0\n",
      "    >>> np.nanmin([1, 2, np.nan, np.NINF])\n",
      "    -inf\n",
      "\n",
      "    \n",
      "code: nanargmax\n",
      "@array_function_dispatch(_nanargmax_dispatcher)\n",
      "def nanargmax(a, axis=None, out=None, *, keepdims=np._NoValue):\n",
      "    a, mask = _replace_nan(a, -np.inf)\n",
      "    if mask is not None:\n",
      "        mask = np.all(mask, axis=axis)\n",
      "        if np.any(mask):\n",
      "            raise ValueError(\"All-NaN slice encountered\")\n",
      "    res = np.argmax(a, axis=axis, out=out, keepdims=keepdims)\n",
      "    return res\n",
      "docstring: nanargmax\n",
      "\n",
      "    Return the indices of the maximum values in the specified axis ignoring\n",
      "    NaNs. For all-NaN slices ``ValueError`` is raised. Warning: the\n",
      "    results cannot be trusted if a slice contains only NaNs and -Infs.\n",
      "\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : int, optional\n",
      "        Axis along which to operate.  By default flattened input is used.\n",
      "    out : array, optional\n",
      "        If provided, the result will be inserted into this array. It should\n",
      "        be of the appropriate shape and dtype.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the array.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    index_array : ndarray\n",
      "        An array of indices or a single index value.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    argmax, nanargmin\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[np.nan, 4], [2, 3]])\n",
      "    >>> np.argmax(a)\n",
      "    0\n",
      "    >>> np.nanargmax(a)\n",
      "    1\n",
      "    >>> np.nanargmax(a, axis=0)\n",
      "    array([1, 0])\n",
      "    >>> np.nanargmax(a, axis=1)\n",
      "    array([1, 1])\n",
      "\n",
      "    \n",
      "code: nanargmin\n",
      "@array_function_dispatch(_nanargmin_dispatcher)\n",
      "def nanargmin(a, axis=None, out=None, *, keepdims=np._NoValue):\n",
      "    a, mask = _replace_nan(a, np.inf)\n",
      "    if mask is not None:\n",
      "        mask = np.all(mask, axis=axis)\n",
      "        if np.any(mask):\n",
      "            raise ValueError(\"All-NaN slice encountered\")\n",
      "    res = np.argmin(a, axis=axis, out=out, keepdims=keepdims)\n",
      "    return res\n",
      "docstring: nanargmin\n",
      "\n",
      "    Return the indices of the minimum values in the specified axis ignoring\n",
      "    NaNs. For all-NaN slices ``ValueError`` is raised. Warning: the results\n",
      "    cannot be trusted if a slice contains only NaNs and Infs.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : int, optional\n",
      "        Axis along which to operate.  By default flattened input is used.\n",
      "    out : array, optional\n",
      "        If provided, the result will be inserted into this array. It should\n",
      "        be of the appropriate shape and dtype.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the array.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    index_array : ndarray\n",
      "        An array of indices or a single index value.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    argmin, nanargmax\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[np.nan, 4], [2, 3]])\n",
      "    >>> np.argmin(a)\n",
      "    0\n",
      "    >>> np.nanargmin(a)\n",
      "    2\n",
      "    >>> np.nanargmin(a, axis=0)\n",
      "    array([1, 1])\n",
      "    >>> np.nanargmin(a, axis=1)\n",
      "    array([1, 0])\n",
      "\n",
      "    \n",
      "code: nanmean\n",
      "@array_function_dispatch(_nanmean_dispatcher)\n",
      "def nanmean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n",
      "            *, where=np._NoValue):\n",
      "    arr, mask = _replace_nan(a, 0)\n",
      "    if mask is None:\n",
      "        return np.mean(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n",
      "                       where=where)\n",
      "    if dtype is not None:\n",
      "        dtype = np.dtype(dtype)\n",
      "    if dtype is not None and not issubclass(dtype.type, np.inexact):\n",
      "        raise TypeError(\"If a is inexact, then dtype must be inexact\")\n",
      "    if out is not None and not issubclass(out.dtype.type, np.inexact):\n",
      "        raise TypeError(\"If a is inexact, then out must be inexact\")\n",
      "    cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims,\n",
      "                 where=where)\n",
      "    tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n",
      "                 where=where)\n",
      "    avg = _divide_by_count(tot, cnt, out=out)\n",
      "    isbad = (cnt == 0)\n",
      "    if isbad.any():\n",
      "        warnings.warn(\"Mean of empty slice\", RuntimeWarning, stacklevel=3)\n",
      " action is needed to handle bad results.\n",
      "    return avg\n",
      "docstring: nanmean\n",
      "\n",
      "    Compute the arithmetic mean along the specified axis, ignoring NaNs.\n",
      "\n",
      "    Returns the average of the array elements.  The average is taken over\n",
      "    the flattened array by default, otherwise over the specified axis.\n",
      "    `float64` intermediate and return values are used for integer inputs.\n",
      "\n",
      "    For all-NaN slices, NaN is returned and a `RuntimeWarning` is raised.\n",
      "\n",
      "    .. versionadded:: 1.8.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose mean is desired. If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the means are computed. The default is to compute\n",
      "        the mean of the flattened array.\n",
      "    dtype : data-type, optional\n",
      "        Type to use in computing the mean.  For integer inputs, the default\n",
      "        is `float64`; for inexact inputs, it is the same as the input\n",
      "        dtype.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  The default\n",
      "        is ``None``; if provided, it must have the same shape as the\n",
      "        expected output, but the type will be cast if necessary. See\n",
      "        :ref:`ufuncs-output-type` for more details.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `a`.\n",
      "\n",
      "        If the value is anything but the default, then\n",
      "        `keepdims` will be passed through to the `mean` or `sum` methods\n",
      "        of sub-classes of `ndarray`.  If the sub-classes methods\n",
      "        does not implement `keepdims` any exceptions will be raised.\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the mean. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    m : ndarray, see dtype parameter above\n",
      "        If `out=None`, returns a new array containing the mean values,\n",
      "        otherwise a reference to the output array is returned. Nan is\n",
      "        returned for slices that contain only NaNs.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    average : Weighted average\n",
      "    mean : Arithmetic mean taken while not ignoring NaNs\n",
      "    var, nanvar\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The arithmetic mean is the sum of the non-NaN elements along the axis\n",
      "    divided by the number of non-NaN elements.\n",
      "\n",
      "    Note that for floating-point input, the mean is computed using the same\n",
      "    precision the input has.  Depending on the input data, this can cause\n",
      "    the results to be inaccurate, especially for `float32`.  Specifying a\n",
      "    higher-precision accumulator using the `dtype` keyword can alleviate\n",
      "    this issue.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, np.nan], [3, 4]])\n",
      "    >>> np.nanmean(a)\n",
      "    2.6666666666666665\n",
      "    >>> np.nanmean(a, axis=0)\n",
      "    array([2.,  4.])\n",
      "    >>> np.nanmean(a, axis=1)\n",
      "    array([1.,  3.5]) # may vary\n",
      "\n",
      "    \n",
      "code: nanmedian\n",
      "@array_function_dispatch(_nanmedian_dispatcher)\n",
      "def nanmedian(a, axis=None, out=None, overwrite_input=False, keepdims=np._NoValue):\n",
      "    a = np.asanyarray(a)\n",
      " so deal them upfront\n",
      "    if a.size == 0:\n",
      "        return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "    return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "                                  axis=axis, out=out,\n",
      "                                  overwrite_input=overwrite_input)\n",
      "docstring: nanmedian\n",
      "\n",
      "    Compute the median along the specified axis, while ignoring NaNs.\n",
      "\n",
      "    Returns the median of the array elements.\n",
      "\n",
      "    .. versionadded:: 1.9.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array or object that can be converted to an array.\n",
      "    axis : {int, sequence of int, None}, optional\n",
      "        Axis or axes along which the medians are computed. The default\n",
      "        is to compute the median along a flattened version of the array.\n",
      "        A sequence of axes is supported since version 1.9.0.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must\n",
      "        have the same shape and buffer length as the expected output,\n",
      "        but the type (of the output) will be cast if necessary.\n",
      "    overwrite_input : bool, optional\n",
      "       If True, then allow use of memory of input array `a` for\n",
      "       calculations. The input array will be modified by the call to\n",
      "       `median`. This will save memory when you do not need to preserve\n",
      "       the contents of the input array. Treat the input as undefined,\n",
      "       but it will probably be fully or partially sorted. Default is\n",
      "       False. If `overwrite_input` is ``True`` and `a` is not already an\n",
      "       `ndarray`, an error will be raised.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `a`.\n",
      "\n",
      "        If this is anything but the default value it will be passed\n",
      "        through (in the special case of an empty array) to the\n",
      "        `mean` function of the underlying array.  If the array is\n",
      "        a sub-class and `mean` does not have the kwarg `keepdims` this\n",
      "        will raise a RuntimeError.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    median : ndarray\n",
      "        A new array holding the result. If the input contains integers\n",
      "        or floats smaller than ``float64``, then the output data-type is\n",
      "        ``np.float64``.  Otherwise, the data-type of the output is the\n",
      "        same as that of the input. If `out` is specified, that array is\n",
      "        returned instead.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    mean, median, percentile\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Given a vector ``V`` of length ``N``, the median of ``V`` is the\n",
      "    middle value of a sorted copy of ``V``, ``V_sorted`` - i.e.,\n",
      "    ``V_sorted[(N-1)/2]``, when ``N`` is odd and the average of the two\n",
      "    middle values of ``V_sorted`` when ``N`` is even.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[10.0, 7, 4], [3, 2, 1]])\n",
      "    >>> a[0, 1] = np.nan\n",
      "    >>> a\n",
      "    array([[10., nan,  4.],\n",
      "           [ 3.,  2.,  1.]])\n",
      "    >>> np.median(a)\n",
      "    nan\n",
      "    >>> np.nanmedian(a)\n",
      "    3.0\n",
      "    >>> np.nanmedian(a, axis=0)\n",
      "    array([6.5, 2. , 2.5])\n",
      "    >>> np.median(a, axis=1)\n",
      "    array([nan,  2.])\n",
      "    >>> b = a.copy()\n",
      "    >>> np.nanmedian(b, axis=1, overwrite_input=True)\n",
      "    array([7.,  2.])\n",
      "    >>> assert not np.all(a==b)\n",
      "    >>> b = a.copy()\n",
      "    >>> np.nanmedian(b, axis=None, overwrite_input=True)\n",
      "    3.0\n",
      "    >>> assert not np.all(a==b)\n",
      "\n",
      "    \n",
      "code: nanpercentile\n",
      "@array_function_dispatch(_nanpercentile_dispatcher)\n",
      "def nanpercentile(\n",
      "        a,\n",
      "        q,\n",
      "        axis=None,\n",
      "        out=None,\n",
      "        overwrite_input=False,\n",
      "        method=\"linear\",\n",
      "        keepdims=np._NoValue,\n",
      "        *,\n",
      "        interpolation=None,\n",
      "):\n",
      "    if interpolation is not None:\n",
      "        method = function_base._check_interpolation_as_method(\n",
      "            method, interpolation, \"nanpercentile\")\n",
      "    a = np.asanyarray(a)\n",
      "    q = np.true_divide(q, 100.0)\n",
      "    # undo any decay that the ufunc performed (see gh-13105)\n",
      "    q = np.asanyarray(q)\n",
      "    if not function_base._quantile_is_valid(q):\n",
      "        raise ValueError(\"Percentiles must be in the range [0, 100]\")\n",
      "    return _nanquantile_unchecked(\n",
      "        a, q, axis, out, overwrite_input, method, keepdims)\n",
      "docstring: nanpercentile\n",
      "\n",
      "    Compute the qth percentile of the data along the specified axis,\n",
      "    while ignoring nan values.\n",
      "\n",
      "    Returns the qth percentile(s) of the array elements.\n",
      "\n",
      "    .. versionadded:: 1.9.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array or object that can be converted to an array, containing\n",
      "        nan values to be ignored.\n",
      "    q : array_like of float\n",
      "        Percentile or sequence of percentiles to compute, which must be\n",
      "        between 0 and 100 inclusive.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the percentiles are computed. The default\n",
      "        is to compute the percentile(s) along a flattened version of the\n",
      "        array.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape and buffer length as the expected output, but the\n",
      "        type (of the output) will be cast if necessary.\n",
      "    overwrite_input : bool, optional\n",
      "        If True, then allow the input array `a` to be modified by\n",
      "        intermediate calculations, to save memory. In this case, the\n",
      "        contents of the input `a` after this function completes is\n",
      "        undefined.\n",
      "    method : str, optional\n",
      "        This parameter specifies the method to use for estimating the\n",
      "        percentile.  There are many different methods, some unique to NumPy.\n",
      "        See the notes for explanation.  The options sorted by their R type\n",
      "        as summarized in the H&F paper [1]_ are:\n",
      "\n",
      "        1. 'inverted_cdf'\n",
      "        2. 'averaged_inverted_cdf'\n",
      "        3. 'closest_observation'\n",
      "        4. 'interpolated_inverted_cdf'\n",
      "        5. 'hazen'\n",
      "        6. 'weibull'\n",
      "        7. 'linear'  (default)\n",
      "        8. 'median_unbiased'\n",
      "        9. 'normal_unbiased'\n",
      "\n",
      "        The first three methods are discontinuous.  NumPy further defines the\n",
      "        following discontinuous variations of the default 'linear' (7.) option:\n",
      "\n",
      "        * 'lower'\n",
      "        * 'higher',\n",
      "        * 'midpoint'\n",
      "        * 'nearest'\n",
      "\n",
      "        .. versionchanged:: 1.22.0\n",
      "            This argument was previously called \"interpolation\" and only\n",
      "            offered the \"linear\" default and last four options.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left in\n",
      "        the result as dimensions with size one. With this option, the\n",
      "        result will broadcast correctly against the original array `a`.\n",
      "\n",
      "        If this is anything but the default value it will be passed\n",
      "        through (in the special case of an empty array) to the\n",
      "        `mean` function of the underlying array.  If the array is\n",
      "        a sub-class and `mean` does not have the kwarg `keepdims` this\n",
      "        will raise a RuntimeError.\n",
      "\n",
      "    interpolation : str, optional\n",
      "        Deprecated name for the method keyword argument.\n",
      "\n",
      "        .. deprecated:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    percentile : scalar or ndarray\n",
      "        If `q` is a single percentile and `axis=None`, then the result\n",
      "        is a scalar. If multiple percentiles are given, first axis of\n",
      "        the result corresponds to the percentiles. The other axes are\n",
      "        the axes that remain after the reduction of `a`. If the input\n",
      "        contains integers or floats smaller than ``float64``, the output\n",
      "        data-type is ``float64``. Otherwise, the output data-type is the\n",
      "        same as that of the input. If `out` is specified, that array is\n",
      "        returned instead.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    nanmean\n",
      "    nanmedian : equivalent to ``nanpercentile(..., 50)``\n",
      "    percentile, median, mean\n",
      "    nanquantile : equivalent to nanpercentile, except q in range [0, 1].\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    For more information please see `numpy.percentile`\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[10., 7., 4.], [3., 2., 1.]])\n",
      "    >>> a[0][1] = np.nan\n",
      "    >>> a\n",
      "    array([[10.,  nan,   4.],\n",
      "          [ 3.,   2.,   1.]])\n",
      "    >>> np.percentile(a, 50)\n",
      "    nan\n",
      "    >>> np.nanpercentile(a, 50)\n",
      "    3.0\n",
      "    >>> np.nanpercentile(a, 50, axis=0)\n",
      "    array([6.5, 2. , 2.5])\n",
      "    >>> np.nanpercentile(a, 50, axis=1, keepdims=True)\n",
      "    array([[7.],\n",
      "           [2.]])\n",
      "    >>> m = np.nanpercentile(a, 50, axis=0)\n",
      "    >>> out = np.zeros_like(m)\n",
      "    >>> np.nanpercentile(a, 50, axis=0, out=out)\n",
      "    array([6.5, 2. , 2.5])\n",
      "    >>> m\n",
      "    array([6.5,  2. ,  2.5])\n",
      "\n",
      "    >>> b = a.copy()\n",
      "    >>> np.nanpercentile(b, 50, axis=1, overwrite_input=True)\n",
      "    array([7., 2.])\n",
      "    >>> assert not np.all(a==b)\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] R. J. Hyndman and Y. Fan,\n",
      "       \"Sample quantiles in statistical packages,\"\n",
      "       The American Statistician, 50(4), pp. 361-365, 1996\n",
      "\n",
      "    \n",
      "code: nanvar\n",
      "@array_function_dispatch(_nanvar_dispatcher)\n",
      "def nanvar(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue,\n",
      "           *, where=np._NoValue):\n",
      "    arr, mask = _replace_nan(a, 0)\n",
      "    if mask is None:\n",
      "        return np.var(arr, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "                      keepdims=keepdims, where=where)\n",
      "    if dtype is not None:\n",
      "        dtype = np.dtype(dtype)\n",
      "    if dtype is not None and not issubclass(dtype.type, np.inexact):\n",
      "        raise TypeError(\"If a is inexact, then dtype must be inexact\")\n",
      "    if out is not None and not issubclass(out.dtype.type, np.inexact):\n",
      "        raise TypeError(\"If a is inexact, then out must be inexact\")\n",
      " we need to special case matrix for reverse compatibility\n",
      " keepdims=True, however matrix now raises an error in this case, but\n",
      " so this used to work by serendipity.\n",
      "    cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=_keepdims,\n",
      "                 where=where)\n",
      "    avg = np.sum(arr, axis=axis, dtype=dtype, keepdims=_keepdims, where=where)\n",
      "    avg = _divide_by_count(avg, cnt)\n",
      " Compute variance.\n",
      "    var = np.sum(sqr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n",
      "                 where=where)\n",
      " Subclasses of ndarray may ignore keepdims, so check here.\n",
      "        cnt = cnt.squeeze(axis)\n",
      "    dof = cnt - ddof\n",
      "    var = _divide_by_count(var, dof)\n",
      "    isbad = (dof <= 0)\n",
      "    if np.any(isbad):\n",
      "        warnings.warn(\"Degrees of freedom <= 0 for slice.\", RuntimeWarning,\n",
      "                      stacklevel=3)\n",
      " values, so explicitly replace them with NaN.\n",
      "        var = _copyto(var, np.nan, isbad)\n",
      "    return var\n",
      "docstring: nanvar\n",
      "\n",
      "    Compute the variance along the specified axis, while ignoring NaNs.\n",
      "\n",
      "    Returns the variance of the array elements, a measure of the spread of\n",
      "    a distribution.  The variance is computed for the flattened array by\n",
      "    default, otherwise over the specified axis.\n",
      "\n",
      "    For all-NaN slices or slices with zero degrees of freedom, NaN is\n",
      "    returned and a `RuntimeWarning` is raised.\n",
      "\n",
      "    .. versionadded:: 1.8.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose variance is desired.  If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the variance is computed.  The default is to compute\n",
      "        the variance of the flattened array.\n",
      "    dtype : data-type, optional\n",
      "        Type to use in computing the variance.  For arrays of integer type\n",
      "        the default is `float64`; for arrays of float types it is the same as\n",
      "        the array type.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  It must have\n",
      "        the same shape as the expected output, but the type is cast if\n",
      "        necessary.\n",
      "    ddof : int, optional\n",
      "        \"Delta Degrees of Freedom\": the divisor used in the calculation is\n",
      "        ``N - ddof``, where ``N`` represents the number of non-NaN\n",
      "        elements. By default `ddof` is zero.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `a`.\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the variance. See `~numpy.ufunc.reduce` for\n",
      "        details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    variance : ndarray, see dtype parameter above\n",
      "        If `out` is None, return a new array containing the variance,\n",
      "        otherwise return a reference to the output array. If ddof is >= the\n",
      "        number of non-NaN elements in a slice or the slice contains only\n",
      "        NaNs, then the result for that slice is NaN.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    std : Standard deviation\n",
      "    mean : Average\n",
      "    var : Variance while not ignoring NaNs\n",
      "    nanstd, nanmean\n",
      "    :ref:`ufuncs-output-type`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The variance is the average of the squared deviations from the mean,\n",
      "    i.e.,  ``var = mean(abs(x - x.mean())**2)``.\n",
      "\n",
      "    The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.\n",
      "    If, however, `ddof` is specified, the divisor ``N - ddof`` is used\n",
      "    instead.  In standard statistical practice, ``ddof=1`` provides an\n",
      "    unbiased estimator of the variance of a hypothetical infinite\n",
      "    population.  ``ddof=0`` provides a maximum likelihood estimate of the\n",
      "    variance for normally distributed variables.\n",
      "\n",
      "    Note that for complex numbers, the absolute value is taken before\n",
      "    squaring, so that the result is always real and nonnegative.\n",
      "\n",
      "    For floating-point input, the variance is computed using the same\n",
      "    precision the input has.  Depending on the input data, this can cause\n",
      "    the results to be inaccurate, especially for `float32` (see example\n",
      "    below).  Specifying a higher-accuracy accumulator using the ``dtype``\n",
      "    keyword can alleviate this issue.\n",
      "\n",
      "    For this function to work on sub-classes of ndarray, they must define\n",
      "    `sum` with the kwarg `keepdims`\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, np.nan], [3, 4]])\n",
      "    >>> np.nanvar(a)\n",
      "    1.5555555555555554\n",
      "    >>> np.nanvar(a, axis=0)\n",
      "    array([1.,  0.])\n",
      "    >>> np.nanvar(a, axis=1)\n",
      "    array([0.,  0.25])  # may vary\n",
      "\n",
      "    \n",
      "code: nanstd\n",
      "@array_function_dispatch(_nanstd_dispatcher)\n",
      "def nanstd(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue,\n",
      "           *, where=np._NoValue):\n",
      "    var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "                 keepdims=keepdims, where=where)\n",
      "    if isinstance(var, np.ndarray):\n",
      "        std = np.sqrt(var, out=var)\n",
      "    elif hasattr(var, 'dtype'):\n",
      "        std = var.dtype.type(np.sqrt(var))\n",
      "    else:\n",
      "        std = np.sqrt(var)\n",
      "    return std\n",
      "docstring: nanstd\n",
      "\n",
      "    Compute the standard deviation along the specified axis, while\n",
      "    ignoring NaNs.\n",
      "\n",
      "    Returns the standard deviation, a measure of the spread of a\n",
      "    distribution, of the non-NaN array elements. The standard deviation is\n",
      "    computed for the flattened array by default, otherwise over the\n",
      "    specified axis.\n",
      "\n",
      "    For all-NaN slices or slices with zero degrees of freedom, NaN is\n",
      "    returned and a `RuntimeWarning` is raised.\n",
      "\n",
      "    .. versionadded:: 1.8.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Calculate the standard deviation of the non-NaN values.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the standard deviation is computed. The default is\n",
      "        to compute the standard deviation of the flattened array.\n",
      "    dtype : dtype, optional\n",
      "        Type to use in computing the standard deviation. For arrays of\n",
      "        integer type the default is float64, for arrays of float types it\n",
      "        is the same as the array type.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output but the type (of the\n",
      "        calculated values) will be cast if necessary.\n",
      "    ddof : int, optional\n",
      "        Means Delta Degrees of Freedom.  The divisor used in calculations\n",
      "        is ``N - ddof``, where ``N`` represents the number of non-NaN\n",
      "        elements.  By default `ddof` is zero.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the original `a`.\n",
      "\n",
      "        If this value is anything but the default it is passed through\n",
      "        as-is to the relevant functions of the sub-classes.  If these\n",
      "        functions do not have a `keepdims` kwarg, a RuntimeError will\n",
      "        be raised.\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the standard deviation.\n",
      "        See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    standard_deviation : ndarray, see dtype parameter above.\n",
      "        If `out` is None, return a new array containing the standard\n",
      "        deviation, otherwise return a reference to the output array. If\n",
      "        ddof is >= the number of non-NaN elements in a slice or the slice\n",
      "        contains only NaNs, then the result for that slice is NaN.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    var, mean, std\n",
      "    nanvar, nanmean\n",
      "    :ref:`ufuncs-output-type`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The standard deviation is the square root of the average of the squared\n",
      "    deviations from the mean: ``std = sqrt(mean(abs(x - x.mean())**2))``.\n",
      "\n",
      "    The average squared deviation is normally calculated as\n",
      "    ``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is\n",
      "    specified, the divisor ``N - ddof`` is used instead. In standard\n",
      "    statistical practice, ``ddof=1`` provides an unbiased estimator of the\n",
      "    variance of the infinite population. ``ddof=0`` provides a maximum\n",
      "    likelihood estimate of the variance for normally distributed variables.\n",
      "    The standard deviation computed in this function is the square root of\n",
      "    the estimated variance, so even with ``ddof=1``, it will not be an\n",
      "    unbiased estimate of the standard deviation per se.\n",
      "\n",
      "    Note that, for complex numbers, `std` takes the absolute value before\n",
      "    squaring, so that the result is always real and nonnegative.\n",
      "\n",
      "    For floating-point input, the *std* is computed using the same\n",
      "    precision the input has. Depending on the input data, this can cause\n",
      "    the results to be inaccurate, especially for float32 (see example\n",
      "    below).  Specifying a higher-accuracy accumulator using the `dtype`\n",
      "    keyword can alleviate this issue.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, np.nan], [3, 4]])\n",
      "    >>> np.nanstd(a)\n",
      "    1.247219128924647\n",
      "    >>> np.nanstd(a, axis=0)\n",
      "    array([1., 0.])\n",
      "    >>> np.nanstd(a, axis=1)\n",
      "    array([0.,  0.5]) # may vary\n",
      "\n",
      "    \n",
      "code: nanprod\n",
      "@array_function_dispatch(_nanprod_dispatcher)\n",
      "def nanprod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n",
      "            initial=np._NoValue, where=np._NoValue):\n",
      "    a, mask = _replace_nan(a, 1)\n",
      "    return np.prod(a, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n",
      "                   initial=initial, where=where)\n",
      "docstring: nanprod\n",
      "\n",
      "    Return the product of array elements over a given axis treating Not a\n",
      "    Numbers (NaNs) as ones.\n",
      "\n",
      "    One is returned for slices that are all-NaN or empty.\n",
      "\n",
      "    .. versionadded:: 1.10.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose product is desired. If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the product is computed. The default is to compute\n",
      "        the product of the flattened array.\n",
      "    dtype : data-type, optional\n",
      "        The type of the returned array and of the accumulator in which the\n",
      "        elements are summed.  By default, the dtype of `a` is used.  An\n",
      "        exception is when `a` has an integer type with less precision than\n",
      "        the platform (u)intp. In that case, the default will be either\n",
      "        (u)int32 or (u)int64 depending on whether the platform is 32 or 64\n",
      "        bits. For inexact inputs, dtype must be inexact.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  The default\n",
      "        is ``None``. If provided, it must have the same shape as the\n",
      "        expected output, but the type will be cast if necessary. See\n",
      "        :ref:`ufuncs-output-type` for more details. The casting of NaN to integer\n",
      "        can yield unexpected results.\n",
      "    keepdims : bool, optional\n",
      "        If True, the axes which are reduced are left in the result as\n",
      "        dimensions with size one. With this option, the result will\n",
      "        broadcast correctly against the original `arr`.\n",
      "    initial : scalar, optional\n",
      "        The starting value for this product. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the product. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "\n",
      "        .. versionadded:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    nanprod : ndarray\n",
      "        A new array holding the result is returned unless `out` is\n",
      "        specified, in which case it is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.prod : Product across array propagating NaNs.\n",
      "    isnan : Show which elements are NaN.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.nanprod(1)\n",
      "    1\n",
      "    >>> np.nanprod([1])\n",
      "    1\n",
      "    >>> np.nanprod([1, np.nan])\n",
      "    1.0\n",
      "    >>> a = np.array([[1, 2], [3, np.nan]])\n",
      "    >>> np.nanprod(a)\n",
      "    6.0\n",
      "    >>> np.nanprod(a, axis=0)\n",
      "    array([3., 2.])\n",
      "\n",
      "    \n",
      "code: nancumsum\n",
      "@array_function_dispatch(_nancumsum_dispatcher)\n",
      "def nancumsum(a, axis=None, dtype=None, out=None):\n",
      "    a, mask = _replace_nan(a, 0)\n",
      "    return np.cumsum(a, axis=axis, dtype=dtype, out=out)\n",
      "docstring: nancumsum\n",
      "\n",
      "    Return the cumulative sum of array elements over a given axis treating Not a\n",
      "    Numbers (NaNs) as zero.  The cumulative sum does not change when NaNs are\n",
      "    encountered and leading NaNs are replaced by zeros.\n",
      "\n",
      "    Zeros are returned for slices that are all-NaN or empty.\n",
      "\n",
      "    .. versionadded:: 1.12.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axis : int, optional\n",
      "        Axis along which the cumulative sum is computed. The default\n",
      "        (None) is to compute the cumsum over the flattened array.\n",
      "    dtype : dtype, optional\n",
      "        Type of the returned array and of the accumulator in which the\n",
      "        elements are summed.  If `dtype` is not specified, it defaults\n",
      "        to the dtype of `a`, unless `a` has an integer dtype with a\n",
      "        precision less than that of the default platform integer.  In\n",
      "        that case, the default platform integer is used.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must\n",
      "        have the same shape and buffer length as the expected output\n",
      "        but the type will be cast if necessary. See :ref:`ufuncs-output-type` for\n",
      "        more details.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    nancumsum : ndarray.\n",
      "        A new array holding the result is returned unless `out` is\n",
      "        specified, in which it is returned. The result has the same\n",
      "        size as `a`, and the same shape as `a` if `axis` is not None\n",
      "        or `a` is a 1-d array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.cumsum : Cumulative sum across array propagating NaNs.\n",
      "    isnan : Show which elements are NaN.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.nancumsum(1)\n",
      "    array([1])\n",
      "    >>> np.nancumsum([1])\n",
      "    array([1])\n",
      "    >>> np.nancumsum([1, np.nan])\n",
      "    array([1.,  1.])\n",
      "    >>> a = np.array([[1, 2], [3, np.nan]])\n",
      "    >>> np.nancumsum(a)\n",
      "    array([1.,  3.,  6.,  6.])\n",
      "    >>> np.nancumsum(a, axis=0)\n",
      "    array([[1.,  2.],\n",
      "           [4.,  2.]])\n",
      "    >>> np.nancumsum(a, axis=1)\n",
      "    array([[1.,  3.],\n",
      "           [3.,  3.]])\n",
      "\n",
      "    \n",
      "code: nancumprod\n",
      "@array_function_dispatch(_nancumprod_dispatcher)\n",
      "def nancumprod(a, axis=None, dtype=None, out=None):\n",
      "    a, mask = _replace_nan(a, 1)\n",
      "    return np.cumprod(a, axis=axis, dtype=dtype, out=out)\n",
      "docstring: nancumprod\n",
      "\n",
      "    Return the cumulative product of array elements over a given axis treating Not a\n",
      "    Numbers (NaNs) as one.  The cumulative product does not change when NaNs are\n",
      "    encountered and leading NaNs are replaced by ones.\n",
      "\n",
      "    Ones are returned for slices that are all-NaN or empty.\n",
      "\n",
      "    .. versionadded:: 1.12.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    axis : int, optional\n",
      "        Axis along which the cumulative product is computed.  By default\n",
      "        the input is flattened.\n",
      "    dtype : dtype, optional\n",
      "        Type of the returned array, as well as of the accumulator in which\n",
      "        the elements are multiplied.  If *dtype* is not specified, it\n",
      "        defaults to the dtype of `a`, unless `a` has an integer dtype with\n",
      "        a precision less than that of the default platform integer.  In\n",
      "        that case, the default platform integer is used instead.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must\n",
      "        have the same shape and buffer length as the expected output\n",
      "        but the type of the resulting values will be cast if necessary.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    nancumprod : ndarray\n",
      "        A new array holding the result is returned unless `out` is\n",
      "        specified, in which case it is returned.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    numpy.cumprod : Cumulative product across array propagating NaNs.\n",
      "    isnan : Show which elements are NaN.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.nancumprod(1)\n",
      "    array([1])\n",
      "    >>> np.nancumprod([1])\n",
      "    array([1])\n",
      "    >>> np.nancumprod([1, np.nan])\n",
      "    array([1.,  1.])\n",
      "    >>> a = np.array([[1, 2], [3, np.nan]])\n",
      "    >>> np.nancumprod(a)\n",
      "    array([1.,  2.,  6.,  6.])\n",
      "    >>> np.nancumprod(a, axis=0)\n",
      "    array([[1.,  2.],\n",
      "           [3.,  2.]])\n",
      "    >>> np.nancumprod(a, axis=1)\n",
      "    array([[1.,  2.],\n",
      "           [3.,  3.]])\n",
      "\n",
      "    \n",
      "code: nanquantile\n",
      "@array_function_dispatch(_nanquantile_dispatcher)\n",
      "def nanquantile(\n",
      "        a,\n",
      "        q,\n",
      "        axis=None,\n",
      "        out=None,\n",
      "        overwrite_input=False,\n",
      "        method=\"linear\",\n",
      "        keepdims=np._NoValue,\n",
      "        *,\n",
      "        interpolation=None,\n",
      "):\n",
      "    if interpolation is not None:\n",
      "        method = function_base._check_interpolation_as_method(\n",
      "            method, interpolation, \"nanquantile\")\n",
      "    a = np.asanyarray(a)\n",
      "    q = np.asanyarray(q)\n",
      "    if not function_base._quantile_is_valid(q):\n",
      "        raise ValueError(\"Quantiles must be in the range [0, 1]\")\n",
      "    return _nanquantile_unchecked(\n",
      "        a, q, axis, out, overwrite_input, method, keepdims)\n",
      "docstring: nanquantile\n",
      "\n",
      "    Compute the qth quantile of the data along the specified axis,\n",
      "    while ignoring nan values.\n",
      "    Returns the qth quantile(s) of the array elements.\n",
      "\n",
      "    .. versionadded:: 1.15.0\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array or object that can be converted to an array, containing\n",
      "        nan values to be ignored\n",
      "    q : array_like of float\n",
      "        Quantile or sequence of quantiles to compute, which must be between\n",
      "        0 and 1 inclusive.\n",
      "    axis : {int, tuple of int, None}, optional\n",
      "        Axis or axes along which the quantiles are computed. The\n",
      "        default is to compute the quantile(s) along a flattened\n",
      "        version of the array.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must\n",
      "        have the same shape and buffer length as the expected output,\n",
      "        but the type (of the output) will be cast if necessary.\n",
      "    overwrite_input : bool, optional\n",
      "        If True, then allow the input array `a` to be modified by intermediate\n",
      "        calculations, to save memory. In this case, the contents of the input\n",
      "        `a` after this function completes is undefined.\n",
      "    method : str, optional\n",
      "        This parameter specifies the method to use for estimating the\n",
      "        quantile.  There are many different methods, some unique to NumPy.\n",
      "        See the notes for explanation.  The options sorted by their R type\n",
      "        as summarized in the H&F paper [1]_ are:\n",
      "\n",
      "        1. 'inverted_cdf'\n",
      "        2. 'averaged_inverted_cdf'\n",
      "        3. 'closest_observation'\n",
      "        4. 'interpolated_inverted_cdf'\n",
      "        5. 'hazen'\n",
      "        6. 'weibull'\n",
      "        7. 'linear'  (default)\n",
      "        8. 'median_unbiased'\n",
      "        9. 'normal_unbiased'\n",
      "\n",
      "        The first three methods are discontinuous.  NumPy further defines the\n",
      "        following discontinuous variations of the default 'linear' (7.) option:\n",
      "\n",
      "        * 'lower'\n",
      "        * 'higher',\n",
      "        * 'midpoint'\n",
      "        * 'nearest'\n",
      "\n",
      "        .. versionchanged:: 1.22.0\n",
      "            This argument was previously called \"interpolation\" and only\n",
      "            offered the \"linear\" default and last four options.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left in\n",
      "        the result as dimensions with size one. With this option, the\n",
      "        result will broadcast correctly against the original array `a`.\n",
      "\n",
      "        If this is anything but the default value it will be passed\n",
      "        through (in the special case of an empty array) to the\n",
      "        `mean` function of the underlying array.  If the array is\n",
      "        a sub-class and `mean` does not have the kwarg `keepdims` this\n",
      "        will raise a RuntimeError.\n",
      "\n",
      "    interpolation : str, optional\n",
      "        Deprecated name for the method keyword argument.\n",
      "\n",
      "        .. deprecated:: 1.22.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    quantile : scalar or ndarray\n",
      "        If `q` is a single percentile and `axis=None`, then the result\n",
      "        is a scalar. If multiple quantiles are given, first axis of\n",
      "        the result corresponds to the quantiles. The other axes are\n",
      "        the axes that remain after the reduction of `a`. If the input\n",
      "        contains integers or floats smaller than ``float64``, the output\n",
      "        data-type is ``float64``. Otherwise, the output data-type is the\n",
      "        same as that of the input. If `out` is specified, that array is\n",
      "        returned instead.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    quantile\n",
      "    nanmean, nanmedian\n",
      "    nanmedian : equivalent to ``nanquantile(..., 0.5)``\n",
      "    nanpercentile : same as nanquantile, but with q in the range [0, 100].\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    For more information please see `numpy.quantile`\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[10., 7., 4.], [3., 2., 1.]])\n",
      "    >>> a[0][1] = np.nan\n",
      "    >>> a\n",
      "    array([[10.,  nan,   4.],\n",
      "          [ 3.,   2.,   1.]])\n",
      "    >>> np.quantile(a, 0.5)\n",
      "    nan\n",
      "    >>> np.nanquantile(a, 0.5)\n",
      "    3.0\n",
      "    >>> np.nanquantile(a, 0.5, axis=0)\n",
      "    array([6.5, 2. , 2.5])\n",
      "    >>> np.nanquantile(a, 0.5, axis=1, keepdims=True)\n",
      "    array([[7.],\n",
      "           [2.]])\n",
      "    >>> m = np.nanquantile(a, 0.5, axis=0)\n",
      "    >>> out = np.zeros_like(m)\n",
      "    >>> np.nanquantile(a, 0.5, axis=0, out=out)\n",
      "    array([6.5, 2. , 2.5])\n",
      "    >>> m\n",
      "    array([6.5,  2. ,  2.5])\n",
      "    >>> b = a.copy()\n",
      "    >>> np.nanquantile(b, 0.5, axis=1, overwrite_input=True)\n",
      "    array([7., 2.])\n",
      "    >>> assert not np.all(a==b)\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] R. J. Hyndman and Y. Fan,\n",
      "       \"Sample quantiles in statistical packages,\"\n",
      "       The American Statistician, 50(4), pp. 361-365, 1996\n",
      "\n",
      "    \n",
      "code: histogram\n",
      "@array_function_dispatch(_histogram_dispatcher)\n",
      "def histogram(a, bins=10, range=None, density=None, weights=None):\n",
      "    r\"\"\"\n",
      "    Compute the histogram of a dataset.\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data. The histogram is computed over the flattened array.\n",
      "    bins : int or sequence of scalars or str, optional\n",
      "        If `bins` is an int, it defines the number of equal-width\n",
      "        bins in the given range (10, by default). If `bins` is a\n",
      "        sequence, it defines a monotonically increasing array of bin edges,\n",
      "        including the rightmost edge, allowing for non-uniform bin widths.\n",
      "        .. versionadded:: 1.11.0\n",
      "        If `bins` is a string, it defines the method used to calculate the\n",
      "        optimal bin width, as defined by `histogram_bin_edges`.\n",
      "    range : (float, float), optional\n",
      "        The lower and upper range of the bins.  If not provided, range\n",
      "        is simply ``(a.min(), a.max())``.  Values outside the range are\n",
      "        ignored. The first element of the range must be less than or\n",
      "        equal to the second. `range` affects the automatic bin\n",
      "        computation as well. While bin width is computed to be optimal\n",
      "        based on the actual data within `range`, the bin count will fill\n",
      "        the entire range including portions containing no data.\n",
      "    weights : array_like, optional\n",
      "        An array of weights, of the same shape as `a`.  Each value in\n",
      "        `a` only contributes its associated weight towards the bin count\n",
      "        (instead of 1). If `density` is True, the weights are\n",
      "        normalized, so that the integral of the density over the range\n",
      "        remains 1.\n",
      "    density : bool, optional\n",
      "        If ``False``, the result will contain the number of samples in\n",
      "        each bin. If ``True``, the result is the value of the\n",
      "        probability *density* function at the bin, normalized such that\n",
      "        the *integral* over the range is 1. Note that the sum of the\n",
      "        histogram values will not be equal to 1 unless bins of unity\n",
      "        width are chosen; it is not a probability *mass* function.\n",
      "    Returns\n",
      "    -------\n",
      "    hist : array\n",
      "        The values of the histogram. See `density` and `weights` for a\n",
      "        description of the possible semantics.\n",
      "    bin_edges : array of dtype float\n",
      "        Return the bin edges ``(length(hist)+1)``.\n",
      "    See Also\n",
      "    --------\n",
      "    histogramdd, bincount, searchsorted, digitize, histogram_bin_edges\n",
      "    Notes\n",
      "    -----\n",
      "    All but the last (righthand-most) bin is half-open.  In other words,\n",
      "    if `bins` is::\n",
      "      [1, 2, 3, 4]\n",
      "    then the first bin is ``[1, 2)`` (including 1, but excluding 2) and\n",
      "    the second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which\n",
      "    *includes* 4.\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.histogram([1, 2, 1], bins=[0, 1, 2, 3])\n",
      "    (array([0, 2, 1]), array([0, 1, 2, 3]))\n",
      "    >>> np.histogram(np.arange(4), bins=np.arange(5), density=True)\n",
      "    (array([0.25, 0.25, 0.25, 0.25]), array([0, 1, 2, 3, 4]))\n",
      "    >>> np.histogram([[1, 2, 1], [1, 0, 1]], bins=[0,1,2,3])\n",
      "    (array([1, 4, 1]), array([0, 1, 2, 3]))\n",
      "    >>> a = np.arange(5)\n",
      "    >>> hist, bin_edges = np.histogram(a, density=True)\n",
      "    >>> hist\n",
      "    array([0.5, 0. , 0.5, 0. , 0. , 0.5, 0. , 0.5, 0. , 0.5])\n",
      "    >>> hist.sum()\n",
      "    2.4999999999999996\n",
      "    >>> np.sum(hist * np.diff(bin_edges))\n",
      "    1.0\n",
      "    .. versionadded:: 1.11.0\n",
      "    Automated Bin Selection Methods example, using 2 peak random data\n",
      "    with 2000 points:\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> rng = np.random.RandomState(10)  # deterministic random data\n",
      "    >>> a = np.hstack((rng.normal(size=1000),\n",
      "    ...                rng.normal(loc=5, scale=2, size=1000)))\n",
      "    >>> _ = plt.hist(a, bins='auto')  # arguments are passed to np.histogram\n",
      "    >>> plt.title(\"Histogram with 'auto' bins\")\n",
      "    Text(0.5, 1.0, \"Histogram with 'auto' bins\")\n",
      "    >>> plt.show()\n",
      "    \"\"\"\n",
      "    a, weights = _ravel_and_check_weights(a, weights)\n",
      "    bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)\n",
      " We set a block size, as this allows us to iterate over chunks when\n",
      " The fast path uses bincount, but that only works for certain types\n",
      " Fast algorithm for equal bins\n",
      " equal bin widths (which is valid here).\n",
      "        first_edge, last_edge, n_equal_bins = uniform_bins\n",
      " Pre-compute histogram scaling factor\n",
      "        norm = n_equal_bins / _unsigned_subtract(last_edge, first_edge)\n",
      " large arrays, it is actually faster (for example for a 10^8 array it\n",
      " limit of large arrays.\n",
      "        for i in _range(0, len(a), BLOCK):\n",
      "            tmp_a = a[i:i+BLOCK]\n",
      "            if weights is None:\n",
      "                tmp_w = None\n",
      "            else:\n",
      "                tmp_w = weights[i:i + BLOCK]\n",
      " This cast ensures no type promotions occur below, which gh-10322\n",
      " like gh-8123.\n",
      "            tmp_a = tmp_a.astype(bin_edges.dtype, copy=False)\n",
      " last_edge we need to subtract one\n",
      "            f_indices = _unsigned_subtract(tmp_a, first_edge) * norm\n",
      "            indices = f_indices.astype(np.intp)\n",
      "            indices[indices == n_equal_bins] -= 1\n",
      " consistent results within ~1 ULP of the bin edges.\n",
      "            decrement = tmp_a < bin_edges[indices]\n",
      "            indices[decrement] -= 1\n",
      " We now compute the histogram using bincount\n",
      "            if ntype.kind == 'c':\n",
      "                n.real += np.bincount(indices, weights=tmp_w.real,\n",
      "                                      minlength=n_equal_bins)\n",
      "                n.imag += np.bincount(indices, weights=tmp_w.imag,\n",
      "                                      minlength=n_equal_bins)\n",
      "            else:\n",
      "                n += np.bincount(indices, weights=tmp_w,\n",
      "                                 minlength=n_equal_bins).astype(ntype)\n",
      "    else:\n",
      "        # Compute via cumulative histogram\n",
      "        cum_n = np.zeros(bin_edges.shape, ntype)\n",
      "        if weights is None:\n",
      "            for i in _range(0, len(a), BLOCK):\n",
      "                sa = np.sort(a[i:i+BLOCK])\n",
      "                cum_n += _search_sorted_inclusive(sa, bin_edges)\n",
      "        else:\n",
      "            zero = np.zeros(1, dtype=ntype)\n",
      "            for i in _range(0, len(a), BLOCK):\n",
      "                tmp_a = a[i:i+BLOCK]\n",
      "                tmp_w = weights[i:i+BLOCK]\n",
      "                sorting_index = np.argsort(tmp_a)\n",
      "                sa = tmp_a[sorting_index]\n",
      "                sw = tmp_w[sorting_index]\n",
      "                cw = np.concatenate((zero, sw.cumsum()))\n",
      "                bin_index = _search_sorted_inclusive(sa, bin_edges)\n",
      "                cum_n += cw[bin_index]\n",
      "        n = np.diff(cum_n)\n",
      "    if density:\n",
      "        db = np.array(np.diff(bin_edges), float)\n",
      "        return n/db/n.sum(), bin_edges\n",
      "    return n, bin_edges\n",
      "docstring: histogram\n",
      "\n",
      "    Compute the histogram of a dataset.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data. The histogram is computed over the flattened array.\n",
      "    bins : int or sequence of scalars or str, optional\n",
      "        If `bins` is an int, it defines the number of equal-width\n",
      "        bins in the given range (10, by default). If `bins` is a\n",
      "        sequence, it defines a monotonically increasing array of bin edges,\n",
      "        including the rightmost edge, allowing for non-uniform bin widths.\n",
      "\n",
      "        .. versionadded:: 1.11.0\n",
      "\n",
      "        If `bins` is a string, it defines the method used to calculate the\n",
      "        optimal bin width, as defined by `histogram_bin_edges`.\n",
      "\n",
      "    range : (float, float), optional\n",
      "        The lower and upper range of the bins.  If not provided, range\n",
      "        is simply ``(a.min(), a.max())``.  Values outside the range are\n",
      "        ignored. The first element of the range must be less than or\n",
      "        equal to the second. `range` affects the automatic bin\n",
      "        computation as well. While bin width is computed to be optimal\n",
      "        based on the actual data within `range`, the bin count will fill\n",
      "        the entire range including portions containing no data.\n",
      "    weights : array_like, optional\n",
      "        An array of weights, of the same shape as `a`.  Each value in\n",
      "        `a` only contributes its associated weight towards the bin count\n",
      "        (instead of 1). If `density` is True, the weights are\n",
      "        normalized, so that the integral of the density over the range\n",
      "        remains 1.\n",
      "    density : bool, optional\n",
      "        If ``False``, the result will contain the number of samples in\n",
      "        each bin. If ``True``, the result is the value of the\n",
      "        probability *density* function at the bin, normalized such that\n",
      "        the *integral* over the range is 1. Note that the sum of the\n",
      "        histogram values will not be equal to 1 unless bins of unity\n",
      "        width are chosen; it is not a probability *mass* function.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    hist : array\n",
      "        The values of the histogram. See `density` and `weights` for a\n",
      "        description of the possible semantics.\n",
      "    bin_edges : array of dtype float\n",
      "        Return the bin edges ``(length(hist)+1)``.\n",
      "\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    histogramdd, bincount, searchsorted, digitize, histogram_bin_edges\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    All but the last (righthand-most) bin is half-open.  In other words,\n",
      "    if `bins` is::\n",
      "\n",
      "      [1, 2, 3, 4]\n",
      "\n",
      "    then the first bin is ``[1, 2)`` (including 1, but excluding 2) and\n",
      "    the second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which\n",
      "    *includes* 4.\n",
      "\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.histogram([1, 2, 1], bins=[0, 1, 2, 3])\n",
      "    (array([0, 2, 1]), array([0, 1, 2, 3]))\n",
      "    >>> np.histogram(np.arange(4), bins=np.arange(5), density=True)\n",
      "    (array([0.25, 0.25, 0.25, 0.25]), array([0, 1, 2, 3, 4]))\n",
      "    >>> np.histogram([[1, 2, 1], [1, 0, 1]], bins=[0,1,2,3])\n",
      "    (array([1, 4, 1]), array([0, 1, 2, 3]))\n",
      "\n",
      "    >>> a = np.arange(5)\n",
      "    >>> hist, bin_edges = np.histogram(a, density=True)\n",
      "    >>> hist\n",
      "    array([0.5, 0. , 0.5, 0. , 0. , 0.5, 0. , 0.5, 0. , 0.5])\n",
      "    >>> hist.sum()\n",
      "    2.4999999999999996\n",
      "    >>> np.sum(hist * np.diff(bin_edges))\n",
      "    1.0\n",
      "\n",
      "    .. versionadded:: 1.11.0\n",
      "\n",
      "    Automated Bin Selection Methods example, using 2 peak random data\n",
      "    with 2000 points:\n",
      "\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> rng = np.random.RandomState(10)  # deterministic random data\n",
      "    >>> a = np.hstack((rng.normal(size=1000),\n",
      "    ...                rng.normal(loc=5, scale=2, size=1000)))\n",
      "    >>> _ = plt.hist(a, bins='auto')  # arguments are passed to np.histogram\n",
      "    >>> plt.title(\"Histogram with 'auto' bins\")\n",
      "    Text(0.5, 1.0, \"Histogram with 'auto' bins\")\n",
      "    >>> plt.show()\n",
      "\n",
      "    \n",
      "code: histogramdd\n",
      "@array_function_dispatch(_histogramdd_dispatcher)\n",
      "def histogramdd(sample, bins=10, range=None, density=None, weights=None):\n",
      "    try:\n",
      " Sample is a sequence of 1D arrays.\n",
      "        sample = np.atleast_2d(sample).T\n",
      "        N, D = sample.shape\n",
      "    nbin = np.empty(D, np.intp)\n",
      "    edges = D*[None]\n",
      "    dedges = D*[None]\n",
      "    if weights is not None:\n",
      "        weights = np.asarray(weights)\n",
      "    try:\n",
      "        M = len(bins)\n",
      "        if M != D:\n",
      "            raise ValueError(\n",
      "                'The dimension of bins must be equal to the dimension of the '\n",
      "                ' sample x.')\n",
      "    except TypeError:\n",
      " normalize the range argument\n",
      "    if range is None:\n",
      "        range = (None,) * D\n",
      "    elif len(range) != D:\n",
      "        raise ValueError('range argument must have one entry per dimension')\n",
      " includes an outlier on each end\n",
      "        dedges[i] = np.diff(edges[i])\n",
      " avoid np.digitize to work around gh-11022\n",
      "        np.searchsorted(edges[i], sample[:, i], side='right')\n",
      "        for i in _range(D)\n",
      "    )\n",
      " For the rightmost bin, we want values equal to the right edge to be\n",
      " Find which points are on the rightmost edge.\n",
      "        on_edge = (sample[:, i] == edges[i][-1])\n",
      " Compute the sample indices in the flattened histogram matrix.\n",
      " Compute the number of repetitions in xy and assign it to the\n",
      " Shape into a proper matrix\n",
      "    hist = hist.reshape(nbin)\n",
      " Remove outliers (indices 0 and -1 for each dimension).\n",
      "    core = D*(slice(1, -1),)\n",
      "    hist = hist[core]\n",
      "    if density:\n",
      "        # calculate the probability density function\n",
      "        s = hist.sum()\n",
      "        for i in _range(D):\n",
      "            shape = np.ones(D, int)\n",
      "            shape[i] = nbin[i] - 2\n",
      "            hist = hist / dedges[i].reshape(shape)\n",
      "        hist /= s\n",
      "    if (hist.shape != nbin - 2).any():\n",
      "        raise RuntimeError(\n",
      "            \"Internal Shape Error\")\n",
      "    return hist, edges\n",
      "docstring: histogramdd\n",
      "\n",
      "    Compute the multidimensional histogram of some data.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    sample : (N, D) array, or (N, D) array_like\n",
      "        The data to be histogrammed.\n",
      "\n",
      "        Note the unusual interpretation of sample when an array_like:\n",
      "\n",
      "        * When an array, each row is a coordinate in a D-dimensional space -\n",
      "          such as ``histogramdd(np.array([p1, p2, p3]))``.\n",
      "        * When an array_like, each element is the list of values for single\n",
      "          coordinate - such as ``histogramdd((X, Y, Z))``.\n",
      "\n",
      "        The first form should be preferred.\n",
      "\n",
      "    bins : sequence or int, optional\n",
      "        The bin specification:\n",
      "\n",
      "        * A sequence of arrays describing the monotonically increasing bin\n",
      "          edges along each dimension.\n",
      "        * The number of bins for each dimension (nx, ny, ... =bins)\n",
      "        * The number of bins for all dimensions (nx=ny=...=bins).\n",
      "\n",
      "    range : sequence, optional\n",
      "        A sequence of length D, each an optional (lower, upper) tuple giving\n",
      "        the outer bin edges to be used if the edges are not given explicitly in\n",
      "        `bins`.\n",
      "        An entry of None in the sequence results in the minimum and maximum\n",
      "        values being used for the corresponding dimension.\n",
      "        The default, None, is equivalent to passing a tuple of D None values.\n",
      "    density : bool, optional\n",
      "        If False, the default, returns the number of samples in each bin.\n",
      "        If True, returns the probability *density* function at the bin,\n",
      "        ``bin_count / sample_count / bin_volume``.\n",
      "    weights : (N,) array_like, optional\n",
      "        An array of values `w_i` weighing each sample `(x_i, y_i, z_i, ...)`.\n",
      "        Weights are normalized to 1 if density is True. If density is False,\n",
      "        the values of the returned histogram are equal to the sum of the\n",
      "        weights belonging to the samples falling into each bin.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    H : ndarray\n",
      "        The multidimensional histogram of sample x. See density and weights\n",
      "        for the different possible semantics.\n",
      "    edges : list\n",
      "        A list of D arrays describing the bin edges for each dimension.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    histogram: 1-D histogram\n",
      "    histogram2d: 2-D histogram\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> r = np.random.randn(100,3)\n",
      "    >>> H, edges = np.histogramdd(r, bins = (5, 8, 4))\n",
      "    >>> H.shape, edges[0].size, edges[1].size, edges[2].size\n",
      "    ((5, 8, 4), 6, 9, 5)\n",
      "\n",
      "    \n",
      "code: histogram_bin_edges\n",
      "@array_function_dispatch(_histogram_bin_edges_dispatcher)\n",
      "def histogram_bin_edges(a, bins=10, range=None, weights=None):\n",
      "    r\"\"\"\n",
      "    Function to calculate only the edges of the bins used by the `histogram`\n",
      "    function.\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data. The histogram is computed over the flattened array.\n",
      "    bins : int or sequence of scalars or str, optional\n",
      "        If `bins` is an int, it defines the number of equal-width\n",
      "        bins in the given range (10, by default). If `bins` is a\n",
      "        sequence, it defines the bin edges, including the rightmost\n",
      "        edge, allowing for non-uniform bin widths.\n",
      "        If `bins` is a string from the list below, `histogram_bin_edges` will use\n",
      "        the method chosen to calculate the optimal bin width and\n",
      "        consequently the number of bins (see `Notes` for more detail on\n",
      "        the estimators) from the data that falls within the requested\n",
      "        range. While the bin width will be optimal for the actual data\n",
      "        in the range, the number of bins will be computed to fill the\n",
      "        entire range, including the empty portions. For visualisation,\n",
      "        using the 'auto' option is suggested. Weighted data is not\n",
      "        supported for automated bin size selection.\n",
      "        'auto'\n",
      "            Maximum of the 'sturges' and 'fd' estimators. Provides good\n",
      "            all around performance.\n",
      "        'fd' (Freedman Diaconis Estimator)\n",
      "            Robust (resilient to outliers) estimator that takes into\n",
      "            account data variability and data size.\n",
      "        'doane'\n",
      "            An improved version of Sturges' estimator that works better\n",
      "            with non-normal datasets.\n",
      "        'scott'\n",
      "            Less robust estimator that takes into account data variability\n",
      "            and data size.\n",
      "        'stone'\n",
      "            Estimator based on leave-one-out cross-validation estimate of\n",
      "            the integrated squared error. Can be regarded as a generalization\n",
      "            of Scott's rule.\n",
      "        'rice'\n",
      "            Estimator does not take variability into account, only data\n",
      "            size. Commonly overestimates number of bins required.\n",
      "        'sturges'\n",
      "            R's default method, only accounts for data size. Only\n",
      "            optimal for gaussian data and underestimates number of bins\n",
      "            for large non-gaussian datasets.\n",
      "        'sqrt'\n",
      "            Square root (of data size) estimator, used by Excel and\n",
      "            other programs for its speed and simplicity.\n",
      "    range : (float, float), optional\n",
      "        The lower and upper range of the bins.  If not provided, range\n",
      "        is simply ``(a.min(), a.max())``.  Values outside the range are\n",
      "        ignored. The first element of the range must be less than or\n",
      "        equal to the second. `range` affects the automatic bin\n",
      "        computation as well. While bin width is computed to be optimal\n",
      "        based on the actual data within `range`, the bin count will fill\n",
      "        the entire range including portions containing no data.\n",
      "    weights : array_like, optional\n",
      "        An array of weights, of the same shape as `a`.  Each value in\n",
      "        `a` only contributes its associated weight towards the bin count\n",
      "        (instead of 1). This is currently not used by any of the bin estimators,\n",
      "        but may be in the future.\n",
      "    Returns\n",
      "    -------\n",
      "    bin_edges : array of dtype float\n",
      "        The edges to pass into `histogram`\n",
      "    See Also\n",
      "    --------\n",
      "    histogram\n",
      "    Notes\n",
      "    -----\n",
      "    The methods to estimate the optimal number of bins are well founded\n",
      "    in literature, and are inspired by the choices R provides for\n",
      "    histogram visualisation. Note that having the number of bins\n",
      "    proportional to :math:`n^{1/3}` is asymptotically optimal, which is\n",
      "    why it appears in most estimators. These are simply plug-in methods\n",
      "    that give good starting points for number of bins. In the equations\n",
      "    below, :math:`h` is the binwidth and :math:`n_h` is the number of\n",
      "    bins. All estimators that compute bin counts are recast to bin width\n",
      "    using the `ptp` of the data. The final bin count is obtained from\n",
      "    ``np.round(np.ceil(range / h))``. The final bin width is often less\n",
      "    than what is returned by the estimators below.\n",
      "    'auto' (maximum of the 'sturges' and 'fd' estimators)\n",
      "        A compromise to get a good value. For small datasets the Sturges\n",
      "        value will usually be chosen, while larger datasets will usually\n",
      "        default to FD.  Avoids the overly conservative behaviour of FD\n",
      "        and Sturges for small and large datasets respectively.\n",
      "        Switchover point is usually :math:`a.size \\approx 1000`.\n",
      "    'fd' (Freedman Diaconis Estimator)\n",
      "        .. math:: h = 2 \\frac{IQR}{n^{1/3}}\n",
      "        The binwidth is proportional to the interquartile range (IQR)\n",
      "        and inversely proportional to cube root of a.size. Can be too\n",
      "        conservative for small datasets, but is quite good for large\n",
      "        datasets. The IQR is very robust to outliers.\n",
      "    'scott'\n",
      "        .. math:: h = \\sigma \\sqrt[3]{\\frac{24 \\sqrt{\\pi}}{n}}\n",
      "        The binwidth is proportional to the standard deviation of the\n",
      "        data and inversely proportional to cube root of ``x.size``. Can\n",
      "        be too conservative for small datasets, but is quite good for\n",
      "        large datasets. The standard deviation is not very robust to\n",
      "        outliers. Values are very similar to the Freedman-Diaconis\n",
      "        estimator in the absence of outliers.\n",
      "    'rice'\n",
      "        .. math:: n_h = 2n^{1/3}\n",
      "        The number of bins is only proportional to cube root of\n",
      "        ``a.size``. It tends to overestimate the number of bins and it\n",
      "        does not take into account data variability.\n",
      "    'sturges'\n",
      "        .. math:: n_h = \\log _{2}(n) + 1\n",
      "        The number of bins is the base 2 log of ``a.size``.  This\n",
      "        estimator assumes normality of data and is too conservative for\n",
      "        larger, non-normal datasets. This is the default method in R's\n",
      "        ``hist`` method.\n",
      "    'doane'\n",
      "        .. math:: n_h = 1 + \\log_{2}(n) +\n",
      "                        \\log_{2}\\left(1 + \\frac{|g_1|}{\\sigma_{g_1}}\\right)\n",
      "            g_1 = mean\\left[\\left(\\frac{x - \\mu}{\\sigma}\\right)^3\\right]\n",
      "            \\sigma_{g_1} = \\sqrt{\\frac{6(n - 2)}{(n + 1)(n + 3)}}\n",
      "        An improved version of Sturges' formula that produces better\n",
      "        estimates for non-normal datasets. This estimator attempts to\n",
      "        account for the skew of the data.\n",
      "    'sqrt'\n",
      "        .. math:: n_h = \\sqrt n\n",
      "        The simplest and fastest estimator. Only takes into account the\n",
      "        data size.\n",
      "    Examples\n",
      "    --------\n",
      "    >>> arr = np.array([0, 0, 0, 1, 2, 3, 3, 4, 5])\n",
      "    >>> np.histogram_bin_edges(arr, bins='auto', range=(0, 1))\n",
      "    array([0.  , 0.25, 0.5 , 0.75, 1.  ])\n",
      "    >>> np.histogram_bin_edges(arr, bins=2)\n",
      "    array([0. , 2.5, 5. ])\n",
      "    For consistency with histogram, an array of pre-computed bins is\n",
      "    passed through unmodified:\n",
      "    >>> np.histogram_bin_edges(arr, [1, 2])\n",
      "    array([1, 2])\n",
      "    This function allows one set of bins to be computed, and reused across\n",
      "    multiple histograms:\n",
      "    >>> shared_bins = np.histogram_bin_edges(arr, bins='auto')\n",
      "    >>> shared_bins\n",
      "    array([0., 1., 2., 3., 4., 5.])\n",
      "    >>> group_id = np.array([0, 1, 1, 0, 1, 1, 0, 1, 1])\n",
      "    >>> hist_0, _ = np.histogram(arr[group_id == 0], bins=shared_bins)\n",
      "    >>> hist_1, _ = np.histogram(arr[group_id == 1], bins=shared_bins)\n",
      "    >>> hist_0; hist_1\n",
      "    array([1, 1, 0, 1, 0])\n",
      "    array([2, 0, 1, 1, 2])\n",
      "    Which gives more easily comparable results than using separate bins for\n",
      "    each histogram:\n",
      "    >>> hist_0, bins_0 = np.histogram(arr[group_id == 0], bins='auto')\n",
      "    >>> hist_1, bins_1 = np.histogram(arr[group_id == 1], bins='auto')\n",
      "    >>> hist_0; hist_1\n",
      "    array([1, 1, 1])\n",
      "    array([2, 1, 1, 2])\n",
      "    >>> bins_0; bins_1\n",
      "    array([0., 1., 2., 3.])\n",
      "    array([0.  , 1.25, 2.5 , 3.75, 5.  ])\n",
      "    \"\"\"\n",
      "    a, weights = _ravel_and_check_weights(a, weights)\n",
      "    bin_edges, _ = _get_bin_edges(a, bins, range, weights)\n",
      "    return bin_edges\n",
      "docstring: histogram_bin_edges\n",
      "\n",
      "    Function to calculate only the edges of the bins used by the `histogram`\n",
      "    function.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data. The histogram is computed over the flattened array.\n",
      "    bins : int or sequence of scalars or str, optional\n",
      "        If `bins` is an int, it defines the number of equal-width\n",
      "        bins in the given range (10, by default). If `bins` is a\n",
      "        sequence, it defines the bin edges, including the rightmost\n",
      "        edge, allowing for non-uniform bin widths.\n",
      "\n",
      "        If `bins` is a string from the list below, `histogram_bin_edges` will use\n",
      "        the method chosen to calculate the optimal bin width and\n",
      "        consequently the number of bins (see `Notes` for more detail on\n",
      "        the estimators) from the data that falls within the requested\n",
      "        range. While the bin width will be optimal for the actual data\n",
      "        in the range, the number of bins will be computed to fill the\n",
      "        entire range, including the empty portions. For visualisation,\n",
      "        using the 'auto' option is suggested. Weighted data is not\n",
      "        supported for automated bin size selection.\n",
      "\n",
      "        'auto'\n",
      "            Maximum of the 'sturges' and 'fd' estimators. Provides good\n",
      "            all around performance.\n",
      "\n",
      "        'fd' (Freedman Diaconis Estimator)\n",
      "            Robust (resilient to outliers) estimator that takes into\n",
      "            account data variability and data size.\n",
      "\n",
      "        'doane'\n",
      "            An improved version of Sturges' estimator that works better\n",
      "            with non-normal datasets.\n",
      "\n",
      "        'scott'\n",
      "            Less robust estimator that takes into account data variability\n",
      "            and data size.\n",
      "\n",
      "        'stone'\n",
      "            Estimator based on leave-one-out cross-validation estimate of\n",
      "            the integrated squared error. Can be regarded as a generalization\n",
      "            of Scott's rule.\n",
      "\n",
      "        'rice'\n",
      "            Estimator does not take variability into account, only data\n",
      "            size. Commonly overestimates number of bins required.\n",
      "\n",
      "        'sturges'\n",
      "            R's default method, only accounts for data size. Only\n",
      "            optimal for gaussian data and underestimates number of bins\n",
      "            for large non-gaussian datasets.\n",
      "\n",
      "        'sqrt'\n",
      "            Square root (of data size) estimator, used by Excel and\n",
      "            other programs for its speed and simplicity.\n",
      "\n",
      "    range : (float, float), optional\n",
      "        The lower and upper range of the bins.  If not provided, range\n",
      "        is simply ``(a.min(), a.max())``.  Values outside the range are\n",
      "        ignored. The first element of the range must be less than or\n",
      "        equal to the second. `range` affects the automatic bin\n",
      "        computation as well. While bin width is computed to be optimal\n",
      "        based on the actual data within `range`, the bin count will fill\n",
      "        the entire range including portions containing no data.\n",
      "\n",
      "    weights : array_like, optional\n",
      "        An array of weights, of the same shape as `a`.  Each value in\n",
      "        `a` only contributes its associated weight towards the bin count\n",
      "        (instead of 1). This is currently not used by any of the bin estimators,\n",
      "        but may be in the future.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    bin_edges : array of dtype float\n",
      "        The edges to pass into `histogram`\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    histogram\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The methods to estimate the optimal number of bins are well founded\n",
      "    in literature, and are inspired by the choices R provides for\n",
      "    histogram visualisation. Note that having the number of bins\n",
      "    proportional to :math:`n^{1/3}` is asymptotically optimal, which is\n",
      "    why it appears in most estimators. These are simply plug-in methods\n",
      "    that give good starting points for number of bins. In the equations\n",
      "    below, :math:`h` is the binwidth and :math:`n_h` is the number of\n",
      "    bins. All estimators that compute bin counts are recast to bin width\n",
      "    using the `ptp` of the data. The final bin count is obtained from\n",
      "    ``np.round(np.ceil(range / h))``. The final bin width is often less\n",
      "    than what is returned by the estimators below.\n",
      "\n",
      "    'auto' (maximum of the 'sturges' and 'fd' estimators)\n",
      "        A compromise to get a good value. For small datasets the Sturges\n",
      "        value will usually be chosen, while larger datasets will usually\n",
      "        default to FD.  Avoids the overly conservative behaviour of FD\n",
      "        and Sturges for small and large datasets respectively.\n",
      "        Switchover point is usually :math:`a.size \\approx 1000`.\n",
      "\n",
      "    'fd' (Freedman Diaconis Estimator)\n",
      "        .. math:: h = 2 \\frac{IQR}{n^{1/3}}\n",
      "\n",
      "        The binwidth is proportional to the interquartile range (IQR)\n",
      "        and inversely proportional to cube root of a.size. Can be too\n",
      "        conservative for small datasets, but is quite good for large\n",
      "        datasets. The IQR is very robust to outliers.\n",
      "\n",
      "    'scott'\n",
      "        .. math:: h = \\sigma \\sqrt[3]{\\frac{24 \\sqrt{\\pi}}{n}}\n",
      "\n",
      "        The binwidth is proportional to the standard deviation of the\n",
      "        data and inversely proportional to cube root of ``x.size``. Can\n",
      "        be too conservative for small datasets, but is quite good for\n",
      "        large datasets. The standard deviation is not very robust to\n",
      "        outliers. Values are very similar to the Freedman-Diaconis\n",
      "        estimator in the absence of outliers.\n",
      "\n",
      "    'rice'\n",
      "        .. math:: n_h = 2n^{1/3}\n",
      "\n",
      "        The number of bins is only proportional to cube root of\n",
      "        ``a.size``. It tends to overestimate the number of bins and it\n",
      "        does not take into account data variability.\n",
      "\n",
      "    'sturges'\n",
      "        .. math:: n_h = \\log _{2}(n) + 1\n",
      "\n",
      "        The number of bins is the base 2 log of ``a.size``.  This\n",
      "        estimator assumes normality of data and is too conservative for\n",
      "        larger, non-normal datasets. This is the default method in R's\n",
      "        ``hist`` method.\n",
      "\n",
      "    'doane'\n",
      "        .. math:: n_h = 1 + \\log_{2}(n) +\n",
      "                        \\log_{2}\\left(1 + \\frac{|g_1|}{\\sigma_{g_1}}\\right)\n",
      "\n",
      "            g_1 = mean\\left[\\left(\\frac{x - \\mu}{\\sigma}\\right)^3\\right]\n",
      "\n",
      "            \\sigma_{g_1} = \\sqrt{\\frac{6(n - 2)}{(n + 1)(n + 3)}}\n",
      "\n",
      "        An improved version of Sturges' formula that produces better\n",
      "        estimates for non-normal datasets. This estimator attempts to\n",
      "        account for the skew of the data.\n",
      "\n",
      "    'sqrt'\n",
      "        .. math:: n_h = \\sqrt n\n",
      "\n",
      "        The simplest and fastest estimator. Only takes into account the\n",
      "        data size.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> arr = np.array([0, 0, 0, 1, 2, 3, 3, 4, 5])\n",
      "    >>> np.histogram_bin_edges(arr, bins='auto', range=(0, 1))\n",
      "    array([0.  , 0.25, 0.5 , 0.75, 1.  ])\n",
      "    >>> np.histogram_bin_edges(arr, bins=2)\n",
      "    array([0. , 2.5, 5. ])\n",
      "\n",
      "    For consistency with histogram, an array of pre-computed bins is\n",
      "    passed through unmodified:\n",
      "\n",
      "    >>> np.histogram_bin_edges(arr, [1, 2])\n",
      "    array([1, 2])\n",
      "\n",
      "    This function allows one set of bins to be computed, and reused across\n",
      "    multiple histograms:\n",
      "\n",
      "    >>> shared_bins = np.histogram_bin_edges(arr, bins='auto')\n",
      "    >>> shared_bins\n",
      "    array([0., 1., 2., 3., 4., 5.])\n",
      "\n",
      "    >>> group_id = np.array([0, 1, 1, 0, 1, 1, 0, 1, 1])\n",
      "    >>> hist_0, _ = np.histogram(arr[group_id == 0], bins=shared_bins)\n",
      "    >>> hist_1, _ = np.histogram(arr[group_id == 1], bins=shared_bins)\n",
      "\n",
      "    >>> hist_0; hist_1\n",
      "    array([1, 1, 0, 1, 0])\n",
      "    array([2, 0, 1, 1, 2])\n",
      "\n",
      "    Which gives more easily comparable results than using separate bins for\n",
      "    each histogram:\n",
      "\n",
      "    >>> hist_0, bins_0 = np.histogram(arr[group_id == 0], bins='auto')\n",
      "    >>> hist_1, bins_1 = np.histogram(arr[group_id == 1], bins='auto')\n",
      "    >>> hist_0; hist_1\n",
      "    array([1, 1, 1])\n",
      "    array([2, 1, 1, 2])\n",
      "    >>> bins_0; bins_1\n",
      "    array([0., 1., 2., 3.])\n",
      "    array([0.  , 1.25, 2.5 , 3.75, 5.  ])\n",
      "\n",
      "    \n",
      "code: matrix._align\n",
      "    def _align(self, axis):\n",
      "        if axis is None:\n",
      "            return self[0, 0]\n",
      "        elif axis==0:\n",
      "            return self\n",
      "        elif axis==1:\n",
      "            return self.transpose()\n",
      "        else:\n",
      "            raise ValueError(\"unsupported axis\")\n",
      "docstring: matrix._align\n",
      "A convenience function for operations that need to preserve axis\n",
      "        orientation.\n",
      "        \n",
      "code: matrix._collapse\n",
      "    def _collapse(self, axis):\n",
      "        if axis is None:\n",
      "            return self[0, 0]\n",
      "        else:\n",
      "            return self\n",
      "docstring: matrix._collapse\n",
      "A convenience function for operations that want to collapse\n",
      "        to a scalar like _align, but are using keepdims=True\n",
      "        \n",
      "code: matrix.all\n",
      "    def all(self, axis=None, out=None):\n",
      "        return N.ndarray.all(self, axis, out, keepdims=True)._collapse(axis)\n",
      "docstring: matrix.all\n",
      "\n",
      "        Test whether all matrix elements along a given axis evaluate to True.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        See `numpy.all` for complete descriptions\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        numpy.all\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This is the same as `ndarray.all`, but it returns a `matrix` object.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> y = x[0]; y\n",
      "        matrix([[0, 1, 2, 3]])\n",
      "        >>> (x == y)\n",
      "        matrix([[ True,  True,  True,  True],\n",
      "                [False, False, False, False],\n",
      "                [False, False, False, False]])\n",
      "        >>> (x == y).all()\n",
      "        False\n",
      "        >>> (x == y).all(0)\n",
      "        matrix([[False, False, False, False]])\n",
      "        >>> (x == y).all(1)\n",
      "        matrix([[ True],\n",
      "                [False],\n",
      "                [False]])\n",
      "\n",
      "        \n",
      "code: matrix.any\n",
      "    def any(self, axis=None, out=None):\n",
      "        return N.ndarray.any(self, axis, out, keepdims=True)._collapse(axis)\n",
      "docstring: matrix.any\n",
      "\n",
      "        Test whether any array element along a given axis evaluates to True.\n",
      "\n",
      "        Refer to `numpy.any` for full documentation.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        axis : int, optional\n",
      "            Axis along which logical OR is performed\n",
      "        out : ndarray, optional\n",
      "            Output to existing array instead of creating new one, must have\n",
      "            same shape as expected output\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "            any : bool, ndarray\n",
      "                Returns a single bool if `axis` is ``None``; otherwise,\n",
      "                returns `ndarray`\n",
      "\n",
      "        \n",
      "code: matrix.argmax\n",
      "    def argmax(self, axis=None, out=None):\n",
      "        return N.ndarray.argmax(self, axis, out)._align(axis)\n",
      "docstring: matrix.argmax\n",
      "\n",
      "        Indexes of the maximum values along an axis.\n",
      "\n",
      "        Return the indexes of the first occurrences of the maximum values\n",
      "        along the specified axis.  If axis is None, the index is for the\n",
      "        flattened matrix.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        See `numpy.argmax` for complete descriptions\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        numpy.argmax\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This is the same as `ndarray.argmax`, but returns a `matrix` object\n",
      "        where `ndarray.argmax` would return an `ndarray`.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.argmax()\n",
      "        11\n",
      "        >>> x.argmax(0)\n",
      "        matrix([[2, 2, 2, 2]])\n",
      "        >>> x.argmax(1)\n",
      "        matrix([[3],\n",
      "                [3],\n",
      "                [3]])\n",
      "\n",
      "        \n",
      "code: matrix.argmin\n",
      "    def argmin(self, axis=None, out=None):\n",
      "        return N.ndarray.argmin(self, axis, out)._align(axis)\n",
      "docstring: matrix.argmin\n",
      "\n",
      "        Indexes of the minimum values along an axis.\n",
      "\n",
      "        Return the indexes of the first occurrences of the minimum values\n",
      "        along the specified axis.  If axis is None, the index is for the\n",
      "        flattened matrix.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        See `numpy.argmin` for complete descriptions.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        numpy.argmin\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This is the same as `ndarray.argmin`, but returns a `matrix` object\n",
      "        where `ndarray.argmin` would return an `ndarray`.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = -np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[  0,  -1,  -2,  -3],\n",
      "                [ -4,  -5,  -6,  -7],\n",
      "                [ -8,  -9, -10, -11]])\n",
      "        >>> x.argmin()\n",
      "        11\n",
      "        >>> x.argmin(0)\n",
      "        matrix([[2, 2, 2, 2]])\n",
      "        >>> x.argmin(1)\n",
      "        matrix([[3],\n",
      "                [3],\n",
      "                [3]])\n",
      "\n",
      "        \n",
      "code: matrix.flatten\n",
      "    def flatten(self, order='C'):\n",
      "        return N.ndarray.flatten(self, order=order)\n",
      "docstring: matrix.flatten\n",
      "\n",
      "        Return a flattened copy of the matrix.\n",
      "\n",
      "        All `N` elements of the matrix are placed into a single row.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        order : {'C', 'F', 'A', 'K'}, optional\n",
      "            'C' means to flatten in row-major (C-style) order. 'F' means to\n",
      "            flatten in column-major (Fortran-style) order. 'A' means to\n",
      "            flatten in column-major order if `m` is Fortran *contiguous* in\n",
      "            memory, row-major order otherwise. 'K' means to flatten `m` in\n",
      "            the order the elements occur in memory. The default is 'C'.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        y : matrix\n",
      "            A copy of the matrix, flattened to a `(1, N)` matrix where `N`\n",
      "            is the number of elements in the original matrix.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        ravel : Return a flattened array.\n",
      "        flat : A 1-D flat iterator over the matrix.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> m = np.matrix([[1,2], [3,4]])\n",
      "        >>> m.flatten()\n",
      "        matrix([[1, 2, 3, 4]])\n",
      "        >>> m.flatten('F')\n",
      "        matrix([[1, 3, 2, 4]])\n",
      "\n",
      "        \n",
      "code: matrix.getA\n",
      "    @property\n",
      "    def A(self):\n",
      "        return self.__array__()\n",
      "docstring: matrix.getA\n",
      "\n",
      "        Return `self` as an `ndarray` object.\n",
      "\n",
      "        Equivalent to ``np.asarray(self)``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        None\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        ret : ndarray\n",
      "            `self` as an `ndarray`\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.getA()\n",
      "        array([[ 0,  1,  2,  3],\n",
      "               [ 4,  5,  6,  7],\n",
      "               [ 8,  9, 10, 11]])\n",
      "\n",
      "        \n",
      "code: matrix.getA1\n",
      "    @property\n",
      "    def A1(self):\n",
      "        return self.__array__().ravel()\n",
      "docstring: matrix.getA1\n",
      "\n",
      "        Return `self` as a flattened `ndarray`.\n",
      "\n",
      "        Equivalent to ``np.asarray(x).ravel()``\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        None\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        ret : ndarray\n",
      "            `self`, 1-D, as an `ndarray`\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.getA1()\n",
      "        array([ 0,  1,  2, ...,  9, 10, 11])\n",
      "\n",
      "\n",
      "        \n",
      "code: matrix.getH\n",
      "    @property\n",
      "    def H(self):\n",
      "        if issubclass(self.dtype.type, N.complexfloating):\n",
      "            return self.transpose().conjugate()\n",
      "        else:\n",
      "            return self.transpose()\n",
      "docstring: matrix.getH\n",
      "\n",
      "        Returns the (complex) conjugate transpose of `self`.\n",
      "\n",
      "        Equivalent to ``np.transpose(self)`` if `self` is real-valued.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        None\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        ret : matrix object\n",
      "            complex conjugate transpose of `self`\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3,4)))\n",
      "        >>> z = x - 1j*x; z\n",
      "        matrix([[  0. +0.j,   1. -1.j,   2. -2.j,   3. -3.j],\n",
      "                [  4. -4.j,   5. -5.j,   6. -6.j,   7. -7.j],\n",
      "                [  8. -8.j,   9. -9.j,  10.-10.j,  11.-11.j]])\n",
      "        >>> z.getH()\n",
      "        matrix([[ 0. -0.j,  4. +4.j,  8. +8.j],\n",
      "                [ 1. +1.j,  5. +5.j,  9. +9.j],\n",
      "                [ 2. +2.j,  6. +6.j, 10.+10.j],\n",
      "                [ 3. +3.j,  7. +7.j, 11.+11.j]])\n",
      "\n",
      "        \n",
      "code: matrix.getI\n",
      "    @property\n",
      "    def I(self):\n",
      "        M, N = self.shape\n",
      "        if M == N:\n",
      "            from numpy.linalg import inv as func\n",
      "        else:\n",
      "            from numpy.linalg import pinv as func\n",
      "        return asmatrix(func(self))\n",
      "docstring: matrix.getI\n",
      "\n",
      "        Returns the (multiplicative) inverse of invertible `self`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        None\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        ret : matrix object\n",
      "            If `self` is non-singular, `ret` is such that ``ret * self`` ==\n",
      "            ``self * ret`` == ``np.matrix(np.eye(self[0,:].size))`` all return\n",
      "            ``True``.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        numpy.linalg.LinAlgError: Singular matrix\n",
      "            If `self` is singular.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        linalg.inv\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> m = np.matrix('[1, 2; 3, 4]'); m\n",
      "        matrix([[1, 2],\n",
      "                [3, 4]])\n",
      "        >>> m.getI()\n",
      "        matrix([[-2. ,  1. ],\n",
      "                [ 1.5, -0.5]])\n",
      "        >>> m.getI() * m\n",
      "        matrix([[ 1.,  0.], # may vary\n",
      "                [ 0.,  1.]])\n",
      "\n",
      "        \n",
      "code: matrix.getT\n",
      "    @property\n",
      "    def T(self):\n",
      "        return self.transpose()\n",
      "docstring: matrix.getT\n",
      "\n",
      "        Returns the transpose of the matrix.\n",
      "\n",
      "        Does *not* conjugate!  For the complex conjugate transpose, use ``.H``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        None\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        ret : matrix object\n",
      "            The (non-conjugated) transpose of the matrix.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        transpose, getH\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> m = np.matrix('[1, 2; 3, 4]')\n",
      "        >>> m\n",
      "        matrix([[1, 2],\n",
      "                [3, 4]])\n",
      "        >>> m.getT()\n",
      "        matrix([[1, 3],\n",
      "                [2, 4]])\n",
      "\n",
      "        \n",
      "code: matrix.max\n",
      "    def max(self, axis=None, out=None):\n",
      "        return N.ndarray.max(self, axis, out, keepdims=True)._collapse(axis)\n",
      "docstring: matrix.max\n",
      "\n",
      "        Return the maximum value along an axis.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        See `amax` for complete descriptions\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        amax, ndarray.max\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This is the same as `ndarray.max`, but returns a `matrix` object\n",
      "        where `ndarray.max` would return an ndarray.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.max()\n",
      "        11\n",
      "        >>> x.max(0)\n",
      "        matrix([[ 8,  9, 10, 11]])\n",
      "        >>> x.max(1)\n",
      "        matrix([[ 3],\n",
      "                [ 7],\n",
      "                [11]])\n",
      "\n",
      "        \n",
      "code: matrix.mean\n",
      "    def mean(self, axis=None, dtype=None, out=None):\n",
      "        return N.ndarray.mean(self, axis, dtype, out, keepdims=True)._collapse(axis)\n",
      "docstring: matrix.mean\n",
      "\n",
      "        Returns the average of the matrix elements along the given axis.\n",
      "\n",
      "        Refer to `numpy.mean` for full documentation.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        numpy.mean\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Same as `ndarray.mean` except that, where that returns an `ndarray`,\n",
      "        this returns a `matrix` object.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3, 4)))\n",
      "        >>> x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.mean()\n",
      "        5.5\n",
      "        >>> x.mean(0)\n",
      "        matrix([[4., 5., 6., 7.]])\n",
      "        >>> x.mean(1)\n",
      "        matrix([[ 1.5],\n",
      "                [ 5.5],\n",
      "                [ 9.5]])\n",
      "\n",
      "        \n",
      "code: matrix.min\n",
      "    def min(self, axis=None, out=None):\n",
      "        return N.ndarray.min(self, axis, out, keepdims=True)._collapse(axis)\n",
      "docstring: matrix.min\n",
      "\n",
      "        Return the minimum value along an axis.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        See `amin` for complete descriptions.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        amin, ndarray.min\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This is the same as `ndarray.min`, but returns a `matrix` object\n",
      "        where `ndarray.min` would return an ndarray.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = -np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[  0,  -1,  -2,  -3],\n",
      "                [ -4,  -5,  -6,  -7],\n",
      "                [ -8,  -9, -10, -11]])\n",
      "        >>> x.min()\n",
      "        -11\n",
      "        >>> x.min(0)\n",
      "        matrix([[ -8,  -9, -10, -11]])\n",
      "        >>> x.min(1)\n",
      "        matrix([[ -3],\n",
      "                [ -7],\n",
      "                [-11]])\n",
      "\n",
      "        \n",
      "code: matrix.prod\n",
      "    def prod(self, axis=None, dtype=None, out=None):\n",
      "        return N.ndarray.prod(self, axis, dtype, out, keepdims=True)._collapse(axis)\n",
      "docstring: matrix.prod\n",
      "\n",
      "        Return the product of the array elements over the given axis.\n",
      "\n",
      "        Refer to `prod` for full documentation.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        prod, ndarray.prod\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Same as `ndarray.prod`, except, where that returns an `ndarray`, this\n",
      "        returns a `matrix` object instead.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.prod()\n",
      "        0\n",
      "        >>> x.prod(0)\n",
      "        matrix([[  0,  45, 120, 231]])\n",
      "        >>> x.prod(1)\n",
      "        matrix([[   0],\n",
      "                [ 840],\n",
      "                [7920]])\n",
      "\n",
      "        \n",
      "code: matrix.ptp\n",
      "    def ptp(self, axis=None, out=None):\n",
      "        return N.ndarray.ptp(self, axis, out)._align(axis)\n",
      "docstring: matrix.ptp\n",
      "\n",
      "        Peak-to-peak (maximum - minimum) value along the given axis.\n",
      "\n",
      "        Refer to `numpy.ptp` for full documentation.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        numpy.ptp\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Same as `ndarray.ptp`, except, where that would return an `ndarray` object,\n",
      "        this returns a `matrix` object.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.ptp()\n",
      "        11\n",
      "        >>> x.ptp(0)\n",
      "        matrix([[8, 8, 8, 8]])\n",
      "        >>> x.ptp(1)\n",
      "        matrix([[3],\n",
      "                [3],\n",
      "                [3]])\n",
      "\n",
      "        \n",
      "code: matrix.ravel\n",
      "    def ravel(self, order='C'):\n",
      "        return N.ndarray.ravel(self, order=order)\n",
      "docstring: matrix.ravel\n",
      "\n",
      "        Return a flattened matrix.\n",
      "\n",
      "        Refer to `numpy.ravel` for more documentation.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        order : {'C', 'F', 'A', 'K'}, optional\n",
      "            The elements of `m` are read using this index order. 'C' means to\n",
      "            index the elements in C-like order, with the last axis index\n",
      "            changing fastest, back to the first axis index changing slowest.\n",
      "            'F' means to index the elements in Fortran-like index order, with\n",
      "            the first index changing fastest, and the last index changing\n",
      "            slowest. Note that the 'C' and 'F' options take no account of the\n",
      "            memory layout of the underlying array, and only refer to the order\n",
      "            of axis indexing.  'A' means to read the elements in Fortran-like\n",
      "            index order if `m` is Fortran *contiguous* in memory, C-like order\n",
      "            otherwise.  'K' means to read the elements in the order they occur\n",
      "            in memory, except for reversing the data when strides are negative.\n",
      "            By default, 'C' index order is used.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        ret : matrix\n",
      "            Return the matrix flattened to shape `(1, N)` where `N`\n",
      "            is the number of elements in the original matrix.\n",
      "            A copy is made only if necessary.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        matrix.flatten : returns a similar output matrix but always a copy\n",
      "        matrix.flat : a flat iterator on the array.\n",
      "        numpy.ravel : related function which returns an ndarray\n",
      "\n",
      "        \n",
      "code: matrix.squeeze\n",
      "    def squeeze(self, axis=None):\n",
      "        return N.ndarray.squeeze(self, axis=axis)\n",
      "docstring: matrix.squeeze\n",
      "\n",
      "        Return a possibly reshaped matrix.\n",
      "\n",
      "        Refer to `numpy.squeeze` for more documentation.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        axis : None or int or tuple of ints, optional\n",
      "            Selects a subset of the axes of length one in the shape.\n",
      "            If an axis is selected with shape entry greater than one,\n",
      "            an error is raised.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        squeezed : matrix\n",
      "            The matrix, but as a (1, N) matrix if it had shape (N, 1).\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        numpy.squeeze : related function\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        If `m` has a single column then that column is returned\n",
      "        as the single row of a matrix.  Otherwise `m` is returned.\n",
      "        The returned matrix is always either `m` itself or a view into `m`.\n",
      "        Supplying an axis keyword argument will not affect the returned matrix\n",
      "        but it may cause an error to be raised.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> c = np.matrix([[1], [2]])\n",
      "        >>> c\n",
      "        matrix([[1],\n",
      "                [2]])\n",
      "        >>> c.squeeze()\n",
      "        matrix([[1, 2]])\n",
      "        >>> r = c.T\n",
      "        >>> r\n",
      "        matrix([[1, 2]])\n",
      "        >>> r.squeeze()\n",
      "        matrix([[1, 2]])\n",
      "        >>> m = np.matrix([[1, 2], [3, 4]])\n",
      "        >>> m.squeeze()\n",
      "        matrix([[1, 2],\n",
      "                [3, 4]])\n",
      "\n",
      "        \n",
      "code: matrix.std\n",
      "    def std(self, axis=None, dtype=None, out=None, ddof=0):\n",
      "        return N.ndarray.std(self, axis, dtype, out, ddof, keepdims=True)._collapse(axis)\n",
      "docstring: matrix.std\n",
      "\n",
      "        Return the standard deviation of the array elements along the given axis.\n",
      "\n",
      "        Refer to `numpy.std` for full documentation.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        numpy.std\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This is the same as `ndarray.std`, except that where an `ndarray` would\n",
      "        be returned, a `matrix` object is returned instead.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3, 4)))\n",
      "        >>> x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.std()\n",
      "        3.4520525295346629 # may vary\n",
      "        >>> x.std(0)\n",
      "        matrix([[ 3.26598632,  3.26598632,  3.26598632,  3.26598632]]) # may vary\n",
      "        >>> x.std(1)\n",
      "        matrix([[ 1.11803399],\n",
      "                [ 1.11803399],\n",
      "                [ 1.11803399]])\n",
      "\n",
      "        \n",
      "code: matrix.sum\n",
      "    def sum(self, axis=None, dtype=None, out=None):\n",
      "        return N.ndarray.sum(self, axis, dtype, out, keepdims=True)._collapse(axis)\n",
      "docstring: matrix.sum\n",
      "\n",
      "        Returns the sum of the matrix elements, along the given axis.\n",
      "\n",
      "        Refer to `numpy.sum` for full documentation.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        numpy.sum\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This is the same as `ndarray.sum`, except that where an `ndarray` would\n",
      "        be returned, a `matrix` object is returned instead.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix([[1, 2], [4, 3]])\n",
      "        >>> x.sum()\n",
      "        10\n",
      "        >>> x.sum(axis=1)\n",
      "        matrix([[3],\n",
      "                [7]])\n",
      "        >>> x.sum(axis=1, dtype='float')\n",
      "        matrix([[3.],\n",
      "                [7.]])\n",
      "        >>> out = np.zeros((2, 1), dtype='float')\n",
      "        >>> x.sum(axis=1, dtype='float', out=np.asmatrix(out))\n",
      "        matrix([[3.],\n",
      "                [7.]])\n",
      "\n",
      "        \n",
      "code: matrix.tolist\n",
      "    def tolist(self):\n",
      "        return self.__array__().tolist()\n",
      "docstring: matrix.tolist\n",
      "\n",
      "        Return the matrix as a (possibly nested) list.\n",
      "\n",
      "        See `ndarray.tolist` for full documentation.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        ndarray.tolist\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3,4))); x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.tolist()\n",
      "        [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]\n",
      "\n",
      "        \n",
      "code: matrix.var\n",
      "    def var(self, axis=None, dtype=None, out=None, ddof=0):\n",
      "        return N.ndarray.var(self, axis, dtype, out, ddof, keepdims=True)._collapse(axis)\n",
      "docstring: matrix.var\n",
      "\n",
      "        Returns the variance of the matrix elements, along the given axis.\n",
      "\n",
      "        Refer to `numpy.var` for full documentation.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        numpy.var\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This is the same as `ndarray.var`, except that where an `ndarray` would\n",
      "        be returned, a `matrix` object is returned instead.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> x = np.matrix(np.arange(12).reshape((3, 4)))\n",
      "        >>> x\n",
      "        matrix([[ 0,  1,  2,  3],\n",
      "                [ 4,  5,  6,  7],\n",
      "                [ 8,  9, 10, 11]])\n",
      "        >>> x.var()\n",
      "        11.916666666666666\n",
      "        >>> x.var(0)\n",
      "        matrix([[ 10.66666667,  10.66666667,  10.66666667,  10.66666667]]) # may vary\n",
      "        >>> x.var(1)\n",
      "        matrix([[1.25],\n",
      "                [1.25],\n",
      "                [1.25]])\n",
      "\n",
      "        \n",
      "code: bmat\n",
      "@set_module('numpy')\n",
      "def bmat(obj, ldict=None, gdict=None):\n",
      "    if isinstance(obj, str):\n",
      "        if gdict is None:\n",
      " [[A,B],[C,D]]\n",
      "        arr_rows = []\n",
      "        for row in obj:\n",
      "            if isinstance(row, N.ndarray):  # not 2-d\n",
      "                return matrix(concatenate(obj, axis=-1))\n",
      "            else:\n",
      "                arr_rows.append(concatenate(row, axis=-1))\n",
      "        return matrix(concatenate(arr_rows, axis=0))\n",
      "    if isinstance(obj, N.ndarray):\n",
      "        return matrix(obj)\n",
      "docstring: bmat\n",
      "\n",
      "    Build a matrix object from a string, nested sequence, or array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    obj : str or array_like\n",
      "        Input data. If a string, variables in the current scope may be\n",
      "        referenced by name.\n",
      "    ldict : dict, optional\n",
      "        A dictionary that replaces local operands in current frame.\n",
      "        Ignored if `obj` is not a string or `gdict` is None.\n",
      "    gdict : dict, optional\n",
      "        A dictionary that replaces global operands in current frame.\n",
      "        Ignored if `obj` is not a string.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : matrix\n",
      "        Returns a matrix object, which is a specialized 2-D array.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    block :\n",
      "        A generalization of this function for N-d arrays, that returns normal\n",
      "        ndarrays.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> A = np.mat('1 1; 1 1')\n",
      "    >>> B = np.mat('2 2; 2 2')\n",
      "    >>> C = np.mat('3 4; 5 6')\n",
      "    >>> D = np.mat('7 8; 9 0')\n",
      "\n",
      "    All the following expressions construct the same block matrix:\n",
      "\n",
      "    >>> np.bmat([[A, B], [C, D]])\n",
      "    matrix([[1, 1, 2, 2],\n",
      "            [1, 1, 2, 2],\n",
      "            [3, 4, 7, 8],\n",
      "            [5, 6, 9, 0]])\n",
      "    >>> np.bmat(np.r_[np.c_[A, B], np.c_[C, D]])\n",
      "    matrix([[1, 1, 2, 2],\n",
      "            [1, 1, 2, 2],\n",
      "            [3, 4, 7, 8],\n",
      "            [5, 6, 9, 0]])\n",
      "    >>> np.bmat('A,B; C,D')\n",
      "    matrix([[1, 1, 2, 2],\n",
      "            [1, 1, 2, 2],\n",
      "            [3, 4, 7, 8],\n",
      "            [5, 6, 9, 0]])\n",
      "\n",
      "    \n",
      "code: mat\n",
      "@set_module('numpy')\n",
      "def asmatrix(data, dtype=None):\n",
      "    return matrix(data, dtype=dtype, copy=False)\n",
      "docstring: mat\n",
      "\n",
      "    Interpret the input as a matrix.\n",
      "\n",
      "    Unlike `matrix`, `asmatrix` does not make a copy if the input is already\n",
      "    a matrix or an ndarray.  Equivalent to ``matrix(data, copy=False)``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    data : array_like\n",
      "        Input data.\n",
      "    dtype : data-type\n",
      "       Data-type of the output matrix.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    mat : matrix\n",
      "        `data` interpreted as a matrix.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([[1, 2], [3, 4]])\n",
      "\n",
      "    >>> m = np.asmatrix(x)\n",
      "\n",
      "    >>> x[0,0] = 5\n",
      "\n",
      "    >>> m\n",
      "    matrix([[5, 2],\n",
      "            [3, 4]])\n",
      "\n",
      "    \n",
      "code: asmatrix\n",
      "@set_module('numpy')\n",
      "def asmatrix(data, dtype=None):\n",
      "    return matrix(data, dtype=dtype, copy=False)\n",
      "docstring: asmatrix\n",
      "\n",
      "    Interpret the input as a matrix.\n",
      "\n",
      "    Unlike `matrix`, `asmatrix` does not make a copy if the input is already\n",
      "    a matrix or an ndarray.  Equivalent to ``matrix(data, copy=False)``.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    data : array_like\n",
      "        Input data.\n",
      "    dtype : data-type\n",
      "       Data-type of the output matrix.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    mat : matrix\n",
      "        `data` interpreted as a matrix.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([[1, 2], [3, 4]])\n",
      "\n",
      "    >>> m = np.asmatrix(x)\n",
      "\n",
      "    >>> x[0,0] = 5\n",
      "\n",
      "    >>> m\n",
      "    matrix([[5, 2],\n",
      "            [3, 4]])\n",
      "\n",
      "    \n",
      "code: round\n",
      "@array_function_dispatch(_around_dispatcher)\n",
      "def round_(a, decimals=0, out=None):\n",
      "    return around(a, decimals=decimals, out=out)\n",
      "docstring: round\n",
      "\n",
      "    Round an array to the given number of decimals.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    around : equivalent function; see for details.\n",
      "    \n",
      "code: max\n",
      "@array_function_dispatch(_amax_dispatcher)\n",
      "def amax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n",
      "         where=np._NoValue):\n",
      "    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n",
      "                          keepdims=keepdims, initial=initial, where=where)\n",
      "docstring: max\n",
      "\n",
      "    Return the maximum of an array or maximum along an axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which to operate.  By default, flattened input is\n",
      "        used.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If this is a tuple of ints, the maximum is selected over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result.  Must\n",
      "        be of the same shape and buffer length as the expected output.\n",
      "        See :ref:`ufuncs-output-type` for more details.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `amax` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    initial : scalar, optional\n",
      "        The minimum value of an output element. Must be present to allow\n",
      "        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.15.0\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to compare for the maximum. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    amax : ndarray or scalar\n",
      "        Maximum of `a`. If `axis` is None, the result is a scalar value.\n",
      "        If `axis` is an int, the result is an array of dimension\n",
      "        ``a.ndim - 1``. If `axis` is a tuple, the result is an array of \n",
      "        dimension ``a.ndim - len(axis)``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    amin :\n",
      "        The minimum value of an array along a given axis, propagating any NaNs.\n",
      "    nanmax :\n",
      "        The maximum value of an array along a given axis, ignoring any NaNs.\n",
      "    maximum :\n",
      "        Element-wise maximum of two arrays, propagating any NaNs.\n",
      "    fmax :\n",
      "        Element-wise maximum of two arrays, ignoring any NaNs.\n",
      "    argmax :\n",
      "        Return the indices of the maximum values.\n",
      "\n",
      "    nanmin, minimum, fmin\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NaN values are propagated, that is if at least one item is NaN, the\n",
      "    corresponding max value will be NaN as well. To ignore NaN values\n",
      "    (MATLAB behavior), please use nanmax.\n",
      "\n",
      "    Don't use `amax` for element-wise comparison of 2 arrays; when\n",
      "    ``a.shape[0]`` is 2, ``maximum(a[0], a[1])`` is faster than\n",
      "    ``amax(a, axis=0)``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(4).reshape((2,2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3]])\n",
      "    >>> np.amax(a)           # Maximum of the flattened array\n",
      "    3\n",
      "    >>> np.amax(a, axis=0)   # Maxima along the first axis\n",
      "    array([2, 3])\n",
      "    >>> np.amax(a, axis=1)   # Maxima along the second axis\n",
      "    array([1, 3])\n",
      "    >>> np.amax(a, where=[False, True], initial=-1, axis=0)\n",
      "    array([-1,  3])\n",
      "    >>> b = np.arange(5, dtype=float)\n",
      "    >>> b[2] = np.NaN\n",
      "    >>> np.amax(b)\n",
      "    nan\n",
      "    >>> np.amax(b, where=~np.isnan(b), initial=-1)\n",
      "    4.0\n",
      "    >>> np.nanmax(b)\n",
      "    4.0\n",
      "\n",
      "    You can use an initial value to compute the maximum of an empty slice, or\n",
      "    to initialize it to a different value:\n",
      "\n",
      "    >>> np.amax([[-50], [10]], axis=-1, initial=0)\n",
      "    array([ 0, 10])\n",
      "\n",
      "    Notice that the initial value is used as one of the elements for which the\n",
      "    maximum is determined, unlike for the default argument Python's max\n",
      "    function, which is only used for empty iterables.\n",
      "\n",
      "    >>> np.amax([5], initial=6)\n",
      "    6\n",
      "    >>> max([5], default=6)\n",
      "    5\n",
      "    \n",
      "code: min\n",
      "@array_function_dispatch(_amin_dispatcher)\n",
      "def amin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n",
      "         where=np._NoValue):\n",
      "    return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n",
      "                          keepdims=keepdims, initial=initial, where=where)\n",
      "docstring: min\n",
      "\n",
      "    Return the minimum of an array or minimum along an axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which to operate.  By default, flattened input is\n",
      "        used.\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        If this is a tuple of ints, the minimum is selected over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result.  Must\n",
      "        be of the same shape and buffer length as the expected output.\n",
      "        See :ref:`ufuncs-output-type` for more details.\n",
      "\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "\n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `amin` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "\n",
      "    initial : scalar, optional\n",
      "        The maximum value of an output element. Must be present to allow\n",
      "        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n",
      "\n",
      "        .. versionadded:: 1.15.0\n",
      "\n",
      "    where : array_like of bool, optional\n",
      "        Elements to compare for the minimum. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "\n",
      "        .. versionadded:: 1.17.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    amin : ndarray or scalar\n",
      "        Minimum of `a`. If `axis` is None, the result is a scalar value.\n",
      "        If `axis` is an int, the result is an array of dimension\n",
      "        ``a.ndim - 1``.  If `axis` is a tuple, the result is an array of \n",
      "        dimension ``a.ndim - len(axis)``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    amax :\n",
      "        The maximum value of an array along a given axis, propagating any NaNs.\n",
      "    nanmin :\n",
      "        The minimum value of an array along a given axis, ignoring any NaNs.\n",
      "    minimum :\n",
      "        Element-wise minimum of two arrays, propagating any NaNs.\n",
      "    fmin :\n",
      "        Element-wise minimum of two arrays, ignoring any NaNs.\n",
      "    argmin :\n",
      "        Return the indices of the minimum values.\n",
      "\n",
      "    nanmax, maximum, fmax\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NaN values are propagated, that is if at least one item is NaN, the\n",
      "    corresponding min value will be NaN as well. To ignore NaN values\n",
      "    (MATLAB behavior), please use nanmin.\n",
      "\n",
      "    Don't use `amin` for element-wise comparison of 2 arrays; when\n",
      "    ``a.shape[0]`` is 2, ``minimum(a[0], a[1])`` is faster than\n",
      "    ``amin(a, axis=0)``.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(4).reshape((2,2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3]])\n",
      "    >>> np.amin(a)           # Minimum of the flattened array\n",
      "    0\n",
      "    >>> np.amin(a, axis=0)   # Minima along the first axis\n",
      "    array([0, 1])\n",
      "    >>> np.amin(a, axis=1)   # Minima along the second axis\n",
      "    array([0, 2])\n",
      "    >>> np.amin(a, where=[False, True], initial=10, axis=0)\n",
      "    array([10,  1])\n",
      "\n",
      "    >>> b = np.arange(5, dtype=float)\n",
      "    >>> b[2] = np.NaN\n",
      "    >>> np.amin(b)\n",
      "    nan\n",
      "    >>> np.amin(b, where=~np.isnan(b), initial=10)\n",
      "    0.0\n",
      "    >>> np.nanmin(b)\n",
      "    0.0\n",
      "\n",
      "    >>> np.amin([[-50], [10]], axis=-1, initial=0)\n",
      "    array([-50,   0])\n",
      "\n",
      "    Notice that the initial value is used as one of the elements for which the\n",
      "    minimum is determined, unlike for the default argument Python's max\n",
      "    function, which is only used for empty iterables.\n",
      "\n",
      "    Notice that this isn't the same as Python's ``default`` argument.\n",
      "\n",
      "    >>> np.amin([6], initial=5)\n",
      "    5\n",
      "    >>> min([6], default=5)\n",
      "    6\n",
      "    \n",
      "code: test\n",
      "\n",
      "docstring: test\n",
      "\n",
      "    Pytest test runner.\n",
      "\n",
      "    A test function is typically added to a package's __init__.py like so::\n",
      "\n",
      "      from numpy._pytesttester import PytestTester\n",
      "      test = PytestTester(__name__).test\n",
      "      del PytestTester\n",
      "\n",
      "    Calling this test function finds and runs all tests associated with the\n",
      "    module and all its sub-modules.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    module_name : str\n",
      "        Full path to the package to test.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    module_name : module name\n",
      "        The name of the module to test.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Unlike the previous ``nose``-based implementation, this class is not\n",
      "    publicly exposed as it performs some ``numpy``-specific warning\n",
      "    suppression.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "extractor = DocstringExtractor(\"numpy\")\n",
    "docstrings = extractor.extract_docstrings()\n",
    "i=0\n",
    "max_i=3\n",
    "for k in docstrings.keys():\n",
    "    # for each write Original, Code, Docstring with the name of the module\n",
    "    # print(\"original:\",k)\n",
    "    # print(docstrings[k][0])\n",
    "    print(\"code:\",k)\n",
    "    print(docstrings[k][1])\n",
    "    print(\"docstring:\",k)\n",
    "    print(docstrings[k][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: test\n",
      "def test():\n",
      "    \"\"\"my test lol\n",
      "    one two three\"\"\"\n",
      "    return \"test\"\n",
      "\n",
      "code: test\n",
      "def test():\n",
      "    return \"test\"\n",
      "docstring: test\n",
      "my test lol\n",
      "    one two three\n",
      "original: two\n",
      "def two():\n",
      "    \"\"\" Returns 2 \"\"\"\n",
      "    return 2\n",
      "\n",
      "code: two\n",
      "def two():\n",
      "    return 2\n",
      "docstring: two\n",
      " Returns 2 \n",
      "original: test2\n",
      "def test2():\n",
      "    \"\"\"\n",
      "    Test one tow\n",
      "    \"\"\"\n",
      "    return None\n",
      "\n",
      "code: test2\n",
      "def test2():\n",
      "    return None\n",
      "docstring: test2\n",
      "\n",
      "    Test one tow\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import test_fishing007\n",
    "extractor = DocstringExtractor(\"test_fishing007\")\n",
    "docstrings = extractor.extract_docstrings()\n",
    "for k in docstrings.keys():\n",
    "    # for each write Original, Code, Docstring with the name of the module\n",
    "    print(\"original:\",k)\n",
    "    print(docstrings[k][0])\n",
    "    print(\"code:\",k)\n",
    "    print(docstrings[k][1])\n",
    "    print(\"docstring:\",k)\n",
    "    print(docstrings[k][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def two():\\n    \"\"\" Returns 2 \"\"\"\\n    return 2\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_key = 'two'\n",
    "#Complete method\n",
    "docstrings['target_key'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test():\n",
      "    return \"test\"\n"
     ]
    }
   ],
   "source": [
    "#only source code\n",
    "\n",
    "print (docstrings['target_key'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my test lol\n",
      "    one two three\n"
     ]
    }
   ],
   "source": [
    "#only docstrings for functions\n",
    "\n",
    "print (docstrings['test'][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ceba285e8b4e6478fe8ad229bc63940a90ad5cf3d143521e7c38823a2e915b21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
